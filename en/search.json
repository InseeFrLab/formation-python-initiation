[
  {
    "objectID": "source/manipulation/pandas/tutorial.html",
    "href": "source/manipulation/pandas/tutorial.html",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "title: “Working with tabular data using Pandas”\nStatistical analysis is generally based on tabular data, where each row represents an observation and each column a variable. To handle this type of data and easily apply standard data analysis methods, dedicated objects have been designed: DataFrames. Users of R are well acquainted with this data structure, which is native to this statistics-oriented language. In Python, a general-purpose language, this object does not exist natively. Fortunately, a very comprehensive and convenient library, designed as an overlay to NumPy, introduces the DataFrame object in Python and allows for simple and intuitive data manipulation and analysis: Pandas.\nLet’s start by importing the Pandas library. The common usage is to give it the alias pd to simplify future calls to the package’s objects and functions. We also import NumPy as we will compare the fundamental objects of the two packages.\nimport pandas as pd\nimport numpy as np",
    "crumbs": [
      "Data handling",
      "Processing tabular data with Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#data-structures",
    "href": "source/manipulation/pandas/tutorial.html#data-structures",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "Data structures",
    "text": "Data structures\nTo fully understand how Pandas works, it is important to focus on its fundamental objects. We will therefore first study the Series, whose concatenation allows us to build a DataFrame.\n\nThe Series\nA Series is a one-dimensional data container that can hold any type of data (integers, strings, Python objects…). However, a Series is of a given type: a Series containing only integers will be of type int, and a Series containing objects of different natures will be of type object. Let’s build our first Series from a list to check this behavior.\n\nl = [1, \"X\", 3]\ns = pd.Series(l)\nprint(s)\n\n0    1\n1    X\n2    3\ndtype: object\n\n\nIn particular, we can access the data of a Series by position, as for a list or an array.\n\nprint(s[1])\n\nX\n\n\nAt first glance, we do not see much difference between a Series and a one-dimensional NumPy array. However, there is a significant difference: the presence of an index. The observations have an associated label. When we create a Series without specifying anything, the index is automatically set to the integers from 0 to n-1 (with n being the number of elements in the Series). But it is possible to pass a specific index (e.g., dates, town names, etc.).\n\ns = pd.Series(l, index=[\"a\", \"b\", \"c\"])\nprint(s)\n\na    1\nb    X\nc    3\ndtype: object\n\n\nThis allows us to access the data by label:\n\ns[\"b\"]\n\n'X'\n\n\nThis difference may seem minor at first, but it becomes essential for constructing the DataFrame. For the rest, Series behave very similarly to NumPy arrays: calculations are vectorized, we can directly sum two Series, etc. Moreover, we can easily convert a Series into an array via the values attribute. This naturally loses the index…\n\ns = pd.Series(l, index=[\"a\", \"b\", \"c\"])\ns.values\n\narray([1, 'X', 3], dtype=object)\n\n\n\n\nThe DataFrame\nFundamentally, a DataFrame consists of a collection of Series, aligned by their indexes. This concatenation thus constructs a data table, with Series corresponding to columns, and the index identifying the rows. The following figure (source) helps to understand this data structure.\n\n\n\n\n\nA DataFrame can be constructed in multiple ways. In practice, we generally build a DataFrame directly from tabular data files (e.g., CSV, Excel), rarely by hand. So, we will only illustrate the most common manual construction method: from a data dictionary.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\n0\n1.3\n-8\ntest\n2022-01-01\nsample1\n\n\n1\n5.6\n7\ntrain\n2022-01-02\nsample1\n\n\n2\nNaN\n-3\ntest\n2022-01-03\nsample1\n\n\n3\nNaN\n8\ntrain\n2022-01-04\nsample1\n\n\n4\n0.0\n-10\ntrain\n2022-01-05\nsample1\n\n\n5\nNaN\n-1\nvalidation\n2022-01-06\nsample1\n\n\n\n\n\n\n\nA Pandas DataFrame has a set of useful attributes that we will discover throughout this tutorial. For now, let’s focus on the most basic ones: the index and the column names. By default, the index is initialized, as for Series, to the list of positions of the observations. We could have specified an alternative index when constructing the DataFrame by specifying the index argument of the pd.DataFrame function.\n\ndf.index\n\nRangeIndex(start=0, stop=6, step=1)\n\n\n\ndf.columns\n\nIndex(['var1', 'var2', 'experiment', 'date', 'sample'], dtype='object')\n\n\nOften, rather than specifying an index manually during the construction of the DataFrame, we will want to use a certain column of the DataFrame as an index. We use the set_index method associated with DataFrames for this.\n\ndf = df.set_index(\"date\")\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-8\ntest\nsample1\n\n\n2022-01-02\n5.6\n7\ntrain\nsample1\n\n\n2022-01-03\nNaN\n-3\ntest\nsample1\n\n\n2022-01-04\nNaN\n8\ntrain\nsample1\n\n\n2022-01-05\n0.0\n-10\ntrain\nsample1\n\n\n2022-01-06\nNaN\n-1\nvalidation\nsample1\n\n\n\n\n\n\n\nThe index attribute has naturally changed:\n\ndf.index\n\nIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05',\n       '2022-01-06'],\n      dtype='object', name='date')",
    "crumbs": [
      "Data handling",
      "Processing tabular data with Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#selecting-data",
    "href": "source/manipulation/pandas/tutorial.html#selecting-data",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "Selecting data",
    "text": "Selecting data\nWhen manipulating tabular data, it is common to want to extract specific columns from a DataFrame. This extraction is simple with Pandas using square brackets.\n\nSelecting columns\n\nSelecting a single column\nTo extract a single column, we can use the following syntax:\n\nselected_column = df[\"var1\"]\nselected_column\n\ndate\n2022-01-01    1.3\n2022-01-02    5.6\n2022-01-03    NaN\n2022-01-04    NaN\n2022-01-05    0.0\n2022-01-06    NaN\nName: var1, dtype: float64\n\n\nThe selected_column object here returns the column named var1 from the DataFrame df. But what type is this object? To answer this question, we use the type() function:\n\ntype(selected_column)\n\npandas.core.series.Series\n\n\nAs we can see, the result is a Series, which is a one-dimensional object in Pandas.\nAnother useful attribute to know is shape. It allows us to know the dimension of the object. For a Series, shape will return a tuple whose first element indicates the number of rows.\n\nselected_column.shape\n\n(6,)\n\n\n\n\nSelecting multiple columns\nTo extract multiple columns, just pass a list of the desired column names:\n\nselected_columns = df[[\"var1\", \"var2\", \"experiment\"]]\nselected_columns\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\n\n\ndate\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-8\ntest\n\n\n2022-01-02\n5.6\n7\ntrain\n\n\n2022-01-03\nNaN\n-3\ntest\n\n\n2022-01-04\nNaN\n8\ntrain\n\n\n2022-01-05\n0.0\n-10\ntrain\n\n\n2022-01-06\nNaN\n-1\nvalidation\n\n\n\n\n\n\n\nThis snippet shows the columns var1, var2, and experiment from the DataFrame df. Let’s now check its type:\n\ntype(selected_columns)\n\npandas.core.frame.DataFrame\n\n\nThe result is a DataFrame because it is a two-dimensional object. We can also check its shape with the shape attribute. In this case, the tuple returned by shape will contain two elements: the number of rows and the number of columns.\n\nselected_columns.shape\n\n(6, 3)\n\n\n\n\n\nSelecting rows\n\nUsing loc and iloc\nWhen we want to select specific rows in a DataFrame, we can use two main methods: loc and iloc.\n\niloc allows selecting rows and columns by their position, i.e., by numeric indices.\n\nExample, selecting the first 3 rows:\n\ndf.iloc[0:3, :]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-8\ntest\nsample1\n\n\n2022-01-02\n5.6\n7\ntrain\nsample1\n\n\n2022-01-03\nNaN\n-3\ntest\nsample1\n\n\n\n\n\n\n\n\nloc works with labels. If the DataFrame’s indexes are numbers, they resemble positions, but this is not necessarily the case. It is crucial to note that, unlike iloc, with loc, the end index is included in the selection.\n\n\ndf.loc[\"2022-01-01\":\"2022-01-03\", :]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-8\ntest\nsample1\n\n\n2022-01-02\n5.6\n7\ntrain\nsample1\n\n\n2022-01-03\nNaN\n-3\ntest\nsample1\n\n\n\n\n\n\n\n\n\nFiltering data based on conditions\nIn practice, rather than selecting rows based on positions or labels, we often want to filter a DataFrame based on certain conditions. In this case, we primarily use boolean filters.\n\nInequalities: We might want to keep only the rows that meet a certain condition.\n\nExample, filtering rows where the value of the var2 column is greater than 0:\n\ndf[df['var2'] &gt;= 0]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n7\ntrain\nsample1\n\n\n2022-01-04\nNaN\n8\ntrain\nsample1\n\n\n\n\n\n\n\n\nMembership with isin: If we want to filter data based on a list of possible values, the isin method is very useful.\n\nExample, to keep only the rows where the experiment column has values ‘test’ or ‘validation’:\n\ndf[df['experiment'].isin(['train', 'validation'])]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n7\ntrain\nsample1\n\n\n2022-01-04\nNaN\n8\ntrain\nsample1\n\n\n2022-01-05\n0.0\n-10\ntrain\nsample1\n\n\n2022-01-06\nNaN\n-1\nvalidation\nsample1\n\n\n\n\n\n\n\nThese methods can be combined to create more complex conditions. It is also possible to use logical operators (& for “and”, | for “or”) to combine multiple conditions. Be careful to enclose each condition in parentheses when combining them.\nExample, selecting rows where var2 is greater than 0 and experiment is equal to ‘test’ or ‘validation’:\n\ndf[(df['var2'] &gt;= 0) & (df['experiment'].isin(['train', 'validation']))]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n7\ntrain\nsample1\n\n\n2022-01-04\nNaN\n8\ntrain\nsample1",
    "crumbs": [
      "Data handling",
      "Processing tabular data with Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#exploring-tabular-data",
    "href": "source/manipulation/pandas/tutorial.html#exploring-tabular-data",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "Exploring tabular data",
    "text": "Exploring tabular data\nIn public statistics, the starting point is generally not the manual generation of data but rather pre-existing tab\nular files. These files, whether from surveys, administrative databases, or other sources, constitute the raw material for any subsequent analysis. Pandas offers powerful tools to import these tabular files and explore them for further manipulations.\n\nImporting and exporting data\n\nImporting a CSV file\nAs we saw in a previous lab, the CSV format is one of the most common formats for storing tabular data. We previously used the csv library to handle them as text files, but it was not very convenient. To recall, the syntax for reading a CSV file and displaying the first lines was as follows:\n\nimport csv\n\nrows = []\n\nwith open(\"data/departement2021.csv\") as file_in:\n    csv_reader = csv.reader(file_in)\n    for row in csv_reader:\n        rows.append(row)\n\nrows[:5]\n\n[['DEP', 'REG', 'CHEFLIEU', 'TNCC', 'NCC', 'NCCENR', 'LIBELLE'],\n ['01', '84', '01053', '5', 'AIN', 'Ain', 'Ain'],\n ['02', '32', '02408', '5', 'AISNE', 'Aisne', 'Aisne'],\n ['03', '84', '03190', '5', 'ALLIER', 'Allier', 'Allier'],\n ['04',\n  '93',\n  '04070',\n  '4',\n  'ALPES DE HAUTE PROVENCE',\n  'Alpes-de-Haute-Provence',\n  'Alpes-de-Haute-Provence']]\n\n\nWith Pandas, just use the read_csv() function to import the file as a DataFrame, then the head() function.\n\ndf_departements = pd.read_csv('data/departement2021.csv')\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\nIt is also possible to import a CSV file directly from a URL. This is particularly convenient when the data is regularly updated on a website, and we want to access the latest version without manually downloading the file each time. Let’s take the example of a CSV file available on the INSEE website: the file of given names, from civil status data. We also note another handy feature: the CSV file is compressed (in zip format), but Pandas can recognize and decompress it before importing.\n\n# Importing a CSV file from a URL\nurl = \"https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\"\ndf_prenoms_url = pd.read_csv(url, sep=\";\")\ndf_prenoms_url.head()\n\n\n\n\n\n\n\n\nsexe\npreusuel\nannais\nnombre\n\n\n\n\n0\n1\n_PRENOMS_RARES\n1900\n1249\n\n\n1\n1\n_PRENOMS_RARES\n1901\n1342\n\n\n2\n1\n_PRENOMS_RARES\n1902\n1330\n\n\n3\n1\n_PRENOMS_RARES\n1903\n1286\n\n\n4\n1\n_PRENOMS_RARES\n1904\n1430\n\n\n\n\n\n\n\nWhen working with CSV files, there are many optional arguments available in the read_csv() function that allow us to adjust the import process according to the specifics of the file. These arguments can, for example, define a specific delimiter (as above for the given names file), skip certain lines at the beginning of the file, or define data types for each column, and many others. All these parameters and their usage are detailed in the official documentation.\n\n\nExporting to CSV format\nOnce the data has been processed and modified within Pandas, it is common to want to export the result as a CSV file for sharing, archiving, or use in other tools. Pandas offers a simple method for this operation: to_csv(). Suppose we want to export the data from the df_departements DataFrame specific to the five overseas departments.\n\ndf_departements_dom = df_departements[df_departements[\"DEP\"].isin([\"971\", \"972\", \"973\", \"974\", \"975\"])]\ndf_departements_dom.to_csv('output/departements2021_dom.csv')\n\nOne of the key arguments of the to_csv() method is index. By default, index=True, which means that the DataFrame’s index will also be written in the CSV file. We can verify this by printing the first lines of our CSV file: Pandas has added an unnamed column, which contains the index of the retained rows.\n\nwith open(\"output/departements2021_dom.csv\") as file_in:\n    for i in range(5):\n        row = next(file_in).strip()\n        print(row)\n\n,DEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n96,971,1,97105,3,GUADELOUPE,Guadeloupe,Guadeloupe\n97,972,2,97209,3,MARTINIQUE,Martinique,Martinique\n98,973,3,97302,3,GUYANE,Guyane,Guyane\n99,974,4,97411,0,LA REUNION,La Réunion,La Réunion\n\n\nIn some cases, notably when the index does not provide useful information or is simply automatically generated by Pandas, we might want to exclude it from the exported file. To do this, we can set index=False.\n\ndf_departements_dom.to_csv('output/departements2021_dom_noindex.csv', index=False)\n\n\n\nImporting a Parquet file\nThe Parquet format is another format for storing tabular data, increasingly used. Without going into technical details, the Parquet format has various characteristics that make it a preferred choice for storing and processing large volumes of data. Due to these advantages, this format is increasingly used for data dissemination at INSEE. It is therefore essential to know how to import and query Parquet files with Pandas.\nImporting a Parquet file into a Pandas DataFrame is as easy as for a CSV file. The function is called read_parquet().\n\ndf_departements = pd.read_parquet('data/departement2021.parquet')\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\n\nExporting to Parquet format\nAgain, everything works as in the CSV world: we use the to_parquet() method to export a DataFrame to a Parquet file. Similarly, we can choose to export or not the index, using the index parameter (which defaults to True).\n\ndf_departements_dom = df_departements[df_departements[\"DEP\"].isin([\"971\", \"972\", \"973\", \"974\", \"975\"])]\ndf_departements_dom.to_parquet('output/departements2021_dom.parquet', index=False)\n\nOne of the major strengths of the Parquet format, compared to text formats like CSV, is its ability to store metadata, i.e., data that helps better understand the data contained in the file. In particular, a Parquet file includes in its metadata the data schema (variable names, variable types, etc.), making it a very suitable format for data dissemination. Let’s verify this behavior by revisiting the DataFrame we defined earlier.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf = df.assign(\n    experiment=pd.Categorical(df[\"experiment\"]),\n    date=pd.to_datetime(df[\"date\"])\n)\n\nThis time, we use two specific data types, for categorical data (category) and for temporal data (datetime). We will see later in the tutorial how to use these types. For now, let’s simply note that Pandas stores these types in the data schema.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nLet’s now verify that exporting and re-importing this data in Parquet preserves the schema.\n\ndf.to_parquet(\"output/df_test_schema.parquet\", index=False)\ndf_test_schema_parquet = pd.read_parquet('output/df_test_schema.parquet')\n\ndf_test_schema_parquet.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nConversely, a CSV file, which by definition only contains text, does not preserve this data. The variables for which we specified the type are imported as strings (type object in Pandas).\n\ndf.to_csv(\"output/df_test_schema.csv\", index=False)\ndf_test_schema_csv = pd.read_csv('output/df_test_schema.csv')\n\ndf_test_schema_csv.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   var1        3 non-null      float64\n 1   var2        6 non-null      int64  \n 2   experiment  6 non-null      object \n 3   date        6 non-null      object \n 4   sample      6 non-null      object \ndtypes: float64(1), int64(1), object(3)\nmemory usage: 368.0+ bytes\n\n\n\n\n\nViewing a sample of data\nWhen working with large datasets, it is often useful to quickly view a sample of the data to get an idea of its structure, format, or even to detect potential problems. Pandas offers several methods for this.\nThe head() method displays the first rows of the DataFrame. By default, it returns the first 5 rows, but we can specify another number as an argument if necessary.\n\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\ndf_departements.head(10)\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n5\n06\n93\n06088\n4\nALPES MARITIMES\nAlpes-Maritimes\nAlpes-Maritimes\n\n\n6\n07\n84\n07186\n5\nARDECHE\nArdèche\nArdèche\n\n\n7\n08\n44\n08105\n4\nARDENNES\nArdennes\nArdennes\n\n\n8\n09\n76\n09122\n5\nARIEGE\nAriège\nAriège\n\n\n9\n10\n44\n10387\n5\nAUBE\nAube\nAube\n\n\n\n\n\n\n\nConversely, the tail() method gives a preview of the last rows of the DataFrame.\n\ndf_departements.tail()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n96\n971\n1\n97105\n3\nGUADELOUPE\nGuadeloupe\nGuadeloupe\n\n\n97\n972\n2\n97209\n3\nMARTINIQUE\nMartinique\nMartinique\n\n\n98\n973\n3\n97302\n3\nGUYANE\nGuyane\nGuyane\n\n\n99\n974\n4\n97411\n0\nLA REUNION\nLa Réunion\nLa Réunion\n\n\n100\n976\n6\n97608\n0\nMAYOTTE\nMayotte\nMayotte\n\n\n\n\n\n\n\nDisplaying the first or last rows may sometimes not be representative of the entire dataset, especially when the data is sorted. To minimize the risk of obtaining a biased overview of the data, we can use the sample() method, which selects a random sample of rows. By default, it returns a single row, but we can request a specific number of rows using the n argument.\n\ndf_departements.sample(n=5)\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n56\n56\n53\n56260\n2\nMORBIHAN\nMorbihan\nMorbihan\n\n\n70\n70\n27\n70550\n3\nHAUTE SAONE\nHaute-Saône\nHaute-Saône\n\n\n45\n45\n24\n45234\n2\nLOIRET\nLoiret\nLoiret\n\n\n92\n92\n11\n92050\n4\nHAUTS DE SEINE\nHauts-de-Seine\nHauts-de-Seine\n\n\n31\n31\n76\n31555\n3\nHAUTE GARONNE\nHaute-Garonne\nHaute-Garonne\n\n\n\n\n\n\n\n\n\nGetting an overview of the data\nOne of the first steps when exploring new data is to understand the general structure of the dataset. The info() method in Pandas provides a quick overview of the data, including data types, the presence of missing values, and memory usage.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nSeveral key pieces of information can be extracted from this result:\n\nindex: The DataFrame has a RangeIndex, which means the index is a simple numeric sequence. Here, the index ranges from 0 to 5, for a total of 6 entries.\nschema: The list of columns is displayed with very useful information about the data schema:\n\nNon-Null Count: The number of non-missing (non-nan) values in the column. If this number is less than the total number of entries (in our case, 6), it means the column contains missing values. Note the possible ambiguity on “null”: this indeed means missing values, not values equal to 0. Thus, in our case, the number of “non-null” values for the var1 variable is 5.\nDtype: The data type of the column, which helps understand the nature of the information stored in each column. For example, float64\n\n\n(real numbers), int32 (integers), category (categorical variable), datetime64[ns] (temporal information), and object (text or mixed data).\nUsing info() is a quick and effective way to get an overview of a DataFrame, quickly identify columns containing missing values, and understand the data structure.\n\n\nCalculating descriptive statistics\nIn addition to the information returned by the info() method, we might want to obtain simple descriptive statistics to quickly visualize the distributions of variables. The describe() method provides a synthetic view of the distribution of data in each column.\n\ndf.describe()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\ncount\n3.00000\n6.00000\n6\n\n\nmean\n2.30000\n3.00000\n2022-01-03 12:00:00\n\n\nmin\n0.00000\n-5.00000\n2022-01-01 00:00:00\n\n\n25%\n0.65000\n2.00000\n2022-01-02 06:00:00\n\n\n50%\n1.30000\n3.00000\n2022-01-03 12:00:00\n\n\n75%\n3.45000\n6.25000\n2022-01-04 18:00:00\n\n\nmax\n5.60000\n8.00000\n2022-01-06 00:00:00\n\n\nstd\n2.93087\n4.64758\nNaN\n\n\n\n\n\n\n\nIt should be noted that describe() only returns statistics for numeric columns by default. If we want to include columns of other types, we need to specify this via the include argument. For example, df.describe(include='all') will return statistics for all columns, including metrics such as the unique count, the most frequent value, and the frequency of the most frequent value for non-numeric columns.\n\ndf.describe(include='all')\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\ncount\n3.00000\n6.00000\n6\n6\n6\n\n\nunique\nNaN\nNaN\n3\nNaN\n1\n\n\ntop\nNaN\nNaN\ntrain\nNaN\nsample1\n\n\nfreq\nNaN\nNaN\n3\nNaN\n6\n\n\nmean\n2.30000\n3.00000\nNaN\n2022-01-03 12:00:00\nNaN\n\n\nmin\n0.00000\n-5.00000\nNaN\n2022-01-01 00:00:00\nNaN\n\n\n25%\n0.65000\n2.00000\nNaN\n2022-01-02 06:00:00\nNaN\n\n\n50%\n1.30000\n3.00000\nNaN\n2022-01-03 12:00:00\nNaN\n\n\n75%\n3.45000\n6.25000\nNaN\n2022-01-04 18:00:00\nNaN\n\n\nmax\n5.60000\n8.00000\nNaN\n2022-01-06 00:00:00\nNaN\n\n\nstd\n2.93087\n4.64758\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nNote again that the count variable returns the number of non-missing values in each variable.",
    "crumbs": [
      "Data handling",
      "Processing tabular data with Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#main-data-manipulations",
    "href": "source/manipulation/pandas/tutorial.html#main-data-manipulations",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "Main data manipulations",
    "text": "Main data manipulations\n\nTransforming data\nData transformation operations are essential for shaping, cleaning, and preparing data for analysis. Transformations can apply to the entire DataFrame, specific columns, or specific rows.\n\nTransforming a DataFrame\nTo transform an entire DataFrame (or a sub-DataFrame), it is possible to use vectorized functions, which allow quickly applying an operation to all elements of the DataFrame. This includes a number of methods available for Series, as well as NumPy mathematical functions, etc.\nFor example, raising each numeric value in a DataFrame to the power of 2:\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n    }\n)\n\ndf ** 2\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.69\n16\n\n\n1\n31.36\n49\n\n\n2\nNaN\n4\n\n\n3\nNaN\n64\n\n\n4\n0.00\n49\n\n\n5\nNaN\n16\n\n\n\n\n\n\n\nor taking the absolute value:\n\nnp.abs(df)\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.3\n4\n\n\n1\n5.6\n7\n\n\n2\nNaN\n2\n\n\n3\nNaN\n8\n\n\n4\n0.0\n7\n\n\n5\nNaN\n4\n\n\n\n\n\n\n\nSome methods available for Series can also be used to transform an entire DataFrame. For example, the very useful replace() method, which allows replacing all occurrences of a given value with another value. For example, suppose the value 0 in the var1 column actually indicates a measurement error. It would be preferable to replace it with a missing value.\n\ndf.replace(0, np.nan)\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.3\n-4\n\n\n1\n5.6\n-7\n\n\n2\nNaN\n-2\n\n\n3\nNaN\n8\n\n\n4\nNaN\n7\n\n\n5\nNaN\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignment or in-place methods?\n\n\n\nIn the previous example, applying the replace() method does not directly modify the DataFrame. To make the modification persistent, one possibility is to assign the result to an object:\n\ndf = df.replace(0, np.nan)\n\nA second possibility is, when methods offer it, to use the inplace argument. When inplace=True, the operation is performed “in place”, and the DataFrame is therefore directly modified.\n\ndf.replace(0, np.nan, inplace=True)\n\nIn practice, it is better to limit inplace operations. They do not favor the reproducibility of analyses, as the re-execution of the same cell will give different results each time.\n\n\n\n\nTransforming columns\nIn some cases, we will not want to apply transformations to the entire data but to specific variables. Transformations possible at the DataFrame level (vectorized functions, methods like replace(), etc.) naturally remain possible at the column level.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n    }\n)\n\nnp.abs(df[\"var2\"])\n\n0    2\n1    4\n2    3\n3    7\n4    1\n5    8\nName: var2, dtype: int64\n\n\n\ndf[\"var1\"].replace(0, np.nan)\n\n0    1.3\n1    5.6\n2    NaN\n3    NaN\n4    NaN\n5    NaN\nName: var1, dtype: float64\n\n\nBut there are other transformations that are generally applied at the level of one or a few columns. For example, when the schema has not been properly recognized upon import, it may happen that numeric variables are defined as strings (type object in Pandas).\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan],\n        \"var2\": [\"1\", \"5\", \"18\"],\n    }\n)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   var1    2 non-null      float64\n 1   var2    3 non-null      object \ndtypes: float64(1), object(1)\nmemory usage: 176.0+ bytes\n\n\nIn this case, we can use the astype method to convert the column to the desired type.\n\ndf['var2'] = df['var2'].astype(int)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   var1    2 non-null      float64\n 1   var2    3 non-null      int64  \ndtypes: float64(1), int64(1)\nmemory usage: 176.0 bytes\n\n\nAnother frequent operation is renaming one or more columns. To do this, we can use the rename() method, passing a dictionary containing as many key-value pairs as variables to be renamed, where each key-value pair is of the form 'old_name': 'new_name'.\n\ndf.rename(columns={'var2': 'age'})\n\n\n\n\n\n\n\n\nvar1\nage\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n5\n\n\n2\nNaN\n18\n\n\n\n\n\n\n\nFinally, we might want to remove columns from the DataFrame that are not or no longer useful for analysis. For this, we use the drop() method, to which we pass either a string (name of a column if we want to remove only one) or a list of column names to remove.\n\ndf.drop(columns=['var1'])\n\n\n\n\n\n\n\n\nvar2\n\n\n\n\n0\n1\n\n\n1\n5\n\n\n2\n18\n\n\n\n\n\n\n\n\n\nTransforming rows\nIn statistics, we generally apply transformations involving one or more columns. However, in some cases, it is necessary to apply transformations at the row level. For this, we can use the apply() method of Pandas, applied to the row axis (axis=1). Let’s illustrate its operation with a simple case. First, we generate data.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\"],\n    }\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nWe now apply the apply() function to the DataFrame to calculate a new variable that is the sum of the two existing ones.\n\ndf['sum_row'] = df.apply(lambda row: row['var1'] + row['var2'], axis=1)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n\n\n1\n5\n7\n2022-01-02\n12\n\n\n2\n9\n11\n2022-01-03\n20\n\n\n3\n13\n15\n2022-01-04\n28\n\n\n\n\n\n\n\n\n\n\n\n\n\nLambda functions\n\n\n\nA lambda function is a small anonymous function. It can take any number of arguments but can have only one expression. In the example above, the lambda function takes a row as an argument and returns the sum of the var1 and var2 columns for that row.\nLambda functions allow defining simple functions “on the fly” without having to give them a name. In our example, this would have been perfectly equivalent to the following code:\n\ndef sum_row(row):\n    return row['var1'] + row['var2']\n\ndf['sum_row'] = df.apply(sum_row, axis=1)\n\n\n\nAlthough apply() offers great flexibility, it is not the most efficient method, especially for large datasets. Vectorized operations are always preferable as they process data in blocks rather than row by row. In our case, it would have been preferable to create our variable using column operations.\n\ndf['sum_row_vect'] = df['var1'] + df['var2']\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\nsum_row_vect\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n4\n\n\n1\n5\n7\n2022-01-02\n12\n12\n\n\n2\n9\n11\n2022-01-03\n20\n20\n\n\n3\n13\n15\n2022-01-04\n28\n28\n\n\n\n\n\n\n\nHowever, we might find ourselves in certain (rare) cases where an operation cannot be easily vectorized or where the logic is complex. Suppose, for example, we want to combine the values of several columns based on certain conditions.\n\ndef combine_columns(row):\n    if row['var1'] &gt; 6:\n        return str(row['var2'])\n    else:\n        return str(row['var2']) + \"_\" + row['date']\n\ndf['combined_column'] = df.apply(combine_columns, axis=1)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\nsum_row_vect\ncombined_column\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n4\n3_2022-01-01\n\n\n1\n5\n7\n2022-01-02\n12\n12\n7_2022-01-02\n\n\n2\n9\n11\n2022-01-03\n20\n20\n11\n\n\n3\n13\n15\n2022-01-04\n28\n28\n15\n\n\n\n\n\n\n\n\n\n\nSorting values\nSorting data is particularly useful for exploring and visualizing data. With Pandas, we use the sort_values() method to sort the values of a DataFrame based on one or more columns.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\"],\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nTo sort the values based on a single column, just pass the column name as a parameter.\n\ndf.sort_values(by='var1')\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nBy default, the sorting is done in ascending\norder. To sort the values in descending order, just set ascending=False.\n\ndf.sort_values(by='var1', ascending=False)\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n3\n13\n15\n2022-01-04\n\n\n2\n9\n11\n2022-01-03\n\n\n1\n5\n7\n2022-01-02\n\n\n0\n1\n3\n2022-01-01\n\n\n\n\n\n\n\nIf we want to sort the DataFrame on multiple columns, we can provide a list of column names. We can also choose to sort in ascending order for some columns and descending order for others.\n\n\nAggregating data\nAggregating data is a process where the data is broken down into groups based on certain criteria and then aggregated using an aggregation function applied independently to each group. This operation is common in exploratory analysis or when preprocessing data for visualization or statistical modeling.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\n0\n1.3\n-2\ntest\n2022-01-01\nsample1\n\n\n1\n5.6\n8\ntrain\n2022-01-02\nsample1\n\n\n2\nNaN\n7\ntest\n2022-01-03\nsample1\n\n\n3\nNaN\n-6\ntrain\n2022-01-04\nsample1\n\n\n4\n0.0\n6\ntrain\n2022-01-05\nsample1\n\n\n\n\n\n\n\n\nThe groupBy operation\nThe groupBy method in Pandas allows dividing the DataFrame into subsets based on the values of one or more columns, and then applying an aggregation function to each subset. It returns a DataFrameGroupBy object that is not very useful by itself but is an essential intermediate step to then apply one or more aggregation function(s) to the different groups.\n\ndf.groupby('experiment')\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f7901adbdf0&gt;\n\n\n\n\nAggregation functions\nOnce the data is grouped, we can apply aggregation functions to obtain a statistical summary. Pandas includes a number of these functions, the complete list of which is detailed in the documentation. Here are some examples of using these methods.\nFor example, count the number of occurrences in each group.\n\ndf.groupby('experiment').size()\n\nexperiment\ntest          2\ntrain         3\nvalidation    1\ndtype: int64\n\n\nCalculate the sum of a variable by group.\n\ndf.groupby('experiment')['var1'].sum()\n\nexperiment\ntest          1.3\ntrain         5.6\nvalidation    0.0\nName: var1, dtype: float64\n\n\nOr count the number of unique values of a variable by group. The possibilities are numerous.\n\n# For the number of unique values of 'var2' in each group\ndf.groupby('experiment')['var2'].nunique()\n\nexperiment\ntest          2\ntrain         3\nvalidation    1\nName: var2, dtype: int64\n\n\nWhen we want to apply multiple aggregation functions at once or custom functions, we use the agg method. This method accepts a list of functions or a dictionary that associates column names with functions to apply. This allows for finer application of aggregation functions.\n\ndf.groupby('experiment').agg({'var1': 'mean', 'var2': 'count'})\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\nexperiment\n\n\n\n\n\n\ntest\n1.3\n2\n\n\ntrain\n2.8\n3\n\n\nvalidation\nNaN\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethod chaining\n\n\n\nThe previous examples illustrate an important concept in Pandas: method chaining. This term refers to the possibility of chaining transformations applied to a DataFrame by applying methods to it in a chain. At each applied method, an intermediate DataFrame is created (but not assigned to a variable), which becomes the input of the next method.\nMethod chaining allows combining several operations into a single code expression. This can improve efficiency by avoiding intermediate assignments and making the code more fluid and readable. It also favors a functional programming style where data flows smoothly through a chain of transformations.\n\n\n\n\nEffects on the index\nIt is interesting to note the effects of the aggregation process on the DataFrame’s index. The last example above illustrates this well: the groups, i.e., the modalities of the variable used for aggregation, become the values of the index.\nWe might want to reuse this information in subsequent analyses and therefore want it as a column. For this, just reset the index with the reset_index() method.\n\ndf_agg = df.groupby('experiment').agg({'var1': 'mean', 'var2': 'count'})\ndf_agg.reset_index()\n\n\n\n\n\n\n\n\nexperiment\nvar1\nvar2\n\n\n\n\n0\ntest\n1.3\n2\n\n\n1\ntrain\n2.8\n3\n\n\n2\nvalidation\nNaN\n1\n\n\n\n\n\n\n\n\n\n\nHandling missing values\nMissing values are a common reality in real-world data processing and can occur for various reasons, such as non-responses to a questionnaire, data entry errors, data loss during transmission, or simply because the information is not applicable. Pandas offers several tools to handle missing values.\n\nRepresentation of missing values\nIn Pandas, missing values are generally represented by np.nan, a special marker provided by the NumPy library. While it is preferable to use this object to denote missing values, note that the None object in Python is also understood as a missing value by Pandas.\nLet’s verify this property. To identify where the missing values are, we use the isna() function, which returns a boolean DataFrame indicating True where the values are NaN.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", None, \"train\", \"validation\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf.isna()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\n\n\n3\nTrue\nFalse\nTrue\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\n\n\n5\nTrue\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\nCalculations on columns containing missing values\nDuring statistical calculations, missing values are generally ignored. For example, the .mean() method calculates the mean of non-missing values.\n\ndf['var1'].mean()\n\nnp.float64(2.3)\n\n\nHowever, calculations involving multiple columns do not always ignore missing values and can often result in NaN.\n\ndf['var3'] = df['var1'] + df['var2']\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nvar3\n\n\n\n\n0\n1.3\n9\ntest\nsample1\n10.3\n\n\n1\n5.6\n-1\ntrain\nsample1\n4.6\n\n\n2\nNaN\n7\ntest\nsample1\nNaN\n\n\n3\nNaN\n-1\nNone\nsample1\nNaN\n\n\n4\n0.0\n3\ntrain\nsample1\n3.0\n\n\n5\nNaN\n-4\nvalidation\nsample1\nNaN\n\n\n\n\n\n\n\n\n\nRemoving missing values\nThe dropna() method allows us to remove rows (axis=0) or columns (axis=1) containing missing values. By default, any row containing at least one missing value is removed.\n\ndf.dropna()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nvar3\n\n\n\n\n0\n1.3\n9\ntest\nsample1\n10.3\n\n\n1\n5.6\n-1\ntrain\nsample1\n4.6\n\n\n4\n0.0\n3\ntrain\nsample1\n3.0\n\n\n\n\n\n\n\nBy changing the axis parameter, we can request that any column containing at least one missing value be removed.\n\ndf.dropna(axis=1)\n\n\n\n\n\n\n\n\nvar2\nsample\n\n\n\n\n0\n9\nsample1\n\n\n1\n-1\nsample1\n\n\n2\n7\nsample1\n\n\n3\n-1\nsample1\n\n\n4\n3\nsample1\n\n\n5\n-4\nsample1\n\n\n\n\n\n\n\nFinally, the how parameter defines the deletion mode. By default, a row or column is removed when at least one value is missing (how=any), but it is possible to remove the row/column only when all values are missing (how=all).\n\n\nReplacing missing values\nTo handle missing values in a DataFrame, a common approach is imputation, which involves replacing the missing values with other values. The fillna() method allows us to perform this operation in various ways. One possibility is replacement by a constant value.\n\ndf['var1'].fillna(value=0)\n\n0    1.3\n1    5.6\n2    0.0\n3    0.0\n4    0.0\n5    0.0\nName: var1, dtype: float64\n\n\n\n\n\n\n\n\nChanging the representation of missing values\n\n\n\nIt can sometimes be tempting to change the manifestation of a missing value for visibility reasons, for example by replacing it with a string:\n\ndf['var1'].fillna(value=\"MISSING\")\n\n0        1.3\n1        5.6\n2    MISSING\n3    MISSING\n4        0.0\n5    MISSING\nName: var1, dtype: object\n\n\nIn practice, this is not recommended. It is indeed preferable to stick to Pandas’ standard convention (using np.nan), firstly for standardization purposes that facilitate reading and maintaining the code, but also because the standard convention is optimized for performance and calculations from data containing missing values.\n\n\nAnother frequent imputation method is to use a statistical value, such as the mean or median of the variable.\n\ndf['var1'].fillna(value=df['var1'].mean())\n\n0    1.3\n1    5.6\n2    2.3\n3    2.3\n4    0.0\n5    2.3\nName: var1, dtype: float64\n\n\n\n\n\n\n\n\nImputation bias\n\n\n\nReplacing missing values with a constant value, such as zero, the mean, or the median, can be problematic. If the data is not missing at random (MNAR), this can introduce bias into the analysis. MNAR variables are variables whose probability of being missing is related to their own value or other variables in the data. In such cases, more sophisticated imputation may be necessary to minimize distortions. We will see an example in the end-of-tutorial exercise.\n\n\n\n\n\nHandling data of specific types\n\nText data\nText data often requires cleaning and preparation before analysis. Pandas provides an array of vectorized operations via the str library that make preparing text data both simple and very efficient. Again, the possibilities are numerous and detailed in the documentation. Here we present the most frequently used methods in data analysis.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"test\", \"train\", \"validation\"],\n        \"sample\": [\"  sample1\", \"sample1\", \"sample2\", \"   sample2   \", \"sample2  \", \"sample1\"]\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n\n\n1\n5.6\n-10\ntrain\nsample1\n\n\n2\nNaN\n1\ntest\nsample2\n\n\n3\nNaN\n2\ntest\nsample2\n\n\n4\n0.0\n9\ntrain\nsample2\n\n\n5\nNaN\n-10\nvalidation\nsample1\n\n\n\n\n\n\n\nA first frequent operation is to extract certain characters from a string. We use the str[n:] function (with a somewhat peculiar syntax) for this. For example, if we want to extract the last character of the sample variable to retain only the sample number.\n\ndf[\"sample_n\"] = df[\"sample\"].str[-1:]\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-10\ntrain\nsample1\n1\n\n\n2\nNaN\n1\ntest\nsample2\n2\n\n\n3\nNaN\n2\ntest\nsample2\n\n\n\n4\n0.0\n9\ntrain\nsample2\n\n\n\n5\nNaN\n-10\nvalidation\nsample1\n1\n\n\n\n\n\n\n\nThe principle was correct, but the presence of extraneous spaces in our text data (which were not visible when viewing the DataFrame!) made the operation more difficult than expected. This is an opportunity to introduce the strip family of methods (.str.strip(), .str.lstrip(), and .str.rstrip()) that respectively remove extr\naneous spaces from both sides or one side.\n\ndf[\"sample\"] = df[\"sample\"].str.strip()\ndf[\"sample_n\"] = df[\"sample\"].str[-1:]\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-10\ntrain\nsample1\n1\n\n\n2\nNaN\n1\ntest\nsample2\n2\n\n\n3\nNaN\n2\ntest\nsample2\n2\n\n\n4\n0.0\n9\ntrain\nsample2\n2\n\n\n5\nNaN\n-10\nvalidation\nsample1\n1\n\n\n\n\n\n\n\nWe might also want to filter a DataFrame based on the presence or absence of a certain string (or substring) of characters. For this, we use the .str.contains() method.\n\ndf[df['experiment'].str.contains('test')]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n2\nNaN\n1\ntest\nsample2\n2\n\n\n3\nNaN\n2\ntest\nsample2\n2\n\n\n\n\n\n\n\nFinally, we might want to replace a string (or substring) of characters with another, which the str.replace() method allows.\n\ndf['experiment'] = df['experiment'].str.replace('validation', 'val')\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-10\ntrain\nsample1\n1\n\n\n2\nNaN\n1\ntest\nsample2\n2\n\n\n3\nNaN\n2\ntest\nsample2\n2\n\n\n4\n0.0\n9\ntrain\nsample2\n2\n\n\n5\nNaN\n-10\nval\nsample1\n1\n\n\n\n\n\n\n\n\n\nCategorical data\nCategorical data is variables that contain a limited number of categories. Similar to R with the notion of factor, Pandas has a special data type, category, which is useful for representing categorical data more efficiently and informatively. Categorical data is indeed optimized for certain types of data and can speed up operations like grouping and sorting. It is also useful for visualization, ensuring that categories are displayed in a coherent and logical order.\nTo convert a variable to the category format, we use the astype() method.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", None, \"train\", \"validation\"],\n    }\n)\nprint(df.dtypes)\n\nvar1          float64\nvar2            int64\nexperiment     object\ndtype: object\n\n\n\ndf['experiment'] = df['experiment'].astype('category')\n\nprint(df.dtypes)\n\nvar1           float64\nvar2             int64\nexperiment    category\ndtype: object\n\n\nThis conversion gives us access to some very useful methods, specific to handling categorical variables. For example, it can be useful to rename categories for clarity or standardization.\n\ndf['experiment'] = df['experiment'].cat.rename_categories({'test': 'Test', 'train': 'Train', 'validation': 'Validation'})\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\n\n\n\n\n0\n1.3\n-1\nTest\n\n\n1\n5.6\n-1\nTrain\n\n\n2\nNaN\n7\nTest\n\n\n3\nNaN\n-3\nNaN\n\n\n4\n0.0\n3\nTrain\n\n\n5\nNaN\n-5\nValidation\n\n\n\n\n\n\n\nSometimes, the order of categories is significant, and we might want to modify it. This is particularly important for visualization, as the categories will by default be displayed in the specified order.\n\ndf_cat = df['experiment'].cat.reorder_categories(['Test', 'Train', 'Validation'], ordered=True)\ndf.groupby(\"experiment\").mean().plot(kind='bar')\n\n/tmp/ipykernel_3387/419168969.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  df.groupby(\"experiment\").mean().plot(kind='bar')\n\n\n\n\n\n\n\n\n\n\n\nTemporal data\nTemporal data is often present in tabular data to temporally identify the observations collected. Pandas offers functionalities for handling these types of data, particularly through the datetime64 type, which allows precise manipulation of dates and times.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2023-01-01\", \"2023-01-02\"],\n        \"sample\": [\"sample1\", \"sample1\", \"sample2\", \"sample2\"]\n    }\n)\n\ndf.dtypes\n\nvar1       int64\nvar2       int64\ndate      object\nsample    object\ndtype: object\n\n\nTo handle temporal data, it is necessary to convert the strings into datetime objects. Pandas does this via the to_datetime() function.\n\ndf['date'] = pd.to_datetime(df['date'])\n\ndf.dtypes\n\nvar1               int64\nvar2               int64\ndate      datetime64[ns]\nsample            object\ndtype: object\n\n\nOnce converted, dates can be formatted, compared, and used in calculations. In particular, Pandas now understands the “order” of the dates present in the data, allowing for filtering over given periods.\n\ndf[(df['date'] &gt;= \"2022-01-01\") & (df['date'] &lt; \"2022-01-03\")]\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n\n\n\n\n\nWe might also want to perform less precise filtering, involving the year or month. Pandas allows us to easily extract specific components of the date, such as the year, month, day, hour, etc.\n\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\n\ndf[df['year'] == 2023]\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\nyear\nmonth\nday\n\n\n\n\n2\n9\n11\n2023-01-01\nsample2\n2023\n1\n1\n\n\n3\n13\n15\n2023-01-02\nsample2\n2023\n1\n2\n\n\n\n\n\n\n\nFinally, calculations involving dates become possible. We can add or subtract time periods from dates and compare them with each other. The functions used come from Pandas but are very similar in operation to those of the time module in Python.\nFor example, we can add time intervals or calculate differences from a reference date.\n\ndf['date_plus_one'] = df['date'] + pd.Timedelta(days=1)\ndf['date_diff'] = df['date'] - pd.to_datetime('2022-01-01')\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\nyear\nmonth\nday\ndate_plus_one\ndate_diff\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n2022\n1\n1\n2022-01-02\n0 days\n\n\n1\n5\n7\n2022-01-02\nsample1\n2022\n1\n2\n2022-01-03\n1 days\n\n\n2\n9\n11\n2023-01-01\nsample2\n2023\n1\n1\n2023-01-02\n365 days\n\n\n3\n13\n15\n2023-01-02\nsample2\n2023\n1\n2\n2023-01-03\n366 days\n\n\n\n\n\n\n\n\n\n\nJoining tables\nIn data analysis, it is common to want to combine different data sources. This combination can be done vertically (one DataFrame on top of another), for example, when combining two years of the same survey for joint analysis. The combination can also be done horizontally (side by side) based on one or more join keys, often to enrich one data source with information from another source covering the same statistical units.\n\nConcatenating tables\nThe vertical concatenation of tables is done using the concat() function in Pandas.\n\ndf1 = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5],\n        \"var2\": [3, 7],\n        \"date\": [\"2022-01-01\", \"2022-01-02\"],\n        \"sample\": [\"sample1\", \"sample1\"]\n    }\n)\n\ndf2 = pd.DataFrame(\n    data = {\n        \"var1\": [9, 13],\n        \"date\": [\"2023-01-01\", \"2023-01-02\"],\n        \"var2\": [11, 15],\n        \"sample\": [\"sample2\", \"sample2\"]\n    }\n)\n\ndf_concat = pd.concat([df1, df2])\n\ndf_concat\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n0\n9\n11\n2023-01-01\nsample2\n\n\n1\n13\n15\n2023-01-02\nsample2\n\n\n\n\n\n\n\nNote that the order of variables in the two DataFrames is not important. Pandas does not “dumbly” juxtapose the two DataFrames; it matches the schemas to align the variables by name. If two variables have the same name but not the same type - for example, if a numeric variable has been interpreted as strings - Pandas will resolve the issue by taking the common denominator, usually converting to strings (type object).\nHowever, the previous concatenation reveals an issue of repetition at the index level. This is logical: we did not specify an index for our initial two DataFrames, which therefore have the same position index ([0, 1]). In this case (where the index is not important), we can pass the ignore_index=True parameter to rebuild the final index from scratch.\n\ndf_concat = pd.concat([df1, df2], ignore_index=True)\n\ndf_concat\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n2\n9\n11\n2023-01-01\nsample2\n\n\n3\n13\n15\n2023-01-02\nsample2\n\n\n\n\n\n\n\n\n\n\n\n\n\nIterative construction of a DataFrame\n\n\n\nOne might have the idea of using pd.concat() to iteratively construct a DataFrame by adding a new row to the existing DataFrame in each iteration of a loop. However, this is not a good idea: as we have seen, a DataFrame is represented in memory as a juxtaposition of Series. Thus, adding a column to a DataFrame is not costly, but adding a row involves modifying each element constituting the DataFrame. To construct a DataFrame, it is therefore advisable to store the rows in a list of lists (one per column) or a dictionary, then call pd.DataFrame() to build the DataFrame, as we did at the beginning of this tutorial.\n\n\n\n\nMerging tables\nMerging tables is an operation that allows us to associate rows from two different DataFrames based on one or more common keys, similar to joins in SQL databases. Different types of joins are possible depending on the data we want to keep, the main ones being represented in the following diagram.\n\nSource: link\nIn Pandas, joins are done with the merge() function. To perform a join, we must specify (at a minimum) two pieces of information:\n\nthe type of join: by default, Pandas performs an inner join. The how parameter allows specifying other types of joins;\nthe join key. By default, Pandas tries to join the two DataFrames based on their indexes. In practice, we often specify a variable present in the DataFrames as the join key (the on parameter if the variable has the same name in both DataFrames, or left_on and right_on otherwise).\n\nLet’s analyze the difference between the different types of joins through examples.\n\ndf_a = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K3', 'K4'],\n    'A': ['A0', 'A1', 'A2', 'A3', 'A4'],\n    'B': ['B0', 'B1', 'B2', 'B3', 'A4']\n})\n\ndf_b = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K5', 'K6'],\n    'C': ['C0', 'C1', 'C2', 'C5', 'C6'],\n    'D': ['D0', 'D1', 'D2', 'D5', 'D6']\n})\n\ndisplay(df_a)\ndisplay(df_b)\n\n\n\n\n\n\n\n\nkey\nA\nB\n\n\n\n\n0\nK0\nA0\nB0\n\n\n1\nK1\nA1\nB1\n\n\n2\nK2\nA2\nB2\n\n\n3\nK3\nA3\nB3\n\n\n4\nK4\nA4\nA4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkey\nC\nD\n\n\n\n\n0\nK0\nC0\nD0\n\n\n1\nK1\nC1\nD1\n\n\n2\nK2\nC2\nD2\n\n\n3\nK5\nC5\nD5\n\n\n4\nK6\nC6\nD6\n\n\n\n\n\n\n\nThe inner join keeps the observations whose key is present in both DataFrames.\n\ndf_merged_inner = pd.merge(df_a, df_b, on='key')\ndf_merged_inner\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n\n\n\n\n\n\n\n\n\n\n\nInner joins\n\n\n\nThe inner join is the most intuitive: it generally does not create missing values and therefore allows working directly on the merged table. But beware: if many keys are not present in both DataFrames, an inner join can result in significant data loss, leading to biased final results. In this case, it is better to choose a left or right join, depending on the source we want to enrich and for which it is most important to minimize data loss.\n\n\nA left join keeps all observations in the left DataFrame (the first DataFrame specified in pd.merge()). As a result, if keys are present in the left DataFrame but not in the right one, the final DataFrame contains missing values at those observations (for the right DataFrame’s variables).\n\ndf_merged_left = pd.merge(df_a, df_b, how=\"left\", on='key')\ndf_merged_left\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n3\nK3\nA3\nB3\nNaN\nNaN\n\n\n4\nK4\nA4\nA4\nNaN\nNaN\n\n\n\n\n\n\n\nThe outer join contains all observations and variables in both DataFrames. Thus, the retained information is maximal, but on the other hand, missing values can be quite numerous. It will therefore be necessary to handle missing values well before proceeding with analyses.\n\ndf_merged_outer = pd.merge(df_a, df_b, how=\"outer\", on='key')\ndf_merged_outer\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n3\nK3\nA3\nB3\nNaN\nNaN\n\n\n4\nK4\nA4\nA4\nNaN\nNaN\n\n\n5\nK5\nNaN\nNaN\nC5\nD5\n\n\n6\nK6\nNaN\nNaN\nC6\nD6",
    "crumbs": [
      "Data handling",
      "Processing tabular data with Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#exercises",
    "href": "source/manipulation/pandas/tutorial.html#exercises",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension questions\n\nWhat is a DataFrame in the context of Pandas, and what type of data structure can it be compared to in Python?\nWhat is the fundamental difference between a NumPy array and a Pandas Series?\nWhat is the relationship between Series and DataFrame in Pandas?\nHow are data structured in a Pandas DataFrame?\nWhat is the role of the index in a Pandas DataFrame, and how can it be used when manipulating data?\nWhat methods can you use to explore an unknown DataFrame and learn more about its content and structure?\nIn Pandas, what is the difference between assigning the result of an operation to a new variable and using a method with the inplace=True argument?\nHow does the principle of vectorization apply in Pandas, and why is it advantageous for manipulating data?\nHow does Pandas represent missing values, and what impact does this have on calculations and data transformations?\nWhat is the difference between concatenating two DataFrames and joining them via a merge, and when would you use one over the other?\n\n\n\n\nShow solution\n\n\nA DataFrame in Pandas is a two-dimensional data structure, comparable to a table or an Excel spreadsheet. In the Python context, it can be compared to a dictionary of NumPy arrays, where the keys are column names, and the values are the columns themselves.\nThe main difference between a NumPy array and a Pandas Series is that the Series can contain labeled data, meaning it has an associated index that allows access and manipulation by label.\nA DataFrame is essentially a collection of Series. Each column of a DataFrame is a Series, and all these Series share the same index, which corresponds to the row labels of the DataFrame.\nData in a Pandas DataFrame are structured in columns and rows. Each column can contain a different type of data (numeric, string, boolean, etc.), and each row represents an observation.\nThe index in a Pandas DataFrame serves to uniquely identify each row in the DataFrame. It allows quick access to rows, performing joins, sorting data, and facilitating grouping operations.\nTo explore an unknown DataFrame, you can use df.head() to see the first rows, df.tail() for the last rows, df.info() to get a summary of data types and missing values, and df.describe() for descriptive statistics.\nAssigning the result of an operation to a new variable creates a copy of the DataFrame with the applied modifications. Using a method with inplace=True modifies the original DataFrame without creating a copy, which can be more memory-efficient.\nPandas represents missing values with the nan (Not a Number) object from NumPy for numeric data and with None or pd.NaT for date/time data. These missing values are generally ignored in statistical calculations, which can affect the results if they are not handled properly.\nConcatenating consists of stacking DataFrames vertically or aligning them horizontally, primarily used when the DataFrames have the same schema or when you want to stack the data. Merging, inspired by SQL JOIN operations, combines DataFrames based on common key values and is used to enrich one dataset with information from another.\n\n\n\n\n\nMultiple ways to create a DataFrame\nIn the following cell, we have retrieved cash register data on sales from different stores. The data is presented in two different ways: one as observations (each list contains data from a row), and the other as variables (each list contains data from a column).\n\ndata_list1 = [\n    ['Carrefour', '01.1.1', 3, 1.50],\n    ['Casino', '02.1.1', 2, 2.30],\n    ['Lidl', '01.1.1', 7, 0.99],\n    ['Carrefour', '03.1.1', 5, 5.00],\n    ['Casino', '01.1.1', 10, 1.20],\n    ['Lidl', '02.1.1', 1, 3.10]\n]\n\ndata_list2 = [\n    ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    [3, 2, 7, 5, 10, 1],\n    [1.50, 2.30, 0.99, 5.00, 1.20, 3.10]\n]\n\nThe goal is to build in both cases the same DataFrame containing each of the 6 observations and 4 variables, with the same names in both DataFrames. Each case will correspond to a more suitable input data structure, dictionary, or list of lists… make the right choice! We will verify that the two DataFrames are identical using the equals() method.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndata_list1 = [\n    ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    [3, 2, 7, 5, 10, 1],\n    [1.50, 2.30, 0.99, 5.00, 1.20, 3.10]\n]\n\ndata_list2 = [\n    ['Carrefour', '01.1.1', 3, 1.50],\n    ['Casino', '02.1.1', 2, 2.30],\n    ['Lidl', '01.1.1', 7, 0.99],\n    ['Carrefour', '03.1.1', 5, 5.00],\n    ['Casino', '01.1.1', 10, 1.20],\n    ['Lidl', '02.1.1', 1, 3.10]\n]\n\n# If the data is in column form: from a dictionary\ndata_dict = {\n    'store': data_list1[0],\n    'product': data_list1[1],\n    'quantity': data_list1[2],\n    'price': data_list1[3]\n}\n\ndf_from_dict = pd.DataFrame(data_dict)\n\n# If the data is in row form: from a list of lists\ncolumns = ['store', 'product', 'quantity', 'price']\ndf_from_list = pd.DataFrame(data_list2, columns=columns)\n\n# Verification\ndf_from_dict.equals(df_from_list)\n\nTrue\n\n\n\n\n\n\nData selection in a DataFrame\nA Pandas DataFrame is created with cash register data (same data as the previous exercise).\n\ndata = {\n    'store': ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    'product': ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    'quantity': [3, 2, 7, 5, 10, 1],\n    'price': [1.50, 2.30, 0.99, 5.00, 1.20, 3.10],\n    'date_time': pd.to_datetime([\"2022-01-01 14:05\", \"2022-01-02 09:30\", \n                                 \"2022-01-03 17:45\", \"2022-01-04 08:20\", \n                                 \"2022-01-05 19:00\", \"2022-01-06 16:30\"])\n}\n\ndf = pd.DataFrame(data)\n\nUse the loc and iloc methods to select specific data:\n\nSelect the data from the first row.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.iloc[0])\n\nstore                  Carrefour\nproduct                   01.1.1\nquantity                       3\nprice                        1.5\ndate_time    2022-01-01 14:05:00\nName: 0, dtype: object\n\n\n\n\n\nSelect all data from the “price” column.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[:, 'price'])\n\n0    1.50\n1    2.30\n2    0.99\n3    5.00\n4    1.20\n5    3.10\nName: price, dtype: float64\n\n\n\n\n\nSelect the rows corresponding to the store “Carrefour” only.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[df['store'] == 'Carrefour'])\n\n       store product  quantity  price           date_time\n0  Carrefour  01.1.1         3    1.5 2022-01-01 14:05:00\n3  Carrefour  03.1.1         5    5.0 2022-01-04 08:20:00\n\n\n\n\n\nSelect the quantities purchased for products classified “01.1.1” (Bread).\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[df['product'] == '01.1.1', 'quantity'])\n\n0     3\n2     7\n4    10\nName: quantity, dtype: int64\n\n\n\n\n\nSelect the data from the “store” and “price” columns for all rows.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[:, ['store', 'price']])\n\n       store  price\n0  Carrefour   1.50\n1     Casino   2.30\n2       Lidl   0.99\n3  Carrefour   5.00\n4     Casino   1.20\n5       Lidl   3.10\n\n\n\n\n\nSelect the rows where the purchased quantity is greater than 5.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[df['quantity'] &gt; 5])\n\n    store product  quantity  price           date_time\n2    Lidl  01.1.1         7   0.99 2022-01-03 17:45:00\n4  Casino  01.1.1        10   1.20 2022-01-05 19:00:00\n\n\n\n\n\nFilter to select all transactions that occurred after 3 PM.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[df['date_time'].dt.hour &gt; 15])\n\n    store product  quantity  price           date_time\n2    Lidl  01.1.1         7   0.99 2022-01-03 17:45:00\n4  Casino  01.1.1        10   1.20 2022-01-05 19:00:00\n5    Lidl  02.1.1         1   3.10 2022-01-06 16:30:00\n\n\n\n\n\nSelect the transactions that took place on “2022-01-03”.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df.loc[df['date_time'].dt.date == pd.to_datetime('2022-01-03').date()])\n\n  store product  quantity  price           date_time\n2  Lidl  01.1.1         7   0.99 2022-01-03 17:45:00\n\n\n\n\n\n\nExploring the first names file\nThe first names file contains data on the first names given to children born in France between 1900 and 2021. This data is available at the national, department, and regional levels at the following address: https://www.insee.fr/fr/statistiques/2540004?sommaire=4767262. The goal of this tutorial is to propose an analysis of this file, from data cleaning to first name statistics.\n\nPart 1: Import and data exploration\n\nImport the data into a DataFrame using this URL.\nView a sample of the data. Do you notice any anomalies?\nDisplay the main information about the DataFrame. Identify any variables with incorrect types or any missing values.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nurl = \"https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\"\ndf_first_names = pd.read_csv(url, sep=\";\")\n\ndf_first_names.head(10)\ndf_first_names.sample(n=50)\n\ndf_first_names.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 686538 entries, 0 to 686537\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   sexe      686538 non-null  int64 \n 1   preusuel  686536 non-null  object\n 2   annais    686538 non-null  object\n 3   nombre    686538 non-null  int64 \ndtypes: int64(2), object(2)\nmemory usage: 21.0+ MB\n\n\n\n\n\n\nPart 2: Data cleaning\n\nThe output of the info() method suggests missing values in the first names column. Display these rows. Verify that these missing values are correctly specified.\nThe output of the head() method shows a recurring “_PRENOMS_RARES” modality in the first names column. What proportion of the individuals in the database does this represent? Convert these values to np.nan.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(df_first_names[df_first_names[\"preusuel\"].isna()])\nprop_rares = df_first_names.groupby(\"preusuel\")[\"nombre\"].sum()[\"_PRENOMS_RARES\"] / df_first_names[\"nombre\"].sum()\nprint(prop_rares)  # ~ 2% of the database\ndf_first_names = df_first_names.replace('_PRENOMS_RARES', np.nan)\n\n        sexe preusuel annais  nombre\n579411     2      NaN   2003       3\n579412     2      NaN   XXXX      29\n0.01965912697163539\n\n\n\n\n\nWe notice that the first names of people whose year of birth is unknown are grouped under the “XXXX” modality. What proportion of the individuals in the database does this represent? Convert these values to np.nan.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprop_xxxx = df_first_names.groupby(\"annais\")[\"nombre\"].sum()[\"XXXX\"] / df_first_names[\"nombre\"].sum()\nprint(prop_xxxx)  # ~ 1% of the database\ndf_first_names = df_first_names.replace('XXXX', np.nan)\n\n0.010007438242954967\n\n\n\n\n\nRemove the rows containing missing values from the sample.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_first_names = df_first_names.dropna()\n\n\n\n\nConvert the annais column to numeric type and the sexe column to categorical type.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_first_names['annais'] = pd.to_numeric(df_first_names['annais'])\ndf_first_names['sexe'] = df_first_names['sexe'].astype('category')\n\n\n\n\nVerify with the info() method that the cleaning has been correctly applied.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_first_names.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 648369 entries, 122 to 686536\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype   \n---  ------    --------------   -----   \n 0   sexe      648369 non-null  category\n 1   preusuel  648369 non-null  object  \n 2   annais    648369 non-null  int64   \n 3   nombre    648369 non-null  int64   \ndtypes: category(1), int64(2), object(1)\nmemory usage: 20.4+ MB\n\n\n\n\n\n\nPart 3: Descriptive statistics on births\n\nThe documentation of the file informs us that the data can be considered quasi-exhaustive from 1946 onwards. For this part only, filter the data to keep only data from 1946 onwards.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_first_names_post_1946 = df_first_names[df_first_names[\"annais\"] &gt;= 1946]\n\n\n\n\nCalculate the total number of births by sex.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nbirths_per_sex = df_first_names_post_1946.groupby('sexe')['nombre'].sum()\nprint(births_per_sex)\n\nsexe\n1    30872950\n2    29314697\nName: nombre, dtype: int64\n\n\n/tmp/ipykernel_3387/4076629916.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  births_per_sex = df_first_names_post_1946.groupby('sexe')['nombre'].sum()\n\n\n\n\n\nIdentify the five years with the highest number of births.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ntop5_years = df_first_names_post_1946.groupby('annais')['nombre'].sum().nlargest(5)\nprint(top5_years)\n\nannais\n1964    902522\n1971    899440\n1972    893901\n1963    893425\n1949    890585\nName: nombre, dtype: int64\n\n\n\n\n\n\nPart 4: First name analysis\n\nIdentify the total number of unique first names in the DataFrame.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ntotal_unique_names = df_first_names['preusuel'].nunique()\nprint(total_unique_names)\n\n34175\n\n\n\n\n\nCount the number of people with a single-letter first name.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nsingle_letter_names = df_first_names[df_first_names['preusuel'].str.len() == 1]['nombre'].sum()\nprint(single_letter_names)\n\n209\n\n\n\n\n\nCreate a “popularity function” that, for a given first name, displays the year it was most given and the number of times it was given that year.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndef popularity_by_year(df, first_name):\n    # Filter the DataFrame to keep only the rows corresponding to the given first name\n    df_first_name = df[df['preusuel'] == first_name]\n\n    # Group by year, sum the births, and identify the year with the maximum births\n    df_agg = df_first_name.groupby('annais')['nombre'].sum()\n    max_year = df_agg.idxmax()\n    max_n = df_agg[max_year]\n\n    print(f\"The first name '{first_name}' was most given in {max_year}, with {max_n} births.\")\n\n# Test the function with an example\npopularity_by_year(df_first_names, 'ALFRED')\n\nThe first name 'ALFRED' was most given in 1910, with 1994 births.\n\n\n\n\n\nCreate a function that, for a given sex, returns a DataFrame containing the most given first name for each decade.\n\n\n# Test\n\n your answer in this cell\n\n\n  Cell In[319], line 3\n    your answer in this cell\n    ^\nIndentationError: unexpected indent\n\n\n\n\n\n\n\nShow solution\n\n\ndef popularity_by_decade(df, sex):\n    # Filter by sex\n    df_sub = df[df[\"sexe\"] == sex]\n\n    # Calculate the decade variable\n    df_sub[\"decade\"] = (df_sub[\"annais\"] // 10) * 10\n\n    # Calculate the sum of births for each first name and each decade\n    df_counts_decade = df_sub.groupby([\"preusuel\", \"decade\"])[\"nombre\"].sum().reset_index()\n\n    # Find the index of the most frequent first name for each decade\n    idx = df_counts_decade.groupby(\"decade\")[\"nombre\"].idxmax()\n\n    # Use the index to obtain the corresponding rows from the df_counts_decade DataFrame\n    df_popularity_decade = df_counts_decade.loc[idx].set_index(\"decade\")\n\n    return df_popularity_decade\n\n# Test the function with an example\npopularity_by_decade(df_first_names, sex=2)\n\n/tmp/ipykernel_3387/171210111.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_sub[\"decade\"] = (df_sub[\"annais\"] // 10) * 10\n\n\n\n\n\n\n\n\n\npreusuel\nnombre\n\n\ndecade\n\n\n\n\n\n\n1900\nMARIE\n490609\n\n\n1910\nMARIE\n329246\n\n\n1920\nMARIE\n322486\n\n\n1930\nMARIE\n247784\n\n\n1940\nMARIE\n265690\n\n\n1950\nMARIE\n217042\n\n\n1960\nSYLVIE\n204773\n\n\n1970\nSANDRINE\n146395\n\n\n1980\nAURÉLIE\n113344\n\n\n1990\nLAURA\n70049\n\n\n2000\nLÉA\n77504\n\n\n2010\nEMMA\n49094\n\n\n2020\nJADE\n7618\n\n\n\n\n\n\n\n\n\n\n\n\nCalculation of a carbon footprint per inhabitant at the municipal level\nThe goal of this exercise is to calculate a carbon footprint per inhabitant at the municipal level. To do this, we will need to combine two data sources:\n\nLegal populations at the municipal level from the population census (source)\nGreenhouse gas emissions estimated at the municipal level by ADEME (source)\n\nThis exercise constitutes a simplified version of a complete practical exercise on Pandas proposed by Lino Galiana in his course at ENSAE.\n\nPart 1: Exploring the legal municipal populations data\n\nImport the CSV file communes.csv.\nUse the .sample(), .info(), and .describe() methods to get an overview of the data.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_pop_communes = pd.read_csv(\"data/communes.csv\", sep=\";\")\n\ndf_pop_communes.sample(10)\ndf_pop_communes.info()\ndf_pop_communes.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 34995 entries, 0 to 34994\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   DEPCOM  34995 non-null  object\n 1   COM     34995 non-null  object\n 2   PMUN    34995 non-null  int64 \n 3   PCAP    34995 non-null  int64 \n 4   PTOT    34995 non-null  int64 \ndtypes: int64(3), object(2)\nmemory usage: 1.3+ MB\n\n\n\n\n\n\n\n\n\nPMUN\nPCAP\nPTOT\n\n\n\n\ncount\n34995.000000\n34995.000000\n34995.000000\n\n\nmean\n1900.966967\n35.340849\n1936.307815\n\n\nstd\n8583.400244\n133.285462\n8696.358429\n\n\nmin\n0.000000\n0.000000\n0.000000\n\n\n25%\n199.000000\n4.000000\n203.000000\n\n\n50%\n457.000000\n9.000000\n468.000000\n\n\n75%\n1159.000000\n24.000000\n1184.000000\n\n\nmax\n479553.000000\n5256.000000\n484809.000000\n\n\n\n\n\n\n\n\n\n\nIdentify and remove rows corresponding to municipalities without population.\nRemove the “PMUN” and “PCAP” columns, which are irrelevant for the analysis.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nn_communes_0_pop = df_pop_communes[df_pop_communes[\"PTOT\"] == 0].shape[0]\nprint(n_communes_0_pop)\ndf_pop_communes = df_pop_communes[df_pop_communes[\"PTOT\"] &gt; 0]\n\ndf_pop_communes = df_pop_communes.drop(columns=[\"PMUN\", \"PCAP\"])\n\n6\n\n\n\n\nDo the municipalities with the longest names also have the smallest populations? To find out: - Create a new variable that contains the number of characters of each municipality using the str.len() method. - Calculate the correlation between this variable and the total population using the corr() method.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_pop_communes_stats = df_pop_communes.copy()\ndf_pop_communes_stats['length'] = df_pop_communes_stats['COM'].str.len()\ndf_pop_communes_stats['length'].corr(df_pop_communes_stats['PTOT'])\n\nnp.float64(0.0037878701156295307)\n\n\n\n\n\n\nPart 2: Exploring the municipal emissions data\n\nImport the emissions data from this URL.\nUse the .sample(), .info(), and .describe() methods to get an overview of the data.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nurl_ademe = \"https://data.ademe.fr/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/data-files/IGT%20-%20Pouvoir%20de%20r%C3%A9chauffement%20global.csv\"\ndf_emissions = pd.read_csv(url_ademe)\n\ndf_emissions.sample(10)\ndf_emissions.info()\ndf_emissions.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35798 entries, 0 to 35797\nData columns (total 12 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   INSEE commune                    35798 non-null  object \n 1   Commune                          35798 non-null  object \n 2   Agriculture                      35736 non-null  float64\n 3   Autres transports                9979 non-null   float64\n 4   Autres transports international  2891 non-null   float64\n 5   CO2 biomasse hors-total          35798 non-null  float64\n 6   Déchets                          35792 non-null  float64\n 7   Energie                          34490 non-null  float64\n 8   Industrie hors-énergie           34490 non-null  float64\n 9   Résidentiel                      35792 non-null  float64\n 10  Routier                          35778 non-null  float64\n 11  Tertiaire                        35798 non-null  float64\ndtypes: float64(10), object(2)\nmemory usage: 3.3+ MB\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\n\n\n\n\ncount\n35736.000000\n9979.000000\n2.891000e+03\n35798.000000\n35792.000000\n3.449000e+04\n3.449000e+04\n35792.000000\n35778.000000\n35798.000000\n\n\nmean\n2459.975760\n654.919940\n7.692345e+03\n1774.381550\n410.806329\n6.625698e+02\n2.423128e+03\n1783.677872\n3535.501245\n1105.165915\n\n\nstd\n2926.957701\n9232.816833\n1.137643e+05\n7871.341922\n4122.472608\n2.645571e+04\n5.670374e+04\n8915.902379\n9663.156628\n5164.182507\n\n\nmin\n0.003432\n0.000204\n3.972950e-04\n3.758088\n0.132243\n2.354558e+00\n1.052998e+00\n1.027266\n0.555092\n0.000000\n\n\n25%\n797.682631\n52.560412\n1.005097e+01\n197.951108\n25.655166\n2.354558e+00\n6.911213e+00\n96.052911\n419.700460\n94.749885\n\n\n50%\n1559.381285\n106.795928\n1.992434e+01\n424.849988\n54.748653\n4.709115e+00\n1.382243e+01\n227.091193\n1070.895593\n216.297718\n\n\n75%\n3007.883903\n237.341501\n3.298311e+01\n1094.749825\n110.820941\n5.180027e+01\n1.520467e+02\n749.469293\n3098.612157\n576.155869\n\n\nmax\n98949.317760\n513140.971691\n3.303394e+06\n576394.181208\n275500.374439\n2.535858e+06\n6.765119e+06\n410675.902028\n586054.672836\n288175.400126\n\n\n\n\n\n\n\n\n\n\nAre there rows with missing values for all emission columns? Check using the isnull() and all() methods.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_emissions_num = df_emissions.select_dtypes(['number'])\nonly_nan = df_emissions_num[df_emissions_num.isnull().all(axis=1)]\nonly_nan.shape[0]\n\n0\n\n\n\n\n\nCreate a new column that gives the total emissions per municipality.\nDisplay the 10 most emitting municipalities. What do you observe in the results?\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_emissions['total_emissions'] = df_emissions.sum(axis=1, numeric_only=True)\n\ndf_emissions.sort_values(by=\"total_emissions\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\ntotal_emissions\n\n\n\n\n4382\n13039\nFOS-SUR-MER\n305.092893\n1893.383189\n1.722723e+04\n50891.367548\n275500.374439\n2.296711e+06\n6.765119e+06\n9466.388806\n74631.401993\n42068.140058\n9.533813e+06\n\n\n22671\n59183\nDUNKERQUE\n811.390947\n3859.548994\n3.327586e+05\n71922.181764\n23851.780482\n1.934988e+06\n5.997333e+06\n113441.727216\n94337.865738\n70245.678455\n8.643550e+06\n\n\n4398\n13056\nMARTIGUES\n855.299300\n2712.749275\n3.043476e+04\n35925.561051\n44597.426397\n1.363402e+06\n2.380185e+06\n22530.797276\n84624.862481\n44394.822725\n4.009663e+06\n\n\n30560\n76476\nPORT-JEROME-SUR-SEINE\n2736.931327\n121.160849\n2.086403e+04\n22846.964780\n78.941581\n1.570236e+06\n2.005643e+06\n21072.566129\n9280.824961\n15270.357772\n3.668151e+06\n\n\n31108\n77291\nLE MESNIL-AMELOT\n782.183307\n133834.090767\n3.303394e+06\n3330.404124\n111.613197\n8.240952e+02\n2.418925e+03\n1404.400153\n11712.541682\n13680.471909\n3.471492e+06\n\n\n31099\n77282\nMAUREGARD\n733.910161\n133699.072712\n3.303394e+06\n193.323752\n44.301447\n2.354558e+00\n6.911213e+00\n468.995242\n2106.579416\n160.309150\n3.440809e+06\n\n\n30438\n76351\nLE HAVRE\n1168.274940\n17358.962736\n2.109460e+06\n141492.414415\n17641.705314\n2.653841e+05\n4.183445e+05\n195864.092574\n111174.296228\n95695.476436\n3.373584e+06\n\n\n30428\n76341\nHARFLEUR\n751.297090\n157.179958\nNaN\n10591.477221\n67.467130\n2.535858e+06\n5.107387e+03\n8739.638694\n29761.043310\n5277.162755\n2.596310e+06\n\n\n31111\n77294\nMITRY-MORY\n1912.746387\n89815.529858\n2.202275e+06\n17540.442778\n159.163608\n3.510646e+03\n1.364685e+04\n26418.982148\n72891.937473\n15163.398499\n2.443335e+06\n\n\n1987\n06088\nNICE\n305.445236\n225204.545951\n1.003572e+06\n169338.333391\n124232.948837\n1.186697e+04\n3.589365e+04\n252857.325855\n352836.864314\n171766.435376\n2.347875e+06\n\n\n\n\n\n\n\n\n\n\nIt seems that the major emission sectors are “Industry excluding energy” and “Other international transport.” To verify if this conjecture holds, calculate the correlation between total emissions and the sectoral emission items using the corrwith() method.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_emissions.corrwith(df_emissions[\"total_emissions\"], numeric_only=True)\n\nAgriculture                        0.032843\nAutres transports                  0.283310\nAutres transports international    0.463660\nCO2 biomasse hors-total            0.466285\nDéchets                            0.409822\nEnergie                            0.711808\nIndustrie hors-énergie             0.835432\nRésidentiel                        0.444557\nRoutier                            0.454902\nTertiaire                          0.488895\ntotal_emissions                    1.000000\ndtype: float64\n\n\n\n\n\nExtract the department number from the municipality code into a new variable.\nCalculate the total emissions by department.\nDisplay the top 10 emitting departments. Are the results logical compared to the analysis at the municipal level?\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_emissions[\"dep\"] = df_emissions[\"INSEE commune\"].str[:2]\ndf_emissions.groupby(\"dep\").agg({\"total_emissions\": \"sum\"}).sort_values(by=\"total_emissions\", ascending=False).head(10)\n\n\n\n\n\n\n\n\ntotal_emissions\n\n\ndep\n\n\n\n\n\n13\n2.657388e+07\n\n\n59\n2.607500e+07\n\n\n76\n2.159825e+07\n\n\n77\n1.818622e+07\n\n\n69\n1.250800e+07\n\n\n62\n1.207887e+07\n\n\n44\n1.053212e+07\n\n\n38\n1.014781e+07\n\n\n57\n1.010131e+07\n\n\n33\n9.352481e+06\n\n\n\n\n\n\n\n\n\n\n\nPart 3: Preliminary checks for merging data sources\nTo perform a merge, it is always preferable to have a join key, i.e., a column common to both sources that uniquely identifies the statistical units. The purpose of this part is to find the relevant join key.\n\nCheck if the variable containing the municipality names contains duplicates.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nduplicates = df_pop_communes.groupby('COM').count()['DEPCOM']\nduplicates = duplicates[duplicates &gt; 1]\nduplicates = duplicates.reset_index()\nduplicates\n\n\n\n\n\n\n\n\nCOM\nDEPCOM\n\n\n\n\n0\nAbancourt\n2\n\n\n1\nAboncourt\n2\n\n\n2\nAbzac\n2\n\n\n3\nAchères\n2\n\n\n4\nAiglun\n2\n\n\n...\n...\n...\n\n\n1451\nÉtaules\n2\n\n\n1452\nÉterpigny\n2\n\n\n1453\nÉtréchy\n3\n\n\n1454\nÉtrépilly\n2\n\n\n1455\nŒuilly\n2\n\n\n\n\n1456 rows × 2 columns\n\n\n\n\n\n\nFilter in the initial DataFrame the municipalities with duplicated names and sort it by municipality code. Do the duplicates seem problematic?\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_pop_communes_duplicates = df_pop_communes[df_pop_communes[\"COM\"].isin(duplicates[\"COM\"])]\ndf_pop_communes_duplicates.sort_values('COM')\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\n\n\n\n\n22473\n60001\nAbancourt\n659\n\n\n21825\n59001\nAbancourt\n476\n\n\n20791\n57001\nAboncourt\n354\n\n\n19453\n54003\nAboncourt\n105\n\n\n12327\n33001\nAbzac\n1963\n\n\n...\n...\n...\n...\n\n\n34450\n91226\nÉtréchy\n6634\n\n\n30189\n77173\nÉtrépilly\n899\n\n\n680\n02297\nÉtrépilly\n119\n\n\n1192\n02565\nŒuilly\n293\n\n\n18782\n51410\nŒuilly\n658\n\n\n\n\n3720 rows × 3 columns\n\n\n\n\n\n\nVerify that the municipality codes uniquely identify the associated municipality.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\n(df_pop_communes_duplicates.groupby(\"DEPCOM\")[\"COM\"].nunique() != 1).sum()\n\nnp.int64(0)\n\n\n\n\n\nDisplay the municipalities present in the population data but not in the emissions data, and vice versa. What do you conclude?\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\n# Observations in the population data but not in the emissions data\ndf_pop_communes[~df_pop_communes[\"DEPCOM\"].isin(df_emissions[\"INSEE commune\"])]\n\n# Observations in the emissions data but not in the population data\ndf_emissions[~df_emissions[\"INSEE commune\"].isin(df_pop_communes[\"DEPCOM\"])]\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\ntotal_emissions\ndep\n\n\n\n\n53\n01059\nBRENAZ\n2059.625278\nNaN\nNaN\n97.460907\n60.369788\n2.354558\n6.911213\n37.806309\n442.992259\n43.546665\n2751.066976\n01\n\n\n83\n01091\nCHATILLON-EN-MICHAILLE\n2716.023992\n154.607070\nNaN\n4479.397305\n26.211975\n489.748010\n1437.532377\n2884.723545\n24426.607714\n2852.127766\n39466.979755\n01\n\n\n89\n01097\nCHAVORNAY\n502.135035\nNaN\nNaN\n119.257319\n28.696758\n2.354558\n6.911213\n90.061423\n187.213742\n103.842046\n1040.472094\n01\n\n\n112\n01122\nCORMARANCHE-EN-BUGEY\n1020.579097\nNaN\nNaN\n548.434440\n134.359486\n35.318366\n103.668200\n323.757897\n1147.594565\n383.306355\n3697.018406\n01\n\n\n130\n01144\nDOMMARTIN\n3514.482852\nNaN\nNaN\n524.037265\n159.287551\nNaN\nNaN\n348.829080\n1529.911692\n422.067671\n6498.616112\n01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35189\n89484\nVOLGRE\n383.961261\nNaN\nNaN\n954.348314\n46.681823\nNaN\nNaN\n424.365746\n10724.104395\n168.922776\n12702.384315\n89\n\n\n35262\n90073\nMOVAL\n281.860724\n57.129390\nNaN\n576.938906\n56.600057\n2.354558\n6.911213\n295.469174\n1439.904381\n205.016539\n2922.184943\n90\n\n\n35348\n91182\nCOURCOURONNES\n24.548795\n103.360309\nNaN\n9623.065698\n111.241872\n1276.170296\n3745.877636\n9978.002088\n57834.224552\n10532.120761\n93228.612007\n91\n\n\n35360\n91222\nESTOUCHES\n1790.002871\nNaN\nNaN\n113.797978\n30.548162\n2.354558\n6.911213\n71.011704\n523.293194\n110.541533\n2648.461213\n91\n\n\n35687\n95259\nGADANCOURT\n312.298700\nNaN\nNaN\n142.113291\n11.372909\nNaN\nNaN\n32.440647\n2060.981036\n41.153991\n2600.360573\n95\n\n\n\n\n922 rows × 14 columns\n\n\n\n\n\n\n\nPart 4: Calculating a carbon footprint per inhabitant for each municipality\n\nMerge the two DataFrames using the municipality code as the join key. Note: the variables are not named the same on both sides!\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_emissions_pop = pd.merge(df_pop_communes, df_emissions, how=\"inner\", left_on=\"DEPCOM\", right_on=\"INSEE commune\")\ndf_emissions_pop\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\ntotal_emissions\ndep\n\n\n\n\n0\n01001\nL' Abergement-Clémenciat\n794\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n5724.424941\n01\n\n\n1\n01002\nL' Abergement-de-Varey\n249\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n1332.811619\n01\n\n\n2\n01004\nAmbérieu-en-Bugey\n14428\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n63259.689119\n01\n\n\n3\n01005\nAmbérieux-en-Dombes\n1723\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n6792.867439\n01\n\n\n4\n01006\nAmbléon\n117\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n1068.584766\n01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n34871\n95676\nVillers-en-Arthies\n513\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n2625.668140\n95\n\n\n34872\n95678\nVilliers-Adam\n870\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n22708.808792\n95\n\n\n34873\n95680\nVilliers-le-Bel\n27808\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n59484.157091\n95\n\n\n34874\n95682\nVilliers-le-Sec\n188\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n6351.999447\n95\n\n\n34875\n95690\nWy-dit-Joli-Village\n340\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n2506.319181\n95\n\n\n\n\n34876 rows × 17 columns\n\n\n\n\n\n\nCalculate a carbon footprint for each municipality, corresponding to the total emissions of the municipality divided by its total population.\nDisplay the top 10 municipalities with the highest carbon footprints.\nAre the results the same as those with total emissions? What do you conclude?\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_emissions_pop[\"carbon_footprint\"] = df_emissions_pop[\"total_emissions\"] / df_emissions_pop[\"PTOT\"]\ndf_emissions_pop.sort_values(\"carbon_footprint\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\ntotal_emissions\ndep\ncarbon_footprint\n\n\n\n\n30289\n77282\nMauregard\n353\n77282\nMAUREGARD\n733.910161\n133699.072712\n3.303394e+06\n193.323752\n44.301447\n2.354558e+00\n6.911213e+00\n468.995242\n2106.579416\n160.309150\n3.440809e+06\n77\n9747.335479\n\n\n30298\n77291\nLe Mesnil-Amelot\n1019\n77291\nLE MESNIL-AMELOT\n782.183307\n133834.090767\n3.303394e+06\n3330.404124\n111.613197\n8.240952e+02\n2.418925e+03\n1404.400153\n11712.541682\n13680.471909\n3.471492e+06\n77\n3406.763878\n\n\n22513\n60049\nBazancourt\n138\n60049\nBAZANCOURT\n4931.402275\nNaN\nNaN\n130.528462\n16.794877\n2.354558e+00\n3.016750e+05\n56.170228\n180.537059\n60.773916\n3.070535e+05\n60\n2225.025699\n\n\n26698\n68064\nChalampé\n969\n68064\nCHALAMPE\n9.216396\n647.802699\n3.558269e+01\n6332.112195\n70576.619047\n2.455804e+03\n1.042746e+06\n1097.958606\n2810.388658\n1362.287485\n1.128073e+06\n68\n1164.162333\n\n\n5501\n16357\nSaint-Vallier\n137\n16357\nSAINT-VALLIER\n1946.660150\nNaN\nNaN\n178.823635\n18.910767\n2.354558e+00\n1.513620e+05\n73.973099\n714.562143\n68.430473\n1.543657e+05\n16\n1126.757043\n\n\n21085\n57314\nHéming\n500\n57314\nHEMING\n509.670358\n167.168713\n8.175536e+00\n1141.352892\n68.237452\n3.343472e+02\n5.114259e+05\n276.118642\n3622.271599\n850.150203\n5.184033e+05\n57\n1036.806699\n\n\n14762\n39236\nFrancheville\n56\n39236\nFRANCHEVILLE\n817.850772\nNaN\nNaN\n63.254271\n5.157482\n2.354558e+00\n4.797800e+04\n23.798701\n103.848909\n18.662856\n4.901293e+04\n39\n875.230849\n\n\n18517\n51377\nMontépreux\n45\n51377\nMONTEPREUX\n3184.753959\nNaN\nNaN\n195.644289\n5.289725\n5.886394e+01\n2.928200e+04\n26.790561\n191.338795\n19.141391\n3.296382e+04\n51\n732.529393\n\n\n13138\n34278\nSaint-Michel\n49\n34278\nSAINT-MICHEL\n4491.844291\nNaN\nNaN\n145.718340\n34.912656\n2.354558e+00\n2.514989e+04\n23.599874\n450.893244\n23.448204\n3.032267e+04\n34\n618.829907\n\n\n4333\n13039\nFos-sur-Mer\n15654\n13039\nFOS-SUR-MER\n305.092893\n1893.383189\n1.722723e+04\n50891.367548\n275500.374439\n2.296711e+06\n6.765119e+06\n9466.388806\n74631.401993\n42068.140058\n9.533813e+06\n13\n609.033668\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of the evolution of a production index\nYou have two CSV data sets available in the data/ folder:\n\nserie_glaces_valeurs.csv contains the monthly values of the production price index of the French ice cream and sorbet industry.\nserie_glaces_metadonnees.csv contains the associated metadata, including the codes indicating the data status.\n\nThe goal is to use Pandas to calculate:\n\nthe evolution of the index between each period (month)\nthe evolution of the index on a year-over-year basis (between a given month and the same month the following year).\n\n\nPart 1: Importing data\n\nImport the two CSV files into DataFrames. Note: in both cases, there are extraneous rows before the data that need to be skipped using the skiprows parameter of the read_csv() function.\nGive simple and relevant names to the various variables.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_values = pd.read_csv('data/serie_glaces_valeurs.csv', delimiter=';',\n                        skiprows=4, names=[\"period\", \"index\", \"code\"])\ndf_metadata = pd.read_csv('data/serie_glaces_metadonnees.csv', delimiter=';',\n                          skiprows=5, names=[\"code\", \"meaning\"])\n\n\n\n\n\nPart 2: Filtering relevant data\n\nMerge the two DataFrames to retrieve the meanings of the codes present in the data.\nFilter the data to keep only the “Normal Value” data.\nRemove the columns related to the codes, which we no longer need for the rest.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_merged = pd.merge(df_values, df_metadata, how='left', on='code')\n\ndf_clean = df_merged[df_merged['code'] == \"A\"]\ndf_clean = df_clean[[\"period\", \"index\"]]\n\n\n\n\n\nPart 3: Data preprocessing\nVerify if the types of variables are relevant according to their nature. If not, convert them with the appropriate functions.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_clean.info()\ndf_clean['period'] = pd.to_datetime(df_clean['period'])\ndf_clean['index'] = pd.to_numeric(df_clean['index'])\ndf_clean.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 198 entries, 3 to 200\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   period  198 non-null    object\n 1   index   198 non-null    object\ndtypes: object(2)\nmemory usage: 4.6+ KB\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 198 entries, 3 to 200\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype         \n---  ------  --------------  -----         \n 0   period  198 non-null    datetime64[ns]\n 1   index   198 non-null    float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 4.6 KB\n\n\n\n\n\n\nPart 4: Calculating periodic evolution\n\nUse the shift() method to create a new column containing the previous month’s index.\nCalculate the difference between the current index and the shifted index to obtain the (percentage) evolution from one month to the next.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_clean['previous_index'] = df_clean['index'].shift(1)\ndf_clean['evolution'] = ((df_clean['index'] - df_clean['previous_index']) / df_clean['previous_index']) * 100\n\n# Alternative method\ndf_clean['alternative_evolution'] = df_clean['index'].pct_change(periods=1) * 100\n\n\n\n\n\nPart 5: Calculating year-over-year evolution\nAs you saw in the previous exercise’s solution, the pct_change() method allows you to calculate an evolution between two periods. Use this method to calculate a year-over-year evolution for each month.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndf_clean[\"year_over_year_evolution\"] = df_clean['index'].pct_change(periods=12) * 100\ndf_clean.head(20)\n\n\n\n\n\n\n\n\nperiod\nindex\nprevious_index\nevolution\nalternative_evolution\nyear_over_year_evolution\n\n\n\n\n3\n2023-06-01\n115.3\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2023-05-01\n112.4\n115.3\n-2.515178\n-2.515178\nNaN\n\n\n5\n2023-04-01\n115.5\n112.4\n2.758007\n2.758007\nNaN\n\n\n6\n2023-03-01\n112.9\n115.5\n-2.251082\n-2.251082\nNaN\n\n\n7\n2023-02-01\n105.1\n112.9\n-6.908769\n-6.908769\nNaN\n\n\n8\n2023-01-01\n104.0\n105.1\n-1.046622\n-1.046622\nNaN\n\n\n9\n2022-12-01\n98.3\n104.0\n-5.480769\n-5.480769\nNaN\n\n\n10\n2022-11-01\n100.0\n98.3\n1.729400\n1.729400\nNaN\n\n\n11\n2022-10-01\n98.2\n100.0\n-1.800000\n-1.800000\nNaN\n\n\n12\n2022-09-01\n98.9\n98.2\n0.712831\n0.712831\nNaN\n\n\n13\n2022-08-01\n99.3\n98.9\n0.404449\n0.404449\nNaN\n\n\n14\n2022-07-01\n97.2\n99.3\n-2.114804\n-2.114804\nNaN\n\n\n15\n2022-06-01\n97.3\n97.2\n0.102881\n0.102881\n-15.611448\n\n\n16\n2022-05-01\n95.0\n97.3\n-2.363823\n-2.363823\n-15.480427\n\n\n17\n2022-04-01\n96.0\n95.0\n1.052632\n1.052632\n-16.883117\n\n\n18\n2022-03-01\n94.3\n96.0\n-1.770833\n-1.770833\n-16.474756\n\n\n19\n2022-02-01\n94.0\n94.3\n-0.318134\n-0.318134\n-10.561370\n\n\n20\n2022-01-01\n94.6\n94.0\n0.638298\n0.638298\n-9.038462\n\n\n21\n2021-12-01\n92.6\n94.6\n-2.114165\n-2.114165\n-5.798576\n\n\n22\n2021-11-01\n92.3\n92.6\n-0.323974\n-0.323974\n-7.700000",
    "crumbs": [
      "Data handling",
      "Processing tabular data with Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/numpy/tutorial.html",
    "href": "source/manipulation/numpy/tutorial.html",
    "title": "Numerical computing with NumPy",
    "section": "",
    "text": "As a statistician, you frequently need to manipulate series of numerical values and perform various mathematical operations, from the most common (mean, variance, etc.) to the more complex. As we did in previous tutorials, you can use Python’s fundamental objects, particularly lists, to perform such operations. However, in practice, you will prefer to use the reference library for scientific computing, NumPy, which provides both objects (arrays) and functions that greatly simplify performing all your calculations in Python efficiently.",
    "crumbs": [
      "Data handling",
      "Numerical computation with NumPy"
    ]
  },
  {
    "objectID": "source/manipulation/numpy/tutorial.html#numpy-1",
    "href": "source/manipulation/numpy/tutorial.html#numpy-1",
    "title": "Numerical computing with NumPy",
    "section": "NumPy",
    "text": "NumPy\nWe start by importing the NumPy library. As explained in a previous tutorial, it is common practice to assign it the alias np.\n\nimport numpy as np\n\n\nWhy use NumPy?\nRather than presenting the advantages of NumPy abstractly, let’s illustrate them through a simple example: element-wise multiplication of two vectors.\nWe generate two vectors containing integers from \\(0\\) to \\(99999\\), which we multiply element-wise. We first perform this using Python lists (function mult_list), then using NumPy (function mult_np), and compare the performance of both methods.\n\ndef mult_list(n):\n    a = range(n)\n    b = range(n)\n\n    c = []\n    for i in range(len(a)):\n        mult = a[i] * b[i]\n        c.append(mult)\n        \n    return c\n\ndef mult_np(n):\n    a_np = np.arange(n)\n    b_np = np.arange(n)\n    \n    c_np = a_np * b_np\n\n    return c_np\n\n\nn = 100000\n\n\n# Verify consistency on the first 10 elements\nprint(mult_list(n)[:10])\nprint(mult_np(n)[:10])\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n[ 0  1  4  9 16 25 36 49 64 81]\n\n\n\n%%timeit -n10\n\nmult_list(n)  # Performance of the list method\n\n16.4 ms ± 80 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%%timeit -n10\n\nmult_np(n)  # Performance of the NumPy method\n\n125 μs ± 23.4 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nThis example illustrates the main advantages of NumPy for scientific computing:\n\nCalculations are vectorized: multiplying two arrays naturally performs element-wise multiplication, unlike lists which do not support this operation. People familiar with R will recognize this as a familiar and very convenient property.\nAs a result of vectorization, the syntax is lighter and clearer: you directly see the operation being performed, reducing the risk of error.\nCalculations are automatically optimized by NumPy (through calls to pre-compiled C code), significantly reducing the time taken for mathematical operations (by a factor of 10 in our example).\n\n\n\nNumPy arrays\n\nDefinition\nThe entire NumPy library is based on a fundamental object: the array. An array is an object that contains a sequence of data and has two main characteristics:\n\nThe data contained in an array must be of homogeneous type, whereas a single list can contain objects of different natures.\nAn array has a fixed size at creation, whereas a list can dynamically grow (e.g., by adding elements via the append method).\n\nThese two constraints largely enable the performance gains and readable syntax that NumPy offers.\n\n\nCreation\nThere are different ways to create an array. The most standard way is to convert a list into an array using the array function from NumPy.\n\nl = [1, 2, 3]\na = np.array(l)\nprint(a)\n\n[1 2 3]\n\n\nAt first glance, the print function returns a representation identical to that of a list. Let’s check the type of our object.\n\ntype(a)\n\nnumpy.ndarray\n\n\nThe object is of type ndarray, which is the standard type corresponding to a NumPy array.\nWe have seen that an array has the property of containing homogeneous data types; in this case, integers. We can check the type of the data contained using the dtype attribute of an array.\n\na.dtype\n\ndtype('int64')\n\n\nAlthough NumPy is primarily a library for numerical computation, it is entirely possible to define arrays containing strings.\n\nb = np.array(['1', 'tiger'])\nb.dtype\n\ndtype('&lt;U5')\n\n\nThe default dtype of arrays containing strings is a bit peculiar, but this doesn’t matter in practice. Just remember its form.\nFinally, an important question: what happens if you try to define an array containing objects of heterogeneous types?\n\nc = np.array([1, 2, '3'])\nprint(c)\nprint(c.dtype)\n\n['1' '2' '3']\n&lt;U21\n\n\nAnswer: all objects are converted to strings by default.\n\n\nDimension\nArrays correspond to data tables, meaning they can be uni- or multi-dimensional. A 1-dimensional array looks like a vector (or list), a 2-dimensional array looks like a matrix, and so on.\nYou can display the number of dimensions of an array using the ndim attribute.\n\nc = np.array([1, 2, '3'])\nc.ndim\n\n1\n\n\nJust as we created a 1-dimensional array from a simple list, we can create a multi-dimensional array from a list of lists.\n\nd = np.array([[1, 2, 3], [4, 5, 6]])\nprint(d)\n\n[[1 2 3]\n [4 5 6]]\n\n\nWe converted a list containing 2 sub-lists with 3 elements each, resulting in a 2-dimensional array. Note that calling print displays a matrix with two rows and three columns.\n\nd.ndim\n\n2\n\n\nWe indeed have a 2-dimensional array. However, in practice, when handling multidimensional arrays, we also want to know the size of each dimension. In 2 dimensions, it’s the number of rows and columns. For this, we use the shape method, which returns a tuple containing the sizes of the different dimensions.\n\nd.shape\n\n(2, 3)\n\n\nThe first number gives the number of rows, the second the number of columns. We will revisit the order of dimensions later through the notion of axis.\n\n\nIndexing\nYou access the elements of a 1-dimensional array in the same way as those of a list.\n\na = np.array([1, 2, 3, 4, 5, 6])\n\nprint(a)\nprint()\nprint(a[1])\nprint()\nprint(a[2:5])\nprint()\nprint(a[-2])\n\n[1 2 3 4 5 6]\n\n2\n\n[3 4 5]\n\n5\n\n\nFor a multidimensional array, you need to specify the desired elements for each dimension of the array, separated by commas.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nprint(b)\nprint()\nprint(b[1, 3])\nprint()\nprint(b[1:3, 1:3])\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n8\n\n[[ 6  7]\n [10 11]]\n\n\nTo access a complete row, you can use : for the column dimension to specify “all columns”. Conversely, to retrieve a complete column.\n\nprint(b[1,:])\nprint()\nprint(b[:,2])\n\n[5 6 7 8]\n\n[ 3  7 11]\n\n\n\n\nModifying elements\nArray elements can be modified. To do this, combine the indexing syntax seen earlier with the assignment operator =.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nb[1, 1] = 18\nprint(b)\n\n[[ 1  2  3  4]\n [ 5 18  7  8]\n [ 9 10 11 12]]\n\n\nYou can also modify series of numbers, or even complete rows/columns, as long as you assign an element of the same size.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nb[:, 2] = [-1, -1, -1]\nb\n\narray([[ 1,  2, -1,  4],\n       [ 5,  6, -1,  8],\n       [ 9, 10, -1, 12]])\n\n\nUnlike lists, you generally do not add or remove elements from an array. This is because, as stated earlier, an array’s size is fixed at creation.\nIf you want to grow an array, you typically do so by starting with a list — which can grow — and then converting it to an array.\nIf you want to delete elements from an array, you can use the indexing syntax studied in the previous section to retrieve the sub-array of interest and assign it to a new variable.\n\n\nBoolean masks\nA significant advantage of NumPy arrays over lists is that they support boolean masks, allowing you to select elements of an array by passing an array of the same size containing booleans.\n\na = np.array([1, 2, 3])\na[[True, True, False]]\n\narray([1, 2])\n\n\nThis property opens many possibilities since it can be combined with the vectorization property of arrays. It becomes very easy to select elements according to conditions, even for multidimensional arrays.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\ncond = (b &gt; 6) & (b != 10)\n\nprint(cond)\nprint()\nprint(b[cond])\n\n[[False False False False]\n [False False  True  True]\n [ True False  True  True]]\n\n[ 7  8  9 11 12]\n\n\nAnd you can, of course, exploit this mechanism to modify elements according to a condition.\n\nb[cond] = -1\nprint(b)\n\n[[ 1  2  3  4]\n [ 5  6 -1 -1]\n [-1 10 -1 -1]]\n\n\nThis last example also illustrates an important property in NumPy called broadcasting: when replacing multiple elements of an array with a single-size element (not an array of the same size), all elements are replaced by this value.\n\n\n\nMathematical operations\n\nArithmetic on arrays\nAt the beginning of this tutorial, we saw that multiplying two arrays using\nthe * operator performs element-wise multiplication of the two arrays in a vectorized manner. Basic operations (+, -, *, and /) apply similarly to multidimensional arrays.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\nb = np.array([[3, 3, 1], [1, 3, 3]])\n\na * b\n\narray([[3, 6, 2],\n       [2, 6, 3]])\n\n\nWe again see the broadcasting property discussed in the previous section: when you perform an operation between an array and a single-size number, the operation is applied to each term in the array.\n\na * 4\n\narray([[4, 8, 8],\n       [8, 8, 4]])\n\n\n\n\nLinear algebra\nNumPy allows you to perform simple and efficient linear algebra operations on arrays. The complete list of available functions is presented in the official documentation (in English).\nFor example, the @ operator performs matrix multiplication (and no longer element-wise multiplication like *).\n\na = np.array([[1, 2, 3], [3, 2, 1]])\nb = np.array([[2, 3], [1, 3], [3, 1]])\n\na @ b\n\narray([[13, 12],\n       [11, 16]])\n\n\n\n\nMathematical functions\nNumPy offers a plethora of mathematical and statistical functions, such as sum, mean, min, round, log, etc. Applying them to one-dimensional objects poses no particular problem.\n\nprint(np.log(12))\nprint()\nprint(np.min([1, 2, 3]))\nprint()\nprint(np.mean([1, 2, 3]))\n\n2.4849066497880004\n\n1\n\n2.0\n\n\nHowever, in the multidimensional case, their use becomes a bit more subtle because you may want to aggregate along different dimensions. If nothing is specified, the aggregation is done over all the array elements.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a)\n\nnp.int64(10)\n\n\nBut how do you sum by rows? Or by columns? This is where a crucial and somewhat complex element of NumPy functions comes in: the axis parameter, which specifies the dimension along which to perform the operation.\nWhen not specified, as in the previous example, it defaults to None.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a, axis=None)  # same as np.sum(a)\n\nnp.int64(10)\n\n\nThe following figure helps visualize how axes work with NumPy, to specify the expected direction of aggregation correctly.\n\n\n\naxis\n\n\nThus, if you want to compute the sum of each column, for example, you need to aggregate along axis \\(0\\).\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a, axis=0)\n\narray([3, 4, 3])\n\n\nConversely, to get the sums of each row.\n\nnp.sum(a, axis=1)\n\narray([5, 5])\n\n\nFinally, note that mathematical functions that perform aggregation are generally also available as methods of an array. They work the same way, except that they do not take the array as an argument since they are already “attached” to it.\n\na.sum(axis=1)\n\narray([5, 5])\n\n\n\n\n\nConclusion\nNumPy is the quasi-standard library for scientific computing in Python. It is preferred whenever you want to perform operations on numerical data, especially when dealing with vectorized operations and/or multidimensional objects like matrices.\nThe possibilities offered by NumPy are vast, and we have only seen a glimpse. The official documentation presents all these possibilities. This cheat sheet can also be useful in case of forgetfulness. We will also see additional functions through the end-of-chapter exercises.",
    "crumbs": [
      "Data handling",
      "Numerical computation with NumPy"
    ]
  },
  {
    "objectID": "source/manipulation/numpy/tutorial.html#exercises",
    "href": "source/manipulation/numpy/tutorial.html#exercises",
    "title": "Numerical computing with NumPy",
    "section": "Exercises",
    "text": "Exercises\n\nQuestions de compréhension\n\n1/ What are the main advantages of NumPy?\n2/ What are the two main characteristics of a NumPy array?\n3/ What happens if you try to define an array containing objects of heterogeneous types?\n4/ What is the primary method for creating an array?\n5/ What information does the shape attribute of an array contain?\n6/ Can you add an element to an array? Remove an element?\n7/ What is a boolean mask, and what is it used for?\n8/ What is the broadcasting property?\n9/ What is the purpose of the axis parameter in NumPy’s mathematical functions?\n\n\n\n\nShow the solution\n\n\n1/ Calculations are vectorized, which greatly simplifies syntax and reduces the risk of errors. Additionally, calculations are automatically optimized by NumPy, significantly increasing performance.\n2/ The data contained in an array must be of homogeneous type. An array has a fixed size at creation.\n3/ All objects are interpreted as strings.\n4/ Create a list and then convert it to an array using the np.array function.\n5/ The shape attribute of an array returns a tuple that contains the size of each dimension, and thus also the number of dimensions.\n6/ There are functions that perform these operations, but they are not commonly used in practice since an array has a fixed size at creation.\n7/ A boolean mask is an array of boolean values (True and False) used to select elements from another array. It is particularly useful for selecting elements based on a condition (test).\n8/ When you perform an operation between an array and a single-size value (typically, an integer or a real number), the operation is applied to each element of the array.\n9/ The axis parameter specifies the dimension along which you want to perform an aggregation (math, stat functions, etc.).\n\n\n\n\n\nSimple manipulations of a DataFrame’s data\nA vector containing integers between 10 and 20 is defined in the following cell. Using NumPy array indexing:\n\nSelect the elements at positions 1, 3, and 4\nSelect all elements except the first one\nSelect all elements except the first and the last one\nSelect the first 3 elements\nSelect the last 5 elements\nSelect all even elements\nSelect all elements in reverse order (NB: the np.flip function can achieve the same result)\n\n\nX = np.arange(10, 21)\n\nprint(X)\n\n[10 11 12 13 14 15 16 17 18 19 20]\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nX = np.arange(10, 21)\n\nprint(X[[1, 3, 4]])\nprint(X[1:])\nprint(X[1:-1])\nprint(X[:3])\nprint(X[-5:])\nprint(X[::2])\nprint(X[::-1])\n\n[11 13 14]\n[11 12 13 14 15 16 17 18 19 20]\n[11 12 13 14 15 16 17 18 19]\n[10 11 12]\n[16 17 18 19 20]\n[10 12 14 16 18 20]\n[20 19 18 17 16 15 14 13 12 11 10]\n\n\n\n\n\n\nSelecting elements in a matrix\nA 5x5 matrix containing integers from 0 to 24 is defined in the following cell. Using NumPy array indexing:\n\nSelect the value \\(19\\)\nSelect the 2nd row\nSelect the 4th column\nSelect the central 3x3 submatrix\nSelect the diagonal elements (NB: the np.diag function can perform the same operation much more easily)\n\n\nY = np.arange(0, 25).reshape((5, 5))\n\nprint(Y)\n\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]]\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nY = np.arange(0, 25).reshape((5, 5))\n\nprint(Y[3, 4])\nprint(Y[1, :])\nprint(Y[:, 3])\nprint(Y[1:4, 1:4])\nprint(Y[np.arange(0, 5), np.arange(0, 5)])\n\n19\n[5 6 7 8 9]\n[ 3  8 13 18 23]\n[[ 6  7  8]\n [11 12 13]\n [16 17 18]]\n[ 0  6 12 18 24]\n\n\n\n\n\n\nSome calculations\nTwo 3x3 square matrices are defined as NumPy arrays in the following cell. Based on these matrices, perform the following mathematical operations:\n\nMultiply all elements of X by 3\nDivide the elements of Y by those of X\nApply the log function to all elements of Y\nSquare all elements of X\nPerform matrix multiplication of X and Y\nTranspose the Y matrix\n\nNB: You can find the necessary functions in the documentation or using a search engine.\n\nX = np.array([[1,2,3],\n              [4,5,6],\n              [7,8,9]])\n\nY = np.array([[10,11,12],\n              [13,14,15],\n              [16,17,18]])\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nX = np.array([[1,2,3],\n              [4,5,6],\n              [7,8,9]])\n\nY = np.array([[10,11,12],\n              [13,14,15],\n              [16,17,18]])\n\nprint(3 * X)\nprint()\nprint(Y / X)\nprint()\nprint(np.log(Y\n\n))\nprint()\nprint(np.square(X))\nprint()\nprint(Y @ X)\nprint()\nprint(Y.T)\n\n[[ 3  6  9]\n [12 15 18]\n [21 24 27]]\n\n[[10.          5.5         4.        ]\n [ 3.25        2.8         2.5       ]\n [ 2.28571429  2.125       2.        ]]\n\n[[2.30258509 2.39789527 2.48490665]\n [2.56494936 2.63905733 2.7080502 ]\n [2.77258872 2.83321334 2.89037176]]\n\n[[ 1  4  9]\n [16 25 36]\n [49 64 81]]\n\n[[138 171 204]\n [174 216 258]\n [210 261 312]]\n\n[[10 13 16]\n [11 14 17]\n [12 15 18]]\n\n\n\n\n\n\nInitializing arrays of various types\nIn the tutorial, we saw that the standard method to create a NumPy array is to initialize a list and then convert it to an array. You can also use native NumPy functions that create arrays of a given size containing basic values (e.g., near-empty values, zeros, ones, a user-specified value, etc.).\nFor example, to create a 3x2 matrix containing zeros, the syntax is:\n\nnp.zeros((3, 2))\n\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.]])\n\n\nReferring to the documentation of these functions, generate:\n\nA vector (1-dimensional array) containing the value \\(1\\) repeated 18 times (using the np.ones function)\nA 3-dimensional array with sizes 2, 3, and 5 respectively, containing only zeros (using the np.zeros function)\nA matrix (2-dimensional array) with 4 rows and 3 columns, containing only the value 5 (using the np.full function)\nA 5x5 identity matrix, i.e., a matrix with 5 rows and 5 columns containing \\(1\\) on its diagonal and \\(0\\) elsewhere (using the np.eye function)\nA vector containing integers from \\(0\\) to \\(99\\) inclusive (using the np.arange function)\nA vector containing even integers from \\(0\\) to \\(99\\) inclusive (using the np.arange function)\nA vector containing 5 values evenly spaced between \\(2\\) and \\(3\\) inclusive (using the np.linspace function)\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\na = np.ones((18,))\nprint(a)\nprint()\n\nb = np.zeros((2, 3, 5))\nprint(b)\nprint()\n\nc = np.full((4, 3), fill_value=5)\nprint(c)\nprint()\n\nd = np.eye(5)\nprint(d)\nprint()\n\ne = np.arange(0, 100)\nprint(e)\nprint()\n\nx = np.arange(0, 100, step=2)\nprint(x)\nprint()\n\ny = np.linspace(2.0, 3.0, num=5)\nprint(y)\nprint()\n\n[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n\n[[[0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0.]]\n\n [[0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0.]\n  [0. 0. 0. 0. 0.]]]\n\n[[5 5 5]\n [5 5 5]\n [5 5 5]\n [5 5 5]]\n\n[[1. 0. 0. 0. 0.]\n [0. 1. 0. 0. 0.]\n [0. 0. 1. 0. 0.]\n [0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 1.]]\n\n[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n 96 97 98 99]\n\n[ 0  2  4  6  8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46\n 48 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 84 86 88 90 92 94\n 96 98]\n\n[2.   2.25 2.5  2.75 3.  ]\n\n\n\n\n\n\n\nDrawing a vector from a normal distribution\nReferring to the documentation of NumPy’s random number generation functions, generate a vector X of size 10000 containing numbers drawn from a normal distribution with mean 0 and variance 2.\nThen verify using NumPy’s mathematical functions that the mean and variance of your sample are consistent with the expected values.\nHint: Pay attention to how the variance is specified in the NumPy function for generating a normal distribution.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nX = np.random.normal(0, np.sqrt(2), 10000)\n\nprint(np.mean(X), np.var(X))\n\n0.006218358750433234 1.9532808780267492\n\n\n\n\n\n\nDrawing a matrix from a uniform distribution\nReferring to the documentation of NumPy’s random number generation functions, generate a matrix U of size 1000 by 1000 containing numbers drawn from a uniform distribution in the interval [-1, 1].\nUsing the np.all function and a boolean test, verify that all numbers in U are indeed between -1 and 1.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nN = 1000\nU = np.random.uniform(-1, 1, size=(N, N))\n\nnp.all((U &gt;= -1) & (U &lt;= 1))\n\nnp.True_\n\n\n\n\n\n\nBinarizing a matrix of numbers\nSometimes, you may need to binarize a numerical matrix, meaning to set a threshold beyond which numerical values are set to 1 and to 0 below. NumPy offers several methods for performing such an operation; we will see two.\nIn the following cell, a 6x6 matrix X is generated, containing integers randomly chosen between 0 and 49. You need to binarize this matrix in two different ways without overwriting it (i.e., the binary matrix should be assigned to a different variable than X, and X should not be modified):\n\nFirst method: using the np.zeros function and boolean masks\nSecond method: using the np.where function (see doc)\n\n\nX = np.random.randint(0, 50, size=(6, 6))\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nX = np.random.randint(0, 50, size=(6, 6))\n\n# First possibility: using boolean masks\nA = np.zeros((6, 6))\nA[X &gt; 25] = 1\n\n# Second possibility: using the np.where function\nB = np.where(X &gt; 25, 1, 0)\n\nprint(X)\nprint()\nprint(A)\nprint()\nprint(B)\n\n[[47 42 36  3 31 43]\n [21 18 28  9 19 18]\n [40 39 23 12 12  8]\n [36 48 38 24 20 47]\n [39 12 13 11 45 37]\n [19 28  9 49  4 19]]\n\n[[1. 1. 1. 0. 1. 1.]\n [0. 0. 1. 0. 0. 0.]\n [1. 1. 0. 0. 0. 0.]\n [1. 1. 1. 0. 0. 1.]\n [1. 0. 0. 0. 1. 1.]\n [0. 1. 0. 1. 0. 0.]]\n\n[[1 1 1 0 1 1]\n [0 0 1 0 0 0]\n [1 1 0 0 0 0]\n [1 1 1 0 0 1]\n [1 0 0 0 1 1]\n [0 1 0 1 0 0]]\n\n\n\n\n\n\nBattleship\nThe objective of this exercise is to program a very basic battleship game using only NumPy objects and functions.\nA 5x5 grid is defined in the following cell as an array, with \\(1\\) values representing the presence of a ship. You need to program a shoot function that:\n\nTakes as input an \\(x\\) coordinate (row index) and a \\(y\\) coordinate (column index)\nTests if at least one \\(1\\) value is present in the grid:\n\nIf yes:\n\nIf there is a ship at the address (x, y), replace the \\(1\\) value with \\(2\\) and print “Hit!”\nOtherwise, print “Missed!”\n\nIf no:\n\nprint “Game over!”\n\n\n\nThen perform some tests to ensure your function works as expected.\n\nX = np.array([[1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1],\n              [1, 0, 0, 0, 0], [0, 1, 1, 1, 1]])\nprint(X)\n\n[[1 1 1 0 0]\n [0 0 0 0 1]\n [1 0 0 0 1]\n [1 0 0 0 0]\n [0 1 1 1 1]]\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nX = np.array([[1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1],\n              [1, 0, 0, 0, 0], [0, 1, 1, 1, 1]])\n\ndef shoot(x, y):\n    if np.any(X == 1):\n        if X[x, y] == 1:\n            print(\"Hit!\")\n            X[x, y] = 2\n        else:\n            print(\"Missed!\")\n        print(X)\n        print()\n    else:\n        print(\"Game over!\")\n\nshoot(0, 1)\nshoot(1, 0)\nshoot(0, 2)\n\nHit!\n[[1 2 1 0 0]\n [0 0 0 0 1]\n [1 0 0 0 1]\n [1 0 0 0 0]\n [0 1 1 1 1]]\n\nMissed!\n[[1 2 1 0 0]\n [0 0 0 0 1]\n [1 0 0 0 1]\n [1 0 0 0 0]\n [0 1 1 1 1]]\n\nHit!\n[[1 2 2 0 0]\n [0 0 0 0 1]\n [1 0 0 0 1]\n [1 0 0 0 0]\n [0 1 1 1 1]]\n\n\n\n\n\n\n\nOne Hot Encoding\nIn statistics, it is common to numerically encode a vector of categories. A frequent way to encode categories is one hot encoding (OHE): each value is represented by a binary vector, containing a \\(1\\) in the column corresponding to the category and \\(0\\) elsewhere.\nIn the following cell, we encode PCS in OHE format using a function from the scikit-learn package. The exercise’s objective is to reproduce this encoding using only NumPy library functions.\nHint: You can use the np.unique, np.zeros, and np.arange functions.\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nvalues = np.array([\"21\", \"46\", \"47\", \"23\", \"66\", \"82\", \"82\"])\n\nprint(OneHotEncoder().fit_transform(values.reshape((-1, 1))).todense())\n\n[[1. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 0. 1.]]\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nvalues = np.array([\"21\", \"46\", \"47\", \"23\", \"66\", \"82\", \"82\"])\n\ncategories, pos = np.unique(values, return_inverse=True)\nn_values = values.shape[0]\nn_categories = categories.shape[0]\n\nohe = np.zeros((n_values, n_categories))\nohe[np.arange(n_values), pos] = 1\nohe\n\narray([[1., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0.],\n       [0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 0., 1.]])",
    "crumbs": [
      "Data handling",
      "Numerical computation with NumPy"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html",
    "href": "source/fundamentals/data-structures1/tutorial.html",
    "title": "Data Structures 1: Lists and Tuples",
    "section": "",
    "text": "In this tutorial, we will focus on basic data structures in Python: lists and tuples. Data structures can be seen as containers because they allow you to store, organize, and access data. Lists and tuples are sequential containers: the elements they contain are ordered, and their position is recorded in an index.",
    "crumbs": [
      "Fundamentals",
      "Data structures 1: lists and tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html#lists",
    "href": "source/fundamentals/data-structures1/tutorial.html#lists",
    "title": "Data Structures 1: Lists and Tuples",
    "section": "Lists",
    "text": "Lists\n\nDefinition\nIn the previous tutorial, we saw that strings were sequences of characters. Lists are also sequences, meaning ordered series of elements, but more general: the elements can be of different types.\nLists are constructed with square brackets [], and the elements of the list are separated by commas.\nLet’s assign a first list to a variable a:\n\na = [1, 2, 3]\nprint(a)\n\n[1, 2, 3]\n\n\nThe list a consists of integers, but a list can practically contain objects of any type.\n\nb = [\"a sequence\", 56, \"d\"]\nprint(b)\n\n['a sequence', 56, 'd']\n\n\nIt is also possible to create lists of lists (and so on), which allows for creating hierarchical data structures.\n\nc = [\"a sequence\", 56, [\"this list is nested\", 75, \"o\"]]\nprint(c)\n\n['a sequence', 56, ['this list is nested', 75, 'o']]\n\n\nA nested list can also be constructed from already defined lists.\n\nitem1 = [\"coffee\", \"500g\"]\nitem2 = [\"biscuits\", \"20\"]\nitem3 = [\"milk\", \"1L\"]\ninventory = [item1, item2, item3]\nprint(inventory)\n\n[['coffee', '500g'], ['biscuits', '20'], ['milk', '1L']]\n\n\nHowever, in the next tutorial, we will see that dictionaries are generally more suitable data structures than lists for representing hierarchical data.\n\n\nList Length\nLike strings, you can use the len function to count the number of elements in a list.\n\nd = [\"this\", \"is\", \"a\", \"list\"]\nlen(d)\n\n4\n\n\n\n\nIndexing\nSince lists are sequences, they are indexed similarly to strings. It is important to remember that position numbering starts at 0 in Python.\n\n# Third element of the list a\nprint(a[2])\n\n3\n\n\nOf course, it is not possible to request an element that does not exist. Python returns an error indicating that the requested index is out of bounds.\n\nprint(a[5])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[46], line 1\n----&gt; 1 print(a[5])\n\nIndexError: list index out of range\n\n\n\nTo index a list contained within another list, use double indexing.\n\n# First element of the sublist at the second position of list c\nprint(c[2][0])\n\nthis list is nested\n\n\nIn terms of indexing, everything that was possible with strings is also possible with lists.\n\n# All elements from the 1st position\nprint(b[1:])\n\n[56, 'd']\n\n\n\n# Reverse a list\nprint(a[::-1])\n\n[3, 2, 1]\n\n\n\n\nModifying Elements\nIt is possible to modify elements of a list manually, with a syntax similar to variable assignment.\n\n# Reassign an element\nd = [1, 2, \"toto\", 4]\nd[2] = 3\nprint(d)\n\n[1, 2, 3, 4]\n\n\n\n# Substitute an element\na = [1, 2, 3]\nb = [\"do\", \"re\", \"mi\"]\nb[0] = a[2]\nprint(b)\n\n[3, 're', 'mi']\n\n\n\n\nDeleting Elements\nThe del statement allows you to delete an element by position. The elements that were after the deleted element then have their index reduced by 1.\n\ne = [1, \"do\", 6]\nprint(e)\nprint(e[2])\n\ndel e[1]\nprint(e)\nprint(e[1])\n\n[1, 'do', 6]\n6\n[1, 6]\n6\n\n\n\n\nSome Useful Properties\nAgain, we find properties inherent to sequences.\n\n# Concatenation\n[1, 2, 3] + [\"a\", 12]\n\n[1, 2, 3, 'a', 12]\n\n\n\n# Replication\n[\"a\", \"b\", \"c\"] * 3\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c']\n\n\n\n\nSome Useful Methods\nAs with strings, lists have many built-in methods, which are used in the format object.method(parameters). The most useful ones are presented below; other methods will be used in the end-of-section exercises.\n\n# Add an element\na = [1, 2, 3]\na.append(4)\nprint(a)\n\n[1, 2, 3, 4]\n\n\n\n# Delete an element by position\nb = [\"do\", \"re\", \"mi\"]\nb.pop(0)\nprint(b)\n\n['re', 'mi']\n\n\n\n# Delete an element by value\nb = [\"do\", \"re\", \"mi\"]\nb.remove(\"mi\")\nprint(b)\n\n['do', 're']\n\n\n\n# Reverse a list\nl = [1, 2, 3, 4, 5]\nl.reverse()\nprint(l)\n\n[5, 4, 3, 2, 1]\n\n\n\n# Find the position of an element\nb = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nb.index(\"d\")\n\n3",
    "crumbs": [
      "Fundamentals",
      "Data structures 1: lists and tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html#tuples-1",
    "href": "source/fundamentals/data-structures1/tutorial.html#tuples-1",
    "title": "Data Structures 1: Lists and Tuples",
    "section": "Tuples",
    "text": "Tuples\n\nDefinition\nTuples are another basic data structure in Python, similar to lists in their functionality. However, there is a fundamental difference: while the elements of a list can be modified by position as we saw earlier, tuples are immutable. Thus, the elements of a tuple cannot be changed without completely redefining the tuple.\nWhen is it relevant to use a tuple rather than a list? In practice, tuples are much less frequently used than lists. Tuples are generally used to store data that is not meant to be modified during the execution of our Python program. This helps prevent data integrity issues, i.e., unwanted modification of input data. This can sometimes save long and tedious debugging sessions.\nAnother minor difference is that tuples are written with parentheses instead of square brackets. The different elements are still separated by commas.\n\nx = (1, 2, \"mi\", \"fa\", 5)\nx\n\n(1, 2, 'mi', 'fa', 5)\n\n\nTo clearly distinguish from the normal use of parentheses (in calculations or to delimit expressions), a tuple with a single element is defined with a comma after the first element.\n\nx1 = (\"a\", )\nx1\n\n('a',)\n\n\nLet’s verify that it is impossible to modify or add an element to a tuple.\n\nt = (\"do\", \"rez\", \"mi\")\nt[1] = \"re\"\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[62], line 2\n      1 t = (\"do\", \"rez\", \"mi\")\n----&gt; 2 t[1] = \"re\"\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\n\nt = (\"do\", \"re\", \"mi\")\nt.append(\"fa\")\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[63], line 2\n      1 t = (\"do\", \"re\", \"mi\")\n----&gt; 2 t.append(\"fa\")\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\n\n\nFunctionality\nTuples are indexed like lists.\n\nprint(x[0])\nprint(x[3:5])\n\n1\n('fa', 5)\n\n\nAnd can also be used hierarchically.\n\nt1 = (\"a\", \"b\", \"c\")\nt2 = (1, 2, 3)\nt3 = (t1, \"and\", t2)\n\nprint(t3)\nprint(t3[2][1])\n\n(('a', 'b', 'c'), 'and', (1, 2, 3))\n2\n\n\nTuples share some built-in methods with lists: those that do not cause modification of the object.\n\nt = (\"do\", \"re\", \"mi\")\nt.index(\"do\")\n\n0\n\n\n\nt = (\"do\", \"re\", \"mi\", \"re\", \"do\")\nt.count(\"re\")\n\n2\n\n\n\n\nConversion\nThe list and tuple functions allow you to convert a list to a tuple and vice versa.\n\ntuple([\"do\", \"re\", \"mi\"])\n\n('do', 're', 'mi')\n\n\n\nlist((1, 2, 3, 4, 5))\n\n[1, 2, 3, 4, 5]\n\n\nThese functions have other practical uses, which we will see in exercises.",
    "crumbs": [
      "Fundamentals",
      "Data structures 1: lists and tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html#exercises",
    "href": "source/fundamentals/data-structures1/tutorial.html#exercises",
    "title": "Data Structures 1: Lists and Tuples",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension Questions\n\nWhy are lists and tuples called containers?\nWhat is the common point between lists and strings?\nHow is the order of elements in a sequence recorded in Python?\nWhat is the fundamental difference between a list and a tuple?\nWhen is it more advantageous to use a tuple rather than a list?\nCan you have elements of different types (e.g., int and string) in the same list? In the same tuple?\n\n\n\n\nShow the solution\n\n\n1/ Lists and tuples are called containers because they allow storing and organizing a collection of elements of different nature in a single data structure.\n2/ Lists and strings are both ordered sequences of elements that can be queried by position. In the case of a string, each element is itself a string. In the case of a list, the elements can be of different nature (string, list, tuple, etc.).\n3/ Each element of a sequence has a unique position, called an index, which starts at 0 for the first element, 1 for the second, and so on. The elements are stored in the order they are added.\n4/ A list is a mutable object: you can add, delete, or modify elements of a list after its creation. In contrast, tuples are immutable: once a tuple is defined, you cannot change its elements, add or delete elements.\n5/ Due to their immutability, tuples are particularly suitable for storing data that you want to ensure will not be modified by mistake. For example, to store constants of an algorithm (parameters, geographical coordinates, file paths, etc.).\n6/ Yes, it is quite possible to have elements of different types in the same list or tuple. These elements can be of basic types (e.g., int and string), but also containers (e.g., list, tuple, dictionary, etc.).\n\n\n\n\n\nThe 4 Seasons\nCreate 4 lists named after the 4 seasons, each containing the names of the associated months (months of changing seasons will be attributed to the previous season). Then\ncreate a list seasons containing the 4 lists. Try to predict what the following instructions will return (object type, number of elements, and content), then verify.\n\nseasons\nseasons[0]\nseasons[0][0]\nseasons[1][-1]\nseasons[2][:3]\nseasons[1][1:2] + seasons[-1][3:]\nseasons[2:]\nseasons + seasons[0]\nseasons[3][::]\nseasons[3][::-1]\nseasons * 3\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nspring = [\"April\", \"May\", \"June\"]\nsummer = [\"July\", \"August\", \"September\"]\nautumn = [\"October\", \"November\", \"December\"]\nwinter = [\"January\", \"February\", \"March\"]\n\nseasons = [spring, summer, autumn, winter]\n\nl = seasons\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[0][0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[1][-1]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[2][:3]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[1][1:2] + seasons[-1][3:]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[2:]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons + seasons[0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[3][::]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons[3][::-1]\nprint(type(l), len(l), l, \"\\n\")\n\nl = seasons * 3\nprint(type(l), len(l), l, \"\\n\")\n\n&lt;class 'list'&gt; 4 [['April', 'May', 'June'], ['July', 'August', 'September'], ['October', 'November', 'December'], ['January', 'February', 'March']] \n\n&lt;class 'list'&gt; 3 ['April', 'May', 'June'] \n\n&lt;class 'str'&gt; 5 April \n\n&lt;class 'str'&gt; 9 September \n\n&lt;class 'list'&gt; 3 ['October', 'November', 'December'] \n\n&lt;class 'list'&gt; 1 ['August'] \n\n&lt;class 'list'&gt; 2 [['October', 'November', 'December'], ['January', 'February', 'March']] \n\n&lt;class 'list'&gt; 7 [['April', 'May', 'June'], ['July', 'August', 'September'], ['October', 'November', 'December'], ['January', 'February', 'March'], 'April', 'May', 'June'] \n\n&lt;class 'list'&gt; 3 ['January', 'February', 'March'] \n\n&lt;class 'list'&gt; 3 ['March', 'February', 'January'] \n\n&lt;class 'list'&gt; 12 [['April', 'May', 'June'], ['July', 'August', 'September'], ['October', 'November', 'December'], ['January', 'February', 'March'], ['April', 'May', 'June'], ['July', 'August', 'September'], ['October', 'November', 'December'], ['January', 'February', 'March'], ['April', 'May', 'June'], ['July', 'August', 'September'], ['October', 'November', 'December'], ['January', 'February', 'March']] \n\n\n\n\n\n\n\nDoing Scales\nBy adding, deleting, and modifying elements, clean up the following list so that it contains the musical notes “do re mi fa sol la si” in the correct order.\nl = [\"do\", \"re\", \"re\", \"re\", \"fa\", \"sol\", \"solsi\", \"la\"]\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nl = [\"do\", \"re\", \"re\", \"re\", \"fa\", \"sol\", \"solsi\", \"la\"]\n\ndel l[1]  # You could also use: l.pop(1)\nl[2] = \"mi\"\ndel l[5]\nl.append(\"si\")\n\nprint(l)\n\n['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\n\nThis example was simply to practice modifying and deleting elements. In practice, it would have been much simpler to directly create the correct list.\n\n\n\n\nList Reversal\nPropose two methods to reverse the list [\"a\", \"random\", \"list\"]. What is the major difference between the two methods?\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nl1 = [\"a\", \"random\", \"list\"]\nl1.reverse()\nprint(l1)\n\nl2 = [\"a\", \"random\", \"list\"]\nprint(l2[::-1])\nprint(l2)\n\n['list', 'random', 'a']\n['list', 'random', 'a']\n['a', 'random', 'list']\n\n\nThe reverse method modifies the list “in place”: the list is permanently reversed after executing it. In contrast, the method that reverses the list using indexing returns a new list and does not modify the existing one. To make this change permanent, you would need to overwrite the existing list or create a new one.\n\nl2 = l2[::-1]\nprint(l2)\n\n['list', 'random', 'a']\n\n\n\n\n\n\nPop’it\nWe saw that the my_list.pop(i) statement removes the i-th element from the list my_list. Using the Python documentation or a Google search, determine the default behavior of this method, i.e., what happens when no parameter is given to the pop function. Verify that you observe this behavior with an example of your choice.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nl = [\"do\", \"re\", \"mi\"]\nl.pop()\nprint(l)\n\n['do', 're']\n\n\n\n\n\n\nMin and Max of Different Lists\nThere are many more built-in methods for lists than those we have already seen. For example: min and max. Verify their behavior:\n\non a list composed solely of numeric objects (int and float);\non a list composed solely of strings;\non a list composed of a mix of numeric and textual objects.\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\na = [5, 800, 9.92, 0]\nb = [\"do\", \"re\", \"mi\", \"fa\", \"sol\"]\nc = [1, \"mix\", \"of\", 2]\n\nprint(min(a), max(a))\nprint(min(b), max(b))\nprint(min(c), max(c))\n\n0 800\ndo sol\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[80], line 7\n      5 print(min(a), max(a))\n      6 print(min(b), max(b))\n----&gt; 7 print(min(c), max(c))\n\nTypeError: '&lt;' not supported between instances of 'str' and 'int'\n\n\n\nThe third expression returns an error: there is no relevant order relationship.\n\n\n\n\nEmpty List\nTry creating an empty list. Verify its type. What could be the use of such an object?\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nl = []\nprint(l)\nprint(type(l))\n\n[]\n&lt;class 'list'&gt;\n\n\nWe can indeed create an empty list. But what is the use? A very common use is to initialize a list, which will then be filled as iterations of a loop progress. Loops will be the subject of a future tutorial; but here is a simple example of such use.\n\nfor i in range(10):\n    l.append(i)\n    \nprint(l)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n\n\n\nThe list Function\nIn the tutorial, we saw the list and tuple functions that allow converting from one type to the other. In reality, the functionality of these functions is more subtle: the code list(my_object) returns the “list version” of that object, just as str(3) returns '3', i.e., the string version of the integer 3.\nUsing the list function, find the “list versions” of the following objects:\n\nthe tuple a = (1, 2, 3);\nthe string b = \"hello\";\nthe integer c = 5\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\na = (1, 2, 3)\nprint(list(a))\n\nb = \"hello\"\nprint(list(b))\n\nc = 5\nprint(list(c))\n\n[1, 2, 3]\n['h', 'e', 'l', 'l', 'o']\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[85], line 8\n      5 print(list(b))\n      7 c = 5\n----&gt; 8 print(list(c))\n\nTypeError: 'int' object is not iterable\n\n\n\nThe last expression returns an error: an integer is not a sequence, so a “list version” does not make sense. However, it is of course possible to create a list with a single element 5.\n\nd = [5]\nprint(d)\n\n[5]\n\n\n\n\n\n\nImmutability of Tuples\nWe saw that tuples are immutable. But does this property transfer recursively? For example, is a list contained in a tuple itself immutable? Verify with an example of your choice.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nt = (1, 2, [\"a\", \"list\"])\nt[2][0] = 26\nprint(t)\n\n(1, 2, [26, 'list'])\n\n\nVerdict: immutability only applies to the first level. It does not transfer to sub-elements.\n\n\n\n\nSequence Unpacking\nRead the section on sequence packing and unpacking in the Python documentation. Unpacking is a commonly used feature in practice. Verify that it works on the various sequential objects we have seen so far (strings, lists, and tuples).\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nx, y, z = \"abc\"\nprint(y)\n\na, b, c, d = [\"do\", \"re\", \"mi\", \"fa\"]\nprint(c)\n\nr, s, t, u = (\"a\", \"tuple\", \"of\", \"test\")\nprint(r)\n\nb\nmi\na",
    "crumbs": [
      "Fundamentals",
      "Data structures 1: lists and tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html",
    "href": "source/fundamentals/functions/tutorial.html",
    "title": "Functions",
    "section": "",
    "text": "In previous tutorials, we studied how tests and loops work, allowing us to write Python programs that make automated decisions. In practice, a program will generally consist of different blocks, each executing an action or a group of actions (e.g., data import, data cleaning, statistical modeling, etc.). Furthermore, some of these actions are repeated with slight differences throughout a program (e.g., importing multiple different datasets). It will be useful to model each of these actions as a function, a sort of mini-program within the overall program. Using functions is a best practice in programming, as they make the logical structure of the code more explicit and help reduce code duplication.",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#definition",
    "href": "source/fundamentals/functions/tutorial.html#definition",
    "title": "Functions",
    "section": "Definition",
    "text": "Definition\nA function can be defined as a structured block of code that:\n\ntakes a set of arguments (Python objects) as input\nperforms a specific action through a set of instructions\nreturns a result (a Python object) as output\n\nWe have already seen and used several functions in previous tutorials (range, len, etc.). We have also used methods, which are simply functions attached to a particular type of object. Let’s use a well-known function to illustrate their general operation.\n\nlen('do re mi fa sol')\n\n15\n\n\nIn this example, the len function:\n\ntakes an argument as input (a string)\ncalculates the number of characters present in the string\nreturns this number as output\n\nThe “set of instructions” that calculate the length of the string is not known. As a user, you only need to know what the function takes as input and what it returns as output. This is true for cases where you use Python’s built-in functions or functions from trusted Python libraries. Such functions are referred to as “black boxes.”\nIn practice, you will want to define your own functions to structure your code and reuse it in analyses.",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#syntax",
    "href": "source/fundamentals/functions/tutorial.html#syntax",
    "title": "Functions",
    "section": "Syntax",
    "text": "Syntax\nThe def statement is used to define a function.\n\ndef welcome(name):\n    msg = \"Greetings \" + name + \"!\"\n    return msg\n\nLet’s analyze the syntax of the function definition:\n\na def statement that:\n\nspecifies the name of the function (here, welcome)\nspecifies the expected arguments in parentheses (here, a single argument: name)\nends with : like the different statements we have seen\n\na set of operations that will be performed by the function, which must be indented one level relative to the def statement\na return statement that specifies what the function will return when called (here, the content of the msg variable)\n\nDefining a function as above makes the function’s code available in the Python environment. It is only when the function is called in the code, with arguments, that the contained code is executed and produces a result.\n\nwelcome(\"Miranda\")\n\n'Greetings Miranda!'\n\n\nAs explained in the introduction, the main purpose of a function is to reuse code without duplicating it in the program.\n\nwelcome(\"Romuald\")\n\n'Greetings Romuald!'",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#passing-arguments",
    "href": "source/fundamentals/functions/tutorial.html#passing-arguments",
    "title": "Functions",
    "section": "Passing Arguments",
    "text": "Passing Arguments\n\nPrinciple\nWhen you call a function and specify arguments, you are “passing” arguments to it. These arguments then become variables that can be used within the context of the function. Unlike a for loop, the variables created do not persist after the function call.\n\ndef addition(x, y):\n    return x + y\n\n\naddition(5, 3)\n\n8\n\n\n\nx  # The variable does not persist in memory after the function call\n\n5\n\n\nNote: We will look more closely at this behavior later in the tutorial through the concepts of global and local variables.\n\n\nNumber of Arguments\nThe number of arguments you can pass to a function varies. Strictly speaking, you can define a function that does not need any arguments, although this is rarely useful in practice.\n\ndef nine():\n    return 9\n\n\na = nine()\na\n\n9\n\n\n\n\nPassing by Position and Passing by Keyword\nIn Python, functions allow two modes of passing arguments:\n\npassing by position, which is the mode we have seen in all previous examples: arguments are passed to the function in the order they were defined, without specifying the parameter name.\npassing by keyword: you specify the parameter name when passing the argument, which allows you not to follow the order specified during the definition.\n\nLet’s illustrate this difference with a function that simply performs a division.\n\ndef division(x, y):\n    return x / y\n\n\ndivision(4, 2)  # Passing by position\n\n2.0\n\n\n\ndivision(x=4, y=2)  # Passing by keyword\n\n2.0\n\n\nIn the case of passing by position, maintaining the order is imperative.\n\nprint(division(0, 5))\nprint(division(5, 0))\n\n0.0\n\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[51], line 2\n      1 print(division(0, 5))\n----&gt; 2 print(division(5, 0))\n\nCell In[48], line 2, in division(x, y)\n      1 def division(x, y):\n----&gt; 2     return x / y\n\nZeroDivisionError: division by zero\n\n\n\nIn the case of passing by keyword, the order no longer matters.\n\nprint(division(x=0, y=5))\nprint(division(y=5, x=0))\n\n0.0\n0.0\n\n\n\n\nMandatory and Optional Arguments\nWhen defining a function, it is common to want to mix arguments that the user must specify and optional arguments that specify a default behavior of the function but can be changed if needed.\nLet’s see how we can modify the behavior of the print function using an optional argument.\n\nprint(\"hello\")\nprint(\"hello\")\n\nhello\nhello\n\n\n\nprint(\"hello\", end=' ')\nprint(\"hello\")\n\nhello hello\n\n\nWe modified the behavior of the first print call via the optional end parameter. By default, this value is set to '\\n', meaning a newline. We changed it to a space in the second cell, hence the difference in result.\nThis example also illustrates the link between the mandatory or optional nature of an argument and its passing mode:\n\ngenerally, mandatory arguments are passed by position. They can also be passed by keyword, but since they are “expected,” they are usually passed by position for conciseness\noptional arguments must be passed by keyword, to clearly indicate that the default behavior of the function is being modified\n\nHow do you specify that an argument is optional when defining a function? Simply by specifying a default value for the argument. For example, let’s build a function that concatenates two strings and allows the user to specify a separator.\n\ndef concat_string(str1, str2, sep=''):\n    return str1 + sep + str2\n\n\nconcat_string('hello', 'world')  # Default behavior\n\n'helloworld'\n\n\n\nconcat_string('hello', 'world', sep=', ')  # Modified behavior\n\n'hello, world'\n\n\nThis example also illustrates the rule when mixing positional and keyword arguments: positional arguments must always be placed before keyword arguments.",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#returning-results",
    "href": "source/fundamentals/functions/tutorial.html#returning-results",
    "title": "Functions",
    "section": "Returning Results",
    "text": "Returning Results\n\nPrinciple\nWe have seen that every function returns a result as output and that the return statement specifies this result. When the function is called, it is evaluated to the value specified by return, and this value can then be stored in a variable and used in subsequent calculations, and so on.\n\ndef division(x, y):\n    return x / y\n\n\na = division(4, 2)\nb = division(9, 3)\ndivision(a, b)  # 2 / 3\n\n0.6666666666666666\n\n\nImportant note: when a return statement is reached in a function, the rest of the function is not executed.\n\ndef test(x):\n    return x\n    print(\"Will I be displayed?\")\n    \ntest(3)\n\n3\n\n\n\n\nThe None Value\nA function necessarily returns a result when called… but what happens if you do not specify a return statement?\n\ndef welcome(name):\n    print(\"Greetings \" + name + \"!\")\n    \nx = welcome(\"Leontine\")\nprint(x)\nprint(type(x))\n\nGreetings Leontine!\nNone\n&lt;class 'NoneType'&gt;\n\n\nAs expected, the function printed a welcome message in the console. But we did not specify a value to return. Since an object must still be returned by definition, Python returns the value None, which is a special object of type NoneType representing the absence of a value. Its only purpose is to clearly indicate the difference between a real value and the absence of a value.\nTo test if an object has the value None, use the following syntax:\n\nx is None  # and not x == None\n\nTrue\n\n\n\n\nReturning Multiple Results\nA function by definition returns one result, which can be any Python object. What if you want to return multiple results? You can simply store the different results in a container (list, tuple, dictionary, etc.), which can hold many objects.\nIn practice, it is very common to return a tuple when you want to return multiple objects. Tuples have the property of tuple unpacking, which we have seen several times in previous tutorials. This property allows a very convenient and elegant syntax for assigning the results of a function to variables.\n\ndef powers(x):\n    return x**2, x**3, x**4\n\na, b, c = powers(2)\n\nprint(a)\nprint(b)\nprint(c)\n\n4\n8\n16",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#local-and-global-variables",
    "href": "source/fundamentals/functions/tutorial.html#local-and-global-variables",
    "title": "Functions",
    "section": "Local and Global Variables",
    "text": "Local and Global Variables\nIn the introduction, we saw that functions could be viewed as mini-programs within a global program. This interpretation gives us an opportunity to quickly discuss the notion of scope in Python. A scope is a sort of container for Python objects, which can only be accessed within the context of that scope.\nAll the objects (variables, functions, etc.) that you define during a Python session are\nrecorded in Python’s global scope. These objects can then be accessed anywhere in the program, including within a function. When this happens, they are referred to as global variables.\n\nx = 5  # global variable\n\ndef add(y):\n    return x + y\n\nadd(6)\n\n11\n\n\nThe x variable was not passed as an argument to the add function nor defined within the function. Yet, it can be called within the function. This allows sharing elements between multiple functions.\nHowever, arguments passed to a function or variables defined within the function are local variables: they only exist within the specific context of the function and cannot be reused once the function has executed.\n\ndef add(y):\n    z = 5  # local variable\n    return z + y\n\nadd(6)\nprint(z)\n\n3\n\n\nWithin a given context, each variable is unique. However, it is possible to have variables with the same name in different contexts. Let’s see what happens when we create a variable within the context of a function, even though it already exists in the global context.\n\nx = 5  # global variable\n\ndef add(y):\n    x = 10\n    return x + y\n\nadd(6)\n\n16\n\n\nThis is a good example of a more general principle: the most local context always takes precedence. When Python performs the x + y operation, it looks for the values of x and y first in the local context and then, only if it doesn’t find them, in the higher context—in this case, the global context.\nNote: We will see in a future tutorial on best practices that it is best to limit the use of global variables to a strict minimum, as they reduce the reproducibility of analyses.",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#exercises",
    "href": "source/fundamentals/functions/tutorial.html#exercises",
    "title": "Functions",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension Questions\n\nWhy is using functions in a program considered a best practice in development?\nWhat are the three characteristics of a function?\nWhat is a “black box” function? What other functions is it opposed to?\nWhat happens when you define a function? And when you call it?\nHow many arguments can you pass to a function?\nWhat are the two modes of passing arguments to a function?\nWhat is the usefulness of passing optional arguments to a function?\nIn what order should arguments be passed to a function if it has both mandatory and optional arguments?\nAre there functions that return nothing?\nCan a function return multiple objects?\nWhat happens to the variables in the local scope of a function once the function has been called?\n\n\n\n\nShow the solution\n\n\nUsing functions helps reduce code duplication and better isolate the logical blocks of a program.\nA function takes arguments as input, performs a specific action through a set of instructions, and returns a result as output.\n“Black box” functions are functions whose code is unknown when executed, such as Python’s built-in functions (len, range..). They are opposed to user-created functions.\nWhen you define a function using the def statement, you store the function’s code in memory. It is only when you call the function that this code is executed, and a result is returned.\nAs many as you want.\nBy position: you pass the arguments in the order they were specified when the function was defined. By keyword: you pass the arguments by naming them.\nTo modify the default behavior of a function, as intended by its designer.\nFirst the mandatory arguments, then the optional arguments.\nNo, a function always returns an object. If no return statement is specified, the function returns the value None, which is an object of type NoneType.\nNo, a function returns a single object. However, if you want a function to return multiple results, you can simply put them in a container (list, tuple, dictionary..).\nThey disappear and cannot be reused in the global scope.\n\n\n\n\n\nPower Function\nCreate a power function that takes two numbers x and y as input and returns the power function \\(x^y\\).\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ndef power(x, y):\n    return x**y\n\npower(2, 3)\n\n8\n\n\n\n\n\n\nPredicting Values Returned by Functions\nGiven x = 5 and y = 3 as arguments passed to each of the functions defined in the following cell. Predict what the functions will return (value and type of the object), and verify your answers.\n\ndef f1(x):\n    return x\n\ndef f2(x):\n    return ''\n\ndef f3(x):\n    print(\"Hello World\")\n    \ndef f4(x, y):\n    print(x + y)\n    \ndef f5(x, y):\n    x + y\n    \ndef f6(x, y):\n    if x &gt;= 3 and y &lt; 9:\n        return 'test ok'\n    else:\n        return 'test not ok'\n    \ndef f7(x, y):\n    return f6(2, 8)\n\ndef f8(x, y, z):\n    return x + y + z\n\ndef f9(x, y, z=5):\n    return x + y + z\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\n- f1. Value: 5; Type: int\n\n- f2. Value: ''; Type: str\n\n- f3. Value: None; Type: NoneType\n\n- f4. Value: None; Type: NoneType\n\n- f5. Value: None; Type: NoneType\n\n- f6. Value: 'test ok'; Type: str\n\n- f7. Value: 'test not ok'; Type: str\n\n- f8. Error: z is not defined\n\n- f9. Value: 13; Type: int\n\n\n  Cell In[71], line 1\n    - f1. Value: 5; Type: int\n    ^\nSyntaxError: illegal target for annotation\n\n\n\n\n\n\n\n\nGlobal and Local Variables\nWhat is the value of the total variable in the following program?\n\nz = 3\n\ndef f1(x, y):\n    z = 5\n    return x + y + z\n\ndef f2(x, y, z=1):\n    return x + y + z\n\ndef f3(x, y):\n    return x + y + z\n\ntotal = f1(2, 3) + f2(3, 1) + f3(1, 0)\nprint(total)\n\n19\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nz = 3\n\ndef f1(x, y):\n    z = 5\n    return x + y + z\n\ndef f2(x, y, z=1):\n    return x + y + z\n\ndef f3(x, y):\n    return x + y + z\n\ntotal = f1(2, 3) + f2(3, 1) + f3(1, 0)\n\nprint(f1(2, 3))  \n# The local variable z within f1 is used -&gt; f1 returns 10\n\nprint(f2(3, 1))  \n# The local variable z within f1 is used\n# Its default value is 1 -&gt; f2 returns 5\n\nprint(f3(1, 0)) \n# The global variable z is used -&gt; f3 returns 4\n\nprint(total)\n\n10\n5\n4\n19\n\n\n\n\n\n\nCalculator\nWrite a calculator function that:\n\ntakes two numbers as input\nreturns the addition, subtraction, multiplication, and division of these two numbers as output\n\nUse the tuple unpacking property to assign the results to variables in a single line.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ndef calculator(a, b):\n    return a + b, a - b, a * b, a / b\n\nadd, sub, mult, div = calculator(5, 3)\nprint(add, sub, mult, div)\n\n8 2 15 1.6666666666666667\n\n\n\n\n\n\nDeduplicating a List\nWrite a function that:\n\ntakes a list of any elements as input\nreturns a new list consisting of the unique elements of the initial list\nallows via an optional parameter to sort or not the final list in alphanumeric order. The default behavior should be not to sort.\n\nHint: The procedure was discussed in the tutorial on dictionaries and sets.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ndef dedup(l, sort=False):\n    l_dedup = list(set(l))\n    if sort:\n        l_dedup.sort()\n    return l_dedup\n\nl = [\"a\", \"a\", \"b\", \"c\"]\nprint(dedup(l))  # Default behavior: no sorting\nprint(dedup(l, sort=True))  # Modified behavior: sorting\n\n['a', 'c', 'b']\n['a', 'b', 'c']\n\n\n\n\n\n\nMultiplying List Elements\nWrite a function that:\n\ntakes a list of numbers as input\nprints: “There are \\(n\\) numbers in the list.” with \\(n\\) being the actual number\nmultiplies all elements of the list (without using a pre-coded function)\nreturns the result\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ndef multiply(l):\n    print(\"There are \" + str(len(l)) + \" numbers in the list.\")\n    c\n\n = 1\n    for x in l:\n        c *= x  # Equivalent to: c = c * x\n    return c\n\nl = [2, 8, 3]\nmultiply(l)\n\n\n  File &lt;tokenize&gt;:5\n    = 1\n    ^\nIndentationError: unindent does not match any outer indentation level\n\n\n\n\n\n\n\n\nVariance in a Population and Variance in a Sample\nIn an exercise from the previous tutorial, we manually coded the calculation of the variance of a list of numbers using the formula: \\[\\sigma^2 = {\\frac {1}{n}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\]\nStrictly speaking, this formula is valid when calculating population variance. If we only observe a sample of the population, we do not calculate the variance but estimate it, and we must then use the following formula to obtain an unbiased estimator of the true variance: \\[s^2 = {\\frac {1}{n-1}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\].\nTo account for this distinction:\n\ncode a mean function that calculates the mean as in the previous tutorial exercise\ncode a var function that calculates the variance as in the previous tutorial exercise (calling the mean function to calculate the mean)\nmodify the var function to allow the user to choose the calculation method via an optional mode parameter (default value: ‘population’ for calculation using the population formula; alternative value: ‘sample’ for calculation using the sample formula)\n\nCompare the values obtained in both cases with what the black box function var from the numpy library returns (see the solution to the previous tutorial exercise for the syntax, and see the doc of the function, especially the ddof parameter to vary the calculation method).\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ndef mean(x):\n    n = len(x)\n    sum_mean = 0\n    for x_i in x:\n        sum_mean += x_i\n    mean = sum_mean / n\n    return mean\n\ndef var(x, mode=\"population\"):\n    n = len(x)\n    mean_value = mean(x)\n    sum_var = 0\n    for x_i in x:\n        sum_var += (x_i - mean_value)**2\n    if mode == \"population\":\n        variance = sum_var / n\n    elif mode == \"sample\":\n        variance = sum_var / (n-1)\n    return variance\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nprint(mean(x))\nprint(var(x))  # population\nprint(var(x, mode=\"sample\"))  # sample\n\n# Verification with numpy library functions\nimport numpy as np\nprint(np.mean(x))\nprint(np.var(x))  # population\nprint(np.var(x, ddof=1))  # sample\n\n9.3125\n42.93359375\n49.066964285714285\n9.3125\n42.93359375\n49.066964285714285\n\n\n\n\n\n\nRecursive Functions: Factorial\nRecursive functions are functions that call themselves within the body of the function, causing infinite calls until a stopping criterion is reached.\nA good example of a recursive function is one that calculates the factorial of an integer. The factorial of a natural number \\(n\\) is the product of all positive integers less than or equal to n. For example: \\(5! = 5*4*3*2*1 = 120\\).\nCode this function and verify that it works correctly.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ndef factorial(n):\n    if n == 0:\n        # Stopping criterion\n        return 1\n    else:\n        return n * factorial(n-1)\n\nfactorial(5)\n\n120",
    "crumbs": [
      "Fundamentals",
      "Functions"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html",
    "href": "source/fundamentals/loops/tutorial.html",
    "title": "Loops",
    "section": "",
    "text": "In the previous tutorial, we studied tests, which allow a computer to make decisions based on conditions specified in a program. We will now go even further in automating operations with the concept of loops. Loops will allow us to repeat an instruction several times without having to rewrite the same code each time.\nTo illustrate this idea, let’s imagine we want to display each element of a list. For now, we would do:\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nprint(gamme[0])\nprint(gamme[1])\nprint(gamme[2])\n\ndo\nre\nmi\nAnd so on. We can immediately see that such an operation would be impractical for a list containing hundreds of elements. Loops will solve this problem in an elegant and efficient manner.",
    "crumbs": [
      "Fundamentals",
      "Loops"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html#for-loops",
    "href": "source/fundamentals/loops/tutorial.html#for-loops",
    "title": "Loops",
    "section": "for loops",
    "text": "for loops\n\nDefinition\nThe first type of loop we will look at is the for loop. A for loop allows you to traverse the different elements contained in an object called an iterable, and perform operations with these elements. Iterable objects include all the sequential objects we have seen so far: strings, lists, tuples, etc.\nLet’s illustrate how a for loop works by solving the problem presented earlier.\n\nfor note in gamme:\n    print(note)\n\ndo\nre\nmi\nfa\nsol\nla\nsi\n\n\n\n\nSyntax\nLet’s analyze the structure of a for loop:\n\nThe first line specifies a for statement, and like any statement in Python ends with :.\nThis is followed by a block of instructions, i.e., a series of operations (just one in our example) that will be executed at each iteration of the loop. This block is visible by its level of indentation, incremented by 1 compared to the statement. The block ends as soon as the indentation returns to its initial level.\n\nAs with conditional statements like if/else, indentation is crucial. If you forget it, Python returns an error.\n\nfor note in gamme:\n    print(note)\n\ndo\nre\nmi\nfa\nsol\nla\nsi\n\n\n\n\nOperation\nNow let’s look in more detail at what the for statement does. It defines an iteration variable (called note in our example), which will traverse the elements of the iterator specified after the in (the list gamme in our example). The syntax of a loop in Python lends itself well to a literal description; in our case: “for each note in the list gamme, print the note.”\nNote that a loop defines a variable without needing the traditional variable = value assignment syntax. Furthermore, this variable is not deleted once the loop is finished; it then takes the value of the last element of the iterator.\n\nnote\n\n'si'\n\n\nThe iterator does not necessarily have to be a list; it can be any iterable object. This includes all the sequential objects we have seen.\n\nfor char in \"YMCA\":\n    print(char)\n\nprint()  # Newline\n\nt = (1, 2, 3, 4, 5)\nfor i in t:\n    print(i*9)\n\nY\nM\nC\nA\n\n9\n18\n27\n36\n45\n\n\nHowever, the class of iterable objects is much larger than just sequential objects. For example, you can iterate over the keys of a dictionary, even though we saw in a previous tutorial that it is not a sequential object, since there is no notion of order in a dictionary.\n\ninventaire = {'coffee': '500g', 'milk': '1.5L', 'cereal': '1kg'}\nfor key in inventaire:\n    print(key)\n    print(inventaire[key])\n    print()  # Newline\n\ncoffee\n500g\n\nmilk\n1.5L\n\ncereal\n1kg\n\n\n\n\n\nIteration over integers with the range function\nIn programming, it is common to want to iterate over a series of integers. Instead of specifying this series in a list, which is not very practical if the series is long, we use the range(n) function. This creates an iterable object that contains all the integers between 0 and n-1, and can be used within a loop.\nFor example, let’s see how we can very simply display a multiplication table using this function.\n\ntable = 9\n\nfor i in range(11):\n    print(i, i*9)\n\n0 0\n1 9\n2 18\n3 27\n4 36\n5 45\n6 54\n7 63\n8 72\n9 81\n10 90\n\n\n\n\nIteration over indices\nWe have seen that a for loop works by iterating over the elements of an iterable. However, in the case of a sequential object like a list, we may sometimes want to iterate over the indices of the object to manipulate both the indices and the elements contained in the object. In this case, the range function can be used in combination with the len function to create an iterable object that contains exactly the indices of the initial list.\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nfor i in range(len(gamme)):\n    print(\"The note number \" + str(i) + \" in the C major scale is \" + gamme[i])\n\nThe note number 0 in the C major scale is do\nThe note number 1 in the C major scale is re\nThe note number 2 in the C major scale is mi\nThe note number 3 in the C major scale is fa\nThe note number 4 in the C major scale is sol\nThe note number 5 in the C major scale is la\nThe note number 6 in the C major scale is si\n\n\nSince this need is frequent but the code above is not very readable, there is a built-in Python function called enumerate that allows iterating over both objects and indices. It is therefore preferable to use this syntax, which is clearer and helps avoid some errors.\nThe enumerate function applied to an iterable object returns a new iterable object that contains all the pairs (index, element) in the object, in the form of tuples. Since it is a special type of object – a generator, which we will see in a more advanced tutorial – you need to apply the list function to display its content.\n\nlist(enumerate(gamme))\n\n[(0, 'do'), (1, 're'), (2, 'mi'), (3, 'fa'), (4, 'sol'), (5, 'la'), (6, 'si')]\n\n\nLet’s see how to rewrite the previous loop with this new syntax.\n\nfor i, note in enumerate(gamme):\n    print(\"The note number \" + str(i) + \" in the C major scale is \" + note)\n\nThe note number 0 in the C major scale is do\nThe note number 1 in the C major scale is re\nThe note number 2 in the C major scale is mi\nThe note number 3 in the C major scale is fa\nThe note number 4 in the C major scale is sol\nThe note number 5 in the C major scale is la\nThe note number 6 in the C major scale is si\n\n\nNB: To assign variables in the if statement, we used a handy technique we had already mentioned in an exercise in the tutorial on lists and tuples: tuple unpacking. Let’s illustrate it with an example:\n\nt = (1, 2, 3)\na, b, c = t\nprint(a)\nprint(b)\nprint(c)\n\n1\n2\n3",
    "crumbs": [
      "Fundamentals",
      "Loops"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html#while-loops",
    "href": "source/fundamentals/loops/tutorial.html#while-loops",
    "title": "Loops",
    "section": "while loops",
    "text": "while loops\n\nDefinition\nwhile loops provide an alternative way to specify repetitive procedures. The idea is no longer to iterate over a fixed number of objects, but to iterate as long as a condition (logical test) is met.\n\ni = 1\nwhile i &lt;= 5:\n    print(i)\n    i = i + 1\n\n1\n2\n3\n4\n5\n\n\n\n\nSyntax\nThe main difference from the for loop is the statement: it is now a while statement, followed by a condition (test), and like any statement, ends with :.\nThe principle is the same for the rest: the while statement is followed by a block of instructions, indented by one level, which is executed sequentially at each iteration of the loop.\n\n\nStopping criterion\nAn essential difference between while loops and for loops lies in the stopping criterion. In a for loop, this criterion is clear: the loop iterates over the elements of an iterable object, necessarily of finite size. The loop stops when each element of the iterable has been traversed.\nIn a while loop, on the other hand, the stopping criterion is given by a logical condition, so the user must set the stopping criterion. In the example, for the loop to stop, the condition i &lt;= 5 must become False, meaning i must become strictly greater than 5. We ensured this by initializing i to 1 before the loop starts, and then incrementing i by one unit at each iteration.\nWhat happens if we forget to increment i? The stopping criterion is never reached, so the loop is infinite, and we must use the “Stop” button (black square) in Jupyter to stop the running program. Let’s verify this by incrementing the wrong variable.\n\ni = 1\nj = 1\nwhile i &lt;= 5:\n    j = j + 1\n\nTherefore, when we suspect that a while loop is taking too long to run, we must consider the possibility that we have fallen into an infinite loop, and ensure that the stopping criterion is reachable.\n\n\nThe break statement\nAn alternative way to specify a stopping criterion is to use the break statement. When this statement is reached and executed, the loop is immediately interrupted.\nLet’s illustrate its operation with an example. The first line creates an infinite loop because, by definition, True is always evaluated as True. The program then asks the user to type a name, and does so indefinitely until the user types the expected name. Only then is the break statement reached, and the loop stops. The message “Welcome ” is finally displayed, as the second print is not included in the loop.\n\nyour_name = \"Romain\"\n\nwhile True:\n    print(\"Please enter your name.\")\n    name = input()\n    if name == your_name:\n        break\nprint(\"Welcome \" + your_name)\n\nIt is important to note that a break statement only terminates the loop of the directly superior level. In the case of a multi-level loop, it is entirely possible for operations to continue even when a break statement has been reached.\nLet’s illustrate this principle with an example.\n\ni = 0\nwhile i &lt;= 5:\n    for j in range(5):\n        if j == 2:\n           \n\n print(\"Break.\")\n            break\n    i += 1\n\n\n  File &lt;tokenize&gt;:7\n    print(\"Break.\")\n    ^\nIndentationError: unindent does not match any outer indentation level\n\n\n\n\nAt each iteration of the while loop, a for loop is launched, which reaches a break statement at the third iteration (when j is 2). This stops the for loop, but not the while loop, which executes its subsequent instructions (incrementing i by one unit) before proceeding to the next iteration.\n\n\nThe continue statement\nThe continue statement allows you to skip to the next iteration of the loop.\nLet’s enhance the previous example to illustrate its operation. As long as a different name than the expected one is entered, the continue statement is evaluated, and the program continues to ask for a name. When the correct name is entered, the program asks the user to enter a password. If the password is the expected one, the break statement is reached and executed, and the loop stops. If the password is incorrect, however, the loop restarts at the beginning of the execution block, so you need to enter a name again before the password.\n\nyour_name = \"\"\n\nwhile True:\n    print(\"Please enter your name.\")\n    name = input()\n    if name != your_name:\n        continue\n    print(\"Please enter your password.\")\n    password = input()\n    if password == \"insee2021\":\n        break\nprint(\"Welcome \" + your_name)\n\nNB: The code above is only for example purposes. As we will see in a future tutorial on best coding practices, you should never write secrets (passwords, tokens, etc.) in plain text in your code.",
    "crumbs": [
      "Fundamentals",
      "Loops"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html#exercises",
    "href": "source/fundamentals/loops/tutorial.html#exercises",
    "title": "Loops",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension questions\n\n1/ How does a for loop work?\n2/ Does the iteration variable defined in a for loop persist in memory once the loop is finished?\n3/ What does the range function do? Why is it particularly useful in for loops?\n4/ What does the enumerate function do? Why is it particularly useful in for loops?\n5/ How does a while loop work?\n6/ When does a while loop stop? How does this differ from for loops?\n7/ What does the break statement do?\n8/ What does the continue statement do?\n\n\n\n\nShow solution\n\n1/ A for loop defines an iteration variable that will traverse each element of an iterable object. At each iteration, a series of instructions is executed.\n2/ Yes, and its final value is equal to the last value of the iterable object.\n3/ The range(n) function creates an iterable object that contains all integers between 0 and n-1. It is widely used as an iterable in for loops because it allows iterating over a sequence of integers without having to manually put them in a list.\n4/ The enumerate function applied to an iterable object returns a new iterable object that contains all pairs (index, element) associated with the initial object, in the form of tuples. In the context of a for loop, it allows iterating over both the elements of an iterable and their positions.\n5/ A while loop executes a series of instructions repeatedly as long as the specified logical condition evaluates to True.\n6/ A while loop stops as soon as the specified logical condition evaluates to False. If this never happens, a while loop can be infinite. In contrast, a for loop can be very long but never infinite, as it stops as soon as it finishes traversing the object.\n7/ The break statement forces the loop of the directly superior level to terminate.\n8/ The continue statement forces the loop of the directly superior level to skip to the next iteration.\n\n\n\n\nPredicting results of while loops\nTry to predict what the following while loops will produce, and check your results.\n\n# 1.\ni = 0\nwhile i &lt;= 10:\n    print(i)\n\n# 2.\na = 1\nwhile (a &lt; 10):\n    a += 1\n    if a == 5:\n        break\n    print(\"Stopping condition reached.\")\n\n# 3.\nwhile False:\n    print(\"hello world\")\n\n# 4.\nwhile True:\n    print(\"hello world\")\n    break\n\n# 5.\nwhile 5 &gt;= 3:\n    continue\n    print(\"hello world\")\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\n\nInfinite loop because i is never incremented, so the condition is always true. 0 will print infinitely.\n\n\nThe loop will stop at the 4th iteration when a is 5. However, the print statement is misindented, so it will print 3 times instead of 1.\n\n\nFalse evaluates to False, so the loop does not execute at all. No output.\n\n\nTrue evaluates to True, so the loop is theoretically infinite, but there is a break. Thus, there will be only one iteration, resulting in one “hello world” print.\n\n\n5 &gt;= 3 evaluates to True, so the loop is infinite. The continue statement is executed at each iteration before the print can execute. The loop runs infinitely, but with no output.\n\n\n\n\n\n\nEffect of an indentation error\nSource: python.sdv.univ-paris-diderot.fr\nTo visualize the importance of indentation in instruction blocks, try to predict what the following two programs will return. Which one has the expected effect?\n\nnumbers = [4, 5, 6]\nfor num in numbers:\n    if num == 5:\n        print(\"The test is true\")\n        print(f\"because the variable num is {num}\")\n\nThe test is true\nbecause the variable num is 5\n\n\n\nnumbers = [4, 5, 6]\nfor num in numbers:\n    if num == 5:\n        print(\"The test is true\")\n    print(f\"because the variable num is {num}\")\n\nbecause the variable num is 4\nThe test is true\nbecause the variable num is 5\nbecause the variable num is 6\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\nThe first program is correct. In the second, the second print is not correctly indented. As a result, it executes at each iteration and not just when num == 5.\n\n\n\n\nConverting a for loop to a while loop\nRewrite the following for loop using a while loop.\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nfor i, note in enumerate(gamme):\n    print(\"The note number \" + str(i) + \" in the C major scale is \" + note)\n\nThe note number 0 in the C major scale is do\nThe note number 1 in the C major scale is re\nThe note number 2 in the C major scale is mi\nThe note number 3 in the C major scale is fa\nThe note number 4 in the C major scale is sol\nThe note number 5 in the C major scale is la\nThe note number 6 in the C major scale is si\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\ni = 0\nwhile i &lt;= (len(gamme) - 1):\n    # Subtract 1 from the length of `gamme` because the max index is 6\n    print(\"The note number \" + str(i) + \" in the C major scale is \" + gamme[i])\n    i += 1\n\nThe note number 0 in the C major scale is do\nThe note number 1 in the C major scale is re\nThe note number 2 in the C major scale is mi\nThe note number 3 in the C major scale is fa\nThe note number 4 in the C major scale is sol\nThe note number 5 in the C major scale is la\nThe note number 6 in the C major scale is si\n\n\n\n\n\n\nFinding an element in a list\nGiven a target integer target_num and a list of integers l as defined in the following cell. Using a for loop and the enumerate function:\n\nCheck if the target integer is present in the list l.\nIf yes, display the message ‘The number target_num is at position i in the list’, and end the loop.\n\n\ntarget_num = 78\n\nl = [12, 98, 65, 39, 78, 55, 119, 27, 33]\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ntarget_num = 78\n\nl = [12, 98, 65, 39, 78, 55, 119, 27, 33]\n\nfor i, n in enumerate(l):\n    if n == target_num:\n        print(\"The number \" + str(n) + \" is at position \" + str(i) + \" in the list.\")\n        break\n\n# NB: more efficient version without loop\nif target_num in l:\n    pos = l.index(target_num)\n    print(\"The number \" + str(target_num) + \" is at position \" + str(pos) + \" in the list.\")\n\nThe number 78 is at position 4 in the list.\nThe number 78 is at position 4 in the list.\n\n\n\n\n\n\nFibonacci sequence\nThe Fibonacci sequence is defined as follows:\n\nThe first two numbers are 0 and 1\nEach subsequent number in the sequence is obtained by adding the two preceding numbers\n\nWrite a program to calculate the first \\(n\\) terms of the sequence using a for loop.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nn_terms = 20\nnum1 = 0\nnum2 = 1\n\nfor i in range(n_terms):\n    print(num1)\n    num3 = num1 + num2\n    num1 = num2\n    num2 =\n\n num3\n\n\n  File &lt;tokenize&gt;:11\n    num3\n    ^\nIndentationError: unindent does not match any outer indentation level\n\n\n\n\n\n\n\n\nMultiplication table dictionary\nUsing two nested for loops, build a dictionary tables that allows generating multiplication tables up to the table of 12. Query your dictionary to check its accuracy.\nHere are some examples of queries your dictionary should return:\n\ntables[2][3] -&gt; 6\ntables[9][5] -&gt; 45\ntables[12][7] -&gt; 84\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ntables = {}\n\nfor i in range(13):\n    tables[i] = {}\n    for j in range(13):\n        tables[i][j] = i*j\n\nprint(tables[2][3])\nprint(tables[9][5])\nprint(tables[12][7])\n\n6\n45\n84\n\n\n\n\n\n\nCalculating the minimum and maximum of a series “by hand”\nCalculate the minimum and maximum of the following series of values without using Python’s min and max functions.\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\n\ncurrent_min = x[0]\ncurrent_max = x[0]\nfor n in x[1:]:\n    if n &lt;= current_min:\n        current_min = n\n    if n &gt;= current_max:\n        current_max = n\n\nprint(current_min == min(x))\nprint(current_max == max(x))\n\nTrue\nTrue\n\n\n\n\n\n\nCalculating the mean and variance “by hand”\nCalculate the mean and variance of the following series of values without using pre-coded functions:\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nTo recall, the formulas are:\n\nmean: \\[\\bar{x} = {\\frac {1}{n}}\\sum_{i=1}^{n}x_{i}\\]\nvariance: \\[\\sigma^2 = {\\frac {1}{n}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\]\n\nNB:\n\nn to the power of k is written in Python as n**k\nin practice, you should never try to recode such functions yourself, but use functions from suitable packages like numpy.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nn = len(x)\n\nsum_mean = 0\nfor x_i in x:\n    sum_mean += x_i\nmean = sum_mean / n\n\nsum_var = 0\nfor x_i in x:\n    sum_var += (x_i - mean)**2\nvariance = sum_var / n\n\nprint(mean)\nprint(variance)\n\n# Verification with numpy package functions\nimport numpy as np\nprint(np.mean(x))\nprint(np.var(x))\n\n9.3125\n42.93359375\n9.3125\n42.93359375\n\n\n\n\n\n\nAdvanced use of the range function\nWe saw earlier the basic use of the range function: range(n) creates an iterable object that contains all integers from 0 to n-1. The possible uses of this function are, however, more comprehensive and sometimes useful for specific problems.\nThe complete syntax of the function is range(start, stop, step) where:\n\nstart is the integer at which the sequence of integers starts\nstop is the integer before which the sequence of integers ends\nstep is the step, i.e., the value of the increment between each integer in the sequence.\n\nOnly the stop parameter is mandatory, which is used when calling range(n).\nUsing the range function, display:\n\nAll integers from 0 to 10 (10 excluded)\nAll integers from 10 to 20 (20 included)\nAll even numbers between 30 and 40 (40 included)\nAll multiples of 10 between 1 and 100 (100 excluded)\nAll integers from 10 to 20 (20 included), in reverse order (from 20 to 10)\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(list(range(10)))\n\nprint(list(range(10, 21)))\n\nprint(list(range(30, 41, 2)))\n\nprint(list(range(10, 100, 10)))\n\nprint(list(range(20, 9, -1)))\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n[10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n[30, 32, 34, 36, 38, 40]\n[10, 20, 30, 40, 50, 60, 70, 80, 90]\n[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10]\n\n\n\n\n\n\nThe price is right, improved version\nIn the previous tutorial, we coded a game of “The Price is Right”. But it was somewhat limited because you had to rerun the code at each stage of the game. Using loops, rewrite the game to be fully automatic.\nGame rules reminder:\nUsing input and the if, elif, and else statements, code the following program:\n\nAsk the user for a value, which will be stored in a variable p\nIf p is strictly less than $15, print (using the print function) the message “too low!”.\nIf p is strictly greater than $15, print the message “too high!”.\nIf p equals $15, print the message “spot on!”\n\nNote, input returns a string by default. Therefore, you need to convert the value of p to an integer (using the int function) for the game to work.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nright_price = 15\n\nwhile True:\n    print(\"Propose a number between 1 and 50.\")\n    p = input()\n    p = int(p)\n    if p &lt; right_price:\n        print(\"too low!\")\n    elif p &gt; right_price:\n        print(\"too high!\")\n    else:\n        break\n\nprint(\"spot on!\")\n\nPropose a number between 1 and 50.\n\n\n\n---------------------------------------------------------------------------\nStdinNotImplementedError                  Traceback (most recent call last)\nCell In[64], line 5\n      3 while True:\n      4     print(\"Propose a number between 1 and 50.\")\n----&gt; 5     p = input()\n      6     p = int(p)\n      7     if p &lt; right_price:\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/ipykernel/kernelbase.py:1281, in Kernel.raw_input(self, prompt)\n   1279 if not self._allow_stdin:\n   1280     msg = \"raw_input was called, but this frontend does not support input requests.\"\n-&gt; 1281     raise StdinNotImplementedError(msg)\n   1282 return self._input_request(\n   1283     str(prompt),\n   1284     self._parent_ident[\"shell\"],\n   1285     self.get_parent(\"shell\"),\n   1286     password=False,\n   1287 )\n\nStdinNotImplementedError: raw_input was called, but this frontend does not support input requests.",
    "crumbs": [
      "Fundamentals",
      "Loops"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html",
    "href": "source/projects/meteo/tutorial.html",
    "title": "Projet 2 - Interaction avec des APIs",
    "section": "",
    "text": "title: “Project 2 - Interaction with APIs”",
    "crumbs": [
      "Projects",
      "Project 2 - API interaction"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#project-context",
    "href": "source/projects/meteo/tutorial.html#project-context",
    "title": "Projet 2 - Interaction avec des APIs",
    "section": "Project context",
    "text": "Project context\nThere are some days when one would prefer to stay working from home… Among those days are the ones that are both humid and windy, making it impossible to maintain a decent hairstyle despite all efforts. Could we use Python to predict what the Anglo-Saxons call bad hair days?\nThe goal of the project is to construct a bad hair index from weather data and graphically represent the evolution of this index to determine in advance the days when it’s better to stay warm inside. To obtain the appropriate data, we will query APIs.\nAn API (Application Programming Interface) is a set of rules and specifications that applications follow to communicate with each other. It allows your code to access external functionalities or data, such as those from weather databases or location services. When querying an API, it is generally done via the HTTP protocol, which is the same protocol used to load web pages. In this tutorial, we will use the requests package, which simplifies the process of querying and handling HTTP responses.\nThe APIs we will use are:\n\nNominatim: a geocoding API provided by OpenStreetMap that allows us to convert a place name into geographic coordinates.\nOpen-Meteo Weather Forecast: an API that provides detailed weather forecasts.\n\nLet’s start by importing the packages we will need throughout this project.\n\nimport requests\nimport pandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt",
    "crumbs": [
      "Projects",
      "Project 2 - API interaction"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#part-1-retrieving-geographic-coordinates-for-a-given-location",
    "href": "source/projects/meteo/tutorial.html#part-1-retrieving-geographic-coordinates-for-a-given-location",
    "title": "Projet 2 - Interaction avec des APIs",
    "section": "Part 1: Retrieving geographic coordinates for a given location",
    "text": "Part 1: Retrieving geographic coordinates for a given location\nThe Open-Meteo prediction API takes as input the geographic coordinates (latitude, longitude) of the location where predictions will be made. We could manually retrieve the coordinates of the location of interest, but this would limit the reproducibility of our analyses with other locations than the one chosen. We will therefore use a second API, Nominatim, to obtain these coordinates for a given place.\nWhen working with an API, the first step is always to read its documentation. It indicates the address to which we must send our requests, in what format, and what the API will return. In our case, the documentation for Nominatim can be found here. Feel free to browse through it quickly to evaluate the possibilities of the API.\n\nQuestion 1\nThe first essential characteristic of an API is the endpoint, which is the URL to which we will send requests. In our case, we will use the endpoint /search since we want to find a geographic object (coordinates) from a location name. The documentation page associated with this endpoint gives us all the information we need:\n\nthe format of a request is https://nominatim.openstreetmap.org/search?&lt;params&gt; where &lt;params&gt; should be replaced by the request parameters, separated by the & symbol\nin the Structured Query section, we see that the API accepts parameters country and city, which we will use to parameterize our request.\n\nDefine a function build_request_nominatim that constructs the request URL for a given country and city.\n\nExpected result\n\nurl_request_nominatim = solutions.build_request_nominatim(\"France\", \"Montrouge\")\nurl_request_nominatim\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[31], line 1\n----&gt; 1 url_request_nominatim = solutions.build_request_nominatim(\"France\", \"Montrouge\")\n      2 url_request_nominatim\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef build_request_nominatim(country, city):\n    # Your code here\n    return url_request\n\n\n# Checking the result\nurl_request_nominatim = build_request_nominatim(\"France\", \"Montrouge\")\nurl_request_nominatim\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[33], line 2\n      1 # Checking the result\n----&gt; 2 url_request_nominatim = build_request_nominatim(\"France\", \"Montrouge\")\n      3 url_request_nominatim\n\nCell In[32], line 3, in build_request_nominatim(country, city)\n      1 def build_request_nominatim(country, city):\n      2     # Your code here\n----&gt; 3     return url_request\n\nNameError: name 'url_request' is not defined\n\n\n\n\n\n\nQuestion 2\nThe next step is to send our parameterized request to the API. To test it beforehand, we can simply put the address in a browser and see what the API returns. If the results look coherent, we can continue. If the API returns an error code, there is likely an error in the request.\nTo perform this request from Python to retrieve the results, we use the requests.get() function to which we provide the request URL as the only parameter. We get back a “response” object, from which we can extract the JSON content as a Python dictionary by applying the .json() method. We then need to parse the dictionary to extract the relevant information; in our case: latitude and longitude.\nDefine a function get_lat_long that retrieves the central latitude and longitude for a given country and city.\n\nExpected result\n\nlat, long = solutions.get_lat_long(query=url_request_nominatim)\nprint(lat, long)\nprint(type(lat))\nprint(type(long))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[34], line 1\n----&gt; 1 lat, long = solutions.get_lat_long(query=url_request_nominatim)\n      2 print(lat, long)\n      3 print(type(lat))\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef get_lat_long(query):\n    # Your code here\n    return latitude, longitude\n\n\n# Checking the result\nlat, long = get_lat_long(query=url_request_nominatim)\nprint(lat, long)\nprint(type(lat))\nprint(type(long))\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[36], line 2\n      1 # Checking the result\n----&gt; 2 lat, long = get_lat_long(query=url_request_nominatim)\n      3 print(lat, long)\n      4 print(type(lat))\n\nNameError: name 'url_request_nominatim' is not defined",
    "crumbs": [
      "Projects",
      "Project 2 - API interaction"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#part-2-retrieving-weather-forecasts",
    "href": "source/projects/meteo/tutorial.html#part-2-retrieving-weather-forecasts",
    "title": "Projet 2 - Interaction avec des APIs",
    "section": "Part 2: Retrieving weather forecasts",
    "text": "Part 2: Retrieving weather forecasts\nNow that we can retrieve the coordinates associated with a given location, we can query the open-meteo.com API to get the associated weather forecast data. Again, the first step is to look at the documentation (homepage, doc), which provides us with several pieces of information:\n\nthe endpoint for the prediction API is https://api.open-meteo.com/v1/forecast\nthe API expects as input a latitude and a longitude, as well as the desired weather variables. For our problem, we will retrieve information on relative humidity (relativehumidity_2m) and wind speed (windspeed_10m)\nby default, the API returns 7-day forecasts\n\n\nQuestion 3\nKnowing all this information and using the documentation, define a function build_request_open_meteo that constructs the request URL for a given latitude and longitude. Again, it is possible to test the validity of the request by executing the link in a browser and verifying that the returned results seem coherent.\n\nExpected result\n\nurl_request_open_meteo = solutions.build_request_open_meteo(latitude=lat, longitude=long)\nurl_request_open_meteo\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[37], line 1\n----&gt; 1 url_request_open_meteo = solutions.build_request_open_meteo(latitude=lat, longitude=long)\n      2 url_request_open_meteo\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef build_request_open_meteo(latitude, longitude):\n    # Your code here\n    return url_request\n\n\n# Checking the result\nurl_request_open_meteo = build_request_open_meteo(latitude=lat, longitude=long)\nurl_request_open_meteo\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[39], line 2\n      1 # Checking the result\n----&gt; 2 url_request_open_meteo = build_request_open_meteo(latitude=lat, longitude=long)\n      3 url_request_open_meteo\n\nNameError: name 'lat' is not defined\n\n\n\n\n\n\nQuestion 4\nAgain, we use the requests.get() function to submit the request to the API. We get back a “response” object, from which we can extract the JSON content as a Python dictionary by applying the .json() method.\nBut what happens if the submitted request is invalid (typo, nonexistent parameters, etc.)? In this case, the API returns an error. The response object of the request contains an attribute .status_code that gives the response code of a request. The code 200 indicates a successful request; any other code indicates an error.\nDefine a function get_meteo_data that retrieves the complete data dictionary returned by the API following our request. The function’s behavior should depend on the request’s response code:\n\nif the code is 200, the function returns the predictions dictionary;\nif the code is different from 200, the function displays the error code and returns None.\n\n\nExpected result\n\npredictions = solutions.get_meteo_data(url_request_open_meteo)\ntype(predictions)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[40], line 1\n----&gt; 1 predictions = solutions.get_meteo_data(url_request_open_meteo)\n      2 type(predictions)\n\nNameError: name 'solutions' is not defined\n\n\n\n\nwrong_request = solutions.build_request_open_meteo(latitude=lat, longitude=\"seventeen-point-four\")\noutput = solutions.get_meteo_data(wrong_request)\nprint(output)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[41], line 1\n----&gt; 1 wrong_request = solutions.build_request_open_meteo(latitude=lat, longitude=\"seventeen-point-four\")\n      2 output = solutions.get_meteo_data(wrong_request)\n      3 print(output)\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef get_meteo_data(query):\n    # Your code here\n    return response.json()\n\n\n# Checking the result\npredictions = get_meteo_data(url_request_open_meteo)\ntype(predictions)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[43], line 2\n      1 # Checking the result\n----&gt; 2 predictions = get_meteo_data(url_request_open_meteo)\n      3 type(predictions)\n\nNameError: name 'url_request_open_meteo' is not defined\n\n\n\n\n# Checking the result\nwrong_request = build_request_open_meteo(latitude=lat, longitude=\"seventeen-point-four\")\noutput = get_meteo_data(wrong_request)\nprint(output)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[44], line 2\n      1 # Checking the result\n----&gt; 2 wrong_request = build_request_open_meteo(latitude=lat, longitude=\"seventeen-point-four\")\n      3 output = get_meteo_data(wrong_request)\n      4 print(output)\n\nNameError: name 'lat' is not defined\n\n\n\n\n\n\nQuestion 5\nTo understand the structure of the data we retrieved, explore the returned predictions dictionary (keys, different levels, format of the predictions, format of the variable indicating the dates/times of the predictions, etc.)\n\n\nShow code\n# Data exploration\nprint(type(predictions))\nprint(predictions.keys())\nprint(type(predictions[\"hourly\"]))\nprint(predictions[\"hourly\"].keys())\nprint(type(predictions[\"hourly\"][\"time\"]))\nprint()\n\n# Display the data\nprint(predictions['hourly'][\"time\"][:5])\nprint(predictions['hourly'][\"time\"][-5:])\nprint()\nprint(predictions['hourly'][\"relativehumidity_2m\"][:5])\nprint(predictions['hourly'][\"windspeed_10m\"][:5])\n\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[45], line 2\n      1 # Data exploration\n----&gt; 2 print(type(predictions))\n      3 print(predictions.keys())\n      4 print(type(predictions[\"hourly\"]))\n\nNameError: name 'predictions' is not defined",
    "crumbs": [
      "Projects",
      "Project 2 - API interaction"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#part-3-constructing-and-visualizing-a-bad-hair-index",
    "href": "source/projects/meteo/tutorial.html#part-3-constructing-and-visualizing-a-bad-hair-index",
    "title": "Projet 2 - Interaction avec des APIs",
    "section": "Part 3: Constructing and visualizing a bad hair index",
    "text": "Part 3: Constructing and visualizing a bad hair index\nThe goal of this last part is to calculate and graphically represent the bad hair index. Recall that we define this index as the **\nproduct of relative humidity and wind speed**. It is a playful measure of the likelihood of having a “bad hair day” due to weather conditions.\n\nQuestion 6\nDefine a function preprocess_predictions that formats the predictions from the API into a Pandas DataFrame for statistical analysis. The steps to implement are as follows:\n\nconvert the predicted data into a 3-column Pandas DataFrame (observation date and time, humidity, wind speed);\nconvert the time column to datetime format (documentation)\nadd two new variables indicating the observation day and the observation hour\nadd a variable that calculates the bad hair index\n\n\nExpected result\n\ndf_preds = solutions.preprocess_predictions(predictions)\ndf_preds.head()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[46], line 1\n----&gt; 1 df_preds = solutions.preprocess_predictions(predictions)\n      2 df_preds.head()\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef preprocess_predictions(predictions):\n    # Your code here\n    return df\n\n\n# Checking the result\ndf_preds = preprocess_predictions(predictions)\ndf_preds.head()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[48], line 2\n      1 # Checking the result\n----&gt; 2 df_preds = preprocess_predictions(predictions)\n      3 df_preds.head()\n\nNameError: name 'predictions' is not defined\n\n\n\n\n\n\nQuestion 7\nFor graphical representation purposes, we will represent the aggregated bad hair index at two levels:\n\naverage hour by hour. This will answer the question: “at what time will it generally be preferable to stay home next week?”\naverage day by day. This will answer the question: “which day will it generally be preferable to stay home next week?”\n\nDefine a function plot_agg_avg_bhi that calculates the aggregated index in each case and represents the result as a lineplot.\n\nExpected result\n\nsolutions.plot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[49], line 1\n----&gt; 1 solutions.plot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\nNameError: name 'solutions' is not defined\n\n\n\n\nsolutions.plot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[50], line 1\n----&gt; 1 solutions.plot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef plot_agg_avg_bhi(df_preds, agg_var=\"day\"):\n    # Your code here\n    return None\n\n\n# Checking the result\nplot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[52], line 2\n      1 # Checking the result\n----&gt; 2 plot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\nNameError: name 'df_preds' is not defined\n\n\n\n\n# Checking the result\nplot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[53], line 2\n      1 # Checking the result\n----&gt; 2 plot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\nNameError: name 'df_preds' is not defined\n\n\n\nWhat do you conclude for the coming week?\n\n\n\nQuestion 8\nOur bad hair days prediction tool works wonderfully. But it’s almost vacation time, and a trip to Berlin is planned. Ideally, we would like to use our tool for any location. Fortunately, we have defined functions at each step, which will allow us to easily move on to an “orchestrator” function that calls all the others for a given location.\nDefine a main function that represents the bad hair index for a given country, city, and aggregation level.\n\nExpected result\n\nsolutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[54], line 1\n----&gt; 1 solutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\nNameError: name 'solutions' is not defined\n\n\n\n\nsolutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[55], line 1\n----&gt; 1 solutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")\n\nNameError: name 'solutions' is not defined\n\n\n\n\n\nYour turn!\n\ndef main(country, city, agg_var=\"day\"):\n    # Your code here\n    return None\n\n\n# Checking the result\nmain(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\n\n# Checking the result\nmain(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")",
    "crumbs": [
      "Projects",
      "Project 2 - API interaction"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html",
    "href": "source/projects/puissance4/tutorial.html",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "title: “Project 1 - Connect 4”\nIn this project, we will implement a Connect 4 game with a rather basic graphical interface. To achieve this, we will use the fundamental objects of Python.\nimport copy\n\nimport solutions",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#game-rules",
    "href": "source/projects/puissance4/tutorial.html#game-rules",
    "title": "Projet 1 - Puissance 4",
    "section": "Game rules",
    "text": "Game rules\nThe goal of Connect 4 is to align a sequence of 4 pieces of the same color on a grid with 6 rows and 7 columns. Each player has 21 pieces of one color (usually yellow or red by convention). The two players take turns placing a piece in the column of their choice, and the piece slides down to the lowest possible position in that column, after which it is the opponent’s turn to play. The winner is the player who first aligns (horizontally, vertically, or diagonally) at least four consecutive pieces of their color. If, when all the grid cells are filled, neither player has achieved such an alignment, the game is declared a draw.\nTo simplify the code for this project, we will assume that winning alignments can only be horizontal or vertical. Diagonals will not be considered (but they are an interesting exercise to go further!).",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#project-plan",
    "href": "source/projects/puissance4/tutorial.html#project-plan",
    "title": "Projet 1 - Puissance 4",
    "section": "Project plan",
    "text": "Project plan\nWe will break down the construction of the game into different parts:\n\ninitialization of the grid\nrepresentation of the grid\ngame function\ndetection of a victory (horizontal)\ndetection of a victory (vertical)\nend of game",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#initialization-of-the-grid",
    "href": "source/projects/puissance4/tutorial.html#initialization-of-the-grid",
    "title": "Projet 1 - Puissance 4",
    "section": "Initialization of the grid",
    "text": "Initialization of the grid\nThe objective of this part is to initialize a Python object that represents a Connect 4 grid. The choice we will make is to represent the grid as a list of lists. It will be a 6x7 matrix: we will therefore have a list of 6 elements (which will represent the rows of the grid), each of which will be a list containing 7 elements (which will represent the pieces).\nEach element of the grid will be represented by a string, which can take three values:\n\n’ ’ : if it is an empty cell\n‘R’ : if it is a red piece.\n‘Y’ : if it is a yellow piece.\n\nIn the grid initialization function, each element will therefore be initialized as a string containing a space.\nNote: Make sure that the rows are independent objects, in other words, modifying one of the lists does not affect the others.\n\nExpected result\n\ngrid = solutions.display_grid()\ngrid\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[28], line 1\n----&gt; 1 grid = solutions.display_grid()\n      2 grid\n\nTypeError: display_grid() missing 1 required positional argument: 'grid'\n\n\n\n\nprint(f'Number of rows: {len(grid)}')\nprint(f'Number of columns: {len(grid[0])}')\n\nNumber of rows: 6\nNumber of columns: 7\n\n\n\n\nYour turn!\n\ndef display_grid():\n    # Your code here\n    return grid\n\n\n# Checking the result\ngrid = display_grid()\ngrid\n\n[[' ', ' ', ' ', ' ', ' ', ' ', ' '],\n [' ', ' ', ' ', ' ', ' ', ' ', ' '],\n [' ', ' ', 'J', ' ', ' ', ' ', ' '],\n [' ', ' ', 'J', ' ', ' ', ' ', ' '],\n [' ', ' ', 'J', ' ', ' ', ' ', ' '],\n [' ', ' ', 'J', ' ', ' ', ' ', ' ']]\n\n\n\n# Checking the result\nprint(f'Number of rows: {len(grid)}')\nprint(f'Number of columns: {len(grid[0])}')\n\nNumber of rows: 6\nNumber of columns: 7",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#representation-of-the-grid",
    "href": "source/projects/puissance4/tutorial.html#representation-of-the-grid",
    "title": "Projet 1 - Puissance 4",
    "section": "Representation of the grid",
    "text": "Representation of the grid\nOur grid is initialized, but its display is quite basic. The idea of this part is to provide a more visual representation of the game during a game.\nTo do this, we will create a function that takes the previously initialized grid as input and returns its representation (via the print function). The columns will be separated by the | character (vertical bar).\nHint: A possible solution involves two concepts we have seen in previous exercises: string concatenation and the join function, which “joins” the elements of a list by separating them with a certain character. Here is a reminder of an example using these two concepts:\n\nl = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nl_join = \"START \" + \", \".join(l) + \" END\"\nprint(l_join)\n\nSTART a, b, c, d, e END\n\n\n\nExpected result\n\nsolutions.display_grid(grid)\n\n|   |   |   |   |   |   |   |\n|   |   |   |   |   |   |   |\n|   |   | J |   |   |   |   |\n|   |   | J |   |   |   |   |\n|   |   | J |   |   |   |   |\n|   |   | J |   |   |   |   |\n\n\n\n\nYour turn!\n\ndef display_grid():\n    # Your code here\n\n\n  Cell In[35], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\n# Checking the result\ndisplay_grid(grid)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[36], line 2\n      1 # Checking the result\n----&gt; 2 display_grid(grid)\n\nTypeError: display_grid() takes 0 positional arguments but 1 was given",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#game-function",
    "href": "source/projects/puissance4/tutorial.html#game-function",
    "title": "Projet 1 - Puissance 4",
    "section": "Game function",
    "text": "Game function\nNow that we can represent our grid, let’s focus on the core of Connect 4: the game. The objective of this part is to code a make_move function that will modify the grid when a player takes their turn.\nThis function takes as input:\n\nthe grid\nthe column chosen by the player\nthe color of the piece (‘R’ for the red piece, and ‘Y’ for the yellow piece)\n\nand returns the updated grid after the player’s turn.\nIf the chosen column is already full, return an error message.\nNote: In Python, numbering starts at 0. The first column is therefore column 0 from the indexing point of view.\nOptional: Return an error message if a player tries to play in a nonexistent column or with an unauthorized color.\n\nExpected result\n\ngrid = solutions.display_grid()  # Initialization\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 1st turn\ngrid = solutions.make_move(grid=grid, column_to_play=5, disc_color=\"Y\")  # 2nd turn\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 3rd turn\nsolutions.display_grid(grid)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[37], line 1\n----&gt; 1 grid = solutions.display_grid()  # Initialization\n      2 grid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 1st turn\n      3 grid = solutions.make_move(grid=grid, column_to_play=5, disc_color=\"Y\")  # 2nd turn\n\nTypeError: display_grid() missing 1 required positional argument: 'grid'\n\n\n\n\n\nYour turn!\n\ndef make_move(grid, column_to_play, disc_color):\n    new_grid = copy.deepcopy(grid)  # Avoid modifying the initial grid\n    # Your code here\n    return new_grid\n\n\n# Checking the result\ngrid = display_grid()  # Initialization\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 1st turn\ngrid = make_move(grid=grid, column_to_play=5, disc_color=\"Y\")  # 2nd turn\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 3rd turn\ndisplay_grid(grid)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[39], line 6\n      4 grid = make_move(grid=grid, column_to_play=5, disc_color=\"Y\")  # 2nd turn\n      5 grid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 3rd turn\n----&gt; 6 display_grid(grid)\n\nTypeError: display_grid() takes 0 positional arguments but 1 was given",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#detection-of-a-victory-horizontal",
    "href": "source/projects/puissance4/tutorial.html#detection-of-a-victory-horizontal",
    "title": "Projet 1 - Puissance 4",
    "section": "Detection of a victory (horizontal)",
    "text": "Detection of a victory (horizontal)\nNow that it is possible to actually play Connect 4, we need to detect a victory to end the current game. To do this, we will simplify the problem by breaking it down as much as possible.\nFirst, we focus on detecting a horizontal victory. To do this, we will use two functions:\n\na check_row_victory function that takes a Connect 4 row as input (i.e., a list of size 7) and returns True if 4 consecutive pieces of the same color are found on the row, and False otherwise\na check_horizontal_victory function that takes a complete grid as input and returns True if any row in the grid meets the previous condition, and False otherwise\n\n\nExpected result\n\n# Detection of a (horizontal) victory on a row\nrow1 = [\" \", \"R\", \"R\", \"R\", \"Y\", \"Y\", \" \"]\nrow2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"Y\", \" \"]\n\nprint(solutions.check_row_victory(row1))  # Returns False\nprint()  # New line\nprint(solutions.check_row_victory(row2))  # Returns True\n\nFalse\n\nRed won!\nTrue\n\n\n\n# Detection of a (horizontal) victory on a grid\ngrid = solutions.display_grid()  # Initialization\nprint(solutions.check_horizontal_victory(grid))  # Returns False\nprint()  # New line\n\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"R\")\ngrid = solutions.make_move(grid=grid, column_to_play=3, disc_color=\"R\")\ngrid = solutions.make_move(grid=grid, column_to_play=4, disc_color=\"R\")\ngrid = solutions.make_move(grid=grid, column_to_play=5, disc_color=\"R\")\nsolutions.display_grid(grid)\nprint()  # New line\n\nprint(solutions.check_horizontal_victory(grid))  # Returns True\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[41], line 2\n      1 # Detection of a (horizontal) victory on a grid\n----&gt; 2 grid = solutions.display_grid()  # Initialization\n      3 print(solutions.check_horizontal_victory(grid))  # Returns False\n      4 print()  # New line\n\nTypeError: display_grid() missing 1 required positional argument: 'grid'\n\n\n\n\n\nYour turn!\n\ndef check_row_victory(row):\n    # Your code here\n\n\n  Cell In[42], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\n# Checking the result\nrow1 = [\" \", \"R\", \"R\", \"R\", \"Y\", \"R\", \" \"]\nrow2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"Y\", \" \"]\n\nprint(check_row_victory(row1))  # Returns False\nprint(check_row_victory(row2))  # Returns True\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[43], line 5\n      2 row1 = [\" \", \"R\", \"R\", \"R\", \"Y\", \"R\", \" \"]\n      3 row2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"Y\", \" \"]\n----&gt; 5 print(check_row_victory(row1))  # Returns False\n      6 print(check_row_victory(row2))  # Returns True\n\nNameError: name 'check_row_victory' is not defined\n\n\n\n\ndef check_horizontal_victory(grid):\n    # Your code here\n\n\n  Cell In[44], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\n# Checking the result\ngrid = display_grid()  # Initialization\nprint(check_horizontal_victory(grid))  # Returns False\n\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=3, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=4, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=5, disc_color=\"R\")\ndisplay_grid(grid)\nprint(check_horizontal_victory(grid))  # Returns True\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[45], line 3\n      1 # Checking the result\n      2 grid = display_grid()  # Initialization\n----&gt; 3 print(check_horizontal_victory(grid))  # Returns False\n      5 grid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")\n      6 grid = make_move(grid=grid, column_to_play=3, disc_color=\"R\")\n\nNameError: name 'check_horizontal_victory' is not defined",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#detection-of-a-victory-vertical",
    "href": "source/projects/puissance4/tutorial.html#detection-of-a-victory-vertical",
    "title": "Projet 1 - Puissance 4",
    "section": "Detection of a victory (vertical)",
    "text": "Detection of a victory (vertical)\nNow, we focus on detecting a vertical victory. Compared to the previous situation, the difficulty is that we cannot directly loop over the columns. We will therefore build a check_vertical_victory function that, for each column:\n\nretrieves the elements of the column in a list\napplies the check_row_victory function to this list to check for 4 consecutive pieces of the same color in the considered column\n\n\nExpected result\n\n# Detection of a (vertical) victory on a grid\ngrid = solutions.display_grid()  # Initialization\nprint(solutions.check_vertical_victory(grid))  # Returns False\nprint()  # New line\n\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ngrid = solutions.make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\nsolutions.display_grid(grid)\nprint()  # New line\n\nprint(solutions.check_vertical_victory(grid))  # Returns True\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[46], line 2\n      1 # Detection of a (vertical) victory on a grid\n----&gt; 2 grid = solutions.display_grid()  # Initialization\n      3 print(solutions.check_vertical_victory(grid))  # Returns False\n      4 print()  # New line\n\nTypeError: display_grid() missing 1 required positional argument: 'grid'\n\n\n\n\n\nYour turn!\n\ndef check_vertical_victory(grid):\n    # Your code here\n\n\n  Cell In[47], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\n# Checking the result\ngrid = display_grid()  # Initialization\nprint(check_vertical_victory(grid))  # Returns False\nprint()  # New line\n\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\ndisplay_grid(grid)\nprint()  # New line\n\nprint(check_vertical_victory(grid))  # Returns True\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[48], line 3\n      1 # Checking the result\n      2 grid = display_grid()  # Initialization\n----&gt; 3 print(check_vertical_victory(grid))  # Returns False\n      4 print()  # New line\n      6 grid = make_move(grid=grid, column_to_play=2, disc_color=\"Y\")\n\nNameError: name 'check_vertical_victory' is not defined",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#end-of-game",
    "href": "source/projects/puissance4/tutorial.html#end-of-game",
    "title": "Projet 1 - Puissance 4",
    "section": "End of game",
    "text": "End of game\nIn our simplified version of Connect 4, we can now declare the end of the game: as soon as a horizontal or vertical victory is detected.\nWe will first create a check_victory function that takes the grid as input and returns True if a horizontal or vertical victory is detected, and False otherwise.\nIdeally, we would not want to manually test after each move if the game is over to limit code duplication. We will therefore create a make_move_and_check_victory function that:\n\ntakes the same inputs as the make_move function\ncalls the make_move function to make the move\ntests after the move if a victory is detected via the check_victory function. If a victory is detected, the function prints “END OF GAME”.\n\n\nExpected result\n\ngrid = solutions.initialize_grid()  # Initialization\nprint(\"Turn 1\")\ngrid = solutions.make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\nprint(\"Turn 2\")\ngrid = solutions.make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\nprint(\"Turn 3\")\ngrid = solutions.make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\nprint(\"Turn 4\")\ngrid = solutions.make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\n\nTurn 1\nTurn 2\nTurn 3\nTurn 4\nYellow won!\nGAME OVER\n\n\n\n\nYour turn!\n\ndef check_victory(grid):\n    # Your code here\n\n\n  Cell In[50], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\ndef make_move_and_check_victory(grid, column_to_play, disc_color):\n    grid = copy.deepcopy(grid)\n    # Your code here\n    return grid\n\n\n# Checking the result\ngrid = initialize_grid()  # Initialization\nprint(\"Turn 1\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\nprint(\"Turn 2\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\nprint(\"Turn 3\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\nprint(\"Turn 4\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[52], line 2\n      1 # Checking the result\n----&gt; 2 grid = initialize_grid()  # Initialization\n      3 print(\"Turn 1\")\n      4 grid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"Y\")\n\nNameError: name 'initialize_grid' is not defined",
    "crumbs": [
      "Projects",
      "Project 1 - Connect 4"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html",
    "href": "source/fundamentals/oop/tutorial.html",
    "title": "Introduction to object-oriented programming",
    "section": "",
    "text": "Python is a so-called “multi-paradigm” language, meaning it allows for multiple ways to code and design programs. One of these ways is object-oriented programming (OOP). OOP is a powerful paradigm but involves fairly complex concepts (polymorphism, inheritance, etc.). Fortunately for us, Python does not enforce coding in OOP. However, the internal workings of Python are heavily influenced by OOP, and most widely used packages rely on objects to varying degrees. In this tutorial, we will study the basics of OOP to be autonomous when its use is necessary.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#object-oriented-programming",
    "href": "source/fundamentals/oop/tutorial.html#object-oriented-programming",
    "title": "Introduction to object-oriented programming",
    "section": "Object-oriented programming",
    "text": "Object-oriented programming\nYou may have heard that Python is an “object-oriented programming” language. OOP is a programming paradigm that structures programs around an abstraction, the object, which contains attributes (characteristics of the object) and methods (functions specific to the object) that act on itself. To illustrate this somewhat abstract definition, we can take the example (source) of a “lemon” object that contains the attributes “flavor” and “color”, and a method “squeeze” that allows extracting its juice.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#everything-is-an-object",
    "href": "source/fundamentals/oop/tutorial.html#everything-is-an-object",
    "title": "Introduction to object-oriented programming",
    "section": "“Everything is an object”",
    "text": "“Everything is an object”\nIn Python, everything is an object (in the OOP sense). Let’s see what this means by retrieving the type of various objects we’ve seen in previous tutorials.\n\nprint(type(1))\nprint(type(\"hello\"))\nprint(type([]))\nprint(type(()))\nprint(type({}))\n\ndef f(x):\n    print(x)\n\nprint(type(f))\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n&lt;class 'list'&gt;\n&lt;class 'tuple'&gt;\n&lt;class 'dict'&gt;\n&lt;class 'function'&gt;\n\n\nThese elements are all of different types, but they have one thing in common: the term class. Just as the def statement defines a function, the class statement defines a class of Python objects. Thus, each object usable in Python has a class that defines the object, its attributes, and its methods.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#defining-your-own-objects",
    "href": "source/fundamentals/oop/tutorial.html#defining-your-own-objects",
    "title": "Introduction to object-oriented programming",
    "section": "Defining your own objects",
    "text": "Defining your own objects\nLet’s see how we can use the class statement to define our “lemon” object.\n\nclass Lemon:\n\n    def __init__(self, color, juice_qty):\n        self.flavor = \"sour\"\n        self.color = color\n        self.juice = juice_qty\n\n    def get_juice_qty(self):\n        print(\"There is \" + str(self.juice) + \" mL of juice left in the lemon.\")\n\n    def squeeze_juice(self, amount):\n        if amount &gt; self.juice:\n            print(\"There is not enough juice in the lemon for the requested amount.\")\n        else:\n            self.juice = max(0, self.juice - amount)  # avoids any negative value of `juice`\n\nLet’s analyze the syntax for constructing a class of objects:\n\nThe class statement defines the class of objects. Different objects can be created according to the model defined by this class. By convention, the class name should start with an uppercase letter.\nThe class specifies several functions. In this particular context, these functions are called “methods”: they are specific to the defined class of objects.\nA first very specific method, named __init__, is called the constructor. It allows defining the attributes attached to this class of objects. It is possible to pass parameters to the function (such as color and juice_qty) to define attributes specific to an instance of the object (more details on this concept in the next section).\nThe constructor has a mandatory parameter: self. It is a reference to the instances that will be created from this class. Note the syntax that defines an attribute: self.attribute = value.\nThe other methods are defined by the user. They also take self as a parameter, allowing them to perform operations on/from the attributes. As they are functions, they can also accept other parameters. Thus, the squeeze_juice function takes an amount parameter that defines how much juice is extracted from the lemon when squeezed.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#the-class-and-its-instances",
    "href": "source/fundamentals/oop/tutorial.html#the-class-and-its-instances",
    "title": "Introduction to object-oriented programming",
    "section": "The class and its instances",
    "text": "The class and its instances\nThe class can be seen as the recipe that allows creating an object: it defines the attributes and methods that all objects defined from this class will have. Defining a class as above simply makes this recipe available in the Python environment. To create an object according to this class, it must be instantiated.\n\nlemon1 = Lemon(color=\"yellow\", juice_qty=45)\nlemon2 = Lemon(color=\"green\", juice_qty=32)\n\nprint(type(lemon1))\nprint(type(lemon2))\n\n&lt;class '__main__.Lemon'&gt;\n&lt;class '__main__.Lemon'&gt;\n\n\nHere, we have created two instances of the Lemon class. These two instances are independent: Python sees them as two distinct objects. However, they were created from the same class and therefore have the same type.\nThis distinction between the class and its instances helps to better understand the meaning of the self parameter. It is a reference to the instances that will be created according to the class, allowing the specification of their attributes and methods. When a given instance is created, it essentially becomes the self.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#attributes",
    "href": "source/fundamentals/oop/tutorial.html#attributes",
    "title": "Introduction to object-oriented programming",
    "section": "Attributes",
    "text": "Attributes\nAn attribute is a variable associated with an object. An attribute can contain any Python object.\n\nAccessing attributes\nOnce the object is instantiated, it is possible to access its attributes. The syntax is simple: instance.attribute.\n\nprint(lemon1.color)\nprint(lemon2.color)\nprint(lemon1.juice)\nprint(lemon2.juice)\n\nyellow\ngreen\n45\n32\n\n\nWe can see that the two instances are independent: although they are of the same type, their attributes differ.\n\n\nModifying an attribute\nModifying an attribute of an instance is very simple, the syntax is: instance.attribute = new_value.\n\nlemon2.color = \"red\"\nprint(lemon2.color)\n\nred\n\n\nIt is also possible to add an attribute according to the same logic: instance.new_attribute = value. However, this is not good programming practice, as the class precisely serves to define the attributes that objects of a given class can have. Therefore, it is generally preferable to define attributes within the class rather than outside.\n\n\nClass attributes and instance attributes\nThe two instances we created illustrate different types of attributes:\n\nClass attributes. These are attributes that have the same value for every instance created according to this class. Here, it is the flavor attribute: all lemons are sour, so there is no reason to allow modifying this parameter during instantiation. Strictly speaking, we could even define this attribute outside the constructor.\nInstance attributes. These are attributes whose values can vary between different instances created according to the same class. Here, these are the color and juice attributes: there are lemons of different colors and larger or smaller lemons that will therefore have different amounts of juice. It is up to the user to define these attributes during instantiation.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#methods",
    "href": "source/fundamentals/oop/tutorial.html#methods",
    "title": "Introduction to object-oriented programming",
    "section": "Methods",
    "text": "Methods\nA method is a function associated with an object. It can use its attributes, modify them, and involve other methods of the object.\n\nCalling a method\nThe syntax for calling a method of an instantiated object is as follows: instance.method(parameters).\n\nlemon1.get_juice_qty()\n\nThere is 45 mL of juice left in the lemon.\n\n\nTwo remarks can be made about this syntax. The first is that a method is a function attached to an instance of an object. Unlike functions defined via the def statement, methods do not have an independent existence outside the object’s instance. In our case, calling the get_juice_qty() function independently of the object returns an error.\n\nget_juice_qty()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[19], line 1\n----&gt; 1 get_juice_qty()\n\nNameError: name 'get_juice_qty' is not defined\n\n\n\nThe second remark is that we no longer specify the self parameter when manipulating an instance. The instance itself has become the self (or rather a self). The link between the method and its instance is already made since the method cannot be used without first calling the instance.\n\n\nActing on attributes\nThe main interest of methods is that they can access attributes and perform operations based on them, as well as modify them. Let’s take our example again to illustrate this possibility.\n\nlemon1 = Lemon(color=\"yellow\", juice_qty=45)\n\nlemon1.get_juice_qty()\nlemon1.squeeze_juice(12)\nlemon1.get_juice_qty()\n\nThere is 45 mL of juice left in the lemon.\nThere is 33 mL of juice left in the lemon.\n\n\nThe get_juice_qty method simply displays the value of an attribute in a formatted way. The squeeze_juice method, on the other hand, permanently modifies the value of the juice attribute, as shown by the second call to get_juice_qty.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#when-to-use-oop",
    "href": "source/fundamentals/oop/tutorial.html#when-to-use-oop",
    "title": "Introduction to object-oriented programming",
    "section": "When to use OOP?",
    "text": "When to use OOP?\nThe previous example is interesting because it illustrates both an advantage and a disadvantage of OOP.\nThe fact that objects have attributes allows maintaining the state of a resource—in our example, the amount of juice contained in a given Lemon class object. To take more realistic examples, this property is interesting and used in several cases:\n\nTraining a machine learning model. It is common to train a model once and then want to continue training it longer or with different data. Saving the state in an instance of the Model class allows for this. This is why most machine learning packages in Python are based on OOP.\nThe continuous operation of a web application. Such an application must keep things in memory to provide a smooth user experience: the fact that the user has logged in, their history, etc. Again, most web frameworks (Django, Flask, etc.) rely on OOP.\n\nAt the same time, using objects that keep a state in memory can limit the reproducibility of analyses. To illustrate this, let’s return to the example in the tutorial: execute the following cell several times in a row.\n\n{python}\nlemon1.get_juice_qty()\nlemon1.squeeze_juice(12)\nlemon1.get_juice_qty()\nThe three executions give different results, even though the executed code is strictly the same. This illustrates the reproducibility issue: when using OOP, you must be mindful of the state of objects kept in memory, or you risk not getting the same results when replicating an analysis.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#exercises",
    "href": "source/fundamentals/oop/tutorial.html#exercises",
    "title": "Introduction to object-oriented programming",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension questions\n\n1/ “In Python, everything is an object”: what does this phrase mean?\n2/ What is the purpose of the class statement?\n3/ What is the purpose of the __init__ constructor?\n4/ What is the purpose of self?\n5/ What is the difference between a class and an instance?\n6/ What is an attribute?\n7/ What is the difference between a method and a function?\n8/ How can you tell the difference between an attribute and a method when calling them?\n9/ Can an attribute be modified by a method? Can an attribute be modified outside a method?\n10/ When is OOP generally used?\n\n\n\n\nShow solution\n\n\n1/ It means that all Python objects (numbers, strings, lists, etc.) are objects in the OOP sense: they have attributes and methods defined by a class.\n2/ The class statement is used to define a class of objects.\n3/ The __init__ constructor is a special method that allows the user to define an object’s attributes.\n4/ self serves as a reference to the instance within the class. It indicates who will carry the attributes and methods once the object is instantiated.\n5/ The class is the “recipe” that defines all the characteristics of the object. But the object is not truly created until the class is instantiated, i.e., when an instance is created from the class.\n6/ An attribute is a variable associated with an object.\n7/ A method is a specific function: it is associated with an object and does not exist independently of it.\n8/ The presence of parentheses distinguishes between calling an attribute and calling a method. Attribute call: instance.attribute Method call: instance.method() with any parameters.\n9/ Yes, this is one of the main uses of methods. But an attribute can also be manually modified.\n10/ When manipulating objects whose state of a resource should be maintained within a program.\n\n\n\n\n\nFrom mass to juice\nAssume that the juice contained in a lemon is a proportional function of its mass, defined as follows: \\(juice = \\frac {mass} {4}\\) where mass is in grams and juice in mL.\nModify the Lemon class, reproduced in the following cell, so that:\n\nDuring instantiation, the user no longer defines the quantity of juice, but the mass of the lemon.\nThe juice attribute is calculated according to the above formula.\nAdd a method that displays “The mass of the lemon is x grams.”\n\nInstantiate a new lemon and verify that everything works as expected.\n\nclass Lemon:\n\n    def __init__(self, color, juice_qty):\n        self.flavor = \"sour\"\n        self.color = color\n        self.juice = juice_qty\n\n    def get_juice_qty(self):\n        print(\"There is \" + str(self.juice) + \" mL of juice left in the lemon.\")\n\n    def squeeze_juice(self, amount):\n        if amount &gt; self.juice:\n            print(\"There is not enough juice in the lemon for the requested amount.\")\n        else:\n            self.juice = max(0, self.juice - amount)  # avoids any negative value of `juice`\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nclass Lemon:\n\n    def __init__(self, color, mass):\n        self.flavor = \"sour\"\n        self.color = color\n        self.mass = mass\n        self.juice = mass / 4\n\n    def get_mass(self):\n        print(\"The mass of the lemon is \" + str(self.mass) + \" grams.\")\n\n    def get_juice_qty(self):\n        print(\"There is \" + str(self.juice) + \" mL of juice left in the lemon.\")\n\n    def squeeze_juice(self, amount):\n        if amount &gt; self.juice:\n            print(\"There is not enough juice in the lemon for the requested amount.\")\n        else:\n            self.juice = max(0, self.juice - amount)  # avoids any negative value of `juice`\n\nlemon = Lemon(\"yellow\", 500)\n\nlemon.get_mass()\nlemon.get_juice_qty()\n\nThe mass of the lemon is 500 grams.\nThere is 125.0 mL of juice left in the lemon.\n\n\n\n\n\n\nBank accounts\nExercise freely inspired by: https://github.com/Pierian-Data/Complete-Python-3-Bootcamp\nWe have seen that OOP is particularly interesting when we want to manipulate objects that keep the state of a resource. This is, for example, the case of a bank account, which keeps a balance and allows or disallows certain operations based on this balance.\nImplement a BankAccount class with:\n\nTwo attributes: holder (account holder’s name) and balance (account balance in euros).\nA show_balance method that displays: “The balance of the account of holder_name is x euros.”\nA deposit method that accepts an amount parameter. When a deposit is made, the account balance is incremented by the deposit amount.\nA withdraw method that accepts an amount parameter. When a withdrawal is made:\n\nIf the amount is less than the balance: the balance is decremented by the amount, and “Withdrawal accepted.” is displayed.\nIf the amount is greater than the balance: “Withdrawal denied: insufficient funds.” is displayed and the balance remains unchanged.\n\nA transfer method that accepts an amount parameter and a recipient parameter that takes another instance of the BankAccount class (i.e., another client). For example, client1.transfer(recipient=client2, amount=1000):\n\nIf the amount is less than client1’s balance: client1’s balance is decremented by the amount, client2’s balance is incremented by the amount.\nIf the amount is greater than client1’s balance: “Transfer denied: insufficient funds.” is displayed and the balances of both clients remain unchanged.\n\n\nCreate two clients and test that the various functionalities to be implemented work as expected.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nclass BankAccount:\n    def __init__(self, holder, balance):\n        self.holder = holder\n        self.balance = balance\n\n    def show_balance(self):\n        print(\"The balance of the account of \" + self.holder + \" is \" + str(self.balance) + \" euros.\")\n\n    def deposit(self, amount):\n        self.balance += amount\n\n    def withdraw(self, amount):\n        if self.balance &gt;= amount:\n            self.balance -= amount\n            print(\"Withdrawal accepted.\")\n        else:\n            print(\"Withdrawal denied: insufficient funds.\")\n\n    def transfer(self, recipient, amount):\n        if self.balance &gt;= amount:\n            recipient.balance += amount\n            self.balance -= amount\n        else:\n            print(\"Transfer denied: insufficient funds.\")\n\nclient1 = BankAccount(\"Bernard\", 2000)\nclient2 = BankAccount(\"Bianca\", 5000)\n\nclient1.show_balance()\nclient2.show_balance()\n\nprint()  # newline\n\nclient1.deposit(1000)\nclient1.show_balance() # +1000\n\nprint()\n\nclient2.withdraw(6000)\nclient2.show_balance() # no change\n\nprint()\n\nclient2.withdraw(1000)\nclient2.show_balance() # -1000\n\nprint()\n\nclient2.transfer(client1, 5000)\nclient2.show_balance() # no change\n\nprint()\n\nclient2.transfer(client1, 2000)\nclient2.show_balance() # - 2000\nclient1.show_balance() # + 2000\n\nThe balance of the account of Bernard is 2000 euros.\nThe balance of the account of Bianca is 5000 euros.\n\nThe balance of the account of Bernard is 3000 euros.\n\nWithdrawal denied: insufficient funds.\nThe balance of the account of Bianca is 5000 euros.\n\nWithdrawal accepted.\nThe balance of the account of Bianca is 4000 euros.\n\nTransfer denied: insufficient funds.\nThe balance of the account of Bianca is 4000 euros.\n\nThe balance of the account of Bianca is 2000 euros.\nThe balance of the account of Bernard is 5000 euros.",
    "crumbs": [
      "Fundamentals",
      "Introduction to object-oriented programming"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introductory training to Python",
    "section": "",
    "text": "The SSPy training offers an introduction to the use of Python in statistical projects. It is particularly designed for agents of the public statistical service (SSP), with applications involving, as much as possible, data from French public statistics. Nevertheless, its materials are completely open-source (GitHub repository) and can therefore be reused in any Python training context.\n\n\n\nPython, created by Dutch developer Guido van Rossum in 1991, is a high-level programming language known for its simple and readable syntax. The founding principles of the language are summarized in a manifesto called the “Zen of Python”. Python is a particularly versatile language, as it has a rich library of packages and brings together diverse communities, making it ideal for many application domains.\n\n\n\nDespite being over 30 years old, Python remains an extremely dynamic language. More than that: not only is it already among the most popular languages, but it is also the one experiencing the fastest growth in terms of the number of users year after year.\n\n\n\n\n\nOne of the main reasons for this strong current growth is the rise of the data science field, within which Python has gradually established itself as the central language. Many key libraries in the field of data manipulation, data visualization, machine learning, and application deployment are available in Python. This growing adoption in various sectors makes it a preferred choice to unify practices through a common language, applicable to data science, development, as well as IT and statistical production.\n\n\n\n\n\nSource: josephsalmon.eu\n\n\n\nPython and R are often compared because of their wide use in the statistical field. The fundamental difference is that Python is a general-purpose language, while R is specifically oriented towards statistics. However, in practice, they are more complementary than competitive, and the choice between the two often depends on the use case: for example, while the tidyverse ecosystem in R is unmatched for data manipulation, the ecosystem that has developed in Python around machine learning techniques (particularly the scikit-learn package) has no direct equivalent in the R world. Finally, the two languages are similar, and transitioning from one to the other is accessible without requiring a complete and costly relearning.\n\n\n\n\n\n\nThis training adopts a tutored e-training format. It takes place over an extended period (several months), with a focus on practical pedagogy. Tutoring is also available via a Tchap Channel, where participants can ask their questions continuously, as well as during periodic videoconference sessions.\n\n\n\nThe training is hosted on the SSP Cloud platform developed by Insee. This platform, dedicated to experimentation around data science and work on open data, offers an environment particularly suited to training with pre-configured environments having all the computing power necessary for common and innovative statistical processing.\n\n\n\nThe training program is divided into three main parts:\n\nFundamentals of the Python language: basic types, data structures, conditional statements, functions, and an introduction to object-oriented programming in Python;\nData manipulation: file manipulation, working with CSV and JSON files, numerical computation with NumPy, tabular data processing with Pandas, and an introduction to data visualization in Python;\nApplication projects: building a Connect 4 game, weather predictions using data from APIs, and population census analysis.\n\nEach chapter ends with a series of guided exercises that aim to directly apply the concepts studied in the chapter. The application projects are more exploratory and aim to apply the concepts studied throughout the training on realistic use cases.\n\n\n\n\n\n\nThe different chapters can be launched with a single click from the training space of the SSP Cloud. Launching a chapter means launching a jupyter-python service on the SSP Cloud, pre-configured for the training and which will open directly on the notebook associated with the chapter.\n\n\n\n\n\n\n\n\n\n\nThe training uses the interactive Jupyter notebook format, combining Markdown text, Python code, and HTML code for visualizations and animations. This format is particularly suitable for training and experimentation phases. Moreover, it allows for simple publication of both exercise notebooks and the associated course site.\n\n\n\n\n\n\n\n\nThe core of the notebook is the kernel, visible at the top right (Python 3 (ipykernel)) and which launches automatically when a notebook is opened. Practically, it is a Python interpreter running continuously in the background, allowing dynamic execution of Python code cells. Thus, objects created in one cell are persisted and can be called in another cell, enabling linear execution of the notebook like a script. When you want to clean the working environment of all objects created during the session, you can restart it (Kernel menu -&gt; Restart Kernel).\nThe greyed-out cells are code cells. To execute the content of a cell, simply click on it and use the keyboard shortcuts Ctrl + Enter (executes the cell and remains on the active cell) or Shift + Enter (executes the cell and moves to the next cell). Note that executing a cell means executing all its content. If you want to execute line by line, you can create new cells (➕ button) and insert the different lines of code. Other code editors (like VSCode, available on the SSP Cloud) allow, like RStudio for example, to execute code line by line, but they are less suitable for discovering Python.\n\n\n\n\nEncountering errors is quite natural and expected when learning (and even after!) a programming language. Resolving these errors is really an opportunity to understand how the language works and to become autonomous in its practice. Here are some suggested steps to follow (in this order) to resolve an error:\n\n1/ Carefully read the logs, i.e., the outputs returned by Python in case of an error. Often, they are informative and can directly contain the answer.\n2/ Search the internet (preferably in English and on Google). For example, giving the error name and an informative part of the error message returned by Python generally helps direct the results towards what you are looking for.\n3/ Often, the search will lead to the forum Stackoverflow, intended for this use. If you really can’t find the answer to your problem, you can post on Stackoverflow detailing the problem encountered so that forum users can reproduce it and find a solution.\n4/ Official documentation (of Python and various packages) is often a bit dry, but generally exhaustive. It helps to understand how to use different objects properly. For example, for functions: what they expect as input, the parameters and their types, what they return as output, etc.\n\n\n\n\n\n\n\nAll training materials remain accessible on the SSP Cloud after the training. The code that generates the materials is available on GitHub.\n\n\n\nTo deepen your knowledge of the Python language after this introductory training, nothing beats practical application on concrete subjects! For the modalities of using Python in the context of statistical projects, it will depend on the organization:\n\nfor open-data and inter-administrative projects, the SSP Cloud is a good alternative since Python services are already pre-configured there and a data storage service is offered (see documentation for more details);\nfor internal Insee projects, refer to the documentation on the use of Python internally;\nfor projects internal to other administrations, contact your IT department to find out the recommended usage modalities.\n\n\n\n\nThe “natural” continuation of this training is the course on Python for data science given by Lino Galiana at ENSAE, also deployed in the training space of the SSP Cloud. The course picks up where this training leaves off and provides a very comprehensive overview of the different data science methods that can be employed in Python.\nTo deepen the more algorithmic approach to coding, the Advent of Code offers an exercise per day each December in the form of two-part puzzles, involving algorithmic solutions. It is an excellent opportunity to develop both algorithmic reflexes and Python knowledge. Note: while the first days remain accessible, the difficulty of the puzzles quickly becomes quite high."
  },
  {
    "objectID": "index.html#context",
    "href": "index.html#context",
    "title": "Introductory training to Python",
    "section": "",
    "text": "The SSPy training offers an introduction to the use of Python in statistical projects. It is particularly designed for agents of the public statistical service (SSP), with applications involving, as much as possible, data from French public statistics. Nevertheless, its materials are completely open-source (GitHub repository) and can therefore be reused in any Python training context.\n\n\n\nPython, created by Dutch developer Guido van Rossum in 1991, is a high-level programming language known for its simple and readable syntax. The founding principles of the language are summarized in a manifesto called the “Zen of Python”. Python is a particularly versatile language, as it has a rich library of packages and brings together diverse communities, making it ideal for many application domains.\n\n\n\nDespite being over 30 years old, Python remains an extremely dynamic language. More than that: not only is it already among the most popular languages, but it is also the one experiencing the fastest growth in terms of the number of users year after year.\n\n\n\n\n\nOne of the main reasons for this strong current growth is the rise of the data science field, within which Python has gradually established itself as the central language. Many key libraries in the field of data manipulation, data visualization, machine learning, and application deployment are available in Python. This growing adoption in various sectors makes it a preferred choice to unify practices through a common language, applicable to data science, development, as well as IT and statistical production.\n\n\n\n\n\nSource: josephsalmon.eu\n\n\n\nPython and R are often compared because of their wide use in the statistical field. The fundamental difference is that Python is a general-purpose language, while R is specifically oriented towards statistics. However, in practice, they are more complementary than competitive, and the choice between the two often depends on the use case: for example, while the tidyverse ecosystem in R is unmatched for data manipulation, the ecosystem that has developed in Python around machine learning techniques (particularly the scikit-learn package) has no direct equivalent in the R world. Finally, the two languages are similar, and transitioning from one to the other is accessible without requiring a complete and costly relearning."
  },
  {
    "objectID": "index.html#training-modalities",
    "href": "index.html#training-modalities",
    "title": "Introductory training to Python",
    "section": "",
    "text": "This training adopts a tutored e-training format. It takes place over an extended period (several months), with a focus on practical pedagogy. Tutoring is also available via a Tchap Channel, where participants can ask their questions continuously, as well as during periodic videoconference sessions.\n\n\n\nThe training is hosted on the SSP Cloud platform developed by Insee. This platform, dedicated to experimentation around data science and work on open data, offers an environment particularly suited to training with pre-configured environments having all the computing power necessary for common and innovative statistical processing.\n\n\n\nThe training program is divided into three main parts:\n\nFundamentals of the Python language: basic types, data structures, conditional statements, functions, and an introduction to object-oriented programming in Python;\nData manipulation: file manipulation, working with CSV and JSON files, numerical computation with NumPy, tabular data processing with Pandas, and an introduction to data visualization in Python;\nApplication projects: building a Connect 4 game, weather predictions using data from APIs, and population census analysis.\n\nEach chapter ends with a series of guided exercises that aim to directly apply the concepts studied in the chapter. The application projects are more exploratory and aim to apply the concepts studied throughout the training on realistic use cases."
  },
  {
    "objectID": "index.html#practically",
    "href": "index.html#practically",
    "title": "Introductory training to Python",
    "section": "",
    "text": "The different chapters can be launched with a single click from the training space of the SSP Cloud. Launching a chapter means launching a jupyter-python service on the SSP Cloud, pre-configured for the training and which will open directly on the notebook associated with the chapter.\n\n\n\n\n\n\n\n\n\n\nThe training uses the interactive Jupyter notebook format, combining Markdown text, Python code, and HTML code for visualizations and animations. This format is particularly suitable for training and experimentation phases. Moreover, it allows for simple publication of both exercise notebooks and the associated course site.\n\n\n\n\n\n\n\n\nThe core of the notebook is the kernel, visible at the top right (Python 3 (ipykernel)) and which launches automatically when a notebook is opened. Practically, it is a Python interpreter running continuously in the background, allowing dynamic execution of Python code cells. Thus, objects created in one cell are persisted and can be called in another cell, enabling linear execution of the notebook like a script. When you want to clean the working environment of all objects created during the session, you can restart it (Kernel menu -&gt; Restart Kernel).\nThe greyed-out cells are code cells. To execute the content of a cell, simply click on it and use the keyboard shortcuts Ctrl + Enter (executes the cell and remains on the active cell) or Shift + Enter (executes the cell and moves to the next cell). Note that executing a cell means executing all its content. If you want to execute line by line, you can create new cells (➕ button) and insert the different lines of code. Other code editors (like VSCode, available on the SSP Cloud) allow, like RStudio for example, to execute code line by line, but they are less suitable for discovering Python.\n\n\n\n\nEncountering errors is quite natural and expected when learning (and even after!) a programming language. Resolving these errors is really an opportunity to understand how the language works and to become autonomous in its practice. Here are some suggested steps to follow (in this order) to resolve an error:\n\n1/ Carefully read the logs, i.e., the outputs returned by Python in case of an error. Often, they are informative and can directly contain the answer.\n2/ Search the internet (preferably in English and on Google). For example, giving the error name and an informative part of the error message returned by Python generally helps direct the results towards what you are looking for.\n3/ Often, the search will lead to the forum Stackoverflow, intended for this use. If you really can’t find the answer to your problem, you can post on Stackoverflow detailing the problem encountered so that forum users can reproduce it and find a solution.\n4/ Official documentation (of Python and various packages) is often a bit dry, but generally exhaustive. It helps to understand how to use different objects properly. For example, for functions: what they expect as input, the parameters and their types, what they return as output, etc."
  },
  {
    "objectID": "index.html#after-the-training",
    "href": "index.html#after-the-training",
    "title": "Introductory training to Python",
    "section": "",
    "text": "All training materials remain accessible on the SSP Cloud after the training. The code that generates the materials is available on GitHub.\n\n\n\nTo deepen your knowledge of the Python language after this introductory training, nothing beats practical application on concrete subjects! For the modalities of using Python in the context of statistical projects, it will depend on the organization:\n\nfor open-data and inter-administrative projects, the SSP Cloud is a good alternative since Python services are already pre-configured there and a data storage service is offered (see documentation for more details);\nfor internal Insee projects, refer to the documentation on the use of Python internally;\nfor projects internal to other administrations, contact your IT department to find out the recommended usage modalities.\n\n\n\n\nThe “natural” continuation of this training is the course on Python for data science given by Lino Galiana at ENSAE, also deployed in the training space of the SSP Cloud. The course picks up where this training leaves off and provides a very comprehensive overview of the different data science methods that can be employed in Python.\nTo deepen the more algorithmic approach to coding, the Advent of Code offers an exercise per day each December in the form of two-part puzzles, involving algorithmic solutions. It is an excellent opportunity to develop both algorithmic reflexes and Python knowledge. Note: while the first days remain accessible, the difficulty of the puzzles quickly becomes quite high."
  },
  {
    "objectID": "slides/index.html#python-en-résumé",
    "href": "slides/index.html#python-en-résumé",
    "title": "Introduction à Python",
    "section": "Python en résumé",
    "text": "Python en résumé\n\nCréé par Guido van Rossum en 1991\nLangage de haut-niveau\n\nSyntaxe simple et lisible\nPrincipes : “Zen de Python”\n\nLangage puissant\n\nVersatile : riche bibliothèque de packages\nFédère des communautés diverses"
  },
  {
    "objectID": "slides/index.html#pourquoi-se-former-à-python",
    "href": "slides/index.html#pourquoi-se-former-à-python",
    "title": "Introduction à Python",
    "section": "Pourquoi se former à Python ?",
    "text": "Pourquoi se former à Python ?\n\nUn langage extrêmement dynamique"
  },
  {
    "objectID": "slides/index.html#pourquoi-se-former-à-python-1",
    "href": "slides/index.html#pourquoi-se-former-à-python-1",
    "title": "Introduction à Python",
    "section": "Pourquoi se former à Python ?",
    "text": "Pourquoi se former à Python ?\n\nLangage central de l’écosystème data science\n\n\n\n\n\n\nSource : josephsalmon.eu"
  },
  {
    "objectID": "slides/index.html#pourquoi-se-former-à-python-2",
    "href": "slides/index.html#pourquoi-se-former-à-python-2",
    "title": "Introduction à Python",
    "section": "Pourquoi se former à Python ?",
    "text": "Pourquoi se former à Python ?\n\nUnifier les pratiques via un langage commun ?\n\nMétier : application des méthodes de data science\nDéveloppement : frameworks de développement applicatif\nProduction : adapté à la production informatique"
  },
  {
    "objectID": "slides/index.html#python-vs.-r",
    "href": "slides/index.html#python-vs.-r",
    "title": "Introduction à Python",
    "section": "Python vs. R ?",
    "text": "Python vs. R ?\n\nDifférence fondamentale\n\nR : langage statistique\nPython : langage généraliste\n\nPlutôt complémentaires que concurrents\n\nPréférer l’un ou l’autre selon le cas d’usage\n\nTransition d’un langage à l’autre accessible"
  },
  {
    "objectID": "slides/index.html#une-e-formation-tutorée",
    "href": "slides/index.html#une-e-formation-tutorée",
    "title": "Introduction à Python",
    "section": "Une “e-formation tutorée”",
    "text": "Une “e-formation tutorée”\n\nE-formation\n\nFormation sur un temps long\nPédagogie par la pratique\n\nTutorat\n\nCanal Tchap : pour poser toutes vos questions en continu\nVisio périodique (dates à définir) : questions de fond, déroulement pas à pas.."
  },
  {
    "objectID": "slides/index.html#hébergée-sur-le-ssp-cloud",
    "href": "slides/index.html#hébergée-sur-le-ssp-cloud",
    "title": "Introduction à Python",
    "section": "Hébergée sur le SSP Cloud",
    "text": "Hébergée sur le SSP Cloud\n\nPlateforme développée à l’Insee\n\nExpérimentation autour de la data science\nTravail sur données ouvertes\n\nEnvironnement particulièrement adapté à la formation\n\nPré-configuré\nReproductibilité"
  },
  {
    "objectID": "slides/index.html#programme-de-la-formation",
    "href": "slides/index.html#programme-de-la-formation",
    "title": "Introduction à Python",
    "section": "Programme de la formation",
    "text": "Programme de la formation\n\nTrois grandes parties\n\nFondamentaux du langage\nManipulation de données\nProjets\n\nApplications : cas d’usage de statistique publique"
  },
  {
    "objectID": "slides/index.html#les-notebooks-jupyter",
    "href": "slides/index.html#les-notebooks-jupyter",
    "title": "Introduction à Python",
    "section": "Les notebooks Jupyter",
    "text": "Les notebooks Jupyter\n\nUn format de type notebook (cahier) interactif qui combine\n\nDu texte Markdown (texte, équations, etc.)\nDu code Python\nDu code HTML (visualisations, animations..)\n\nParticulièrement adapté aux phases d’expérimentation"
  },
  {
    "objectID": "slides/index.html#démo",
    "href": "slides/index.html#démo",
    "title": "Introduction à Python",
    "section": "Démo",
    "text": "Démo\n\nSeul pré-requis : créer un compte sur le SSP Cloud"
  },
  {
    "objectID": "slides/index.html#comment-résoudre-les-bugs",
    "href": "slides/index.html#comment-résoudre-les-bugs",
    "title": "Introduction à Python",
    "section": "Comment résoudre les bugs ?",
    "text": "Comment résoudre les bugs ?\n\nEtapes de résolution\n\n1/ Bien lire les logs\n2/ Chercher sur internet (de préférence en Anglais et sur Google)\n3/ Sources fréquentes : documentations officielles et Stackoverflow\n4/ Poser une question détaillée (problème ET logs) sur le canal Tchap"
  },
  {
    "objectID": "slides/index.html#accès-aux-supports",
    "href": "slides/index.html#accès-aux-supports",
    "title": "Introduction à Python",
    "section": "Accès aux supports",
    "text": "Accès aux supports\n\nTous les supports de formation restent accessibles sur le SSP Cloud après la formation\nLe code qui génère les supports est disponible sur GitHub"
  },
  {
    "objectID": "slides/index.html#après-la-formation",
    "href": "slides/index.html#après-la-formation",
    "title": "Introduction à Python",
    "section": "Après la formation ?",
    "text": "Après la formation ?\n\nSuite logique : Python pour la data science (ENSAE)\nOrientation algorithmie : Advent of Code"
  },
  {
    "objectID": "slides/index.html#utiliser-python-dans-des-projets-statistiques",
    "href": "slides/index.html#utiliser-python-dans-des-projets-statistiques",
    "title": "Introduction à Python",
    "section": "Utiliser Python dans des projets statistiques",
    "text": "Utiliser Python dans des projets statistiques\n\nModalités selon la nature des données utilisées\n\nProjets open-data : SSP Cloud\nProjets internes : AUSV3 / LS3\n\n\n\n\n\nFormation “Introduction à Python”"
  },
  {
    "objectID": "source/manipulation/dataviz/tutorial.html",
    "href": "source/manipulation/dataviz/tutorial.html",
    "title": "Introduction à la visualisation de données",
    "section": "",
    "text": "title: “Introduction to data visualization”\nData visualization (or dataviz) is an essential tool for understanding data and highlighting phenomena from it, as well as for effectively communicating analysis results. However, it is a field that goes far beyond mere technical skill: the best visualizations are those that are well-suited to the data they represent and can tell a story from it (data storytelling). This tutorial does not aim to cover the topic in detail but provides an introduction to the main tools available in Python for producing data visualizations.\nWe will start our exploration with the built-in plotting capabilities in Pandas, which are very simple and therefore perfect for quick data analysis. Then, we will discover Seaborn, a library that allows you to create attractive visualizations with very few lines of code. Both libraries are based on Matplotlib, the comprehensive reference library for visualization in Python, which allows for very advanced customization but is more complex to use, and will therefore not be directly addressed in this tutorial.",
    "crumbs": [
      "Data handling",
      "Introduction to data visualization"
    ]
  },
  {
    "objectID": "source/manipulation/dataviz/tutorial.html#pandas-1",
    "href": "source/manipulation/dataviz/tutorial.html#pandas-1",
    "title": "Introduction à la visualisation de données",
    "section": "Pandas",
    "text": "Pandas\nAs we saw in the dedicated tutorial, the Pandas library offers numerous powerful tools for manipulating tabular data. But it is also equipped with built-in tools for visualizing it. In particular, the .plot() method allows for quick visualizations of analyzed data.\n\nThe .plot() method\nThe .plot() method, integrated into Series and DataFrames, simplifies the process of creating charts by allowing standard visualizations to be generated with a single line of code directly from the data structure. Behind the scenes, .plot() calls Matplotlib for the graphical rendering, which means that any chart generated by Pandas can be further customized with Matplotlib functions. This integration offers a balance between convenience for quick visualization tasks and the power of Matplotlib for more extensive customization needs, making .plot() the ideal starting point for data visualization in Python.\n\n\nExample plots\nEven though the .plot() method allows for simple and quick chart generation, the possibilities are vast and depend on the input data. In this section, we provide some standard examples to understand the method’s functionality. For more possibilities, you can refer to the numerous examples in the official documentation.\nLet’s generate some synthetic data mimicking cash register data, which we will use as the basis for the charts.\n\nimport pandas as pd\nimport numpy as np\n\n\n# Configuration for reproducibility\nnp.random.seed(0)\n\n# Generate a range of dates over a month\ndates = pd.date_range(start='2023-01-01', end='2023-01-31', freq='D')\n\n# Simulate cash register data for the month\nN_POINTS = 1000\nmean_price = 10\nstd_dev_price = 4\nprices = np.random.normal(mean_price, std_dev_price, N_POINTS)\nquantities = 10 - 0.5 * prices + np.random.normal(0, 1.5, N_POINTS)\ndata = {\n    'Date': np.random.choice(dates, N_POINTS),\n    'Transaction_ID': np.arange(N_POINTS) + 1,\n    'COICOP': np.random.choice(['01.1.1', '02.1.1', '03.1.1', '04.1.1'], N_POINTS),\n    'Store': np.random.choice(['Carrefour', 'Casino', 'Lidl', 'Monoprix'], N_POINTS),\n    'Price': prices,\n    'Quantity': quantities\n}\n\n# Create the DataFrame\ndf_cash = pd.DataFrame(data)\n\n# Sort by date for consistency\ndf_cash = df_cash.sort_values(by='Date').reset_index(drop=True)\n\n# Display the first rows of the cash register data\nprint(df_cash.head())\n\n        Date  Transaction_ID  COICOP     Store      Price  Quantity\n0 2023-01-01             766  02.1.1      Lidl   5.588375  9.151826\n1 2023-01-01              32  03.1.1      Lidl  11.512650  4.450210\n2 2023-01-01             139  02.1.1  Monoprix  11.584027  6.314805\n3 2023-01-01             415  02.1.1    Casino  16.930885  0.861407\n4 2023-01-01             418  01.1.1    Casino  10.568247  2.590971\n\n\n\nScatter plot\nScatter plots allow for visualizing the relationship between two continuous numerical variables. Let’s illustrate this with the relationship between price and quantities of transactions.\n\ndf_cash.plot(x='Quantity', y='Price', kind='scatter')\n\n\n\n\n\n\n\n\n\n\nBar chart\nBar charts are ideal for visually comparing different categories. Here, we use the .value_counts() method to retrieve the frequencies of each category in a Series, and then apply the .plot() method to visualize a bar chart.\n\ndf_cash['Store'].value_counts().plot(kind='bar')\n\n\n\n\n\n\n\n\n\n\nBox plot\nThe box plot allows for quickly visualizing the dispersion statistics of a statistical series (median, quartiles, min, max) as well as the presence of any outliers.\n\ndf_cash['Price'].plot(kind=\"box\")\n\n\n\n\n\n\n\n\n\n\nHistogram\nHistograms help understand the distribution of a numerical variable. Let’s calculate the histogram of the prices of transactions over the studied period.\n\ndf_cash['Price'].plot(kind='hist', bins=20)\n\n\n\n\n\n\n\n\n\n\nLine plot\n\ndf_cash.groupby('Date')['Quantity'].sum().plot(kind='line')\n\n\n\n\n\n\n\n\n\n\n\nCustomization\nAs mentioned earlier, the built-in plotting functionality in Pandas is actually based on the Matplotlib library, as the .plot() method in Pandas is just a wrapper around the plot() function of Matplotlib. In theory, all the customization possibilities allowed by Matplotlib are available with the charts created this way in Pandas. To access them, you need to import Matplotlib in addition to Pandas.\n\nimport matplotlib.pyplot as plt\n\nLet’s illustrate some customization possibilities by revisiting one of the previous charts.\n\ndf_cash.plot(x='Quantity', y='Price', kind='scatter', color=\"green\", alpha=0.6)\nplt.title('Relationship between price and quantity of products')\nplt.xlabel('Quantity sold')\nplt.ylabel('Price (in €)')\n\nText(0, 0.5, 'Price (in €)')\n\n\n\n\n\n\n\n\n\n\n\nGoing further\nOnce again, many other possibilities are described in the documentation. However, the built-in plotting functionality in Pandas is mainly designed for quick visualization of analyzed data. For more attractive visualizations without needing to write much more code, the Seaborn library is preferable.",
    "crumbs": [
      "Data handling",
      "Introduction to data visualization"
    ]
  },
  {
    "objectID": "source/manipulation/dataviz/tutorial.html#seaborn-1",
    "href": "source/manipulation/dataviz/tutorial.html#seaborn-1",
    "title": "Introduction à la visualisation de données",
    "section": "Seaborn",
    "text": "Seaborn\nSeaborn is a data visualization library that provides a high-level interface for creating attractive statistical graphics. It is also built on Matplotlib and integrates well with Pandas data structures, allowing for more elaborate visualizations than those natively offered by Pandas without requiring significant amounts of code. This makes it an excellent choice for going beyond Pandas’ plotting capabilities while avoiding the complexity of Matplotlib.\nLet’s import the Seaborn package. The common practice is to give it the alias sns to avoid code redundancy.\n\nimport seaborn as sns\n\n\nExample plots\nFor the same charts created earlier with Pandas, Seaborn offers much more visually appealing representations. Here are a few examples.\n\nScatter plot\nWe can easily add information to a scatter plot, for example, through the color of the points or their style (size, marker, etc.). Let’s analyze the scatter plot of prices against quantity by store where the transaction took place.\n\nsns.scatterplot(data=df_cash, x='Price', y='Quantity', hue='Store', alpha=0.6)\n\n\n\n\n\n\n\n\n\n\nHistogram\nWith Seaborn, you can easily add a density estimation curve to a histogram. This allows you to visually check the normality of the data.\n\nsns.histplot(df_cash['Price'], kde=True, color='skyblue')\n\n\n\n\n\n\n\n\n\n\nPair plot\nThe pair plot allows for analyzing the relationships between two continuous variables by combining a scatter plot and density curves.\n\nsubset = df_cash[['Price', 'Quantity', 'Store']]\nsns.pairplot(subset, hue='Store')\n\n\n\n\n\n\n\n\n\n\nViolin plot\nSimilar to the box plot, the violin plot adds a density estimation curve to better visualize the masses of the distribution.\n\nsns.violinplot(data=df_cash, x='Store', y='Price', hue=\"Store\")\n\n\n\n\n\n\n\n\n\n\n\nCustomization\nLike Pandas, Seaborn’s plotting functionality is based on Matplotlib. Again, you can customize the charts by using the plt.xxx functions from Matplotlib.\n\nsns.scatterplot(data=df_cash, x='Price', y='Quantity', hue='Store', alpha=0.6)\nplt.title('Relationship between price and quantity by store')\n\nText(0.5, 1.0, 'Relationship between price and quantity by store')\n\n\n\n\n\n\n\n\n\n\n\nGoing further\nSeaborn’s possibilities are truly extensive, and the gallery of Seaborn examples illustrates many visually pleasing and easy-to-reproduce possibilities. For more advanced needs, you can consider other graphic libraries depending on the case:\n\nFor maximum customization possibilities (at the cost of some learning curve): Matplotlib, the fundamental visualization library in Python;\nFor R users: plotnine, a library that implements the “grammar of graphics” specific to ggplot2;\nFor interactive visualization: plotly and bokeh are the most used.",
    "crumbs": [
      "Data handling",
      "Introduction to data visualization"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html",
    "href": "source/projects/RP/tutorial.html",
    "title": "Projet 3 - Analyse du recensement de la population",
    "section": "",
    "text": "title: “Project 3 - Population census analysis”\nThe goal of this project is to perform a quick statistical analysis of a dataset whose format is not directly optimized for analysis in python. We will exclusively use the pandas library for data analysis. To best reproduce a situation you might encounter, we strongly encourage you to consult the library’s documentation (docs).\nWe will focus on the population estimate as of January 1st of each year, this estimate being made from censuses and population evolution models. The data is accessible on the Insee website at the following address: https://www.insee.fr/en/statistics/1893198. The file we will use can be downloaded directly via this url: https://www.insee.fr/fr/statistiques/fichier/1893198/estim-pop-dep-sexe-aq-1975-2023.xls.\nimport copy\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport seaborn as sns\n\nimport solutions",
    "crumbs": [
      "Projects",
      "Project 3 - Population census analysis"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html#part-1-downloading-and-formatting-data",
    "href": "source/projects/RP/tutorial.html#part-1-downloading-and-formatting-data",
    "title": "Projet 3 - Analyse du recensement de la population",
    "section": "Part 1: Downloading and formatting data",
    "text": "Part 1: Downloading and formatting data\nBefore downloading the data with python, it is necessary to know the format of our data. In our case, it is the Excel format (.xlsx). Additionally, it can be useful to look at what the data we want to import looks like, especially when its format is not standard. So, before starting, take the time to glance at the data.\n\nQuestion 0\nDownload the data by clicking on this link and open it with your favorite spreadsheet software. Analyze the data structure.\n\n\nQuestion 1\nDefine the load_data() function which has no parameters and returns a Dict where the keys correspond to the names of the tabs of our file and the values correspond to the data of the different spreadsheets. To do this, use a function from the pandas library by specifying the correct parameters.\n\nExpected result\n\ndata = solutions.load_data()\ndata[\"2022\"]\n\n\n\n\n\n\n\n\nDépartements\nEnsemble\n...\nFemmes\n\n\n\nUnnamed: 0_level_1\nUnnamed: 1_level_1\n0 à 4 ans\n5 à 9 ans\n10 à 14 ans\n15 à 19 ans\n20 à 24 ans\n25 à 29 ans\n30 à 34 ans\n35 à 39 ans\n...\n55 à 59 ans\n60 à 64 ans\n65 à 69 ans\n70 à 74 ans\n75 à 79 ans\n80 à 84 ans\n85 à 89 ans\n90 à 94 ans\n95 ans et plus\nTotal\n\n\n\n\n0\n01\nAin\n37584.0\n44592.0\n46872.0\n41596.0\n32455.0\n32252.0\n40494.0\n44180.0\n...\n22455.0\n20459.0\n18543.0\n17382.0\n12387.0\n8494.0\n6821.0\n3955.0\n1583.0\n337889.0\n\n\n1\n02\nAisne\n26469.0\n32510.0\n35567.0\n32782.0\n28024.0\n25419.0\n29274.0\n31434.0\n...\n17976.0\n17975.0\n17252.0\n16532.0\n10599.0\n8058.0\n6997.0\n3923.0\n1290.0\n268287.0\n\n\n2\n03\nAllier\n13508.0\n16754.0\n18159.0\n18286.0\n16279.0\n14083.0\n15296.0\n16672.0\n...\n11825.0\n12482.0\n13125.0\n13189.0\n9667.0\n7466.0\n6559.0\n3800.0\n1410.0\n173172.0\n\n\n3\n04\nAlpes-de-Haute-Provence\n7211.0\n8751.0\n9467.0\n8656.0\n6977.0\n6822.0\n8163.0\n9022.0\n...\n6528.0\n6420.0\n6160.0\n6044.0\n4680.0\n3413.0\n2748.0\n1478.0\n587.0\n85859.0\n\n\n4\n05\nHautes-Alpes\n6041.0\n7183.0\n7943.0\n7522.0\n5521.0\n5804.0\n7219.0\n7987.0\n...\n5252.0\n5463.0\n5291.0\n5116.0\n3683.0\n2836.0\n2189.0\n1207.0\n375.0\n71697.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n101\n976\nMayotte\n47016.0\n43895.0\n39982.0\n29873.0\n19284.0\n19923.0\n20467.0\n19851.0\n...\n3405.0\n2308.0\n1570.0\n981.0\n701.0\n375.0\n216.0\n64.0\n65.0\n156507.0\n\n\n102\nDOM\nNaN\n172294.0\n176252.0\n182101.0\n169777.0\n127009.0\n116519.0\n129841.0\n131092.0\n...\n77860.0\n64319.0\n55570.0\n42452.0\n30534.0\n22192.0\n14489.0\n7007.0\n3126.0\n1163453.0\n\n\n103\nFrance métropolitaine et DOM\nNaN\n3573900.0\n4025667.0\n4271387.0\n4208524.0\n3922318.0\n3725962.0\n4064176.0\n4200292.0\n...\n2279864.0\n2177958.0\n2077890.0\n1997938.0\n1398856.0\n1054963.0\n870391.0\n491588.0\n182900.0\n35020367.0\n\n\n104\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n105\nSource : Insee - Estimations de population (ré...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n106 rows × 65 columns\n\n\n\n\n\nYour turn!\n\ndef load_data():\n    # Your code here\n    return data\n\n\n\n\nQuestion 2\nNow that the data is imported, we will format it into a single DataFrame with the columns:\n\ngender;\nage;\npopulation;\ndep_code;\ndep;\nyear.\n\n2.1 - To do this, create a function reshape_data_by_year(df, year) which takes as argument a DataFrame from your Dict data and a given year.\n\nExpected result\n\nyear = 2022\ndf = solutions.reshape_table_by_year(data[f\"{year}\"], year)\ndf\n\n\n\n\n\n\n\n\ngenre\nage\npopulation\ndep_code\ndep\nannee\n\n\n\n\n0\nEnsemble\n0 à 4 ans\n37584\n01\nAin\n2022\n\n\n1\nHommes\n0 à 4 ans\n19489\n01\nAin\n2022\n\n\n2\nFemmes\n0 à 4 ans\n18095\n01\nAin\n2022\n\n\n3\nEnsemble\n0 à 4 ans\n26469\n02\nAisne\n2022\n\n\n4\nHommes\n0 à 4 ans\n13538\n02\nAisne\n2022\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n6358\nHommes\nTotal\n413939\n974\nLa Réunion\n2022\n\n\n6359\nFemmes\nTotal\n456054\n974\nLa Réunion\n2022\n\n\n6360\nEnsemble\nTotal\n299022\n976\nMayotte\n2022\n\n\n6361\nHommes\nTotal\n142515\n976\nMayotte\n2022\n\n\n6362\nFemmes\nTotal\n156507\n976\nMayotte\n2022\n\n\n\n\n6363 rows × 6 columns\n\n\n\n\n\nYour turn!\n\ndef reshape_table_by_year(df, year):\n    # Your code here\n    return df\n\n2.2 - Create a function reshape_data(data) which produces a DataFrame with the data for all the years between 1975 and 2022.\n\n\nExpected result\n\ndf = solutions.reshape_data(data)\ndf\n\n\n\n\n\n\n\n\ngenre\nage\npopulation\ndep_code\ndep\nannee\n\n\n\n\n0\nEnsemble\n0 à 4 ans\n30696\n01\nAin\n1975\n\n\n1\nHommes\n0 à 4 ans\n15608\n01\nAin\n1975\n\n\n2\nFemmes\n0 à 4 ans\n15088\n01\nAin\n1975\n\n\n3\nEnsemble\n0 à 4 ans\n45959\n02\nAisne\n1975\n\n\n4\nHommes\n0 à 4 ans\n23589\n02\nAisne\n1975\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n6358\nHommes\nTotal\n413939\n974\nLa Réunion\n2022\n\n\n6359\nFemmes\nTotal\n456054\n974\nLa Réunion\n2022\n\n\n6360\nEnsemble\nTotal\n299022\n976\nMayotte\n2022\n\n\n6361\nHommes\nTotal\n142515\n976\nMayotte\n2022\n\n\n6362\nFemmes\nTotal\n156507\n976\nMayotte\n2022\n\n\n\n\n296919 rows × 6 columns\n\n\n\n\n\nYour turn!\n\ndef reshape_data(data):\n    # Your code here\n    return df",
    "crumbs": [
      "Projects",
      "Project 3 - Population census analysis"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html#part-2-data-visualization",
    "href": "source/projects/RP/tutorial.html#part-2-data-visualization",
    "title": "Projet 3 - Analyse du recensement de la population",
    "section": "Part 2: Data visualization",
    "text": "Part 2: Data visualization\nWe now have a dataset ready to be analyzed! Let’s start by visualizing the population evolution for different departments.\n\nQuestion 3\nWrite a function plot_population_by_gender_per_department(df, department_code) which returns a graph representing the population evolution in a given department. Use the matplotlib library. You can look at the data for Haute Garonne (31), Loir-et-Cher (41), and Réunion (974) to see disparities in evolution.\n\nExpected result\n\nsolutions.plot_population_by_gender_per_department(df, \"31\")\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef plot_population_by_gender_per_department(data, department_code):\n    # Your code here\n\n\n  Cell In[36], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\n\n\nQuestion 4\nTo compare 2 graphs, it can be useful to display them side by side. Thanks to the subplots() method of matplotlib, this is very easy to achieve in python. To see this, we will represent the age pyramid of France in 1975 and in 2022.\n4.1- Define the get_age_pyramid_data(df, year) function which, from the DataFrame generated by the reshape_data() function, returns a DataFrame with the columns age, Females, Males. The age column should contain all the age groups present in the dataset, the Females/Males columns correspond to the female/male population for a given age group. For aesthetics, the Males column will be multiplied by -1 beforehand.\n\nExpected result\n\npyramide_data = solutions.get_age_pyramid_data(df, 2022)\npyramide_data\n\n\n\n\n\n\n\ngenre\nage\nannee\nEnsemble\nFemmes\nHommes\n\n\n\n\n47\n0 à 4 ans\n2022\n3573900\n1746143\n-1827757\n\n\n95\n10 à 14 ans\n2022\n4271387\n2083665\n-2187722\n\n\n143\n15 à 19 ans\n2022\n4208524\n2045731\n-2162793\n\n\n191\n20 à 24 ans\n2022\n3922318\n1919937\n-2002381\n\n\n239\n25 à 29 ans\n2022\n3725962\n1875046\n-1850916\n\n\n287\n30 à 34 ans\n2022\n4064176\n2075051\n-1989125\n\n\n335\n35 à 39 ans\n2022\n4200292\n2161802\n-2038490\n\n\n383\n40 à 44 ans\n2022\n4239439\n2164498\n-2074941\n\n\n431\n45 à 49 ans\n2022\n4320709\n2186078\n-2134631\n\n\n479\n5 à 9 ans\n2022\n4025667\n1968494\n-2057173\n\n\n527\n50 à 54 ans\n2022\n4454399\n2261574\n-2192825\n\n\n575\n55 à 59 ans\n2022\n4437879\n2279864\n-2158015\n\n\n623\n60 à 64 ans\n2022\n4176777\n2177958\n-1998819\n\n\n671\n65 à 69 ans\n2022\n3904715\n2077890\n-1826825\n\n\n719\n70 à 74 ans\n2022\n3707830\n1997938\n-1709892\n\n\n767\n75 à 79 ans\n2022\n2524031\n1398856\n-1125175\n\n\n815\n80 à 84 ans\n2022\n1802512\n1054963\n-747549\n\n\n863\n85 à 89 ans\n2022\n1360236\n870391\n-489845\n\n\n911\n90 à 94 ans\n2022\n692422\n491588\n-200834\n\n\n959\n95 ans et plus\n2022\n229416\n182900\n-46516\n\n\n1007\nTotal\n2022\n67842591\n35020367\n-32822224\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef get_age_pyramid_data(df, year):\n    # Your code here\n    return pyramide_data\n\n4.2- Define the plot_age_pyramid(df, year, ax=None) function which represents the age pyramid of France for a given year. You can get inspiration from what was done in this blog.\n\n\nExpected result\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n\nsolutions.plot_age_pyramid(df, 1975, ax=ax1)\nsolutions.plot_age_pyramid(df, 2022, ax=ax2)\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef plot_age_pyramid(df, year, ax=None):\n    if ax is None:\n        ax = plt.gca()\n    # Your code here\n    return df",
    "crumbs": [
      "Projects",
      "Project 3 - Population census analysis"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html#part-3-an-introduction-to-geographical-data-optional-to-go-further",
    "href": "source/projects/RP/tutorial.html#part-3-an-introduction-to-geographical-data-optional-to-go-further",
    "title": "Projet 3 - Analyse du recensement de la population",
    "section": "Part 3: An introduction to geographical data (optional to go further?)",
    "text": "Part 3: An introduction to geographical data (optional to go further?)\nGeographical data is very useful because it allows for visualizing and analyzing information related to specific locations on Earth. Geographical data can be used to create maps, 3D visualizations, and spatial analyses to understand trends, patterns, and relationships in the data. By using Python libraries such as Geopandas or Folium, you can easily manipulate and visualize geographical data to meet your analytical needs.\nTo graphically represent geographical data, it is necessary to obtain the contour data (shapefile) of the areas we want to represent. The goal of this part is to create a choropleth map of regions based on their respective population.\nThe data we currently have contains information by department and not by region. First, it is necessary to assign each department to its corresponding region. For this, you can use the .json file available at the following address: https://static.data.gouv.fr/resources/departements-et-leurs-regions/20190815-175403/departements-region.json.\n\nQuestion 5\nCreate a DataFrame from the .json file of French departments and regions mentioned earlier. Ensure that the columns are in the correct format.\n\nExpected result\n\ndf_matching = solutions.load_departements_regions(\"https://static.data.gouv.fr/resources/departements-et-leurs-regions/20190815-175403/departements-region.json\")\ndf_matching\n\n\n\n\n\n\n\n\nnum_dep\ndep_name\nregion_name\n\n\n\n\n0\n01\nAin\nAuvergne-Rhône-Alpes\n\n\n1\n02\nAisne\nHauts-de-France\n\n\n2\n03\nAllier\nAuvergne-Rhône-Alpes\n\n\n3\n04\nAlpes-de-Haute-Provence\nProvence-Alpes-Côte d'Azur\n\n\n4\n05\nHautes-Alpes\nProvence-Alpes-Côte d'Azur\n\n\n...\n...\n...\n...\n\n\n96\n971\nGuadeloupe\nGuadeloupe\n\n\n97\n972\nMartinique\nMartinique\n\n\n98\n973\nGuyane\nGuyane\n\n\n99\n974\nLa Réunion\nLa Réunion\n\n\n100\n976\nMayotte\nMayotte\n\n\n\n\n101 rows × 3 columns\n\n\n\n\n\nYour turn!\n\ndef load_departements_regions(url):\n    # Your code here\n    return df_matching\n\n\n\n\nQuestion 6\nMatch the DataFrame containing population data by department with the DataFrame of French regions.\n\nExpected result\n\ndf_regions = solutions.match_department_regions(df, df_matching)\ndf_regions\n\n\n\n\n\n\n\n\ngenre\nage\npopulation\ndep_code\ndep\nannee\nnum_dep\ndep_name\nregion_name\n\n\n\n\n0\nEnsemble\n0 à 4 ans\n30696\n01\nAin\n1975\n01\nAin\nAuvergne-Rhône-Alpes\n\n\n1\nHommes\n0 à 4 ans\n15608\n01\nAin\n1975\n01\nAin\nAuvergne-Rhône-Alpes\n\n\n2\nFemmes\n0 à 4 ans\n15088\n01\nAin\n1975\n01\nAin\nAuvergne-Rhône-Alpes\n\n\n3\nEnsemble\n0 à 4 ans\n45959\n02\nAisne\n1975\n02\nAisne\nHauts-de-France\n\n\n4\nHommes\n0 à 4 ans\n23589\n02\nAisne\n1975\n02\nAisne\nHauts-de-France\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n296914\nHommes\nTotal\n413939\n974\nLa Réunion\n2022\n974\nLa Réunion\nLa Réunion\n\n\n296915\nFemmes\nTotal\n456054\n974\nLa Réunion\n2022\n974\nLa Réunion\nLa Réunion\n\n\n296916\nEnsemble\nTotal\n299022\n976\nMayotte\n2022\n976\nMayotte\nMayotte\n\n\n296917\nHommes\nTotal\n142515\n976\nMayotte\n2022\n976\nMayotte\nMayotte\n\n\n296918\nFemmes\nTotal\n156507\n976\nMayotte\n2022\n976\nMayotte\nMayotte\n\n\n\n\n296919 rows × 9 columns\n\n\n\n\n\nYour turn!\n\ndef match_department_regions(df, df_matching):\n    # Your code here\n    return df_regions\n\n\n\n\nQuestion 7\nDownload the geographical contour data of the regions using the cartiflette package and the geopandas library. The data is accessible via the following url: https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year=2022/administrative_level=REGION/crs=4326/FRANCE_ENTIERE=metropole/vectorfile_format=‘geojson’/provider=‘IGN’/source=‘EXPRESS-COG-CARTO-TERRITOIRE’/raw.geojson.\n\nExpected result\n\ngeo = solutions.load_geo_data(\"https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year=2022/administrative_level=REGION/crs=4326/FRANCE_ENTIERE=metropole/vectorfile_format='geojson'/provider='IGN'/source='EXPRESS\n\n-COG-CARTO-TERRITOIRE'/raw.geojson\")\ngeo\n\n\n  Cell In[45], line 1\n    geo = solutions.load_geo_data(\"https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year=2022/administrative_level=REGION/crs=4326/FRANCE_ENTIERE=metropole/vectorfile_format='geojson'/provider='IGN'/source='EXPRESS\n                                  ^\nSyntaxError: unterminated string literal (detected at line 1)\n\n\n\n\n\n\nYour turn!\n\ndef load_geo_data(url):\n    # Your code here\n    return geo\n\n\n\n\nQuestion 8\nProduce a choropleth map of the 2022 population of French regions. You can consult the geopandas documentation here.\n\nExpected result\n\nsolutions.plot_population_by_regions(df_regions, geo, 2022)\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef plot_population_by_regions(df, geo, year):\n    # Your code here\n\n\n  Cell In[48], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input\n\n\n\n\n\n\n\nQuestion 9\nThe total population of a region is not sufficient to analyze the demographics of a region. It can be interesting to look at demographic growth.\n9.1- Write a function compute_population_growth_per_region(df) which calculates the annual population growth percentage for each region.\n\nExpected result\n\ndf_growth = solutions.compute_population_growth_per_region(df_regions)\ndf_growth\n\n\n\n\n\n\n\nregion_name\nAuvergne-Rhône-Alpes\nBourgogne-Franche-Comté\nBretagne\nCentre-Val de Loire\nCorse\nGrand Est\nGuadeloupe\nGuyane\nHauts-de-France\nLa Réunion\nMartinique\nMayotte\nNormandie\nNouvelle-Aquitaine\nOccitanie\nPays de la Loire\nProvence-Alpes-Côte d'Azur\nÎle-de-France\n\n\nannee\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1975\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1976\n0.440555\n0.219955\n0.564478\n0.669816\n0.713244\n0.061420\nNaN\nNaN\n0.141119\nNaN\nNaN\nNaN\n0.460176\n0.346167\n0.545603\n0.799056\n0.972566\n0.139918\n\n\n1977\n0.501002\n0.220041\n0.547561\n0.686405\n0.800052\n0.068762\nNaN\nNaN\n0.117183\nNaN\nNaN\nNaN\n0.439001\n0.394459\n0.632119\n0.761169\n1.086540\n0.240243\n\n\n1978\n0.543552\n0.285482\n0.603619\n0.746818\n0.831456\n0.135696\nNaN\nNaN\n0.193716\nNaN\nNaN\nNaN\n0.490210\n0.434355\n0.666995\n0.819542\n1.110065\n0.322886\n\n\n1979\n0.482266\n0.186234\n0.572699\n0.654878\n0.624045\n0.051279\nNaN\nNaN\n0.109454\nNaN\nNaN\nNaN\n0.436886\n0.355334\n0.564264\n0.769432\n1.025683\n0.207729\n\n\n1980\n0.560626\n0.284930\n0.612505\n0.702602\n0.824619\n0.137384\nNaN\nNaN\n0.193575\nNaN\nNaN\nNaN\n0.515840\n0.415768\n0.646836\n0.809755\n1.096914\n0.284899\n\n\n1981\n0.639192\n0.343167\n0.672048\n0.768892\n0.908655\n0.221558\nNaN\nNaN\n0.295761\nNaN\nNaN\nNaN\n0.599858\n0.486488\n0.741603\n0.857139\n1.181448\n0.394224\n\n\n1982\n0.649068\n0.319212\n0.665890\n0.812739\n0.966894\n0.236789\nNaN\nNaN\n0.340500\nNaN\nNaN\nNaN\n0.596950\n0.468565\n0.748759\n0.864358\n1.179598\n0.428124\n\n\n1983\n0.660477\n0.170043\n0.408204\n0.790898\n0.522119\n0.132003\nNaN\nNaN\n0.547784\nNaN\nNaN\nNaN\n0.618118\n0.466702\n1.049500\n0.798719\n0.837187\n0.569620\n\n\n1984\n0.615003\n0.192499\n0.320168\n0.589604\n0.785738\n0.203314\nNaN\nNaN\n-0.006766\nNaN\nNaN\nNaN\n0.599975\n0.317899\n0.947900\n0.662753\n0.783779\n0.399595\n\n\n1985\n0.439074\n0.172289\n0.376437\n0.577606\n0.463987\n0.221769\nNaN\nNaN\n0.046509\nNaN\nNaN\nNaN\n0.496844\n0.400583\n0.948529\n0.524187\n0.804716\n0.652446\n\n\n1986\n0.441459\n0.005675\n0.380064\n0.524933\n0.374711\n0.117934\nNaN\nNaN\n0.201369\nNaN\nNaN\nNaN\n0.463820\n0.393369\n0.466300\n0.509533\n0.929494\n0.750377\n\n\n1987\n0.516957\n0.113678\n0.390557\n0.422141\n0.220890\n-0.012922\nNaN\nNaN\n0.227265\nNaN\nNaN\nNaN\n0.320152\n0.280869\n0.728475\n0.601497\n0.955603\n0.846468\n\n\n1988\n0.664239\n0.130443\n0.413969\n0.544764\n0.513190\n-0.002904\nNaN\nNaN\n0.101615\nNaN\nNaN\nNaN\n0.553174\n0.389860\n0.787373\n0.239723\n0.968478\n0.841564\n\n\n1989\n0.730248\n0.101007\n0.426841\n0.603119\n0.476990\n0.112899\nNaN\nNaN\n0.241265\nNaN\nNaN\nNaN\n0.455996\n0.372505\n0.874334\n0.532381\n0.902868\n0.764421\n\n\n1990\n0.861964\n0.011347\n0.410941\n0.566870\n0.519823\n-0.022899\nNaN\nNaN\n0.340457\nNaN\nNaN\nNaN\n0.414747\n0.392892\n0.996738\n0.398017\n0.987160\n0.699250\n\n\n1991\n0.608818\n0.174217\n0.328023\n0.489449\n0.806746\n0.269489\nNaN\nNaN\n0.214672\nNaN\nNaN\nNaN\n0.396532\n0.364489\n0.756250\n0.536888\n0.851607\n0.478089\n\n\n1992\n0.621292\n0.186347\n0.285003\n0.488619\n0.015497\n0.285462\nNaN\nNaN\n0.249332\nNaN\nNaN\nNaN\n0.381874\n0.343430\n0.760485\n0.606362\n0.772424\n0.539663\n\n\n1993\n0.599160\n0.162948\n0.400111\n0.436432\n0.753681\n0.377232\nNaN\nNaN\n0.262649\nNaN\nNaN\nNaN\n0.366458\n0.321189\n0.778556\n0.665291\n0.698275\n0.373263\n\n\n1994\n0.315172\n0.107757\n0.278490\n0.287374\n1.333623\n0.294869\nNaN\nNaN\n0.163865\nNaN\nNaN\nNaN\n0.262679\n0.205144\n0.538612\n0.567510\n0.613215\n0.368827\n\n\n1995\n0.367380\n0.150646\n0.356711\n0.328618\n0.559972\n0.262236\nNaN\nNaN\n0.176324\nNaN\nNaN\nNaN\n0.260099\n0.275161\n0.585658\n0.553599\n0.495484\n0.237713\n\n\n1996\n0.370379\n0.059478\n0.457074\n0.248561\n0.291004\n0.206722\nNaN\nNaN\n0.188667\nNaN\nNaN\nNaN\n0.206080\n0.222749\n0.691074\n0.581164\n0.474019\n0.229055\n\n\n1997\n0.410964\n0.016455\n0.584862\n0.317944\n-0.027395\n0.201467\nNaN\nNaN\n0.110328\nNaN\nNaN\nNaN\n0.206221\n0.296646\n0.700223\n0.577300\n0.560527\n0.106387\n\n\n1998\n0.399849\n0.000989\n0.623024\n0.253738\n0.142418\n0.072912\nNaN\nNaN\n0.031197\nNaN\nNaN\nNaN\n0.178357\n0.336006\n0.796266\n0.570467\n0.643450\n0.157819\n\n\n1999\n0.451058\n-0.038877\n0.548362\n0.085719\n0.264389\n0.160629\nNaN\nNaN\n0.062819\nNaN\nNaN\nNaN\n0.133921\n0.410027\n0.731983\n0.609319\n0.507652\n0.305976\n\n\n2000\n0.735912\n0.228878\n0.810482\n0.402656\n1.686322\n0.248018\n0.631728\n4.017720\n0.091436\n1.775170\n0.712067\nNaN\n0.282721\n0.739755\n1.190374\n0.901688\n0.868939\n0.675853\n\n\n2001\n0.815198\n0.293161\n0.912416\n0.475772\n1.789528\n0.293953\n0.676983\n4.071153\n0.155252\n1.772407\n0.773512\nNaN\n0.320816\n0.830550\n1.275936\n1.006004\n0.943982\n0.751661\n\n\n2002\n0.823526\n0.275166\n0.928842\n0.454956\n1.790005\n0.294789\n0.602040\n4.758798\n0.170224\n1.535919\n0.714023\nNaN\n0.313303\n0.851270\n1.367198\n1.004669\n0.984146\n0.745207\n\n\n2003\n0.814720\n0.248992\n0.921736\n0.457343\n1.800119\n0.252728\n0.472490\n4.616221\n0.132894\n1.436490\n0.609809\nNaN\n0.276617\n0.843565\n1.359134\n0.996365\n0.984124\n0.755536\n\n\n2004\n0.807285\n0.224722\n0.924749\n0.402168\n1.772230\n0.228277\n0.534591\n4.532123\n0.106153\n1.437057\n0.555561\nNaN\n0.258575\n0.824192\n1.342890\n0.959143\n0.942791\n0.711761\n\n\n2005\n0.880579\n0.325741\n0.971592\n0.519870\n1.802995\n0.300281\n0.550641\n3.126310\n0.181270\n1.480640\n0.540812\nNaN\n0.304135\n0.921700\n1.417286\n1.053529\n1.047481\n0.809257\n\n\n2006\n0.846671\n0.271543\n0.911405\n0.491416\n1.738547\n0.270708\n0.390302\n3.387448\n0.141550\n1.171551\n0.441939\nNaN\n0.268356\n0.865408\n1.339015\n1.025417\n0.978659\n0.788795\n\n\n2007\n0.651354\n0.471350\n0.832242\n0.291796\n1.730938\n0.300979\n-0.037930\n3.436204\n0.152731\n1.553145\n-0.000503\nNaN\n0.315100\n0.948013\n1.132581\n0.932671\n1.013098\n0.576359\n\n\n2008\n0.727677\n0.356554\n0.942637\n0.184770\n1.255644\n0.269421\n0.299563\n2.926804\n0.153005\n1.780994\n-0.009303\nNaN\n0.455959\n0.771278\n0.909103\n0.791824\n0.388527\n0.520689\n\n\n2009\n0.789801\n0.290060\n0.805251\n0.276585\n0.893830\n0.175063\n-0.057245\n2.372917\n0.223618\n1.003897\n-0.324119\nNaN\n0.325834\n0.659857\n0.989881\n0.822695\n0.125745\n0.591633\n\n\n2010\n0.799068\n0.114920\n0.755953\n0.373239\n1.314799\n0.025528\n0.448508\n2.036361\n0.145466\n0.584543\n-0.562810\nNaN\n0.200556\n0.647964\n0.813158\n0.916828\n0.206625\n0.494482\n\n\n2011\n0.740887\n0.081596\n0.584577\n0.344183\n1.547662\n0.117577\n0.317338\n3.715072\n0.120427\n0.906671\n-0.477455\nNaN\n0.139830\n0.480238\n1.003243\n0.829289\n0.345243\n0.565210\n\n\n2012\n0.799571\n0.022726\n0.600727\n0.264037\n0.563141\n0.179093\n-0.326467\n0.883607\n0.216907\n0.647251\n-1.001043\nNaN\n0.231639\n0.615200\n0.957968\n0.874757\n0.396801\n0.385148\n\n\n2013\n0.809992\n0.105403\n0.667573\n0.271573\n1.249300\n0.061868\n-0.296295\n1.865236\n0.247526\n0.138978\n-0.724320\nNaN\n0.168776\n0.612592\n1.013354\n0.777347\n0.366705\n0.515233\n\n\n2014\n0.816890\n0.029790\n0.547334\n0.267920\n1.250437\n0.040649\n-0.480703\n3.367224\n0.305166\n0.917731\n-0.425365\nNaN\n0.218756\n0.598322\n0.824701\n0.818962\n0.600827\n0.566548\n\n\n2015\n0.725384\n0.011239\n0.528209\n0.044890\n0.947220\n0.079321\n-0.548745\n2.982904\n0.063601\n0.944508\n-0.790287\n3.788783\n0.104508\n0.550046\n0.757876\n0.749939\n0.492411\n0.453783\n\n\n2016\n0.497493\n-0.092239\n0.384929\n-0.028155\n0.969192\n-0.069526\n-0.974899\n3.650742\n-0.051681\n0.258250\n-1.154441\n3.789155\n-0.095893\n0.408036\n0.593157\n0.514184\n0.278576\n0.289584\n\n\n2017\n0.396595\n-0.245357\n0.374260\n-0.062610\n1.356614\n-0.100807\n-0.978661\n-0.242062\n-0.050858\n0.086174\n-1.032193\n3.799375\n-0.163403\n0.360115\n0.631272\n0.534242\n0.178457\n0.476581\n\n\n2018\n0.580905\n-0.128618\n0.497453\n-0.131936\n1.079603\n0.014470\n-0.672384\n2.764421\n0.004880\n0.269663\n-1.022829\n3.789033\n-0.090107\n0.382744\n0.691074\n0.633995\n0.436145\n0.316775\n\n\n2019\n0.606382\n-0.079315\n0.582836\n0.012710\n0.557075\n0.105038\n-0.874548\n2.009937\n0.013974\n0.613229\n-1.159218\n3.835591\n-0.073479\n0.510236\n0.810280\n0.662132\n0.559468\n0.401991\n\n\n2020\n0.444067\n-0.138474\n0.565777\n0.065405\n0.957878\n0.115762\n-0.176973\n1.226578\n-0.120118\n0.217485\n-0.900666\n3.752889\n0.014737\n0.393708\n0.687388\n0.674091\n0.345693\n0.075433\n\n\n2021\n0.436397\n-0.222223\n0.573413\n-0.042604\n0.772765\n-0.039711\n-0.509179\n1.957332\n-0.110809\n0.415487\n-1.116755\n3.228148\n-0.091414\n0.452390\n0.731155\n0.655486\n0.421169\n0.207443\n\n\n2022\n0.523595\n-0.159651\n0.560713\n-0.043905\n0.714003\n0.018704\n-0.820218\n1.838233\n-0.093556\n0.383537\n-1.395892\n3.566369\n-0.082438\n0.417983\n0.709297\n0.665139\n0.384306\n0.261693\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef compute_population_growth_per_region(df_regions):\n    # Your code here\n    return df_growth\n\n9.2- Write a function compute_mean_population_growth_per_region(df, min_year, max_year) which calculates the average population growth between two given years.\n\n\nExpected result\n\ndf_growth = solutions.compute_mean_population_growth_per_region(df_regions, 2015, 2022)\ndf_growth\n\n\n\n\n\n\n\n\nannee\ncroissance_pop\n\n\nregion\n\n\n\n\n\n\nAuvergne-Rhône-Alpes\n2018.5\n0.526352\n\n\nBourgogne-Franche-Comté\n2018.5\n-0.131830\n\n\nBretagne\n2018.5\n0.508449\n\n\nCentre-Val de Loire\n2018.5\n-0.023276\n\n\nCorse\n2018.5\n0.919294\n\n\nGrand Est\n2018.5\n0.015406\n\n\nGuadeloupe\n2018.5\n-0.694451\n\n\nGuyane\n2018.5\n2.023511\n\n\nHauts-de-France\n2018.5\n-0.043071\n\n\nLa Réunion\n2018.5\n0.398542\n\n\nMartinique\n2018.5\n-1.071535\n\n\nMayotte\n2018.5\n3.693668\n\n\nNormandie\n2018.5\n-0.059686\n\n\nNouvelle-Aquitaine\n2018.5\n0.434407\n\n\nOccitanie\n2018.5\n0.701437\n\n\nPays de la Loire\n2018.5\n0.636151\n\n\nProvence-Alpes-Côte d'Azur\n2018.5\n0.387028\n\n\nÎle-de-France\n2018.5\n0.310410\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef compute_mean_population_growth_per_region(df, geo, year):\n    # Your code here\n    return df_growth\n\n9.3- Write a function plot_growth_population_by_regions(df, geo, min_year, max_year) which represents the average population growth between two given years for all French regions on a choropleth map.\n\n\nExpected result\n\nsolutions.plot_growth_population_by_regions(df_regions, geo, 2015, 2022)\n\n\n\n\n\n\n\n\n\n\nYour turn!\n\ndef plot_growth_population_by_regions(df, geo, min_year, max_year):\n    # Your code here\n\n\n  Cell In[54], line 2\n    # Your code here\n                    ^\nSyntaxError: incomplete input",
    "crumbs": [
      "Projects",
      "Project 3 - Population census analysis"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html",
    "href": "source/manipulation/csv-json-files/tutorial.html",
    "title": "Working with CSV and JSON files",
    "section": "",
    "text": "In the previous tutorial, we learned how to use functions from modules and how to read and write text files. In this tutorial, we will leverage these new skills by focusing on two types of text files commonly used for storing and sharing data: CSV and JSON files. We will learn to handle these two types of files using Python modules dedicated to their respective processing: the csv module and the json module.",
    "crumbs": [
      "Data handling",
      "Working with CSV and JSON files"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html#handling-csv-files",
    "href": "source/manipulation/csv-json-files/tutorial.html#handling-csv-files",
    "title": "Working with CSV and JSON files",
    "section": "Handling CSV files",
    "text": "Handling CSV files\n\nCSV files\nCSV stands for comma-separated values. CSV files aim to reproduce the structure of data from spreadsheet software like Microsoft Excel or LibreOffice Calc, reduced to strictly textual data (no formatting, no column types, etc.).\nWe will use the CSV file containing the list of departments in 2021 from the Official Geographic Code (COG) as an example. Let’s look at the first few lines of this file using a shell command to keep in mind the structure of such a file.\n\n!head -n 5 departement2021.csv\n\nDEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n01,84,01053,5,AIN,Ain,Ain\n02,32,02408,5,AISNE,Aisne,Aisne\n03,84,03190,5,ALLIER,Allier,Allier\n04,93,04070,4,ALPES DE HAUTE PROVENCE,Alpes-de-Haute-Provence,Alpes-de-Haute-Provence\n\n\nIn analogy with a spreadsheet file, each line of the file represents a row in the spreadsheet, and the cells in a row are separated by commas. The first line may contain a header, i.e., the column names, but this is not always the case.\nThe main advantages of CSV files are:\n\ntheir simplicity: they contain raw textual data, so they are very lightweight and can be easily edited using any text editor or programming language\ntheir universality: they are widely used as a standard format for data exchange\n\n\n\nThe csv module\nSince the data in a CSV file is textual, one might wonder why a particular module is needed to manipulate them and why the tools we saw in the previous tutorial would not suffice. The main reason is that CSV files have some subtleties and standards, often invisible to the user, but very important in practice. For example: if we want to separate different data with commas, what happens if the text data itself contains commas?\nThis is why we use the csv module to interact with such files, leveraging the fact that others have already considered these questions, thus avoiding reinventing the wheel every time we import a CSV file.\nIn practice, we tend to handle this type of data in the form of DataFrames (like in R) to take advantage of their tabular structure. We will study the Pandas package, which allows us to do this in Python in a future tutorial. However, it is always useful to know how to handle CSV data as textual data and, thus, know the csv module.\n\n\nReading\n\nimport csv\n\nThe syntax for reading and manipulating CSV files in Python is very similar to that for simple text files. The only difference is that you must create a reader object from the file object to iterate over the lines.\n\nrows = []\n\nwith open(\"departement2021.csv\") as file_in:\n    csv_reader = csv.reader(file_in)\n    for row in csv_reader:\n        rows.append(row)\n\nrows[:4]\n\n[['DEP', 'REG', 'CHEFLIEU', 'TNCC', 'NCC', 'NCCENR', 'LIBELLE'],\n ['01', '84', '01053', '5', 'AIN', 'Ain', 'Ain'],\n ['02', '32', '02408', '5', 'AISNE', 'Aisne', 'Aisne'],\n ['03', '84', '03190', '5', 'ALLIER', 'Allier', 'Allier']]\n\n\nThe syntax is the same as for simple text files: once the reader is created, you can iterate over the lines and perform operations with them, such as storing them in a list as shown above.\nWhen you have a CSV file with column names like in our case, it is useful to use them to manipulate named data rather than by position using a simple list. To do this, use a DictReader instead of a reader. Now, when iterating over the DictReader object, each line is a dictionary, with the key being the column name and the value being the cell data.\nTo illustrate its usefulness, display the names of departments whose department number is between 20 and 29.\n\nwith open(\"departement2021.csv\") as file_in:\n    dict_reader = csv.DictReader(file_in)\n    for row in dict_reader:\n        if row[\"DEP\"].startswith(\"2\"):\n            print(row[\"LIBELLE\"])\n\nCôte-d'Or\nCôtes-d'Armor\nCreuse\nDordogne\nDoubs\nDrôme\nEure\nEure-et-Loir\nFinistère\nCorse-du-Sud\nHaute-Corse\n\n\nThe code is much more readable: you can easily understand which data is being manipulated and how.\n\n\nWriting\nThe syntax for writing is again quite similar to that for text files. The difference is that you are dealing with 2D data (row x column), so you cannot just pass a string to write, but pass a list of elements.\n\nheader = [\"name\", \"class\", \"age\"]\nrow1 = [\"Maurice\", \"5thB\", 12]\nrow2 = [\"Manuela\", \"6thA\", 11]\n\nwith open(\"test.csv\", \"w\") as file_out:\n    csv_writer = csv.writer(file_out)\n    csv_writer.writerow(header)\n    csv_writer.writerow(row1)\n    csv_writer.writerow(row2)\n\nLet’s check that our raw CSV file looks as expected.\n\n# Shell command to display the content of a file\n!cat test.csv\n\nname,class,age\nMaurice,5thB,12\nManuela,6thA,11\n\n\n\n\nThe header\nLike in a spreadsheet document, the first line of a CSV file usually contains the variable names (columns). This line is called the header. This line is not mandatory in theory, but it is quite handy for quickly understanding the nature of the data in a CSV file. Therefore, it is good practice to include a header when generating a CSV file.\nWe saw in the previous example that writing the header is done like writing any other data row. It’s during reading that things get complicated because you need to retrieve the header separately from the other data if the CSV file contains one. Let’s use the CSV generated in the previous step to illustrate this.\n\ndata = []\nwith open(\"test.csv\", \"r\") as file_in:\n    csv_reader = csv.reader(file_in)\n    header = next(csv_reader)\n    for row in csv_reader:\n        data.append(row)\n\n\nprint(header)\n\n['name', 'class', 'age']\n\n\n\nprint(data)\n\n[['Maurice', '5thB', '12'], ['Manuela', '6thA', '11']]\n\n\nTo retrieve the header, use the next function. It is a built-in function that calls the __next__ method of the reader object, allowing it to iterate one step forward on the reader. The first call to the next function returns the first line of the document. If a header is present in the file (which must be ensured), the returned element is the header. Then, you typically retrieve the rest of the data via a loop on the reader object, storing it in a list of lists (one list per line).\n\n\nImportance of the delimiter\nThe delimiter is the character used to separate successive values in a line in a CSV file.\nThe CSV standard uses — as its name suggests — the comma as the delimiter, but this can be modified, and it is not uncommon to encounter CSV files that have a different delimiter. In such a case, look directly at the raw text to see the delimiter used. For example, you often find tab-separated values (the character is \\t), i.e., a given number of spaces, and the file may have the extension .tsv for tab-separated value. In this case, specify the delimiter with the delimiter parameter when creating the reader.\nIn practice, like text file encoding, there is little valid reason to change the delimiter. Even if commas appear in file values — for example, in an address — these values are then enclosed in quotes, allowing the separation of values to be done correctly in most cases.",
    "crumbs": [
      "Data handling",
      "Working with CSV and JSON files"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html#handling-json-files",
    "href": "source/manipulation/csv-json-files/tutorial.html#handling-json-files",
    "title": "Working with CSV and JSON files",
    "section": "Handling JSON files",
    "text": "Handling JSON files\n\nJSON files\nJSON (JavaScript Object Notation) is a very popular file format for writing and exchanging data in the form of a single, human-readable string — at least in theory.\nAs its name suggests, JSON is linked to the JavaScript language, as it is derived from the notation of objects in that language. However, the format is now independent of any programming language but is widely used in various languages.\nThe JSON format is particularly important for statisticians and data scientists because it is the quasi-standard response format for APIs. Interacting with APIs goes beyond this introductory course’s scope. However, as APIs are becoming the standard mode of communication for data exchange, it is essential to master the basics of the JSON format to handle API responses when interacting with them.\nSince JSON stores objects as key-value pairs and the values can be arrays — a broad concept in computing that includes lists we know — it closely resembles Python dictionaries. Thus, it is a natural file format for serializing them, i.e., converting a data structure in memory (here, a dictionary) to a byte sequence that any computer can read. Let’s look at the JSON representation of a Python dictionary as an example.\n\ncv = {\n    \"marc\": {\"position\": \"manager\", \"experience\": 7, \"hobbies\": [\"sewing\", \"frisbee\"]},\n    \"miranda\": {\"position\": \"engineer\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(cv)\n\n{'marc': {'position': 'manager', 'experience': 7, 'hobbies': ['sewing', 'frisbee']}, 'miranda': {'position': 'engineer', 'experience': 5, 'hobbies': ['trekking']}}\n\n\n\nimport json\n\nprint(json.dumps(cv))\n\n{\"marc\": {\"position\": \"manager\", \"experience\": 7, \"hobbies\": [\"sewing\", \"frisbee\"]}, \"miranda\": {\"position\": \"engineer\", \"experience\": 5, \"hobbies\": [\"trekking\"]}}\n\n\nYou can see that the JSON representation is quite similar to the Python dictionary, with a few peculiarities. In this case, for example, special characters like accents are automatically encoded in Unicode.\n\n\nThe json module\nThe json module handles importing JSON files and exporting Python objects to JSON format. It takes care of handling the conversion constraints to JSON mentioned earlier, such as accents.\nIn particular, JSON can store most of the built-in Python object types we have seen so far (strings, numeric values, Booleans, lists, dictionaries, NoneType) and many others, but it cannot represent manually created Python objects via classes.\n\n\nWriting\nLet’s start with writing. As we saw in the previous example, the dumps function (for dump string) converts a serializable Python value to its JSON representation as a string.\n\nx = \"test\"\njson.dumps(x)\n\n'\"test\"'\n\n\n\nx = [1, 2, 3]\njson.dumps(x)\n\n'[1, 2, 3]'\n\n\nWriting a JSON file from Python simply means writing this representation into a text file, which we will give the .json extension to clearly indicate that it is a particular text file. As this operation is very common, there is a similar function, dump, which performs both conversion and writing.\n\nwith open(\"cv.json\", \"w\") as file_out:\n    json.dump(cv, file_out)\n\n\n!cat cv.json\n\n{\"marc\": {\"position\": \"manager\", \"experience\": 7, \"hobbies\": [\"sewing\", \"frisbee\"]}, \"miranda\": {\"position\": \"engineer\", \"experience\": 5, \"hobbies\": [\"trekking\"]}}\n\n\nIn a single operation, we serialized a Python dictionary (the cv object) into a JSON file.\n\n\nReading\nThe json module provides the load and loads functions, which respectively perform the opposite operations of the dump and dumps functions:\n\nThe load function imports JSON content from a text file and converts it into a dictionary.\nThe loads function converts JSON content from a string into a dictionary.\n\nLet’s reuse the CV we serialized earlier into JSON format to illustrate reading from a file.\n\nwith open(\"cv.json\", \"r\") as file_in:\n    data = json.load(file_in)\n    \ndata\n\n{'marc': {'position': 'manager',\n  'experience': 7,\n  'hobbies': ['sewing', 'frisbee']},\n 'miranda': {'position': 'engineer', 'experience': 5, 'hobbies': ['trekking']}}\n\n\nWe will illustrate reading JSON content from a string with a realistic example: querying an API. For example, we will query the French National Address Base (BAN), which allows geolocating any national address.\nQuerying an API in Python is straightforward with the requests library. Let’s see how we can retrieve geographical information about all streets that contain the name “comedie” in France in just two lines of code.\n\nimport requests\n\n\nresponse = requests.get(\"https://api-adresse.data.gouv.fr/search/?q=comedie&type=street\")\nr_text = response.text\nprint(r_text[:150])\n\n{\"type\":\"FeatureCollection\",\"version\":\"draft\",\"features\":[{\"type\":\"Feature\",\"geometry\":{\"type\":\"Point\",\"coordinates\":[3.063832,50.635192]},\"properties\n\n\nThe API sends us a response, from which we extract the textual content. As with most APIs, this content is JSON. We can then import it into a Python dictionary using the loads function (for load string) to manipulate the data it contains.\n\nr_dict = json.loads(r_text)\n\n\nr_dict.keys()\n\ndict_keys(['type', 'version', 'features', 'attribution', 'licence', 'query', 'filters', 'limit'])\n\n\n\ntype(r_dict[\"features\"])\n\nlist\n\n\nThe results we are interested in are contained in the dictionary value associated with the features key, which is a list of dictionaries, one per result.\n\nr_dict[\"features\"][0]\n\n{'type': 'Feature',\n 'geometry': {'type': 'Point', 'coordinates': [3.063832, 50.635192]},\n 'properties': {'label': 'Rue de la Vieille Comédie 59800 Lille',\n  'score': 0.7018699999999999,\n  'id': '59350_9149',\n  'name': 'Rue de la Vieille Comédie',\n  'postcode': '59800',\n  'citycode': '59350',\n  'oldcitycode': '59350',\n  'x': 704523.56,\n  'y': 7059804.63,\n  'city': 'Lille',\n  'oldcity': 'Lille',\n  'context': '59, Nord, Hauts-de-France',\n  'type': 'street',\n  'importance': 0.72057,\n  'street': 'Rue de la Vieille Comédie'}}\n\n\n\nr_dict[\"features\"][1]\n\n{'type': 'Feature',\n 'geometry': {'type': 'Point', 'coordinates': [3.879638, 43.608525]},\n 'properties': {'label': 'Place de la Comédie 34000 Montpellier',\n  'score': 0.70161,\n  'id': '34172_1485',\n  'name': 'Place de la Comédie',\n  'postcode': '34000',\n  'citycode': '34172',\n  'x': 771035.57,\n  'y': 6279225.95,\n  'city': 'Montpellier',\n  'context': '34, Hérault, Occitanie',\n  'type': 'street',\n  'importance': 0.71771,\n  'street': 'Place de la Comédie'}}",
    "crumbs": [
      "Data handling",
      "Working with CSV and JSON files"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html#exercises",
    "href": "source/manipulation/csv-json-files/tutorial.html#exercises",
    "title": "Working with CSV and JSON files",
    "section": "Exercises",
    "text": "Exercises\n\nQuestions of understanding\n\n1/ What is a CSV file?\n2/ What are the advantages of the CSV format?\n3/ Why do we use the csv module to read and write CSV files?\n4/ Are the data in a CSV file always separated by commas?\n5/ What is the header of a CSV file? Does it necessarily exist?\n6/ Why is the JSON format widely used in data manipulation?\n7/ What Python object does JSON content resemble?\n8/ What types of Python objects can be converted to JSON?\n9/ What is the serialization of a Python object?\n10/ What is the main similarity between CSV and JSON files?\n11/ Does a file with a .json extension necessarily contain JSON?\n\n\n\n\nShow solution\n\n\n1/ A CSV is a text file that represents the raw data of a spreadsheet-like document. Each line of the file represents a row in the spreadsheet, and the cells in a row are separated by commas. The first line may contain a header (column names), but this is not always the case.\n2/ Simplicity of reading and editing, universality.\n3/ Even though the CSV format is very simple, it has some characteristics (delimiter, end-of-line character, etc.) that need to be considered when reading or editing CSV. The csv module provides functions that account for these peculiarities.\n4/ No, data can theoretically be separated by any character or sequence of characters. In practice, follow the convention in most cases, which is to use a comma.\n5/ It is the first line of the CSV file, which usually contains the variable names, but this is not always the case.\n6/ It is the primary response format for APIs, which are widely used for data dissemination and exchange.\n7/ Dictionaries.\n8/ All serializable objects, which include most of the basic objects we have seen, but not manually created objects via classes.\n9/ The serialization of a (serializable) Python object is converting the data contained in that object into a byte sequence, i.e., a message that any computer can understand.\n10/ They are text files.\n11/ No, JSON files like CSV files are text files. The extension is a convention that allows, in most cases, knowing what the file contains, but it cannot guarantee it.\n\n\n\n\n\nSort the keys when writing a JSON\nThe following cell contains a dictionary. The goal of the exercise is to write this data to a JSON file, sorting the dictionary keys alphabetically.\nHint: The dump function of the json module contains a parameter that allows sorting the keys. Read the function documentation to determine it.\n\ndata = {\"id\": 1, \"name\": \"Isidore\", \"age\": 29}\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nimport json\n\ndata = {\"id\": 1, \"name\": \"Isidore\", \"age\": 29}\n\nwith open(\"data_sorted.json\", \"w\") as file_out:\n    json.dump(data, file_out, sort_keys=True)\n\n\n\n\n\nConvert a non-serializable object to JSON\nWe have seen that manually created objects via classes are generally not serializable. The following cell shows an example with our Citron object used in the OOP tutorial. Trying to convert the object directly to JSON returns an error.\nYou must modify the following code to serialize the object. To do this, you must:\n\nConvert the mon_citron instance using the built-in __dict__ method that all Python objects have.\nConvert the obtained dictionary to JSON as a string.\n\n\nimport json\n\nclass Citron:\n\n    def __init__(self, color, juice_qty):\n        self.flavor = \"acidic\"\n        self.color = color\n        self.juice = juice_qty\n        \nmon_citron = Citron(color=\"yellow\", juice_qty=45)\njson.dumps(mon_citron)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[58], line 11\n      8         self.juice = juice_qty\n     10 mon_citron = Citron(color=\"yellow\", juice_qty=45)\n---&gt; 11 json.dumps(mon_citron)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/__init__.py:231, in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\n    226 # cached encoder\n    227 if (not skipkeys and ensure_ascii and\n    228     check_circular and allow_nan and\n    229     cls is None and indent is None and separators is None and\n    230     default is None and not sort_keys and not kw):\n--&gt; 231     return _default_encoder.encode(obj)\n    232 if cls is None:\n    233     cls = JSONEncoder\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:199, in JSONEncoder.encode(self, o)\n    195         return encode_basestring(o)\n    196 # This doesn't pass the iterator directly to ''.join() because the\n    197 # exceptions aren't as detailed.  The list call should be roughly\n    198 # equivalent to the PySequence_Fast that ''.join() would do.\n--&gt; 199 chunks = self.iterencode(o, _one_shot=True)\n    200 if not isinstance(chunks, (list, tuple)):\n    201     chunks = list(chunks)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:257, in JSONEncoder.iterencode(self, o, _one_shot)\n    252 else:\n    253     _iterencode = _make_iterencode(\n    254         markers, self.default, _encoder, self.indent, floatstr,\n    255         self.key_separator, self.item_separator, self.sort_keys,\n    256         self.skipkeys, _one_shot)\n--&gt; 257 return _iterencode(o, 0)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:179, in JSONEncoder.default(self, o)\n    160 def default(self, o):\n    161     \"\"\"Implement this method in a subclass such that it returns\n    162     a serializable object for ``o``, or calls the base implementation\n    163     (to raise a ``TypeError``).\n   (...)\n    177 \n    178     \"\"\"\n--&gt; 179     raise TypeError(f'Object of type {o.__class__.__name__} '\n    180                     f'is not JSON serializable')\n\nTypeError: Object of type Citron is not JSON serializable\n\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nimport json\n\nclass Citron:\n\n    def __init__(self, color, juice_qty):\n        self.flavor = \"acidic\"\n        self.color = color\n        self.juice = juice_qty\n        \nmon_citron = Citron(color=\"yellow\", juice_qty=45)\nmon_citron_dict = mon_citron.__dict__\n\njson.dumps(mon_citron_dict)\n\n'{\"flavor\": \"acidic\", \"color\": \"yellow\", \"juice\": 45}'\n\n\n\n\n\n\nChange the delimiter of a CSV file\nYour current directory contains the file nat2020.csv. It is the file of first names published by Insee, containing data on the first names given to children born in France between 1900 and 2020.\nProblem: Contrary to the CSV standard, the delimiter used is not a comma. You must:\n\nFind the delimiter used (via the Jupyter text editor, a shell command, or by testing with the csv module in Python) to read the file correctly.\nGenerate a new CSV file nat2020_corr.csv containing the same data, but this time with a comma as the separator.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\n# Let's find the delimiter used with a shell command\n!head -n 3 nat2020.csv\n\nwith open('nat2020.csv', 'r') as file_in:\n    # Read the existing CSV file\n    reader = csv.reader(file_in, delimiter=';')\n    with open('nat2020_corr.csv', 'w') as file_out:\n        # Write to the new CSV file\n        writer = csv.writer(file_out)  # By default, the delimiter is a comma\n        for row in reader:\n            writer.writerow(row)\n            \n# Verify with a shell command\n!head -n 3 nat2020_corr.csv\n\nsexe;preusuel;annais;nombre\n1;TRESOR;2002;4\n2;AWATEF;1972;3\nsexe,preusuel,annais,nombre\n1,TRESOR,2002,4\n2,AWATEF,1972,3\n\n\n\n\n\n\nExtract and save data from an API\nThe exercise is to make a request to the National Address Base API and save the results in a CSV file. Here are the steps to implement:\n\nMake a street name request with a keyword like in the tutorial (if you want to make a more complex request, you can check the API documentation) and store the results in a dictionary.\nCreate a CSV file resultats_ban.csv in which we will store the following information: ‘name’, ‘city’, ‘city_code’, ‘longitude’, ‘latitude’.\nUsing a writer object and a loop on the results returned by the API, write each line to the CSV.\n\nFor example, for the query of streets containing the word “comédie”, here is the CSV to obtain:\nname,city,city_code,longitude,latitude\nRue de la Vieille Comedie,Lille,59350,3.063832,50.635192\nPlace de la Comédie,Montpellier,34172,3.879638,43.608525\nRue de la Comédie,Cherbourg-en-Cotentin,50129,-1.629732,49.641574\nAllee de la Comedie,Villeneuve-d'Ascq,59009,3.162808,50.64628\nRue de l’Ancienne Comedie,Poitiers,86194,0.342649,46.580457\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nresponse = requests.get(\"https://api-adresse.data.gouv.fr/search/?q=comedie&type=street\")\nr_text = response.text\nr_dict = json.loads(r_text)\n\nwith open('resultats_ban.csv', 'w') as file_out:\n    header = ['name', 'city', 'city_code', 'longitude', 'latitude']\n    csv_writer = csv.writer(file_out)\n    csv_writer.writerow(header)\n    for result in r_dict['features']:\n        name = result['properties']['name']\n        city = result['properties']['city']\n        city_code = result['properties']['citycode']\n        long, lat = result['geometry']['coordinates']\n        row = [name, city, city_code, long, lat]\n        csv_writer.writerow(row)\n\n\n\n\n\nSplit the department base by regions\nThe goal of this exercise is to split the CSV file of French departments used in the tutorial into several small CSV files, one per region. This type of operation can be useful, for example, when working with a very large file that does not fit in memory; splitting it into several files to process independently, when possible, reduces the volume.\nHere are the operations to perform:\n\nCreate a dep folder in the current directory using the pathlib module (cf. previous tutorial).\nWith a csv module reader object, loop through the lines of the department CSV file. Be careful not to include the header, using the next function to skip the first line. For each following line:\n\nRetrieve the region code (variable REG).\nGenerate the path of the CSV file dep/{REG}.csv where {REG} is to be replaced by the region code of the line.\nOpen this CSV file in append mode to write the line at the end of the file.\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nfrom pathlib import Path\n\npath_dep = Path(\"dep/\")\npath_dep.mkdir(exist_ok=True)\n\nwith open('departement2021.csv', 'r') as file_in:\n    csv_reader = csv.reader(file_in)\n    next(csv_reader)  # Skip the header\n    for row in csv_reader:\n        reg = row[1]\n        filename = reg + '.csv'\n        path_reg_file = path_dep / filename  # Path of the region csv file\n        with open(path_reg_file, 'a') as file_reg_in:\n                writer = csv.writer(file_reg_in)\n                writer.writerow(row)\n\n\n\n\n\nAdd missing headers\nIn the previous exercise, we split the CSV file of French departments into several CSV files, one per region. However, we did not include the header in the different files, i.e., the first line containing the column names. We will add it manually to each of the CSV files created in the previous exercise.\nHere are the operations to perform:\n\nRead the complete department file and retrieve the header in a list with the next function.\nRecord in a list the paths of the different CSV files contained in the dep folder using the glob method of pathlib (cf. previous tutorial).\nFor each path:\n\nOpen the existing CSV file and retrieve the data as a list of lists (one list per line).\nOpen the CSV file in write mode to reset it, write the header first, and then write the data previously saved in a list of lists.\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nfrom pathlib import Path\n\nwith open('departement2021.csv', 'r') as file_in:\n    csv_reader = csv.reader(file_in)\n    header = next(csv_reader)\n\ndep_files_paths = list(Path(\"dep/\").glob('*.csv'))\n\nfor path in dep_files_paths:\n    # Read the existing file, storing the lines in a list\n    with open(path, 'r') as file_dep_in:\n        reader = csv.reader(file_dep_in)\n        dep_rows = []\n        for row in reader:\n            dep_rows.append(row)\n    # Rewrite the output file, adding the header first\n    with open(path, 'w') as file_dep_out:\n        writer = csv.writer(file_dep_out)\n        writer.writerow(header)\n        for row in dep_rows:\n            writer.writerow(row)",
    "crumbs": [
      "Data handling",
      "Working with CSV and JSON files"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html",
    "href": "source/manipulation/modules-files/tutorial.html",
    "title": "File manipulation",
    "section": "",
    "text": "In previous tutorials, we have consistently used variables to store data and perform operations on it. This method may suffice within a given Python session, such as here in a Jupyter notebook or in a program.\nBut what happens, for example, if we want to retain the outputs of the calculations performed or transformed data once the session is over? We need to save these elements in a file, in a location where this data will persist over time for future use. In this tutorial, we will see how to read and write files with Python.",
    "crumbs": [
      "Data handling",
      "File manipulation"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#some-notions-about-modules-and-packages",
    "href": "source/manipulation/modules-files/tutorial.html#some-notions-about-modules-and-packages",
    "title": "File manipulation",
    "section": "Some notions about modules and packages",
    "text": "Some notions about modules and packages\nBefore discussing file manipulation, we need to make a brief detour into the world of modules and packages (libraries).\nSo far, we have primarily used standard Python objects and instructions that did not require any third-party imports. In this tutorial and all the ones to follow, we will perform more complex operations (interacting with a file system, performing vector calculations, manipulating tabular data, etc.) that would be very costly, inefficient, and error-prone to code by hand using basic Python objects.\nThis is why we will use packages, which are toolboxes filled with functions and classes developed by others (often communally) that allow us to perform complex operations at a lower cost.\n\nTerminology\nLet’s start with a few brief elements of terminology to navigate the Python ecosystem properly:\n\nA module is a text file (with a .py extension to indicate it is Python) containing a set of definitions (of classes, functions) and instructions that can be imported into a Python environment for use.\nA package is a collection of modules grouped in a directory.\n\nFor example, we will see in detail the use of numpy in the next part. numpy is a package that allows for scientific computation on multidimensional objects. To do this, numpy provides a vast number of functions and tools. Putting them all in a single module would be highly unreadable. Thus, numpy is structured into different modules that group functions performing similar operations: random number generation in the random module, linear algebra in the linalg module, etc.\n\n\nImporting a module\nTo use the functions of a module and the various modules that constitute a package, we first need to import them.\nThe syntax is straightforward; let’s illustrate it with an example.\n\nimport random\nrandom.randint(0, 100)\n\n55\n\n\nWe imported the random module (entirely) from the standard Python library using the import statement. Then, we called the randint function contained in the random module, which returns a random number between a and b, its parameters.\nWe could also import only the randint function using the from module import function syntax. Then, specifying the module name is no longer necessary when calling the function.\n\nfrom random import randint\nrandint(0, 100)\n\n48\n\n\nNote that once an import is performed, the imported module is available for the entire duration of the Python session. Therefore, there’s no need to import the module before each use of one of its functions; once at the beginning of the notebook or script is enough.\n\n\n\n\n\n\nToo many imports spoil the import\n\n\n\nYou sometimes see the syntax from module import * (* is called the wildcard), which imports all the functions of the module into memory. While this can save time, it is not a good practice:\n\nOn the one hand, it loads more code into memory than necessary for our application;\nOn the other hand, it limits the code’s readability since you cannot explicitly see where the functions used in the code are imported from.\n\n\n\n\n\nImporting a package\nA package is simply a collection of modules, structured hierarchically. The syntax for importing a package is the same as for importing a module.\nFor example, let’s see again how to use the randint function, but this time from the numpy package (which does the same thing).\n\nimport numpy\nnumpy.random.randint(0, 100)\n\n46\n\n\nWe imported the numpy package, which allowed us to access the randint function via its random module. Again, we could import the function directly.\n\nfrom numpy.random import randint\nrandint(0, 100)\n\n18\n\n\nIn practice, the first syntax is preferable: it is always more readable to explicitly show where the function being called comes from. To reduce verbosity, it is common to give aliases to imported packages. Here are the three most common ones, which we will encounter very often in the tutorials of the next chapter on data manipulation.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nWe can then use these aliases to call modules and functions.\n\nx = np.linspace(0, 10, 1000)\nplt.plot(x, np.sin(x))\n\n\n\n\n\n\n\n\n\n\nInstalling packages\nSo far, we have been able to import various packages via the import statement without any issues. But how were they installed? We need to distinguish between two cases:\n\nA certain number of packages are part of the standard library, which means they are installed along with Python. This is the case for the random package used earlier, but there are many others;\nOther “third-party” packages are developed by the Python user community and must be installed to be used. This is the case for numpy and pandas. In our case, we did not have to install them because the environment provided for the training already contains all the necessary packages to run the different chapters.\n\nLet’s illustrate package installation with the emoji package, which allows for representing emojis in Python outputs. This package is not yet installed; trying to import it produces a ModuleNotFoundError.\n\nimport emoji\n\nTo install a package, the command is simple: pip install package_name. Without going into details, pip is a package manager installed with Python that is used via the command line (i.e., in a terminal). To send a command to the terminal from a Jupyter notebook, we add a ! at the beginning of the line.\n\n!pip install emoji\n\nRequirement already satisfied: emoji in /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages (2.12.1)\nRequirement already satisfied: typing-extensions&gt;=4.7.0 in /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages (from emoji) (4.12.2)\n\n[notice] A new release of pip is available: 24.1.2 -&gt; 24.2\n[notice] To update, run: pip install --upgrade pip\n\n\nWe can now import the package and use its functions.\n\nimport emoji\nprint(emoji.emojize('Python is :thumbs_up:'))\n\nPython is 👍\n\n\n\n\n\n\n\n\npip and PyPI\n\n\n\npip is the standard package manager for Python. It allows installing, updating, and removing Python packages found in the Python Package Index (PyPI), a directory of packages for programming in Python. This directory contains a vast number of projects (about 500,000 at the time of writing this tutorial), from the most amateur to the most essential.\nIn general, it is always preferable, before starting to write an application “by hand,” to check if a package doing the same thing or almost already exists. A simple Google search—preferably in English—containing the keywords of what you are looking to do often ensures this.",
    "crumbs": [
      "Data handling",
      "File manipulation"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#file-manipulation",
    "href": "source/manipulation/modules-files/tutorial.html#file-manipulation",
    "title": "File manipulation",
    "section": "File manipulation",
    "text": "File manipulation\n\nInteracting with the local file system\nTo read and write files with Python, we first need to understand how they are represented on the local file system and how Python interacts with it.\nThe pathlib module\nFor this, we will repeatedly use the pathlib module and, in particular, the Path class. This module allows interacting with the file system in the form of objects, manipulating attributes and their methods. Don’t worry; we have already seen everything we need to know about this in the previous tutorial.\n\nfrom pathlib import Path\n\nFile properties\nA file has two properties:\n\nA file name\nA path that specifies its location in the file system.\n\nFor example, let’s look at the files in our current directory (by default, the folder where this notebook is located). The method to use is called cwd, for current working directory.\n\nPath.cwd()\n\nPosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files')\n\n\nThe path of our current directory is contained in a PosixPath object, which simply means that pathlib understood that we were on a Unix-like environment (the SSP Cloud servers run on Linux). If you were running this notebook locally on a Windows computer, the object would be WindowsPath. Practically, this doesn’t change much for you, but it is quite important: file systems do not use the same conventions between different environments (e.g., the separators between folders in a path are not the same), but pathlib allows you to interact with these different systems in a harmonized way.\nNow, let’s list all the files in our current directory. We use another method, glob, which will simply return all files whose name has a certain structure. For example, .glob('*.txt') will retrieve all files with the .txt extension, and .glob('test.*') will retrieve all files named test, regardless of their extension. Here, we retrieve all files using the wildcard * in both positions.\nThis method returns a somewhat special object (a generator). If you remember, we encountered the same case with the range function. Simply call the list function on it to display the results legibly.\n\nPath.cwd().glob('*.*')\n\n&lt;generator object Path.glob at 0x7f3d55993ed0&gt;\n\n\n\nlist(Path.cwd().glob('*.*'))\n\n[PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/notes.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/write_list.py'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/tutorial.quarto_ipynb'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/output_script.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/normalisation.py'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/tutorial.qmd'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/gamme.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/notes_clean.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/test.txt')]\n\n\nWe find our notebook, a file that contains the solutions to the tutorial exercises, and several text files that will serve as examples in the rest of the tutorial. For instance, if we take the notebook, we can clearly distinguish:\n\nIts file name: tutorial.ipynb\nIts path: /home/onyxia/work/\n\nAbsolute paths and relative paths\nThere are two possible ways to specify the path of a file:\n\nAbsolute, the path then starts from the root (/ on Unix, C:\\ on Windows, etc.). The paths returned above are therefore absolute.\nRelative, i.e., relative to the current directory of the Python program. As soon as a path does not start from the root, pathlib will consider it relative.\n\nThis distinction will prove quite important later when it comes to reading and writing files.\nForming paths\nIn practice, what interests us is being able to form our own paths—whether they are absolute or relative to the current directory—to specify where the files we want to read are located or where the files we want to write should be.\npathlib offers a very intuitive syntax for forming paths, very similar to the concatenation of strings we have already seen. Instead of a +, this time, we will use a / to concatenate the different parts of a path.\nFor example, let’s try to reconstruct the full path of this notebook. We can start by finding the path of the home directory, which is the standard folder where all the user’s files are located.\n\nPath.home()\n\nPosixPath('/home/runner')\n\n\nWe can then concatenate the different subfolders and the file name of the notebook to get the full path to it.\n\npath_nb = Path.home() / 'work' / 'tutorial.ipynb'\npath_nb\n\nPosixPath('/home/runner/work/tutorial.ipynb')\n\n\nWe get exactly the same path as the one obtained by listing the files in the current directory.\nMore about pathlib\nWe have only seen a glimpse of the tools offered by the pathlib module to interact with the local file system. The official documentation presents these possibilities exhaustively. We will present other methods from this library in this tutorial and the following ones as the opportunity arises. For now, we know enough to read and write files on the file system.\n\n\nText files and binary files\nIn programming, we generally deal with two large families of files:\n\nText files. They contain only standard textual characters—technically, those that comply with the Unicode standard—without formatting information (font, color, etc.). .txt files or Python scripts ending in .py are examples of text files. These files can be read with any text editor.\nBinary files. These are all other types of files: compressed files (.zip, tar.gz, etc.), PDF documents, images, programs, etc. Opening such a file with a text editor generally produces a large sequence of incomprehensible characters because the textual representation is not suited to this data.\n\nAs you can imagine, these two types of files are handled with different tools. Moreover, due to the diversity of binary files, each of them requires particular handling. In a programming context, however, we mainly deal with code, which is textual data. So, we will focus only on writing and reading text files in this tutorial, but it is important to recognize binary data when you need to handle it.\n\n\nOpening a file\nAsking Python to open a file is like opening a connection between your Python environment and the file. As long as this connection is open, the file can be manipulated.\nTo open a file, we use the open function. For example, let’s open the gamme.txt file that has been placed in the current directory.\n\npath_range = Path.cwd() / 'gamme.txt'\nfile_in = open(path_range, 'r')\nfile_in\n\n&lt;_io.TextIOWrapper name='/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/gamme.txt' mode='r' encoding='UTF-8'&gt;\n\n\nThe open function returns an object of type _io.TextIOWrapper, which specifies the encoding mode of the file and the opening mode.\nEncoding and decoding are technical subjects that we will not cover in this tutorial. Let’s simply note that the default encoding mode is UTF-8, and there is rarely a good reason to choose another mode.\nHowever, the opening mode is very important. There are three main modes:\n\nr: read-only. The file can only be read, not modified. This is the default mode when no mode is specified.\nw: write. This mode allows writing to a file. Warning: if a file with the same name already exists, it will be automatically overwritten.\na: appending. This mode only allows adding lines to the end of an existing file.\n\nOnce the file is open, operations can be performed on it using methods attached to the object representing it. In the next section, we will see what the readlines method does.\n\nfile_in.readlines()\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nOnce the manipulations are done, close the connection with the close method. It is no longer possible to manipulate the file.\n\nfile_in.close()\n\nIn practice, it is easy to forget to close the connection to a file, which can create annoying errors. There is a syntax that avoids this problem by using a context manager that handles the entire connection for us.\n\nwith open(path_range, 'r') as file_in:\n    lines = file_in.readlines()\nlines\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nThis syntax is much more readable: thanks to the indentation, it is clear which operations are performed while the file is open, and the file is automatically closed once we return to the initial indentation level. We will always prefer to use this syntax if possible, as it is a good programming practice.\n\n\nReading a file\nOnce a file is open, we may want to read its content. There are different ways to do this. A simple and elegant method is to traverse the file using a loop, which is possible because the Python object representing the file is iterable.\n\nwith open(path_range, 'r') as file_in:\n    for line in file_in:\n        print(line)\n\ndo\n\nre\n\nmi\n\nfa\n\nsol\n\nla\n\nsi\n\n\nIn our example, we simply displayed the lines, but many things can be done with the data in the text file: storing it in a Python object, using it for calculations, keeping only the lines that meet a certain condition via an if statement, etc.\nThere are also built-in methods for reading the content of a file. The most basic is the read method, which returns the entire file as a (potentially very long) string.\n\nwith open(path_range, 'r') as file_in:\n    txt = file_in.read()\ntxt\n\n'do\\nre\\nmi\\nfa\\nsol\\nla\\nsi'\n\n\nThis is rarely very useful: we generally prefer to retrieve individual lines from a file. The readlines method traverses the entire file and returns a list whose elements are the lines of the file, in order of appearance.\n\nwith open(path_range, 'r') as file_in:\n    l = file_in.readlines()\nl\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nNote that each element of the list (except the last one) ends with the special character \\n (“newline”) which simply marks the end of each line in a text file. It is the (hidden) presence of this same character at the end of each call to the print function that causes a line break every time a print is used.\n\n\nWriting to a file\nWriting to a file is very simple; it is done using the write method. For example, let’s write the various elements contained in a list to a file, line by line.\n\nex = [\"this\", \"is\", \"a\", \"very\", \"original\", \"example\"]\nwith open(\"test.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem)\n\nEverything seems to have gone smoothly. We can check that our file was created correctly via the Jupyter file explorer (on the left) or via the ls command in the terminal.\n\n!ls\n\n__pycache__   notes.txt      test.txt           write_list.py\ngamme.txt     notes_clean.txt    tutorial.qmd\nnormalisation.py  output_script.txt  tutorial.quarto_ipynb\n\n\nIt is there. Let’s now verify that its content is what we wanted.\n\nwith open(\"test.txt\", \"r\") as file_out:\n    print(file_out.read())\n\nthisisaveryoriginalexample\n\n\nThe different elements of our list have merged into a single block of text! This is because, unlike the print function, for example, the write function does not automatically add the newline character. It must be added manually.\n\nwith open(\"test.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem + \"\\n\")\nwith open(\"test.txt\", \"r\") as file_out:\n    print(file_out.read())\n\nthis\nis\na\nvery\noriginal\nexample\n\n\n\nThat’s much better.\nA few additional remarks about writing to files:\n\nIt bears repeating: using the \\w opening mode for a file completely overwrites its content. When we rewrote our file with line breaks, we completely overwrote the old one.\nWhy were we able to just put the file name in the open function and not a Path object containing the full path to the file we wanted to create? This is because Python automatically interpreted it as a relative path (to our current directory) due to the absence of a root.\nYou can only write elements of type str (string) to a file. If one of the elements in the list above had been of type int or float, for example, it would have needed to be converted via the\n\nstr() function before being written to the file. Otherwise, Python would have returned an error.",
    "crumbs": [
      "Data handling",
      "File manipulation"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#executing-code-from-.py-files",
    "href": "source/manipulation/modules-files/tutorial.html#executing-code-from-.py-files",
    "title": "File manipulation",
    "section": "Executing code from .py files",
    "text": "Executing code from .py files\nSo far in this tutorial, we have explored the use of packages/modules, whether from the standard Python library or developed by third parties. We have also addressed interacting with the local file system. Now, let’s discover how to combine these skills by writing and executing our own Python scripts and modules as .py files.\n\nPython scripts\nIn a Jupyter notebook environment (like the one you are in), Python code is executed interactively, cell by cell. This is possible because a Python kernel runs in the background throughout the notebook session. However, outside of Jupyter, code is generally written and executed as scripts. A Python script is simply a text file with a .py extension containing a series of Python instructions that will be executed linearly by the Python interpreter.\nThe write_list.py file repeats a code cell seen earlier. Let’s display its content.\n\nwith open('write_list.py', 'r') as script:\n    print(script.read())\n\nex = [\"ceci\", \"est\", \"un\", \"exemple\", \"très\", \"original\"]\n\nwith open(\"output_script.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem)\n\nprint(\"Succès !\")\n\n\n\nA Python script is executed in a terminal using the command python script_name.py. To execute it from a Jupyter notebook, we again add a ! at the beginning of the line.\n\n!python write_list.py\n\nSuccès !\n\n\nThe output_script.txt file has indeed been created locally (it may take a while or require refreshing for it to appear), and the expected message was printed in the console output.\n\n\n\n\n\n\nNotebook vs. scripts\n\n\n\nShould we prefer using Jupyter notebooks, as in this training, or prefer execution via scripts? There is no definitive answer to this question:\n\nNotebooks allow interactive execution, which is very practical for experimentation;\nScripts make it easier to automate a process, as they are executed linearly and do not require intermediate actions from the user.\n\nIn short, notebooks are very useful during the development phase, but scripts are preferred when it comes to automating processes or producing code intended to run in production.\n\n\n\n\nScripts and modules\nAs we have seen, a script is a .py file intended to be executed directly. It generally contains a complete workflow or an automated task. A module is also a .py file, but it contains definitions of functions and/or classes intended to be used by other scripts or modules. It is not intended to be executed alone but imported elsewhere. At the beginning of this tutorial, we used modules from packages written by others. Now let’s see how we can write our own modules and import them according to the same principles.\nLet’s display the content of the normalisation.py file, which will serve as an example.\n\nwith open('normalisation.py', 'r') as module:\n    print(module.read())\n\nimport numpy as np\n\n\ndef normalise(x):\n    \"\"\"Normalise un vecteur de valeurs à une moyenne de 0 et un écart-type de 1.\"\"\"\n    return (x - np.mean(x)) / np.std(x)\n\n\nif __name__ == \"__main__\":\n    vec = [2, 4, 6, 8, 10]\n    vec_norm = normalise(vec)\n    print(np.mean(vec), np.var(vec), np.mean(vec_norm), np.var(vec_norm))\n\n\n\nThe function contained in this module can be imported as we have seen in this tutorial. Note that the module itself must import the necessary packages/modules for the proper functioning of its functions (in this case, numpy).\nTo import a local module, use the import statement followed by the file name without the extension. All functions defined in the module can then be used via the module_name.function_name syntax.\n\nimport normalisation\nx = [1, 2, 3, 4, 5]\nx_norm = normalisation.normalise(x)\nprint(x_norm)\n\n[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n\n\nAs explained at the beginning of the chapter, we could also import the function directly to avoid recalling the module name containing it. This is particularly practical if this function is to be used multiple times in the same notebook/script.\n\nfrom normalisation import normalise\nx = [1, 2, 3, 4, 5]\nx_norm = normalise(x)\nprint(x_norm)\n\n[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n\n\n\n\n\n\n\n\nThe bad idea: import *\n\n\n\nA crucial good practice is to prioritize code readability. In both import variants presented above, the code is readable: it is clear from which module the function used comes.\nHowever, it is not uncommon to see the instruction from my_module import * in Python code, which imports all functions defined in the my_module.py file. This should be avoided whenever possible for two reasons:\n\nIt becomes difficult to determine from which module or package the functions used come;\nIf functions imported from different packages/modules have the same name, they can replace each other and generate difficult-to-debug errors.\n\nTo limit the length of the instruction line when importing multiple functions, you can adopt the following syntax:\n\nfrom my_module import (\n    function1,\n    function2,\n    function3\n)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[72], line 1\n----&gt; 1 from my_module import (\n      2     function1,\n      3     function2,\n      4     function3\n      5 )\n\nModuleNotFoundError: No module named 'my_module'\n\n\n\n\n\nFinally, note that a .py file can serve both as a module and a script. To differentiate between the two usages, use the __name__ variable, which is defined by default by Python when using a .py file:\n\nIf the file is used as a module (e.g., import my_file), the __name__ variable is set to the file name (e.g., my_file).\nIf the file is used as a script (e.g., python my_file.py), the __name__ variable is set to __main__.\n\nIn the previous cell, the normalisation.py file was imported as a module. In this case, the __name__ variable is set to normalisation, and that’s why the code under the if condition was not executed. When the file is executed as a script, this code is executed.\n\n!python normalisation.py\n\n6.0 8.0 0.0 0.9999999999999998\n\n\nIt is therefore very common to see the condition if __name__ == \"__main__\" in Python scripts, distinguishing the usage as a module and the usage as a script.",
    "crumbs": [
      "Data handling",
      "File manipulation"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#exercises",
    "href": "source/manipulation/modules-files/tutorial.html#exercises",
    "title": "File manipulation",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension questions\n\n1/ What is a module?\n2/ What is a package?\n3/ Why is it not a good practice to import all functions from a module using the from module import * syntax?\n4/ What are the advantages of the pathlib library?\n5/ What are the two properties of a file that allow identifying its position in the file system?\n6/ What is the current directory?\n7/ What are the two ways to specify a path? How does Python differentiate between the two?\n8/ What are the two major families of files that we handle in programming?\n9/ What are the different modes for opening a file?\n10/ Why is it preferable to use the with open(...) as ... syntax to open a file?\n11/ Why can we traverse the lines of a file using a loop?\n12/ What is the difference between a module and a script?\n\n\n\n\nShow the solution\n\n\n1/ A module is a text file (with a .py extension to indicate it is Python) containing a set of definitions (of classes, functions) and instructions.\n2/ A package is a collection of modules.\n3/ It overloads the memory if only a few functions are needed, and it reduces readability since it is not clear from which module a function originates.\n4/ It allows interacting with the file system using a unified OOP syntax, regardless of the environment.\n5/ File name and path of the folder containing the file.\n6/ It is the directory in which the current Python session is opened. In a Jupyter notebook context, it is by default the folder containing it.\n7/ Absolute path (complete) and relative path (relative to the current directory). An absolute path is recognizable because it always starts from the file system’s root.\n8/ Text files and binary files (anything that is not text).\n9/ r: read. w: write. a: appending.\n10/ This syntax involves a context manager that handles the connection to the file (opening and closing) for us.\n11/ Because the object representing the file in Python is an iterable.\n12/ As we have seen, a script is a .py file intended to be executed directly. It generally contains a complete workflow or an automated task. A module is also a .py file, but it contains definitions of functions and/or classes intended to be used by other scripts or modules. It is not intended to be executed alone but imported elsewhere.\n\n\n\n\n\nMean and standard deviation of exam scores\nExercise inspired by: python.sdv.univ-paris-diderot.fr\nThe text file notes.txt is in your current directory. It contains the scores obtained by 50 students in an exam. Problem: all the scores are written on a single line, with a space each time. Open this file and calculate the mean and standard deviation of the scores.\nHints:\n\nStrings have a split method that allows splitting text based on a given character.\nThe scores will need to be converted to numeric format to apply mathematical functions.\nYou can use functions from the numpy package to calculate the required statistics.\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\nimport numpy as np\n\nwith open(\"notes.txt\", \"r\") as file_in:\n    notes = file_in.read()\n\nnotes = notes.split()\nnotes_num = []\nfor n in notes:\n    notes_num.append(int(n))\n\nprint(np.mean(notes_num))\nprint(np.std(notes_num))\n\n\n\n\nPassed or failed\nExercise inspired by: python.sdv.univ-paris-diderot.fr\nThe text file notes_clean.txt is in your current directory. It contains the scores obtained by 50 students in an exam. Unlike the previous exercise, the scores are correctly written: one score per line.\nWrite code that:\n\nStores each score as an int in a list.\nRewrites the scores in a file notes_mentions.txt with each line containing the score, followed by a space, followed by the mention “passed” if the score is greater than or equal to 10, and “failed” otherwise.\n\nFor example, the first three lines of this new file should be:\n5 failed\n5 failed\n18 passed\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\nnotes = []\n\nwith open(\"notes_clean.txt\", \"r\") as file_in:\n    for n in file_in:\n        notes.append(int(n))\n        \nwith open(\"notes_mentions.txt\", \"w\") as file_out:\n    for n in notes:\n        if n &gt;= 10:\n            mention = \"passed\"\n        else:\n            mention = \"failed\"\n        file_out.write(str(n) + \" \" + mention + \"\\n\")\n\n\n\n\nLatecomers\n3 students did not submit their papers on time for the exam:\n\nMiranda scored 16 and submitted her paper 3 days late.\nPaolo scored 11 and submitted his paper 1 day late.\nIsidore scored 3 and submitted his paper 5 days late.\n\nEach student will have a final score equal to the obtained score minus the number of late days. A score cannot be negative; it will be replaced by 0.\nThe necessary information is placed in a list in the following cell. Using a loop on this list, add (without completely rewriting the file!) the scores to the notes_clean.txt file (without the mention).\nNB: if you accidentally overwrite the content of a file, you can find the clean files on the GitHub repository associated with the training.\n\nsupp = [(16, 3), (11, 1), (3, 5)]\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\nsupp = [(16, 3), (11, 1), (3, 5)]\n\nwith open(\"notes_clean.txt\", \"a\") as file_out:\n    for elem in supp:\n        final_score = elem[0] - elem[1]\n        final_score = max(0, final_score)\n        file_out.write(str(final_score) + \"\\n\")\n\n\n\n\nScanning files\nWrite a program that performs the following operations:\n\nIn the current directory, list the paths of files with the .txt extension (the syntax was seen in the pathlib part).\nLoop through these paths and open each file sequentially.\nFor each file, perform a membership test (recall the syntax: if pattern in string: ...) to check if the file contains the word “sol”. If so, print its absolute path in the console (only the path of the gamme.txt file should appear).\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\nfrom pathlib import Path\n\ntxt_files_paths = list(Path.cwd().glob('*.txt'))\n\nfor path in txt_files_paths:\n    with open(path, \"r\") as file_in:\n        content = file_in.read()\n        if \"sol\" in content:\n            print(path)",
    "crumbs": [
      "Data handling",
      "File manipulation"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html",
    "href": "source/fundamentals/data-structures2/tutorial.html",
    "title": "Data Structures 2: Dictionaries and Sets",
    "section": "",
    "text": "In the previous tutorial, we worked with sequential data structures: lists and tuples. Now, we will discover dictionaries and sets, which are unordered data structures: objects are no longer stored by position (or index) but by key, which is a unique identifier.",
    "crumbs": [
      "Fundamentals",
      "Data structures 2: dictionaries and sets"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html#dictionaries",
    "href": "source/fundamentals/data-structures2/tutorial.html#dictionaries",
    "title": "Data Structures 2: Dictionaries and Sets",
    "section": "Dictionaries",
    "text": "Dictionaries\n\nDefinition\nDictionaries are unordered collections of key-value pairs. A dictionary is defined using the following syntax: d = {'key1': 'value1', 'key2': 'value2'}.\n\ninventory = {'coffee': '500g', 'milk': '1.5L'}\ninventory\n\n{'coffee': '500g', 'milk': '1.5L'}\n\n\n\ntype(inventory)\n\ndict\n\n\nIt is possible to have as many keys as desired in a dictionary. However, keys are unique to uniquely identify the associated value. If you try to define a dictionary with a duplicated key, Python does not return an error, but only the last duplicated key is taken into account.\n\ninventory = {'coffee': '500g', 'milk': '1.5L', 'coffee': '300g'}\ninventory\n\n{'coffee': '300g', 'milk': '1.5L'}\n\n\nWhat can a dictionary contain? Keys can be of different types, but strings or integers are generally used. The values of a dictionary can be any type of Python object.\n\n\nUsage\nSince dictionaries are unordered, there is no notion of position: you access a value by its associated key. For example, to retrieve the value ('1.5L') associated with the key 'milk':\n\ninventory['milk']\n\n'1.5L'\n\n\nAdditional key-value pairs can be added to an existing dictionary using variable assignment syntax.\n\ninventory[\"cereal\"] = \"250g\"\ninventory\n\n{'coffee': '300g', 'milk': '1.5L', 'cereal': '250g'}\n\n\nUnlike lists, keys do not necessarily start at 0 and can be any number.\n\ndic1 = {12: \"Aveyron\", 33: \"Gironde\"}\n\nprint(\"The department 33 is \" + dic1[33])  # String concatenation!\n\nThe department 33 is Gironde\n\n\nSimilarly, values can be of different types, including data containers.\n\ndic2 = {\"scale\": \"C major\",\n        \"notes\": [\"do\", \"re\", \"mi\", \"fa\", \"sol\", \"la\", \"si\"]}\n\ndic2[\"notes\"]\n\n['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\n\nDictionaries can also contain other dictionaries. This makes them particularly suitable for representing hierarchical data structures.\n\nresume = {\n    \"marc\": {\"position\": \"manager\", \"experience\": 7, \"hobbies\": [\"sewing\", \"frisbee\"]},\n    \"mirande\": {\"position\": \"engineer\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(resume[\"marc\"])\nprint(resume[\"marc\"][\"hobbies\"][0])\n\n{'position': 'manager', 'experience': 7, 'hobbies': ['sewing', 'frisbee']}\nsewing\n\n\nLet’s repeat: dictionaries have no notion of order. Therefore, there is no sense in querying the element at position 0 in a dictionary (unless the key 0 exists). Querying a non-existent key returns an error.\n\ndic1 = {12: \"Aveyron\", 33: \"Gironde\"}\n\ndic1[0]\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[49], line 3\n      1 dic1 = {12: \"Aveyron\", 33: \"Gironde\"}\n----&gt; 3 dic1[0]\n\nKeyError: 0\n\n\n\n\n\nModifying Elements\nIt is possible to modify a value associated with an existing key in the dictionary. The new value can be of a different type from the original.\n\ninventory = {'coffee': '500g', 'milk': '1.5L'}\ninventory['coffee'] = {'arabica': '250g', 'robusta': '400g'}\ninventory\n\n{'coffee': {'arabica': '250g', 'robusta': '400g'}, 'milk': '1.5L'}\n\n\n\n\nDeleting Elements\nTo delete a key (and the associated value), you can use the same operations as those used to delete elements from a list.\n\n# Using the `del` operator\ninventory = {'coffee': '500g', 'milk': '1.5L'}\ndel inventory['milk']\ninventory\n\n{'coffee': '500g'}\n\n\n\n# Using the `pop` method\ninventory = {'coffee': '500g', 'milk': '1.5L'}\ninventory.pop('milk')\ninventory\n\n{'coffee': '500g'}\n\n\n\n\nSome Useful Methods\nWe saw earlier that querying a non-existent key returns an error. The .get() method allows querying a key without being sure of its existence, as it does not return an error in this case, but the None object, which we will see in a future tutorial.\n\ninventory = {'coffee': '500g', 'milk': '1.5L'}\ninventory.get('honey')\n\nYou can also specify a default value when the key does not exist.\n\ninventory.get('honey', 'not found')\n\n'not found'\n\n\nThe .keys(), .values(), and .items() methods return the keys, values, and key-value pairs of a dictionary, respectively. The objects returned by these methods are a bit complex, but they can be converted to lists using the list function to query them by position.\n\nresume = {\n    \"marc\": {\"position\": \"manager\", \"experience\": 7, \"hobbies\": [\"sewing\", \"frisbee\"]},\n    \"mirande\": {\"position\": \"engineer\", \"experience\": 5, \"hobbies\": [\"triathlon\"]}\n}\n\nlist(resume.keys())\n\n['marc', 'mirande']\n\n\n\nlist(resume.values())\n\n[{'position': 'manager', 'experience': 7, 'hobbies': ['sewing', 'frisbee']},\n {'position': 'engineer', 'experience': 5, 'hobbies': ['triathlon']}]\n\n\n\nlist(resume.items())\n\n[('marc',\n  {'position': 'manager', 'experience': 7, 'hobbies': ['sewing', 'frisbee']}),\n ('mirande',\n  {'position': 'engineer', 'experience': 5, 'hobbies': ['triathlon']})]",
    "crumbs": [
      "Fundamentals",
      "Data structures 2: dictionaries and sets"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html#sets-1",
    "href": "source/fundamentals/data-structures2/tutorial.html#sets-1",
    "title": "Data Structures 2: Dictionaries and Sets",
    "section": "Sets",
    "text": "Sets\n\nDefinition\nSets are unordered collections of unique elements. As such, they can be seen as dictionaries without values, where only the keys (which are unique by definition in a dictionary) are kept. Another analogy is that of mathematical sets, whose elements are also unordered and unique.\nDue to their similarity to dictionaries, sets are also defined using curly braces {}.\n\nx = {3, 2, 1}\nx\n\n{1, 2, 3}\n\n\n\ntype(x)\n\nset\n\n\nJust like dictionaries, sets are unordered, so there is no notion of position. Asking for the element at position i, as in a list, returns an error.\n\nx = {3, 2, 1}\nx[0]\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[60], line 2\n      1 x = {3, 2, 1}\n----&gt; 2 x[0]\n\nTypeError: 'set' object is not subscriptable\n\n\n\n\n\nModifying Elements\nIt is possible to add an element to a set using the add method.\n\nx = {3, 2, 1}\nx.add(\"4\")\nx\n\n{1, 2, 3, '4'}\n\n\nAdding an existing element changes nothing by definition.\n\nx = {3, 2, 1}\nx.add(2)\nx\n\n{1, 2, 3}\n\n\nIt is possible to remove an element from a set using the remove method.\n\nx = {3, 2, 1}\nx.remove(2)\nx\n\n{1, 3}\n\n\n\n\nUsage\nSets are not very often used in practice, but they are quite useful in certain specific situations. Due to the uniqueness of the elements they contain, sets allow you to simply and effectively remove duplicates from a sequential container, such as a list.\nDeduplication\nSuppose you want to remove duplicates from a given list. By definition, converting a list to a set removes duplicates. However, you generally want to return to a list, as sets do not offer the same flexibility as lists (for example, the ability to find an element by position). It is therefore common to perform the list -&gt; set -&gt; list chain of operations to deduplicate a list.\n\nl = [1, 2, 3, 3, 2, 1]\nl_dedup = list(set(l))\nl_dedup\n\n[1, 2, 3]\n\n\nSet Operations\nSince sets programmatically represent mathematical sets, it is not surprising that they allow for elementary set operations. For example, union and intersection.\n\nl1 = [5, 3, 2, 3, 3, 5, 8, 9]\nl2 = [3, 7, 0, 0, 1, 9, 4, 6]\n\n\n# Union: elements in l1, l2, or both\nl_union = list(set(l1) | set(l2))\nl_union\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n# Intersection: elements in both l1 and l2\nl_inter = list(set(l1) & set(l2))\nl_inter\n\n[9, 3]\n\n\nMembership Tests\nSets are also very useful for membership tests, as they offer much better performance than lists for this type of test.\nThe concept of testing will be covered in a future tutorial. For now, let’s note that a membership test such as “is element a in list l” is written in Python as a in l and returns True or False depending on whether a is actually present in list l.\n\nl = [1, 2, 3]\n2 in l\n\nTrue\n\n\n\n4 in l\n\nFalse\n\n\nNow, imagine performing this test on a list containing millions of elements. Exaggerating, the Python interpreter would then have to go through all the elements of the list one by one until it finds the element in question, which can take a long time.\nIn contrast, since the elements of a set are unique, Python can easily keep track of the list of unique elements contained in the set and thus conclude the test very quickly. We will see a performance comparison in an end-of-tutorial exercise.\nNB: The implementation of the concepts mentioned above is called a “hash table”. Interested readers can find more information about this data structure here.",
    "crumbs": [
      "Fundamentals",
      "Data structures 2: dictionaries and sets"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html#exercises",
    "href": "source/fundamentals/data-structures2/tutorial.html#exercises",
    "title": "Data Structures 2: Dictionaries and Sets",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension Questions\n\nCan you access the ith element of a dictionary? of a set?\nWhat types of objects can be used as dictionary keys? As values?\nFor what types of data is it beneficial to use a dictionary?\nCan a dictionary have duplicate keys?\nWhy can we say that a set is a special type of dictionary?\nWhy are sets used to deduplicate lists?\nWhy are sets more suitable than lists for membership tests?\n\n\n\n\nShow the solution\n\n\nNo, dictionaries and sets are unordered collections of objects.\nFor values: any type of object. For keys, we generally restrict to strings and/or integers.\nHierarchical data.\nNo, keys are unique.\nA set contains only unique elements and is written with curly braces. It can thus be seen as a special dictionary containing only keys.\nBy definition, the elements of a set are unique. Converting a list to a set removes duplicates.\nDue to the uniqueness of elements, Python can keep track of the positions of different elements. Membership tests are therefore highly optimized compared to performing them with a list.\n\n\n\n\n\nQuerying a Dictionary\nGiven the dictionary defined in the cell below.\nDisplay using print operations:\n\nthe list of class names\nMiranda’s history grade\nthe list of grades obtained by Hypolyte\nthe list of student names in 6emeB\nthe list of subjects taught in 6emeA\nthe list of all subjects taught\nthe list of grades obtained by girls in both classes\n\n\nresults = {\n    \"6emeA\": {\"Miranda\" : {\"grades\": {\"physics\": 16, \"history\": 12}},\n              \"Celestin\": {\"grades\": {\"physics\": \"absent\", \"history\": 18}}\n             },\n    \"6emeB\": {\"Hypolyte\": {\"grades\": {\"math\": 11, \"english\": 0}},\n              \"Josephine\": {\"grades\": {\"math\": 16, \"english\": 20}}\n             }\n}\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nprint(list(results.keys()))\n\nprint(results[\"6emeA\"][\"Miranda\"][\"grades\"][\"history\"])\n\nprint(list(results[\"6emeB\"][\"Hypolyte\"][\"grades\"].values()))\n\nprint(list(results[\"6emeB\"].keys()))\n\nprint(list(results[\"6emeA\"][\"Miranda\"][\"grades\"].keys()))\n\nprint(list(results[\"6emeA\"][\"Miranda\"][\"grades\"].keys()) \n      + list(results[\"6emeB\"][\"Josephine\"][\"grades\"].keys()))\n\nprint(list(results[\"6emeA\"][\"Miranda\"][\"grades\"].values()) \n      + list(results[\"6emeB\"][\"Josephine\"][\"grades\"].values()))\n\n['6emeA', '6emeB']\n12\n[11, 0]\n['Hypolyte', 'Josephine']\n['physics', 'history']\n['physics', 'history', 'math', 'english']\n[16, 12, 16, 20]\n\n\n\n\n\n\nDictionary Length\nIn previous tutorials, we saw the len function, which counts the number of elements in a sequence. Does this function work with dictionaries? What does it count?\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nresume = {\n    \"marc\": {\"position\": \"manager\", \"experience\": 7, \"hobbies\": [\"sewing\", \"frisbee\"]},\n    \"miranda\": {\"position\": \"engineer\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(len(resume))\nprint(len(resume[\"marc\"]))\n\n2\n3\n\n\nThe len function applied to a dictionary counts the number of keys.\n\n\n\n\nDeleting Dictionary Elements\nWe saw that we can delete a key from a dictionary in two different ways:\n\nwith the del operator: del my_dict[key]\nwith the pop method: my_dict.pop(key)\n\nBeyond syntax, what are the two major differences between these two ways of deleting a key from a dictionary? Feel free to experiment with examples of your choice.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ninventory = {'coffee': '500g', 'milk': '1.5L'}\n\nprint(inventory.pop('coffee'))\nprint(inventory.pop('orange', 'unavailable'))\n\n500g\nunavailable\n\n\n1st difference: when deleting an existing key with the pop method, the value associated with the key is returned. The del operation returns nothing (actually, a None object).\n2nd difference: the pop method allows specifying a default value in case the key does not exist, and thus does not return an error in this case. The del operation necessarily returns an error when the key does not exist.\n\n\n\n\nRenaming a Dictionary Key\nBy exploiting the fact that the pop method used to delete a key from a dictionary returns the value associated with that key, propose a method to rename a dictionary key in a single operation.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ninventory = {'coffee': '500g', 'milk': '1.5L'}\n\ninventory['water'] = inventory.pop('milk')\n\ninventory\n\n{'coffee': '500g', 'water': '1.5L'}\n\n\n\n\n\n\nDictionary Membership Tests\nGiven the following dictionary:\nanimals = {'cats': 5, 'dogs': 12}\nWhat will the following membership tests return? Verify your predictions.\n\n'cats' in animals.keys()\n'cats' in animals.values()\n'cats' in animals\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nanimals = {'cats': 5, 'dogs': 12}\n\nprint(animals.keys())\nprint('cats' in animals.keys()) \n# True: 'cats' is indeed in the keys of `animals`\n\nprint()\nprint(animals.values())\nprint('cats' in animals.values()) \n# False: 'cats' is not a value in `animals`\n\nprint()\nprint(animals)\nprint('cats' in animals) \n# True: this test is strictly equivalent to 'cats' in animals.keys()\n\ndict_keys(['cats', 'dogs'])\nTrue\n\ndict_values([5, 12])\nFalse\n\n{'cats': 5, 'dogs': 12}\nTrue\n\n\n\n\n\n\nDeleting a Non-Existent Key\nWe saw that the del operation returns an error when used to delete a non-existent key from a dictionary. Using your new knowledge of membership tests, can you imagine a method (without necessarily implementing it) that would handle this case without an error?\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ninventory = {'coffee': '500g', 'milk': '1.5L'}\n\nkey = 'chocolate'\n\nif key in inventory.keys():\n    del inventory[key]\n\nWe use a membership test: if the key exists in the dictionary’s keys, it is deleted. Otherwise, nothing happens. This syntax will become clearer with the next tutorial.\n\n\n\n\nDeduplication\nGiven the following string with repetitions:\nx = \"cdabcdabcdabcdabcdabcdabcdabcdabcdab\"\nConstruct a list of unique characters in this string, sorted alphabetically, i.e.:\nl = ['a', 'b', 'c', 'd']\nHint: the procedure is similar to removing duplicates from a list.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nx = \"cdabcdabcdabcdabcdabcdabcdabcdabcdab\"\nl = list(set(x))\nl.sort()\nl\n\n['a', 'b', 'c', 'd']\n\n\n\n\n\n\nIntersections and Unions of Strings\nGiven the following two strings:\ncyrano1 = 'C’est un roc ! … c’est un pic ! … c’est un cap !'\ncyrano2 = 'Que dis-je, c’est un cap ? … C’est une péninsule !'\nQuestion 1: find the characters that appear in both strings.\nQuestion 2: find the characters that appear in at least one of the two texts.\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\ncyrano1 = 'C’est un roc ! … c’est un pic ! … c’est un cap !'\ncyrano2 = 'Que dis-je, c’est un cap ? … C’est une péninsule !'\n\n# Question 1\n\ninter = list(set(cyrano1) & set(cyrano2))\nprint(inter)\n\n# Question 2\n\nunion = list(set(cyrano1) | set(cyrano2))\nprint(union)\n\n['a', 'c', 't', 'n', 'i', 'e', 's', '…', 'C', 'p', 'u', ' ', '’', '!']\n['?', ',', '…', 'é', 'o', 'c', 'a', 't', 'Q', ' ', '’', 'd', 'n', '-', 's', 'r', 'p', 'u', '!', 'l', 'i', 'e', 'C', 'j']\n\n\n\n\n\n\nThe Usefulness of Sets for Membership Tests\nThe code below generates a list with the letters a, b, c, and d repeated 1 million times. Then, it performs a membership test for a letter that does not exist in the list and calculates the time taken by the Python interpreter to perform the test.\nUsing this syntax, compare the time taken for the same membership test when the list is converted to a set beforehand.\n\nx = ['a', 'b', 'c', 'd'] * 1000000\nprint(x[:10])\n\n%time 'e' in x\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\nCPU times: user 41.8 ms, sys: 175 μs, total: 42 ms\nWall time: 41.8 ms\n\n\nFalse\n\n\n\n# Test your answer in this cell\n\n\n\n\nShow the solution\n\n\nx = ['a', 'b', 'c', 'd'] * 1000000\nprint(x[:10])\n\nx_set = set(x)\nprint(x_set)\n\n%time 'e' in x\n%time 'e' in x_set\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n{'c', 'd', 'a', 'b'}\nCPU times: user 41.3 ms, sys: 0 ns, total: 41.3 ms\nWall time: 41.2 ms\nCPU times: user 3 μs, sys: 0 ns, total: 3 μs\nWall time: 4.77 μs\n\n\nFalse\n\n\nThe initial membership test is measured in milliseconds. The one performed on the set is measured in microseconds. The test is much faster when converted to a set beforehand.",
    "crumbs": [
      "Fundamentals",
      "Data structures 2: dictionaries and sets"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html",
    "href": "source/fundamentals/tests/tutorial.html",
    "title": "Conditionals",
    "section": "",
    "text": "In the previous tutorial, we mentioned – without detailing – the notion of conditional statements, through the example of membership tests. Now, we will delve into the details of how conditions work in Python. They are a major step in creating programs that automate operations since they allow you to execute or not execute code based on certain conditions. They enable the computer to make decisions based on criteria set by the user.",
    "crumbs": [
      "Fundamentals",
      "Tests and conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#the-boolean-type",
    "href": "source/fundamentals/tests/tutorial.html#the-boolean-type",
    "title": "Conditionals",
    "section": "The boolean type",
    "text": "The boolean type\nIn its simplest form, a test in Python is an expression that evaluates to “true” or “false.” For example, the expression \\(3 &gt; 2\\) is true, so the associated test will return “true.” For this type of evaluation, Python has a particular type of object: booleans. Unlike the object types we have seen (int, float, str, etc.), booleans can only take two values: True and False.\n\ntype(True)\n\nbool\n\n\nLike any object, booleans can be assigned to variables.\n\na = False\nprint(a)\nprint(type(a))\n\nFalse\n&lt;class 'bool'&gt;\n\n\nThe values True and False must be written precisely this way (first letter capitalized, no quotes). They also cannot be used as variable names to avoid ambiguities.\n\na = true  # Python will look for the variable `true`, but it doesn't exist\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[51], line 1\n----&gt; 1 a = true  # Python will look for the variable `true`, but it doesn't exist\n\nNameError: name 'true' is not defined\n\n\n\n\nTrue = 3\n\n\n  Cell In[52], line 1\n    True = 3\n    ^\nSyntaxError: cannot assign to True",
    "crumbs": [
      "Fundamentals",
      "Tests and conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#comparison-operators",
    "href": "source/fundamentals/tests/tutorial.html#comparison-operators",
    "title": "Conditionals",
    "section": "Comparison operators",
    "text": "Comparison operators\nComparison operators formalize mathematical comparison operations (equality, inequality, inequalities). They compare two values and return a boolean value.\nOperator | Meaning |\n| |\n== | Equal to |\n!= | Not equal to |\n&lt; | Less than |\n&gt; | Greater than |\n&lt;= | Less than or equal to |\n&gt;= | Greater than or equal to |\nLet’s illustrate these operators with a few examples.\n\n3 == 3\n\nTrue\n\n\n\n63 == 36\n\nFalse\n\n\n\n2 != 3\n\nTrue\n\n\n\n2 != 2\n\nFalse\n\n\n\n3 &gt; 2\n\nTrue\n\n\n\na = 36\na &lt;= a\n\nTrue\n\n\n\na &lt; a\n\nFalse\n\n\nEverything seems to work correctly for usual mathematical operations. But these operators actually work on any type of object.\n\n'do re mi fa sol' == 'do re mi fa sol'\n\nTrue\n\n\n\n'do re mi fa sol' == 'Do Re Mi Fa Sol'\n\nFalse\n\n\n\n'duck' != 'bee'\n\nTrue\n\n\n\nTrue == True\n\nTrue\n\n\n\nTrue == False\n\nFalse\n\n\n\n[1, 2, 3] == [1, 2, 3]\n\nTrue\n\n\n\n[1, 2] != [3, 4]\n\nTrue\n\n\nFinally, it is possible to chain comparisons. The expression returns True provided that each of the comparisons is true.\n\n5 &lt; 7 &lt;= 8\n\nTrue\n\n\n\n5 &lt; 7 &lt;= 6\n\nFalse",
    "crumbs": [
      "Fundamentals",
      "Tests and conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#boolean-operators",
    "href": "source/fundamentals/tests/tutorial.html#boolean-operators",
    "title": "Conditionals",
    "section": "Boolean operators",
    "text": "Boolean operators\nBoolean operators allow simultaneous testing of multiple logical expressions. Fundamentally, these operators take two boolean values as input and return a single boolean value according to fixed logic rules. These rules are stated in truth tables.\n\nand operator\nThe first boolean operator is and. Let’s look at its truth table:\nExpression | Evaluation |\n| |\nTrue and True | True |\nTrue and False | False |\nFalse and True | False |\nFalse and False | False |\nLet’s verify these rules in practice with a few examples.\n\nTrue and True\n\nTrue\n\n\n\nFalse and True\n\nFalse\n\n\nThe rules seem to work on boolean values. Of course, in practice, we are more interested in evaluating real logical expressions. We can use these operators to test expressions that return a boolean value.\n\n(3 &gt; 2) and (5 &lt;= 9)\n\nTrue\n\n\n\na = (\"x\" != \"z\")\nb = (\"x\" == \"y\")\na and b\n\nFalse\n\n\nNote the use of parentheses to delimit the tests: they are not mandatory but are strongly recommended as they greatly improve the readability of tests.\n\n\nor operator\nThe second boolean operator is or. Its truth table is as follows:\nExpression | Evaluation |\n| |\nTrue or True | True |\nTrue or False | True |\nFalse or True | True |\nFalse or False | False |\n\nTrue or True\n\nTrue\n\n\n\nFalse or True\n\nTrue\n\n\n\n(3 &gt; 2) or (5 &lt;= 9)\n\nTrue\n\n\n\na = (\"x\" != \"z\")\nb = (\"x\" == \"y\")\na or b\n\nTrue\n\n\n\n\nnot operator\nThe last boolean operator is not. Its truth table is as follows:\n\n\n\nExpression\nEvaluation\n\n\n\n\nnot True\nFalse\n\n\nnot False\nTrue\n\n\n\n\nnot True\n\nFalse\n\n\n\nnot False\n\nTrue\n\n\n\nnot (3 + 3 == 6)\n\nFalse\n\n\n\nnot (7 &lt; 7)\n\nTrue",
    "crumbs": [
      "Fundamentals",
      "Tests and conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#conditional-structures",
    "href": "source/fundamentals/tests/tutorial.html#conditional-structures",
    "title": "Conditionals",
    "section": "Conditional structures",
    "text": "Conditional structures\nAll the expressions we have seen so far are boolean expressions: a test is performed, and the operation returns True or False depending on whether the evaluated expression is true or not. In the context of a computer program that automates operations, we want to use them as conditions: if the expression is true, then the computer must perform a certain operation. Conditional structures allow precisely this usage.\nLet’s illustrate this principle by implementing the following program:\n\nDefine a variable x.\nIf x is greater than \\(5\\), then print “The expression is true.”\nOtherwise, print “The expression is false.”\n\nVary the value of x to verify the correct operation of the test.\n\nx = 7\n\nif x &gt;= 5:\n    print(\"The expression is true.\")\nelse:\n    print(\"The expression is false.\")\n\nThe expression is true.\n\n\n\nInstruction blocks and indentation\nThe previous example illustrates the syntax of conditional structures in Python. These structures are based on instruction blocks, which delimit the set of instructions to be executed when a test is true. Conditional structures have three rules:\n\nThe line specifying the test ends with :.\nAll instructions that must be executed if the test is true are at the same level of indentation.\nThe conditional structure ends when the indentation returns to its original level.\n\nNote that conditional structures can indeed be nested, as illustrated in the following example.\n\nx = 7\n\nif x &gt;= 5:\n    print(\"The first expression is true.\")\n    if x &gt;= 12:\n        print(\"The second expression is true.\")\n\nThe first expression is true.\n\n\nWhen x = 7, the first test returns True, so the instruction block at indentation level 1 is executed line by line. The second test returns False, so the instruction block at indentation level 2 is not executed.\nVary the value of x so that both blocks are executed.\n\n\nif, else, and elif statements\nIn conditional structures, tests can be specified using three statements: if, else, and elif. The previous examples have already illustrated the operation of the first two (and most frequent) statements.\nIn the case of a simple test (a single condition), only an if statement will be used, whose operation is simple: if the condition (test) returns True, then the instruction block (indented) that follows is executed. If the condition returns False, nothing happens. Let’s illustrate this with a membership test, for which we have seen examples in the previous tutorial.\n\nclient = \"Isidore\"\n\nif client in [\"Alexandrine\", \"Achille\", \"Colette\"]:\n    print(\"Known client.\")\n\nIn practice, we often want to specify an alternative when the condition of the if statement returns False. The else statement allows specifying an alternative instruction block.\n\nclient = \"Isidore\"\n\nif client in [\"Alexandrine\", \"Achille\", \"Colette\"]:\n    print(\"Known client.\")\nelse:\n    print(\"Unknown client.\")\n\nUnknown client.\n\n\nFinally, we may want to specify multiple alternatives. In this case, we will use elif statements. The first elif statement will only execute if the test of the if statement returns False. The second elif statement will only execute if the test of the first elif statement returns False, and so on. Again, a final else statement can be specified, which only executes if none of the previous tests returned True.\n\nclient = \"Isidore\"\n\nif client == \"Alexandrine\":\n    print(\"Hello Alexandrine.\")\nelif client == \"Achille\":\n    print(\"Hello Achille.\")\nelif client == \"Colette\":\n    print(\"Hello Colette.\")\nelse:\n    print(\"Hello dear unknown.\")\n\nHello dear unknown.\n\n\nNB: The previous instructions are for example purposes only. In practice, there are much more concise ways to code a program that performs the same operations.",
    "crumbs": [
      "Fundamentals",
      "Tests and conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#exercises",
    "href": "source/fundamentals/tests/tutorial.html#exercises",
    "title": "Conditionals",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension questions\n\n1/ What is the particularity of booleans compared to other basic object types in Python?\n2/ What are the inputs and outputs of a comparison operator?\n3/ What types of objects can be compared using a comparison operator?\n4/ What is the difference between the = operator and the == operator?\n5/ What are the inputs and outputs of a boolean operator?\n6/ Explain in English the principle of the and boolean operator. Same for or and not.\n7/ What is the difference between a boolean expression and a condition?\n8/ What is the structure of a conditional statement?\n9/ Can conditional statements be nested?\n10/ Among the if, else, and elif statements, which ones are mandatory and which ones are optional?\n\n\n\n\nShow solution\n\n1/ They have only two values: True and False. Other types have an infinite number of possible values.\n2/ Inputs: two values. Output: boolean value.\n3/ All types of objects. In practice, however, it often does not make much sense to compare objects of different types; the result will generally be False.\n4/ The = operator assigns a value to a variable. The == operator tests the equality of two objects.\n5/ Inputs: two boolean values or two expressions that return booleans. Output: boolean value.\n6/ The and operator returns True if both of its inputs are True, and False in all other cases. The or operator returns True if at least one of its inputs is True, and False if both are False. The not operator returns False if its input is True, and True otherwise.\n7/ In both cases, they are tests. A condition is when the expressions are used within conditional structures.\n8/ The conditional statement starts with an if, else, or elif statement, ending with :. Then comes an indented instruction block that only executes if the statement is True. The block ends when the indentation returns to its original level.\n9/ Yes, conditional statements can be nested indefinitely (in theory). Just be careful to respect the levels of indentation.\n10/ Only the if statement is mandatory.\n\n\n\n\nPredicting test results\nPredict the results of the following tests and verify your predictions:\n\n'Simon' in ['simon', 'oceane', 'veronique']\n[1, 2, 3] == ['1', '2', '3']\n'x' != 'x'\n(9 &gt; 5) and (3 == 5)\n(3 &gt; 2 and 5 &gt;= 1) or (5 &lt;= 9 and 6 &gt; 12)\nnot (9 &gt; 2*3)\nnot (9 &gt; (2*3))\nnot ((7 &gt; 8) or (5 &lt;= 5))\n(True and True) or (True == False)\n(not False) or (not True)\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\n'Simon' in ['simon', 'oceane', 'veronique'] : False\n[1, 2, 3] == ['1', '2', '3'] : False\n'x' != 'x' : False\n(9 &gt; 5) and (3 == 5) : False\n(3 &gt; 2 and 5 &gt;= 1) or (5 &lt;= 9 and 6 &gt; 12) : True\nnot (9 &gt; 2*3) : False\nnot (9 &gt; (2*3)) : False\nnot ((7 &gt; 8) or (5 &lt;= 5)) : False\n(True and True) or (True == False) : True\n(not False) or (not True) : True\n\n\n\n\n\nPredicting nested test results\nConsider the program written in the following cell.\n\nx = 10\n\nif True:\n    print(\"Initialization.\")\n    l = []\n    if x &gt; 8:\n        l.append(\"a\")\n    elif x &gt;= 2:\n        l.append(\"b\")\n    else:\n        l.append(\"c\")\n    if x - 6 &lt; 0:\n        print(\"Negative.\")\n        \nprint(l)\n\nInitialization.\n['a']\n\n\nFor the following values:\n\nx = 1\nx = 5\nx = 10\n\npredict the program’s results:\n\nWhat is l at the end of the program?\nWhat is printed in the console during the program?\n\nVerify your results.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nx = 1 : l = ['c'] and messages printed: ‘Initialization’ and ‘Negative’\nx = 5 : l = ['b'] and messages printed: ‘Initialization’ and ‘Negative’\nx = 10 : l = ['a'] and messages printed: ‘Initialization’\n\n\n\n\n\nThree and no more\nWrite a program that performs the following operations:\n\nDefine a list that contains 4 names.\nWrite a test that prints the message (‘Too many people.’) if the list contains more than three people.\nRemove a person from the list (using the del function or the pop method seen in a previous tutorial).\nPerform the test again, there should be no output.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\npeople = [\"Romuald\", \"Ursula\", \"Jean-Vincent\", \"Philomène\"]\n\nif len(people) &gt; 3:\n    print('Too many people.')\n\nprint(people)    \npeople.remove(\"Jean-Vincent\")\nprint(people)\n\nif len(people) &gt; 3:\n    print('Too many people.')\n\nToo many people.\n['Romuald', 'Ursula', 'Jean-Vincent', 'Philomène']\n['Romuald', 'Ursula', 'Philomène']\n\n\n\n\n\n\nThe price is right\nThe input function allows the user to enter a value in a Python program. The syntax is as follows: x = input(). When this command is executed, the user must enter a value, which is then assigned to the variable x.\nUsing input and the if, elif, and else statements, code the following program:\n\nAsk the user for a value, which will be stored in a variable p.\nIf p is strictly less than $15, print the message “too low!”.\nIf p is strictly greater than $15, print the message “too high!”.\nIf p is equal to $15, print the message “right on!”.\n\nNote, input returns a string by default. Therefore, you need to convert the value of p to an integer (using the int function) for the game to work.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\np = input()\np = int(p)\n\nif p &lt; 15:\n    print(\"too low!\")\nelif p &gt; 15:\n    print(\"too high!\")\nelse:\n    print(\"right on!\")\n\n\n---------------------------------------------------------------------------\nStdinNotImplementedError                  Traceback (most recent call last)\nCell In[92], line 1\n----&gt; 1 p = input()\n      2 p = int(p)\n      4 if p &lt; 15:\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/ipykernel/kernelbase.py:1281, in Kernel.raw_input(self, prompt)\n   1279 if not self._allow_stdin:\n   1280     msg = \"raw_input was called, but this frontend does not support input requests.\"\n-&gt; 1281     raise StdinNotImplementedError(msg)\n   1282 return self._input_request(\n   1283     str(prompt),\n   1284     self._parent_ident[\"shell\"],\n   1285     self.get_parent(\"shell\"),\n   1286     password=False,\n   1287 )\n\nStdinNotImplementedError: raw_input was called, but this frontend does not support input requests.\n\n\n\n\n\n\n\nBoolean evaluation of various objects\nIn Python, all objects evaluate to True or False in a conditional test (if/else). The general rule is that objects that are zero or empty (e.g., an empty list, an empty dictionary) evaluate to False, and vice versa. But there is no need to know these rules by heart: they can be easily found in practice! For example, you can use the following conditional test:\n\nif \"test\":\n    print(\"True.\")\nelse:\n    print(\"False.\")\n\nTrue.\n\n\nPredict which boolean value the following objects will evaluate to, and verify using the previous syntax.\n\n0\n1\n12\n-1\n’’ (empty string)\n’ ’ (string containing only a space)\n[] (empty list)\n[''] (list containing only an empty string)\n{}\n{-1}\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\n0 : False\n1 : True\n12 : True\n-1: True\n'' (empty string): False\n' ' (string containing only a space): True\n[] (empty list): False\n[''] (list containing only an empty string): True\n{}: False\n{-1}: True\n\n\n\n\n\nChained comparisons\nWe have seen that it is possible to perform chained comparisons, which return True provided that each of the included comparisons is true. Find a way to rewrite the following chained comparison using boolean operators.\n5 &lt; 7 &lt;= 8 &lt; 18\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(5 &lt; 7 &lt;= 8 &lt; 18)\n\nprint(5 &lt; 7 and 7 &lt;= 8 and 8 &lt; 18)\n\nTrue\nTrue\n\n\nA chained comparison can be rewritten with and operators. It makes sense: each comparison must be true for the whole to be true. In practice, the version with and is probably preferable for readability.\n\n\n\n\nBooleans and binary language\nBooleans are strongly linked to binary language, where `1\ncorresponds to \"true\" and0` to “false.” Let’s see if this link exists in the context of Python. To do this:\n\nCalculate the “integer representation” of the boolean value of your choice using the int function.\nUse booleans in the context of mathematical calculations to verify their behavior in this context.\n\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(int(True))  \n\n1\n\n\nA boolean evaluated as an integer indeed gives the associated binary value.\n\nprint(True + 3)  \n\n4\n\n\nBooleans behave like their associated integer value in calculations.\n\n\n\n\nString comparisons\nWhat do inequality comparison tests applied to strings return? Produce some examples to test the behavior.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\nprint(\"a\" &gt; \"b\")\nprint(\"a\" &lt; \"b\")\nprint(\"apricot\" &gt; \"avocado\")\nprint(\"apricot\" &lt; \"avocado\")\nprint(\"1\" &gt; \"2\")\nprint(\"1\" &lt; \"2\")\nprint(\"A1\" &lt; \"A2\")\n\nFalse\nTrue\nFalse\nTrue\nFalse\nTrue\nTrue\n\n\n\n\nThe order relation used is alphanumeric order: each character is taken individually, and the orders are A &lt; Z and 1 &lt; 9.\n\n\nEquality tests on floats\nEquality tests between real numbers (type float in Python) can be misleading. To convince yourself, perform the following test: (6 - 5.8) == 0.2\nTo understand the test result, perform the calculation of the left-hand side of the test alone. What do you notice?\nImagine (without necessarily implementing it) another test, based on inequalities, that would allow testing approximate equality.\n\n# Test your answer in this cell\n\n\n\n\nShow solution\n\n\ndiff = 3 - 2.7\n\nprint(diff == 0.3)\n\nprint(diff)\n\nFalse\n0.2999999999999998\n\n\nIn Python, floating-point numbers are always approximate values. We can therefore have such surprises in calculations.\n\ntolerance = 0.0001\nnew_test = (0.3 - tolerance) &lt; diff &lt; (0.3 + tolerance)\nprint(new_test)\n\nTrue\n\n\nThis last test allows testing the equality between diff and 0.3 approximately, allowing for some tolerance in the comparison.",
    "crumbs": [
      "Fundamentals",
      "Tests and conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html",
    "href": "source/fundamentals/types-variables/tutorial.html",
    "title": "Basic types and variables",
    "section": "",
    "text": "In this first practical session, we will discover the most fundamental objects in Python: numbers and strings. We will also see how we can assign objects to variables to perform operations with these objects.",
    "crumbs": [
      "Fundamentals",
      "Basic types and variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#numbers",
    "href": "source/fundamentals/types-variables/tutorial.html#numbers",
    "title": "Basic types and variables",
    "section": "Numbers",
    "text": "Numbers\n\nTypes of numbers\nPython offers different types of numerical objects. In this tutorial, we will focus on the two most commonly used types:\n\nintegers (type int for integer)\nfloating-point numbers (type float for decimal numbers)\n\nIn general, we use the type function to print the type of a Python object.\n\ntype(3)\n\nint\n\n\n\ntype(3.14)\n\nfloat\n\n\nThe float and int functions can be used to convert from one type to another.\n\n# Convert to float\nfloat(3)\n\n3.0\n\n\n\n# Convert to float\ntype(float(3))\n\nfloat\n\n\n\n# Convert to int\nint(3.79)\n\n3\n\n\nBe cautious with float to int conversion, which truncates the decimal part.\nFloats can also be written in scientific notation:\n\n2e3\n\n2000.0\n\n\n\ntype(2e3)\n\nfloat\n\n\n\n\nBasic arithmetic operations\n\n# Addition\n8 + 9\n\n17\n\n\n\n# Subtraction\n5 - 2\n\n3\n\n\n\n# Multiplication\n2 * 6\n\n12\n\n\n\n# Division\n9 / 4\n\n2.25\n\n\n\n# Division by 0\n3 / 0\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[78], line 2\n      1 # Division by 0\n----&gt; 2 3 / 0\n\nZeroDivisionError: division by zero\n\n\n\nDivision by 0 produces an error. This was, of course, predictable. But it is not uncommon to have such errors in statistical calculations, especially with NumPy or Pandas, producing a similar error that needs to be debugged.\n\n\n\n\n\n\nDebugging an error\n\n\n\nCode errors are a necessary and actually essential part of learning a language: debugging the errors our code produces helps us learn to avoid them in the future! To do this, it is necessary to understand them well in the first place.\nThe error above, related to division by 0, produced a Traceback, i.e., a detailed log indicating at which step of the various operations performed by Python the error occurred, as well as the name of the error (ZeroDivisionError) and a description (“division by zero”). In this case, the error is simple, so the message allows us to understand the problem directly. For more complicated operations, the names and messages may be less obvious… but still useful to understand the source of the error - by indicating them in a search engine, for example.\n\n\n\n# Euclidean division: quotient\n9 // 4\n\n2\n\n\n\n# Euclidean division: remainder\n9 % 4\n\n1\n\n\n\n# Power\n2 ** 5\n\n32\n\n\n\n# Square root\n5 ** 0.5\n\n2.23606797749979\n\n\n\n# Order of operations: usual convention\n2 + 5 * (10 - 4)\n\n32",
    "crumbs": [
      "Fundamentals",
      "Basic types and variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#strings",
    "href": "source/fundamentals/types-variables/tutorial.html#strings",
    "title": "Basic types and variables",
    "section": "Strings",
    "text": "Strings\nStrings are used to store textual information. More precisely, they can store any character of type Unicode, which includes letters from different languages, punctuation, numbers, emojis, etc.\nA string is defined by enclosing the information in single or double quotes.\n\nDefinition\n\n# First way\n'word'\n\n'word'\n\n\n\n# Second way\n\"this also works\"\n\n'this also works'\n\n\n\n# But be careful with mixing the two!\n'it's a disaster'\n\n\n  Cell In[86], line 2\n    'it's a disaster'\n                    ^\nSyntaxError: unterminated string literal (detected at line 2)\n\n\n\n\nSyntax error: the second apostrophe is understood as the end of the string, and Python cannot interpret the rest of the sequence.\n\n\n\n\n\n\nSyntax errors and exceptions\n\n\n\nSince the beginning of the session, we have seen several errors produced by the code. In practice, it is important to distinguish between two types of errors:\n\nsyntax errors: the code does not comply with Python’s syntax rules, such as the error above. The Traceback (error message) indicates with arrows pointing upwards the line and the moment where the problem started.\nexceptions: the code is syntactically correct but produces an error during its execution, such as the division by zero performed earlier.\n\nWhy is it important to distinguish between these two types of errors? Because while incorrect syntax necessarily generates a SyntaxError and stops code execution, an exception can be handled in the code. For example, in a code where multiple divisions are performed with various parameters, one might want to ensure that a division by zero does not return an error that interrupts code execution but an arbitrary value (infinity, missing value…).\n\n\nTo avoid the syntax error, vary the characters when needed:\n\n\"it's fine\"\n\n\"it's fine\"\n\n\nSame in the reverse:\n\n'no problem with \"quotes\"'\n\n'no problem with \"quotes\"'\n\n\n\n\nThe print function\nWorking with strings is an opportunity to discover the very practical and widely used print function. It simply displays the argument passed to it within parentheses and a newline by default.\n\n# Display the string \"me\"\n\"me\"\n\n'me'\n\n\n\n# Display the string \"me\" with print\nprint(\"me\")\n\nme\n\n\nSo far, we have seen that we can simply execute a cell to display the contents of a string. But does it work with multiple strings?\n\n# Who will be displayed?\n\"me\"\n\"not me\"\n\n'not me'\n\n\nHere we see a characteristic behavior of Jupyter notebooks: only the last value returned in a cell is displayed. The print function allows us to overcome this limitation.\n\n# And this time?\nprint(\"me\")\nprint(\"me too\")\n\nme\nme too\n\n\n\n\nLength of a string\nThe len function counts the number of characters in a string, all characters included (letters, numbers, spaces, punctuation…).\n\nlen(\"I have 19 characters\")\n\n20\n\n\nThe “character” type does not exist in Python: a single character is defined as a string of length 1.\n\nprint(type(\"a\"))\nprint(len(\"a\"))\n\n&lt;class 'str'&gt;\n1\n\n\n\n\nIndexing\nIn Python, a string is a sequence, meaning a series of characters in a specific order. Therefore, each character in a string is indexed (Python knows its position), and we can use this index to extract specific characters, substrings, etc.\nIn Python, we use brackets [] to call the index of a sequence. More precisely, the index works as follows: x[a:b:c] returns a substring of the string x where a is the starting character’s position, b is the position of the ending character plus 1, and c is the indexing step. This will be clearer with the following examples.\nImportant note: indexing starts at 0 in Python.\n\n\"a sequence that we will index\"\n\n'a sequence that we will index'\n\n\n\n# First element\n\"a sequence that we will index\"[0]\n\n'a'\n\n\n\n# Second element\n\"a sequence that we will index\"[1]\n\n' '\n\n\n\n# Last element\n\"a sequence that we will index\"[-1]\n\n'x'\n\n\n\n# Extract everything from a certain character\n\"a sequence that we will index\"[4:]\n\n'quence that we will index'\n\n\n\n# Extract everything up to a certain character\n\"a sequence that we will index\"[:12]\n\n'a sequence t'\n\n\n\n# Extract a substring\n\"a sequence that we will index\"[4:12]\n\n'quence t'\n\n\n\n# Extract every 2 characters, starting from the 4th position\n\"a sequence that we will index\"[4::2]\n\n'qec htw ilidx'\n\n\n\n# Reverse a sequence\n\"a sequence that we will index\"[::-1]\n\n'xedni lliw ew taht ecneuqes a'\n\n\nTo remember: it is because a string is considered a sequence by Python that we can index it. For example, indexing a number does not make sense and therefore returns an error.\n\n2[3]\n\n&lt;&gt;:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n&lt;&gt;:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n/tmp/ipykernel_3354/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n/tmp/ipykernel_3354/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n/tmp/ipykernel_3354/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[104], line 1\n----&gt; 1 2[3]\n\nTypeError: 'int' object is not subscriptable\n\n\n\n\n\nSome useful properties\n\n# String concatenation\n\"my address is: \" + \"10 Maple Street\"\n\n'my address is: 10 Maple Street'\n\n\n\n# Repetition\n\"echo - \" * 5\n\n'echo - echo - echo - echo - echo - '\n\n\n\n\nSome useful methods\nDifferent Python objects generally have built-in methods that allow performing basic operations on the object.\nWe will see in a future chapter what methods in Python precisely consist of. For now, you can remember that methods are used in the format object.method(parameters) where the parameters are optional.\n\n# Convert to uppercase\n\"sequence 850\".upper()\n\n'SEQUENCE 850'\n\n\n\n# Convert to lowercase\n\"sequence 850\".lower()\n\n'sequence 850'\n\n\n\n# Split words by spaces\n\"a sequence    to split\".split()\n\n['a', 'sequence', 'to', 'split']\n\n\n\n# Split words by an arbitrary character\n\"useful for making sub-sequences\".split(\"-\")\n\n['useful for making sub', 'sequences']\n\n\n\n# Use strings as templates\n\"my address is: {}\".format(\"10 Maple Street\")\n\n'my address is: 10 Maple Street'\n\n\n\n\nGoing further with strings\nThis is just a glimpse of the countless operations possible on strings. The official documentation lists all the available built-in methods. The chapter exercises and the mini-projects at the end of the section will be an opportunity to discover other uses.",
    "crumbs": [
      "Fundamentals",
      "Basic types and variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#variables-1",
    "href": "source/fundamentals/types-variables/tutorial.html#variables-1",
    "title": "Basic types and variables",
    "section": "Variables",
    "text": "Variables\nSo far, we have had to define our object each time before we could apply a transformation to it. What if we want to reuse an object and apply multiple transformations to it? Or perform operations with different objects?\nTo do this, we will assign objects to variables.\n\nAssignment and operations\nAssignment is done in the format: variable_name = object. This allows us to perform operations with these variables.\n\nx = 5\nx\n\n5\n\n\n\ntype(x)\n\nint\n\n\n\nx + 5\n\n10\n\n\n\ny = x + 2*x\ny\n\n15\n\n\nUnlike other programming languages, Python is said to be dynamically typed: it is possible to reassign a variable to an object of a different type. This makes reading and developing easier, but it can sometimes create problems that are difficult to debug… Therefore, always make sure that the type of the variable is the one you think you are handling.\n\nx = 3\nx = \"blabla\"\ntype(x)\n\nstr\n\n\nNaturally, there are certain constraints on operations depending on the types of objects.\n\nx = \"test\"\ny = 3\nx + y\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[117], line 3\n      1 x = \"test\"\n      2 y = 3\n----&gt; 3 x + y\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\nHowever, it is possible to harmonize the types beforehand:\n\nx = \"test\"\ny = 3\nz = str(y)\nx + z\n\n'test3'\n\n\n\n\nIncrementation\nIt is common to use a variable as a counter, incrementing it each time a given event occurs, for example.\n\na = 0\nprint(a)\na = a +1\nprint(a)\n\n0\n1\n\n\nThis practice is so common that there are special operators for common arithmetic operations.\n\na = 0\na += 1\na\n\n1\n\n\n\nb = 5\nb *= 3\nb\n\n15",
    "crumbs": [
      "Fundamentals",
      "Basic types and variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#exercises",
    "href": "source/fundamentals/types-variables/tutorial.html#exercises",
    "title": "Basic types and variables",
    "section": "Exercises",
    "text": "Exercises\n\nComprehension questions\n\nWhat are the different basic types of Python seen in this tutorial?\nHow to convert an integer to a float and vice versa?\nHow do you define a string in Python?\nWhat is a Traceback?\nWhat is the difference between a syntax error and an exception?\nWhat is the purpose of the print function?\nHow to display multiple values in a Jupyter notebook cell?\nWhat is the purpose of the len function?\nWhat is a built-in method and how to recognize it?\nWhat are variables for?\nWhy is Python said to be “dynamically typed”?\n\n\n\n\nShow solution\n\n\n1/ The basic types in Python seen in this tutorial are numerical types, including integers (int) and floats (decimal numbers, float), and strings (str), which store textual information.\n2/ To convert an integer to a float, we use the float() function. To convert a float to an integer, we use the int() function.\n3/ A string is defined by enclosing the information in single (’) or double (“) quotes.\n4/ A Traceback is an error report that shows the sequence of operations that led to an exception. It helps identify the origin of the error in the code.\n5/ A syntax error occurs when Python code does not comply with the language’s syntax rules, making the script unexecutable. An exception is an error detected during execution, even if the code has correct syntax. Exceptions can be handled in the code, whereas syntax errors necessarily lead to code execution stopping.\n6/ The print function displays the content of the argument passed to it within parentheses on the Python console or in a Jupyter notebook cell.\n7/ By default, executing a Jupyter cell displays the last value returned by the code executed in that cell. If two lines of code return something, only the last one will be displayed. To display multiple elements in the same cell, we use the print function for each operation whose result we want to display.\n8/ The len function returns the number of elements in an object. For example, the number of characters in a string. This function only makes sense for sequence-type objects.\n9/ A built-in method is a function integrated into a Python object type that allows performing specific operations on that object. It is recognized because it is called directly on the object with the syntax object.method().\n10/ Variables are used to store values or objects to reuse and manipulate them more easily in the code. They also give a name to the data to make it more readable and easier to manipulate.\n11/ Python is said to be dynamically typed because the type of variables is determined at runtime and can change during execution. Thus, a variable initially defined as a string can become a numeric variable during code execution, which is impossible in programming languages based on static typing.\n\n\n\n\n\nDisplaying basic types\nDisplay the type of x when:\n\nx = 3\nx = “test”\nx = 3.5\n\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\nx = 3\nprint(type(x))\n\nx = \"test\"\nprint(type(x))\n\nx = 3.5\nprint(type(x))\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n&lt;class 'float'&gt;\n\n\n\n\n\n\nString lengths\nCalculate the sum of the lengths of the following three strings:\n\n“a first string”\n“and a second”\n“never two without three”\n\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\na = \"a first string\"\nb = \"and a second\"\nc = \"never two without three\"\n\nlen(a) + len(b) + len(c)\n\n49\n\n\n\n\n\n\nFormatting postal codes\nWhat is the appropriate type to define a postal code?\nTry defining the following postal codes in both int and string format:\n\n92120\n02350\n\nWhat do you conclude?\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\ncp1_int = 92120\ncp1_str = \"92120\"\n\nprint(cp1_int, cp1_str) # No problem\n\ncp2_int = 02350 \n\n\n  Cell In[127], line 6\n    cp2_int = 02350\n              ^\nSyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers\n\n\n\n\nError: Python does not accept defining an integer that starts with a 0. Postal codes must therefore be defined as strings.\n\n\n\n\nCounting letters\nCount the number of times the letter e appears in the following string: “I am counting the e’s.”\nHint: you can use the built-in method count.\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\na = \"I am counting the e's.\"\na.count('e')\n\n2\n\n\n\n\n\n\nDetecting letters\nFind the first position where the letter e appears in the following string: “I am counting the e’s.”\nHint: you can use the built-in method find.\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\na = \"I am counting the e's.\"\na.find('e')\n\n16\n\n\n\n\n\n\nRemoving spaces in a string\nRemove the extra spaces at the beginning and end of the following string:\nHint: you can use the built-in method strip.\n\n# Type your answer in this cell\na = \"    A poorly formatted string.         \"\n\n\n\n\nShow solution\n\n\na = \"    A poorly formatted string.         \"\na.strip()\n\n'A poorly formatted string.'\n\n\n\n\n\n\nEscaping characters\nThe \\ character allows escaping (neutralizing) a special character within a string. Find how this character solves the problem of using quotes (or apostrophes) within a string defined by quotes (apostrophes).\nHint: examples of usage are available in the official documentation.\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\n\"just a \\\"small\\\" test\"\n\n'just a \"small\" test'\n\n\n\n\n\n\nA first algorithm\nPerform the following sequence of operations using increment operators, and print the final value:\n\ninitialize a variable to 1\nsubtract 5 from it\nmultiply it by 4\nadd 22 to it\n\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\na = 1\na -= 5\na *= 4\na += 22\nprint(a)\n\n6\n\n\n\n\n\n\nComposing strings\nConsider the following two sequences:\n\n“we are in”\n“2024”\n\nFind two different ways from the tutorial to compose the sequence “we are in 2024”.\nHint: one of the two methods involves modifying (slightly) one of the two sequences.\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\n\na1 = \"we are in\"\na2 = \"we are in {}\"\nb = \"2024\"\n\nprint(a1 + \" \" + b)\nprint(a2.format(b))\n\nwe are in 2024\nwe are in 2024\n\n\n\n\n\n\nf-strings\nf-strings are a somewhat special but very practical form of strings, added in Python version 3.6. To understand their interest, let’s go back to the solution of the previous exercise, which illustrated two ways to compose the string “we are in 2024”.\n\na1 = \"we are in\"\na2 = \"we are in {}\"\nb = \"2024\"\n\nprint(a1 + \" \" + b)\nprint(a2.format(b))\n\nwe are in 2024\nwe are in 2024\n\n\nThese two methods work but have limitations. Think about what would happen in the following cases, and feel free to run tests to convince yourself:\n\nif you want to inject a variable that is not a string using the format() method (e.g., if “2024” were an integer and not a string)?\nif you want to concatenate several strings together?\nif you want to concatenate several strings together and also inject the values of other variables in each part?\n\nUsing the official documentation as inspiration, use f-strings to solve these various problems.\n\n# Type your answer in this cell\n\n\n\n\nShow solution\n\nFirst problem: composing strings with numeric values.\n\na1 = \"we are in\"\nb = 2024\n\n# print(a1 + \" \" + b)  # Error\nprint(a1 + \" \" + str(b))\n\nwe are in 2024\n\n\nDirect concatenation returns an error -&gt; you must convert the numeric value to a string first.\nSecond problem: juxtaposition of multiple strings.\n\na = \"we are in\"\nb = \"2024\"\nc = \"and my name is\"\nd = \"Miranda\"\n\nprint(a + \" \" + b + \" \" + c + \" \" + d)\n\nwe are in 2024 and my name is Miranda\n\n\nThe syntax quickly becomes unreadable, as you must manually add separators (space) between each part.\nThird problem: composing strings with variable injection.\n\na = \"we are in {}\"\nb = \"2024\"\nc = \"and my name is {}\"\nd = \"Miranda\"\n\nprint(a.format(b) + \" \" + c.format(d))\n\nwe are in 2024 and my name is Miranda\n\n\nThe syntax remains unreadable, as you must inject values into each string.\nSolution: using f-strings.\n\nyear = 2024\nname = \"Miranda\"\n\nprint(f\"we are in {year} and my name is {name}\")\n\nwe are in 2024 and my name is Miranda\n\n\nMuch more readable!",
    "crumbs": [
      "Fundamentals",
      "Basic types and variables"
    ]
  }
]