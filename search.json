[
  {
    "objectID": "source/manipulation/pandas/tutorial.html",
    "href": "source/manipulation/pandas/tutorial.html",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "L’analyse statistique a généralement pour base des données tabulaires, dans lesquelles chaque ligne représente une observation et chaque colonne une variable. Pour traiter ce type de données et y appliquer facilement les méthodes d’analyse de données standards, des objets dédiés ont été conçus : les DataFrames. Les utilisateurs de R connaissent bien cette structure de données, qui est native à ce langage orienté statistique. En Python, langage généraliste, cet objet n’existe pas nativement. Heureusement, une librairie très complete et bien pratique, pensée comme une surcouche à NumPy, introduit en Python l’objet DataFrame et permet la manipulation et l’analyse de données de manière simple et intuitive : Pandas.\n\n\n\n\n\n\nNote\n\n\n\nPandas étant l’élément central de l’éco-système data science en Python, il offre des possibilités de traitement de la donnée quasi-infinies. En plus de ça, il existe généralement de multiples manières de réaliser une même opération en Pandas. En conséquence, ce chapitre est particulièrement long et dense en nouvelles fonctionnalités. L’objectif n’est pas de retenir toutes les méthodes présentées tout au long de ce chapitre, mais plutôt d’avoir une vision générale de ce qu’il est possible de faire afin de pouvoir mobiliser les bons outils dans les projets. En particulier, les exercices de fin de chapitre et les mini-projets de fin de formation seront l’occasion d’appliquer ces nouvelles connaissances à des problématiques concrètes.\n\n\nOn commence par importer la librairie Pandas. L’usage est courant est de lui attribuer l’alias pd afin de simplifier les futurs appels aux objets et fonctions du package. On importe également NumPy car on va comparer les objets fondamentaux des deux packages.\n\nimport pandas as pd\nimport numpy as np\n\n\n\nPour bien comprendre le fonctionnement de Pandas, il faut s’intéresser à ses objets fondamentaux. On va donc d’abord étudier les Series, dont la concaténation permet de construire un DataFrame.\n\n\nUne Series est un conteneur de données unidimensionnel pouvant accueillir n’importe quel type de données (entiers, strings, objets Python…). Une Series est néanmoins d’un type donné : une Series ne contenant que des entiers sera de type int, et une Series contenant des objets de différente nature sera de type object. Construisons notre première Series à partir d’une liste pour vérifier ce comportement.\n\nl = [1, \"X\", 3]\ns = pd.Series(l)\nprint(s)\n\n0    1\n1    X\n2    3\ndtype: object\n\n\nOn peut notamment accéder aux données d’une Series par position, comme pour une liste ou un array.\n\nprint(s[1])\n\nX\n\n\nA priori, on ne voit pas beaucoup de différence entre une Series et un array NumPy à 1 dimension. Pourtant, il existe une différence de taille qui est la présence d’un index : les observations ont un label associé. Lorsqu’on crée une Series sans rien spécifier, l’index est automatiquement fixé aux entiers de 0 à n-1 (avec n le nombre d’éléments de la Series). Mais il est possible de passer un index spécifique (ex : des dates, des noms de communes, etc.).\n\ns = pd.Series(l, index=[\"a\", \"b\", \"c\"])\nprint(s)\n\na    1\nb    X\nc    3\ndtype: object\n\n\nCe qui permet d’accéder aux données par label :\n\ns[\"b\"]\n\n'X'\n\n\nCette différence apparaît secondaire à première vue, mais deviendra essentielle pour la construction du DataFrame. Pour le reste, les Series se comportent de manière très proche des arrays NumPy : les calculs sont vectorisés, on peut directement faire la somme de deux Series, etc. D’ailleurs, on peut très facilement convertir une Series en array via l’attribut values. Ce qui, naturellement, fait perdre l’index…\n\ns = pd.Series(l, index=[\"a\", \"b\", \"c\"])\ns.values\n\narray([1, 'X', 3], dtype=object)\n\n\n\n\n\nFondamentalement, un DataFrame consiste en une collection de Series, alignées par les index. Cette concaténation construit donc une table de données, dont les Series correspondent aux colonnes, et dont l’index identifie les lignes. La figure suivante (source) permet de bien comprendre cette structure de données.\n\n\n\n\n\nUn DataFrame peut être construit de multiples manières. En pratique, on construit généralement un DataFrame directement à partir de fichiers de données tabulaires (ex : CSV, excel), rarement à la main. On illustrera donc seulement la méthode de construction manuelle la plus usuelle : à partir d’un dictionnaire de données.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\n0\n1.3\n-2\ntest\n2022-01-01\nsample1\n\n\n1\n5.6\n2\ntrain\n2022-01-02\nsample1\n\n\n2\nNaN\n5\ntest\n2022-01-03\nsample1\n\n\n3\nNaN\n-8\ntrain\n2022-01-04\nsample1\n\n\n4\n0.0\n3\ntrain\n2022-01-05\nsample1\n\n\n5\nNaN\n2\nvalidation\n2022-01-06\nsample1\n\n\n\n\n\n\n\nUn DataFrame Pandas dispose d’un ensemble d’attributs utiles que nous allons découvrir tout au long de ce tutoriel. Pour l’instant, intéressons-nous aux plus basiques : l’index et le nom des colonnes. Par défaut, l’index est initialisé comme pour les Series à la liste des positions des observations. On aurait pu spécifier un index alternatif lors de la construction du DataFrame en spécifiant l’argument index de la fonction pd.DataFrame.\n\ndf.index\n\nRangeIndex(start=0, stop=6, step=1)\n\n\n\ndf.columns\n\nIndex(['var1', 'var2', 'experiment', 'date', 'sample'], dtype='object')\n\n\nSouvent, plutôt que de spécifier un index à la main lors de la construction du DataFrame, on va vouloir utiliser une certaine colonne du DataFrame comme index. On utilise pour cela la méthode set_index associée aux DataFrames.\n\ndf = df.set_index(\"date\")\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\nsample1\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n2022-01-04\nNaN\n-8\ntrain\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\nL’attribut index a naturellement changé :\n\ndf.index\n\nIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05',\n       '2022-01-06'],\n      dtype='object', name='date')\n\n\n\n\n\n\nLors de la manipulation des données tabulaires, il est fréquent de vouloir extraire des colonnes spécifiques d’un DataFrame. Cette extraction est simple avec Pandas grâce à l’utilisation des crochets.\n\n\n\n\nPour extraire une seule colonne, on peut utiliser la syntaxe suivante :\n\nselected_column = df[\"var1\"]\nselected_column\n\ndate\n2022-01-01    1.3\n2022-01-02    5.6\n2022-01-03    NaN\n2022-01-04    NaN\n2022-01-05    0.0\n2022-01-06    NaN\nName: var1, dtype: float64\n\n\nL’objet selected_column renvoie ici la colonne nommée var1 du DataFrame df. Mais de quel type est cet objet ? Pour répondre à cette question, on utilise la fonction type() :\n\ntype(selected_column)\n\npandas.core.series.Series\n\n\nComme on peut le voir, le résultat est une Series, qui est un objet unidimensionnel dans Pandas.\nUn autre attribut utile à connaître est shape. Il permet de connaître la dimension de l’objet. Pour une Series, shape retournera un tuple dont le premier élément indique le nombre de lignes.\n\nselected_column.shape\n\n(6,)\n\n\n\n\n\nPour extraire plusieurs colonnes, il suffit de passer une liste des noms des colonnes souhaitées :\n\nselected_columns = df[[\"var1\", \"var2\", \"experiment\"]]\nselected_columns\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\n\n\ndate\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\n\n\n2022-01-02\n5.6\n2\ntrain\n\n\n2022-01-03\nNaN\n5\ntest\n\n\n2022-01-04\nNaN\n-8\ntrain\n\n\n2022-01-05\n0.0\n3\ntrain\n\n\n2022-01-06\nNaN\n2\nvalidation\n\n\n\n\n\n\n\nCet extrait montre les colonnes var1, var2 et experiment du DataFrame df. Vérifions maintenant son type :\n\ntype(selected_columns)\n\npandas.core.frame.DataFrame\n\n\nLe résultat est un DataFrame, car il s’agit d’un objet bidimensionnel. On peut aussi vérifier sa forme avec l’attribut shape. Dans ce cas, le tuple renvoyé par shape contiendra deux éléments : le nombre de lignes et le nombre de colonnes.\n\nselected_columns.shape\n\n(6, 3)\n\n\n\n\n\n\n\n\nLorsqu’on veut sélectionner des lignes spécifiques dans un DataFrame, on peut se servir des deux principales méthodes : loc et iloc.\n\niloc permet de sélectionner des lignes et des colonnes par leur position, c’est-à-dire par des indices numériques.\n\nExemple, sélection des 3 premières lignes :\n\ndf.iloc[0:3, :]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\nsample1\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n\n\n\n\n\n\nloc quant à lui, fonctionne avec des labels. Si les index du DataFrame sont des numéros, ils ressemblent aux positions, mais ce n’est pas forcément le cas. Il est crucial de noter que, contrairement à iloc, avec loc, l’index de fin est inclus dans la sélection.\n\n\ndf.loc[\"2022-01-01\":\"2022-01-03\", :]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\nsample1\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n\n\n\n\n\n\n\n\nEn pratique, plutôt que de sélectionner des lignes basées sur des positions ou des labels, on souhaite souvent filtrer un DataFrame selon certaines conditions. Dans ce cas, on se sert principalement de filtres booléens.\n\nInégalités : On peut vouloir garder seulement les lignes qui respectent une certaine condition.\n\nExemple, filtrer les lignes où la valeur de la colonne var2 est supérieure à 0 :\n\ndf[df['var2'] &gt;= 0]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\n\nAppartenance avec isin : Si on veut filtrer les données basées sur une liste de valeurs possibles, la méthode isin est très utile.\n\nExemple, pour garder uniquement les lignes où la colonne experiment a des valeurs ‘test’ ou ‘validation’ :\n\ndf[df['experiment'].isin(['train', 'validation'])]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-04\nNaN\n-8\ntrain\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\nCes méthodes peuvent être combinées pour créer des conditions plus complexes. Il est aussi possible d’utiliser les opérateurs logiques (& pour “et”, | pour “ou”) pour combiner plusieurs conditions. Attention, il faut bien prendre soin d’encadrer chaque condition par des parenthèses lors de la combinaison.\nExemple, sélectionner les lignes où var2 est supérieur à 0 et experiment est égal à ‘test’ ou ‘validation’:\n\ndf[(df['var2'] &gt;= 0) & (df['experiment'].isin(['train', 'validation']))]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\n\n\n\n\n\nEn statistique publique, le point de départ n’est généralement pas la génération manuelle de données, mais plutôt des fichiers tabulaires préexistants. Ces fichiers, qu’ils soient issus d’enquêtes, de bases administratives ou d’autres sources, constituent la matière première pour toute analyse ultérieure. Pandas offre des outils puissants pour importer ces fichiers tabulaires et les explorer en vue de manipulations plus poussées.\n\n\n\n\nComme nous l’avons vu dans un précédent TP, le format CSV est l’un des formats les plus courants pour stocker des données tabulaires. Nous avons précédemment utilisé la librairie csv pour les manipuler comme des fichiers texte, mais ce n’était pas très pratique. Pour rappel, la syntaxe pour lire un fichier CSV et afficher les premières lignes était la suivante :\n\nimport csv\n\nrows = []\n\nwith open(\"data/departement2021.csv\") as file_in:\n    csv_reader = csv.reader(file_in)\n    for row in csv_reader:\n        rows.append(row)\n\nrows[:5]\n\n[['DEP', 'REG', 'CHEFLIEU', 'TNCC', 'NCC', 'NCCENR', 'LIBELLE'],\n ['01', '84', '01053', '5', 'AIN', 'Ain', 'Ain'],\n ['02', '32', '02408', '5', 'AISNE', 'Aisne', 'Aisne'],\n ['03', '84', '03190', '5', 'ALLIER', 'Allier', 'Allier'],\n ['04',\n  '93',\n  '04070',\n  '4',\n  'ALPES DE HAUTE PROVENCE',\n  'Alpes-de-Haute-Provence',\n  'Alpes-de-Haute-Provence']]\n\n\nAvec Pandas, il suffit d’utiliser la fonction read_csv() pour importer le fichier comme un DataFrame, puis la fonction head().\n\ndf_departements = pd.read_csv('data/departement2021.csv')\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\nIl est également possible d’importer un fichier CSV directement à partir d’une URL. C’est particulièrement pratique lorsque les données sont régulièrement mises à jour sur un site web et que l’on souhaite accéder à la version la plus récente sans avoir à télécharger manuellement le fichier à chaque fois. Prenons l’exemple d’un fichier CSV disponible sur le site de l’INSEE : le fichier des prénoms, issu des données de l’état civil. On note au passage une autre fonctionnalité bien pratique : le fichier CSV est compressé (format zip), mais Pandas est capable de le reconnaître et de le décompresser avant de l’importer.\n\n# Importer un fichier CSV depuis une URL\nurl = \"https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\"\ndf_prenoms_url = pd.read_csv(url, sep=\";\")\ndf_prenoms_url.head()\n\n\n\n\n\n\n\n\nsexe\npreusuel\nannais\nnombre\n\n\n\n\n0\n1\n_PRENOMS_RARES\n1900\n1249\n\n\n1\n1\n_PRENOMS_RARES\n1901\n1342\n\n\n2\n1\n_PRENOMS_RARES\n1902\n1330\n\n\n3\n1\n_PRENOMS_RARES\n1903\n1286\n\n\n4\n1\n_PRENOMS_RARES\n1904\n1430\n\n\n\n\n\n\n\nLorsqu’on travaille avec des fichiers CSV, il y a de nombreux arguments optionnels disponibles dans la fonction read_csv() qui permettent d’ajuster le processus d’importation en fonction des spécificités du fichier. Ces arguments peuvent notamment permettre de définir un délimiteur spécifique (comme ci-dessus pour le fichier des prénoms), de sauter certaines lignes en début de fichier, ou encore de définir les types de données pour chaque colonne, et bien d’autres. Tous ces paramètres et leur utilisation sont détaillés dans la documentation officielle.\n\n\n\nUne fois que les données ont été traitées et modifiées au sein de Pandas, il est courant de vouloir exporter le résultat sous forme de fichier CSV pour le partager, l’archiver ou l’utiliser dans d’autres outils. Pandas offre une méthode simple pour cette opération : to_csv(). Supposons par exemple que l’on souhaite exporter les données du DataFrame df_departements spécifiques aux cinq départements d’outre-mer.\n\ndf_departements_dom = df_departements[df_departements[\"DEP\"].isin([\"971\", \"972\", \"973\", \"974\", \"975\"])]\ndf_departements_dom.to_csv('output/departements2021_dom.csv')\n\nUn des arguments clés de la méthode to_csv() est index. Par défaut, index=True, ce qui signifie que l’index du DataFrame sera également écrit dans le fichier CSV. On peut le vérifier en imprimant les premières lignes de notre fichier CSV : Pandas a ajouté une colonne non-nommée, qui contient l’index des lignes retenues.\n\nwith open(\"output/departements2021_dom.csv\") as file_in:\n    for i in range(5):\n        row = next(file_in).strip()\n        print(row)\n\n,DEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n96,971,1,97105,3,GUADELOUPE,Guadeloupe,Guadeloupe\n97,972,2,97209,3,MARTINIQUE,Martinique,Martinique\n98,973,3,97302,3,GUYANE,Guyane,Guyane\n99,974,4,97411,0,LA REUNION,La Réunion,La Réunion\n\n\nDans certains cas, notamment lorsque l’index n’apporte pas d’information utile ou est simplement généré automatiquement par Pandas, on pourrait vouloir l’exclure du fichier exporté. Pour ce faire, on peut définir index=False.\n\ndf_departements_dom.to_csv('output/departements2021_dom_noindex.csv', index=False)\n\n\n\n\nLe format Parquet est un autre format pour le stockage de données tabulaires, de plus en plus fréquemment utilisé. Sans entrer dans les détails techniques, le format Parquet présente différentes caractéristiques qui en font un choix privilégié pour le stockage et le traitement de gros volumes de données. En raison de ces avantages, ce format est de plus en plus utilisé pour la mise à disposition de données à l’Insee. Il est donc essentiel de savoir importer et requêter des fichiers Parquet avec Pandas.\nImporter un fichier Parquet dans un DataFrame Pandas se fait tout aussi facilement que pour un fichier CSV. La fonction se nomme read_parquet().\n\ndf_departements = pd.read_parquet('data/departement2021.parquet')\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\n\n\nLà encore, tout se passe comme dans le monde des CSV : on utilise la méthode to_parquet() pour exporter un DataFrame dans un fichier Parquet. De même, on peut choisir d’exporter ou non l’index, à l’aide du paramètre index (qui vaut True par défaut).\n\ndf_departements_dom = df_departements[df_departements[\"DEP\"].isin([\"971\", \"972\", \"973\", \"974\", \"975\"])]\ndf_departements_dom.to_parquet('output/departements2021_dom.parquet', index=False)\n\nUne des grandes forces du format Parquet, en comparaison des formats texte comme le CSV, est sa capacité à stocker des méta-données, i.e. des données permettant de mieux comprendre les données contenues dans le fichier. En particulier, un fichier Parquet inclut dans ses méta-données le schéma des données (noms des variables, types des variables, etc.), ce qui en fait un format très adapté à la diffusion de données. Vérifions ce comportement en reprenant le DataFrame que nous avons défini précédemment.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf = df.assign(\n    experiment=pd.Categorical(df[\"experiment\"]),\n    date=pd.to_datetime(df[\"date\"])\n)\n\nOn utilise cette fois deux types de données spécifiques, pour les données catégorielles (category) et pour les données temporelles (datetime). On verra plus loin dans le tutoriel comment utiliser ces types. Pour l’instant, notons simplement que Pandas stocke ces types dans le schéma des données.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nVérifions à présent que l’export et le ré-import de ces données en Parquet préserve le schéma.\n\ndf.to_parquet(\"output/df_test_schema.parquet\", index=False)\ndf_test_schema_parquet = pd.read_parquet('output/df_test_schema.parquet')\n\ndf_test_schema_parquet.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nA l’inverse, un fichier CSV ne contenant par définition que du texte, ne permet pas de préserver ces données. Les variables dont nous avons spécifié le type sont importées comme des strings (type object en Pandas).\n\ndf.to_csv(\"output/df_test_schema.csv\", index=False)\ndf_test_schema_csv = pd.read_csv('output/df_test_schema.csv')\n\ndf_test_schema_csv.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   var1        3 non-null      float64\n 1   var2        6 non-null      int64  \n 2   experiment  6 non-null      object \n 3   date        6 non-null      object \n 4   sample      6 non-null      object \ndtypes: float64(1), int64(1), object(3)\nmemory usage: 368.0+ bytes\n\n\n\n\n\n\nLorsqu’on travaille avec des jeux de données volumineux, il est souvent utile de visualiser rapidement un échantillon des données pour avoir une idée de leur structure, de leur format ou encore pour détecter d’éventuels problèmes. Pandas offre plusieurs méthodes pour cela.\nLa méthode head() permet d’afficher les premières lignes du DataFrame. Par défaut, elle retourne les 5 premières lignes, mais on peut spécifier un autre nombre en argument si nécessaire.\n\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\ndf_departements.head(10)\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n5\n06\n93\n06088\n4\nALPES MARITIMES\nAlpes-Maritimes\nAlpes-Maritimes\n\n\n6\n07\n84\n07186\n5\nARDECHE\nArdèche\nArdèche\n\n\n7\n08\n44\n08105\n4\nARDENNES\nArdennes\nArdennes\n\n\n8\n09\n76\n09122\n5\nARIEGE\nAriège\nAriège\n\n\n9\n10\n44\n10387\n5\nAUBE\nAube\nAube\n\n\n\n\n\n\n\nÀ l’inverse, la méthode tail() donne un aperçu des dernières lignes du DataFrame.\n\ndf_departements.tail()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n96\n971\n1\n97105\n3\nGUADELOUPE\nGuadeloupe\nGuadeloupe\n\n\n97\n972\n2\n97209\n3\nMARTINIQUE\nMartinique\nMartinique\n\n\n98\n973\n3\n97302\n3\nGUYANE\nGuyane\nGuyane\n\n\n99\n974\n4\n97411\n0\nLA REUNION\nLa Réunion\nLa Réunion\n\n\n100\n976\n6\n97608\n0\nMAYOTTE\nMayotte\nMayotte\n\n\n\n\n\n\n\nL’affichage des premières ou dernières lignes peut parfois ne pas être représentatif de l’ensemble du jeu de données, lorsque les données sont triées par exemple. Afin de minimiser le risque d’obtenir un aperçu biaisé des données, on peut utiliser la méthode sample(), qui sélectionne un un échantillon aléatoire de lignes. Par défaut, elle retourne une seule ligne, mais on peut demander un nombre spécifique de lignes en utilisant l’argument n.\n\ndf_departements.sample(n=5)\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n79\n79\n75\n79191\n4\nDEUX SEVRES\nDeux-Sèvres\nDeux-Sèvres\n\n\n85\n85\n52\n85191\n3\nVENDEE\nVendée\nVendée\n\n\n88\n88\n44\n88160\n4\nVOSGES\nVosges\nVosges\n\n\n66\n66\n76\n66136\n4\nPYRENEES ORIENTALES\nPyrénées-Orientales\nPyrénées-Orientales\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\n\n\nL’une des premières étapes lors de l’exploration de nouvelles données est de comprendre la structure générale du jeu de données. La méthode info() de Pandas offre une vue d’ensemble rapide des données, notamment en termes de types de données, de présence de valeurs manquantes et de mémoire utilisée.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nPlusieurs éléments d’information clés peuvent être extraits de ce résultat :\n\nindex : le DataFrame a un RangeIndex, ce qui signifie que l’index est constitué d’une suite numérique simple. Ici, l’index va de 0 à 5, soit 6 entrées au total.\nschéma : la liste des colonnes est affichée avec des informations très utiles sur le schéma des données :\n\nNon-Null Count : le nombre de valeurs non-manquantes (non nan) dans la colonne. Si ce nombre est inférieur au nombre total d’entrées (dans notre cas, 6), cela signifie que la colonne contient des valeurs manquantes. Attention à l’ambiguité possible sur “null” : cela signifie bien les valeurs manquantes, pas les valeurs égales à 0. Ainsi, dans notre cas, le nombre de valeurs “non-null” pour la variable var1 est 5.\nDtype : Le type de données de la colonne, qui permet decomprendre la nature des informations stockées dans chaque colonne. Par exemple, float64 (nombres réels), int32 (nombres entiers), category (variable catégorielle), datetime64[ns] (information temporelle) et object (données textuelles ou mixtes).\n\n\nL’utilisation de info() est un moyen rapide et efficace d’obtenir une vue d’ensemble d’un DataFrame, d’identifier rapidement les colonnes contenant des valeurs manquantes et de comprendre la structure des données.\n\n\n\nEn complément des informations renvoyées par la méthode info(), on peut vouloir obtenir des statistiques descriptives simples afin de visualiser rapidement les distributions des variables. La méthode describe() permet d’avoir une vue synthétique de la distribution des données dans chaque colonne.\n\ndf.describe()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\ncount\n3.00000\n6.000000\n6\n\n\nmean\n2.30000\n-0.500000\n2022-01-03 12:00:00\n\n\nmin\n0.00000\n-8.000000\n2022-01-01 00:00:00\n\n\n25%\n0.65000\n-2.750000\n2022-01-02 06:00:00\n\n\n50%\n1.30000\n-1.500000\n2022-01-03 12:00:00\n\n\n75%\n3.45000\n2.000000\n2022-01-04 18:00:00\n\n\nmax\n5.60000\n8.000000\n2022-01-06 00:00:00\n\n\nstd\n2.93087\n5.468089\nNaN\n\n\n\n\n\n\n\nIl est à noter que describe() ne renvoie des statistiques que pour les colonnes numériques par défaut. Si l’on souhaite inclure des colonnes d’autres types, il est nécessaire de le préciser via l’argument include. Par exemple, df.describe(include='all') renverra des statistiques pour toutes les colonnes, y compris des métriques comme le nombre unique, la valeur la plus fréquente et la fréquence de la valeur la plus fréquente pour les colonnes non numériques.\n\ndf.describe(include='all')\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\ncount\n3.00000\n6.000000\n6\n6\n6\n\n\nunique\nNaN\nNaN\n3\nNaN\n1\n\n\ntop\nNaN\nNaN\ntrain\nNaN\nsample1\n\n\nfreq\nNaN\nNaN\n3\nNaN\n6\n\n\nmean\n2.30000\n-0.500000\nNaN\n2022-01-03 12:00:00\nNaN\n\n\nmin\n0.00000\n-8.000000\nNaN\n2022-01-01 00:00:00\nNaN\n\n\n25%\n0.65000\n-2.750000\nNaN\n2022-01-02 06:00:00\nNaN\n\n\n50%\n1.30000\n-1.500000\nNaN\n2022-01-03 12:00:00\nNaN\n\n\n75%\n3.45000\n2.000000\nNaN\n2022-01-04 18:00:00\nNaN\n\n\nmax\n5.60000\n8.000000\nNaN\n2022-01-06 00:00:00\nNaN\n\n\nstd\n2.93087\n5.468089\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nNotons que, là encore, la variable count renvoie le nombre de valeurs non-manquantes dans chaque variable.\n\n\n\n\n\n\nLes opérations de transformation sur les données sont essentielles pour façonner, nettoyer et préparer les données en vue de leur analyse. Les transformations peuvent concerner l’ensemble du DataFrame, des colonnes spécifiques ou encore des lignes spécifiques.\n\n\nPour transformer un DataFrame complet (ou un sous-DataFrame), il est possible d’utiliser des fonctions vectorisées, qui permettent d’appliquer rapidement une opération à l’ensemble des éléments du DataFrame. Cela inclut un certain nombre de méthodes disponibles pour les Series, mais aussi les fonctions mathématiques de NumPy, etc.\nPar exemple, passer chaque valeur numérique d’un DataFrame à la puissance 2 :\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n    }\n)\n\ndf ** 2\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.69\n1\n\n\n1\n31.36\n64\n\n\n2\nNaN\n36\n\n\n3\nNaN\n36\n\n\n4\n0.00\n49\n\n\n5\nNaN\n36\n\n\n\n\n\n\n\nou les passer en valeur absolue :\n\nnp.abs(df)\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n8\n\n\n2\nNaN\n6\n\n\n3\nNaN\n6\n\n\n4\n0.0\n7\n\n\n5\nNaN\n6\n\n\n\n\n\n\n\nCertaines méthodes, disponibles pour les Series, peuvent aussi être utilisées pour transformer un DataFrame complet. Par exemple, la bien utile méthode replace(), qui permet de remplacer toutes les occurences d’une valeur donnée par une autre valeur. Par exemple, supposons que la valeur 0 dans la colonne var1 indique en fait une erreur de mesure. Il serait préférable de la remplacer par une valeur manquante.\n\ndf.replace(0, np.nan)\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n-8\n\n\n2\nNaN\n6\n\n\n3\nNaN\n-6\n\n\n4\nNaN\n7\n\n\n5\nNaN\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignation ou méthodes in place (en place) ?\n\n\n\nDans l’exemple précédent, l’application de la méthode replace() ne modifie pas directement le DataFrame. Pour que la modifiction soit persistente, une première possibilité est d’assigner le résultat à un objet :\n\ndf = df.replace(0, np.nan)\n\nUne seconde possibilité est, lorsque les méthodes le proposent, d’utiliser l’argument inplace. Lorsque inplace=True, l’opération est effectuée “en place”, et le DataFrame est donc modifié directement.\n\ndf.replace(0, np.nan, inplace=True)\n\nEn pratique, il est préférable de limiter les opérations inplace. Elles ne favorisent pas la reproductibilité des analyses, dans la mesure où la ré-exécution d’une même cellule va donner à chaque fois des résultats différents.\n\n\n\n\n\nDans certains cas, on ne va pas vouloir appliquer les transformations à l’ensemble des données, mais à des variables spécifiques. Les transformations qui sont possibles à l’échelle du DataFrame (fonctions vectorisées, méthodes comme replace(), etc.) restent naturellement possibles à l’échelle d’une colonne.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n    }\n)\n\nnp.abs(df[\"var2\"])\n\n0    5\n1    7\n2    1\n3    2\n4    8\n5    6\nName: var2, dtype: int64\n\n\n\ndf[\"var1\"].replace(0, np.nan)\n\n0    1.3\n1    5.6\n2    NaN\n3    NaN\n4    NaN\n5    NaN\nName: var1, dtype: float64\n\n\nMais il existe d’autres transformations que l’on applique généralement au niveau d’une ou de quelques colonnes. Par exemple, lorsque le schéma n’a pas été bien reconnu à l’import, il peut arriver que des variables numériques soient définies comme des string (type object en Pandas).\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan],\n        \"var2\": [\"1\", \"5\", \"18\"],\n    }\n)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   var1    2 non-null      float64\n 1   var2    3 non-null      object \ndtypes: float64(1), object(1)\nmemory usage: 176.0+ bytes\n\n\nDans ce cas, on peut utiliser la méthode astype pour convertir la colonne dans le type souhaité.\n\ndf['var2'] = df['var2'].astype(int)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   var1    2 non-null      float64\n 1   var2    3 non-null      int64  \ndtypes: float64(1), int64(1)\nmemory usage: 176.0 bytes\n\n\nUne autre opération fréquente est le renommage d’une ou plusieurs colonnes. Pour cela, on peut utiliser la méthode rename(), à laquelle on passe un dictionnaire qui contient autant de couples clé-valeur que de variables à renommer, et dans lequel chaque couple clé-valeur est de la forme 'ancien_nom': 'nouveau_nom'.\n\ndf.rename(columns={'var2': 'age'})\n\n\n\n\n\n\n\n\nvar1\nage\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n5\n\n\n2\nNaN\n18\n\n\n\n\n\n\n\nEnfin, on peut souhaiter supprimer du DataFrame des colonnes qui ne sont pas ou plus utiles à l’analyse. Pour cela, on utilise la méthode drop(), à laquelle on passe soit un string (nom d’une colonne si l’on souhaite n’en supprimer qu’une seule) ou une liste de noms de colonne à supprimer.\n\ndf.drop(columns=['var1'])\n\n\n\n\n\n\n\n\nvar2\n\n\n\n\n0\n1\n\n\n1\n5\n\n\n2\n18\n\n\n\n\n\n\n\n\n\n\nEn statistiques, on applique généralement des tranformations faisant intervenir une ou plusieurs colonnes. Néanmoins, dans certains cas, il est nécessaire d’appliquer des transformations au niveau des lignes. Pour cela, on peut utiliser la méthode apply() de Pandas, appliquée à l’axe des lignes (axis=1). Illustrons son fonctionnement avec un cas simple. Pour cela, on génère d’abord des données.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\"],\n    }\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nOn applique maintenant la fonction apply() au DataFrame afin de calculer une nouvelle variable qui est la somme des deux existantes.\n\ndf['sum_row'] = df.apply(lambda row: row['var1'] + row['var2'], axis=1)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n\n\n1\n5\n7\n2022-01-02\n12\n\n\n2\n9\n11\n2022-01-03\n20\n\n\n3\n13\n15\n2022-01-04\n28\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes fonctions lambda\n\n\n\nUne fonction lambda est une petite fonction anonyme. Elle peut prendre n’importe quel nombre d’arguments, mais ne peut avoir qu’une seule expression. Dans l’exemple ci-dessus, la fonction lambda prend une ligne en argument et renvoie la somme des colonnes var1 et var2 pour cette ligne.\nLes fonctions lambda permettent de définir simplement des fonctions “à la volée”, sans devoir leur donner un nom. Dans notre exemple, cela aurait été parfaitement équivalent au code suivant :\n\ndef sum_row(row):\n    return row['var1'] + row['var2']\n\ndf['sum_row'] = df.apply(sum_row, axis=1)\n\n\n\nBien que apply() offre une grande flexibilité, elle n’est pas la méthode la plus efficiente, notamment pour de grands jeux de données. Les opérations vectorisées sont toujours préférables car elles traitent les données en bloc plutôt que ligne par ligne. Dans notre cas, il aurait été bien entendu préférable de créer notre variable en utilisant des opérations sur les colonnes.\n\ndf['sum_row_vect'] = df['var1'] + df['var2']\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\nsum_row_vect\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n4\n\n\n1\n5\n7\n2022-01-02\n12\n12\n\n\n2\n9\n11\n2022-01-03\n20\n20\n\n\n3\n13\n15\n2022-01-04\n28\n28\n\n\n\n\n\n\n\nNéanmoins, on peut se retrouver dans certains (rares) cas où une opération ne peut pas être facilement vectorisée ou où la logique est complexe. Supposons par exemple que l’on souhaite combiner les valeurs de plusieurs colonnes en fonction de certaines conditions.\n\ndef combine_columns(row):\n    if row['var1'] &gt; 6:\n        return str(row['var2'])\n    else:\n        return str(row['var2']) + \"_\" + row['date']\n\ndf['combined_column'] = df.apply(combine_columns, axis=1)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\nsum_row_vect\ncombined_column\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n4\n3_2022-01-01\n\n\n1\n5\n7\n2022-01-02\n12\n12\n7_2022-01-02\n\n\n2\n9\n11\n2022-01-03\n20\n20\n11\n\n\n3\n13\n15\n2022-01-04\n28\n28\n15\n\n\n\n\n\n\n\n\n\n\n\nLe tri des données est particulièrement utile pour l’exploration et la visualisation de données. Avec Pandas, on utilise la méthode sort_values() pour trier les valeurs d’un DataFrame selon une ou plusieurs colonnes.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\"],\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nPour trier les valeurs selon une seule colonne, il suffit de passer le nom de la colonne en paramètre.\n\ndf.sort_values(by='var1')\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nPar défaut, le tri est effectué dans l’ordre croissant. Pour trier les valeurs dans un ordre décroissant, il suffit de paramétrer ascending=False.\n\ndf.sort_values(by='var1', ascending=False)\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n3\n13\n15\n2022-01-04\n\n\n2\n9\n11\n2022-01-03\n\n\n1\n5\n7\n2022-01-02\n\n\n0\n1\n3\n2022-01-01\n\n\n\n\n\n\n\nSi on souhaite trier le DataFrame sur plusieurs colonnes, on peut fournir une liste de noms de colonnes. On peut également choisir de trier de manière croissante pour certaines colonnes et décroissante pour d’autres.\n\n\n\nL’agrégation des données est un processus dans lequel les données vont être ventilées en groupes selon certains critères, puis agrégées selon une fonction d’agrégation appliquée indépendamment à chaque groupe. Cette opération est courante lors de l’analyse exploratoire ou lors du prétraitement des données pour la visualisation ou la modélisation statistique.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\n0\n1.3\n-9\ntest\n2022-01-01\nsample1\n\n\n1\n5.6\n7\ntrain\n2022-01-02\nsample1\n\n\n2\nNaN\n8\ntest\n2022-01-03\nsample1\n\n\n3\nNaN\n-3\ntrain\n2022-01-04\nsample1\n\n\n4\n0.0\n-2\ntrain\n2022-01-05\nsample1\n\n\n\n\n\n\n\n\n\nLa méthode groupBy de Pandas permet de diviser le DataFrame en sous-ensembles selon les valeurs d’une ou plusieurs colonnes, puis d’appliquer une fonction d’agrégation à chaque sous-ensemble. Elle renvoie un objet de type DataFrameGroupBy qui ne présente pas de grand intérêt en soi, mais constitue l’étape intermédiaire indispensable pour pouvoir ensuite appliquer une ou plusieurs fonction(s) d’agrégation aux différents groupes.\n\ndf.groupby('experiment')\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f5ad8479930&gt;\n\n\n\n\n\nUne fois les données groupées, on peut appliquer des fonctions d’agrégation pour obtenir un résumé statistique. Pandas intègre un certain nombre de ces fonctions, dont la liste complète est détaillée dans la documentation. Voici quelques exemples d’utilisation de ces méthodes.\nPar exemple, compter le nombre d’occurrences dans chaque groupe.\n\ndf.groupby('experiment').size()\n\nexperiment\ntest          2\ntrain         3\nvalidation    1\ndtype: int64\n\n\nCalculer la somme d’une variable par groupe.\n\ndf.groupby('experiment')['var1'].sum()\n\nexperiment\ntest          1.3\ntrain         5.6\nvalidation    0.0\nName: var1, dtype: float64\n\n\nOu encore compter le nombre de valeurs unique d’une variable par groupe. Les possibilités sont nombreuses.\n\n# Pour le nombre de valeurs uniques de 'var2' dans chaque groupe\ndf.groupby('experiment')['var2'].nunique()\n\nexperiment\ntest          2\ntrain         3\nvalidation    1\nName: var2, dtype: int64\n\n\nLorsqu’on souhaite appliquer plusieurs fonctions d’agrégation à la fois ou des fonctions personnalisées, on utilise la méthode agg. Cette méthode accepte une liste de fonctions ou un dictionnaire qui associe les noms des colonnes aux fonctions à appliquer. Cela permet d’appliquer plus finement les fonctions d’agrégation.\n\ndf.groupby('experiment').agg({'var1': 'mean', 'var2': 'count'})\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\nexperiment\n\n\n\n\n\n\ntest\n1.3\n2\n\n\ntrain\n2.8\n3\n\n\nvalidation\nNaN\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nLe chaînage de méthodes\n\n\n\nLes exemples précédents illustrent un concept important en Pandas : le chaînage de méthodes. Ce terme désigne la possibilité d’enchaîner les transformations appliquées à un DataFrame en lui appliquant à la chaîne des méthodes. A chaque méthode appliquée, un DataFrame intermédiaire est créé (mais non assigné à une variable), qui devient l’input de la méthode suivante.\nLe chaînage de méthodes permet de combiner plusieurs opérations en une seule expression de code. Cela peut améliorer l’efficacité en évitant les assignations intermédiaires et en rendant le code plus fluide et plus facile à lire. Cela favorise également un style de programmation fonctionnel où les données passent à travers une chaîne de transformations de manière fluide.\n\n\n\n\n\nIl est intéressant de noter les effets du processus d’agrégation sur l’index du DataFrame. Le dernier exemple ci-dessus l’illustre bien : les groupes, i.e. les modalités de la variable utilisée pour effectuer l’agrégation, deviennent les valeurs de l’index.\nOn peut vouloir réutiliser cette information dans des analyses ultérieures, et donc la vouloir comme une colonne. Il suffit pour cela de réinitialiser l’index avec la méthode reset_index().\n\ndf_agg = df.groupby('experiment').agg({'var1': 'mean', 'var2': 'count'})\ndf_agg.reset_index()\n\n\n\n\n\n\n\n\nexperiment\nvar1\nvar2\n\n\n\n\n0\ntest\n1.3\n2\n\n\n1\ntrain\n2.8\n3\n\n\n2\nvalidation\nNaN\n1\n\n\n\n\n\n\n\n\n\n\n\nLes valeurs manquantes sont une réalité courante dans le traitement des données réelles et peuvent survenir pour diverses raisons, telles que des non-réponses à un questionnaire, des erreurs de saisie, des pertes de données lors de la transmission ou simplement parce que l’information n’est pas applicable. Pandas offre plusieurs outils pour gérer les valeurs manquantes.\n\n\nDans Pandas, les valeurs manquantes sont généralement représentées par np.nan, qui est un marqueur spécial fourni par la bibliothèque NumPy. S’il est préférable d’utiliser cet objet pour dénoter les valeurs manquantes, notons que l’objet None de Python est également compris comme une valeur manquante par Pandas.\nVérifions cette propriété. Pour identifier où se trouvent les valeurs manquantes, on utilise la fonction isna() qui retourne un DataFrame booléen indiquant True là où les valeurs sont NaN.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", None, \"train\", \"validation\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf.isna()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\n\n\n3\nTrue\nFalse\nTrue\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\n\n\n5\nTrue\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\n\nLors de calculs statistiques, les valeurs manquantes sont généralement ignorées. Par exemple, la méthode .mean() calcule la moyenne des valeurs non manquantes.\n\ndf['var1'].mean()\n\nnp.float64(2.3)\n\n\nEn revanche, les calculs faisant intervenir plusieurs colonnes n’ignorent pas toujours les valeurs manquantes et peuvent souvent donner des résultats en NaN.\n\ndf['var3'] = df['var1'] + df['var2']\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nvar3\n\n\n\n\n0\n1.3\n8\ntest\nsample1\n9.3\n\n\n1\n5.6\n4\ntrain\nsample1\n9.6\n\n\n2\nNaN\n-3\ntest\nsample1\nNaN\n\n\n3\nNaN\n5\nNone\nsample1\nNaN\n\n\n4\n0.0\n-10\ntrain\nsample1\n-10.0\n\n\n5\nNaN\n-6\nvalidation\nsample1\nNaN\n\n\n\n\n\n\n\n\n\n\nLa méthode dropna() permet de supprimer les lignes (axis=0) ou les colonnes (axis=1) contenant des valeurs manquantes. Par défaut, toute ligne contenant au moins une valeur manquante est supprimée.\n\ndf.dropna()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nvar3\n\n\n\n\n0\n1.3\n8\ntest\nsample1\n9.3\n\n\n1\n5.6\n4\ntrain\nsample1\n9.6\n\n\n4\n0.0\n-10\ntrain\nsample1\n-10.0\n\n\n\n\n\n\n\nEn modifiant le paramètre axis, on peut demander à ce que toute colonne contenant au moins une valeur manquante soit supprimée.\n\ndf.dropna(axis=1)\n\n\n\n\n\n\n\n\nvar2\nsample\n\n\n\n\n0\n8\nsample1\n\n\n1\n4\nsample1\n\n\n2\n-3\nsample1\n\n\n3\n5\nsample1\n\n\n4\n-10\nsample1\n\n\n5\n-6\nsample1\n\n\n\n\n\n\n\nEnfin, le paramètre how définit la modalité de supression. Par défaut, une ligne ou colonne est supprimée lorsqu’au moins une valeur est manquante (how=any), mais il est possible de ne supprimer la ligne/colonne que lorsque toutes les valeurs sont manquantes (how=all).\n\n\n\nPour gérer les valeurs manquantes dans un DataFrame, une approche commune est l’imputation, qui consiste à remplacer les valeurs manquantes par d’autres valeurs. La méthode fillna() permet d’effectuer cette opération de différentes manières. Une première possibilité est le remplacement par une valeur constante.\n\ndf['var1'].fillna(value=0)\n\n0    1.3\n1    5.6\n2    0.0\n3    0.0\n4    0.0\n5    0.0\nName: var1, dtype: float64\n\n\n\n\n\n\n\n\nChangement de représentation des valeurs manquantes\n\n\n\nOn peut parfois être tentant de changer la manifestation d’une valeur manquante pour des raisons de visibilité, par exemple en la remplaçant par une chaîne de caractères :\n\ndf['var1'].fillna(value=\"MISSING\")\n\n0        1.3\n1        5.6\n2    MISSING\n3    MISSING\n4        0.0\n5    MISSING\nName: var1, dtype: object\n\n\nEn pratique, cette façon de faire n’est pas recommandée. Il est en effet préférable de conserver la convention standard de Pandas (l’utilisation des np.nan), d’abord pour des questions de standardisation des pratiques qui facilitent la lecture et la maintenance du code, mais également parce que la convention standard est optimisée pour la performance et les calculs à partir de données contenant des valeurs manquantes.\n\n\nUne autre méthode d’imputation fréquente est d’utiliser une valeur statistique, comme la moyenne ou la médiane de la variable.\n\ndf['var1'].fillna(value=df['var1'].mean())\n\n0    1.3\n1    5.6\n2    2.3\n3    2.3\n4    0.0\n5    2.3\nName: var1, dtype: float64\n\n\n\n\n\n\n\n\nBiais d’imputation\n\n\n\nRemplacer les valeurs manquantes par une valeur constante, telle que zéro, la moyenne ou la médiane, peut être problématique. Si les données ne sont pas manquantes au hasard (Missing Not At Random - MNAR), cela peut introduire un biais dans l’analyse. Les variables MNAR sont des variables dont la probabilité d’être manquantes est liée à leur propre valeur ou à d’autres variables dans les données. Dans de tels cas, une imputation plus sophistiquée peut être nécessaire pour minimiser les distorsions. Nous en verrons un exemple en exercice de fin de tutoriel.\n\n\n\n\n\n\n\n\nLes données textuelles nécessitent souvent un nettoyage et une préparation avant l’analyse. Pandas fournit via la librairie de méthodes str un ensemble d’opérations vectorisées qui rendent la préparation des données textuelles à la fois simple et très efficace. Là encore, les possibilités sont multiples et détaillées dans la documentation. Nous présentons ici les méthodes les plus fréquemment utilisées dans l’analyse de données.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"test\", \"train\", \"validation\"],\n        \"sample\": [\"  sample1\", \"sample1\", \"sample2\", \"   sample2   \", \"sample2  \", \"sample1\"]\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n\n\n1\n5.6\n-6\ntrain\nsample1\n\n\n2\nNaN\n-3\ntest\nsample2\n\n\n3\nNaN\n6\ntest\nsample2\n\n\n4\n0.0\n-9\ntrain\nsample2\n\n\n5\nNaN\n0\nvalidation\nsample1\n\n\n\n\n\n\n\nUne première opération fréquente consiste à extraire certains caractères d’une chaîne. On utilise pour cela la fonction (à la syntaxe un peu particulière) str[n:] Par exemple, si l’on veut extraire le dernier caractère de la variable sample afin de ne retenir que le chiffre de l’échantillon.\n\ndf[\"sample_n\"] = df[\"sample\"].str[-1:]\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-6\ntrain\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n\n\n\n4\n0.0\n-9\ntrain\nsample2\n\n\n\n5\nNaN\n0\nvalidation\nsample1\n1\n\n\n\n\n\n\n\nLe principe était le bon, mais la présence d’espaces superflus dans nos données textuelles (qui ne se voyaient pas à la visualisation du DataFrame !) a rendu l’opération plus difficile que prévue. C’est l’occasion d’introduire la famille de méthode strip (.str.strip(), .str.lstrip() et .str.rstrip()) qui respectivement retirent les espaces superflus des deux côtés ou d’un seul.\n\ndf[\"sample\"] = df[\"sample\"].str.strip()\ndf[\"sample_n\"] = df[\"sample\"].str[-1:]\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-6\ntrain\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n2\n\n\n4\n0.0\n-9\ntrain\nsample2\n2\n\n\n5\nNaN\n0\nvalidation\nsample1\n1\n\n\n\n\n\n\n\nOn peut également vouloir filtrer un DataFrame en fonction de la présence ou non d’une certaine chaîne (ou sous-chaîne) de caractères. On utilise pour cela la méthode .str.contains().\n\ndf[df['experiment'].str.contains('test')]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n2\n\n\n\n\n\n\n\nEnfin, on peut vouloir remplacer une chaîne (ou sous-chaîne) de caractères par une autre, ce que permet la méthode str.replace().\n\ndf['experiment'] = df['experiment'].str.replace('validation', 'val')\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-6\ntrain\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n2\n\n\n4\n0.0\n-9\ntrain\nsample2\n2\n\n\n5\nNaN\n0\nval\nsample1\n1\n\n\n\n\n\n\n\n\n\n\nLes données catégorielles sont des variables qui contiennent un nombre restreint de modalités. A l’instar de R avec la notion de factor, Pandas a un type de données spécial, category, qui est utile pour représenter des données catégorielles de manière plus efficace et plus informative. Les données catégorielles sont en effet optimisées pour certains types de données et peuvent accélérer les opérations comme le groupement et le tri. Elles sont également utiles pour la visualisation, car elles permettent d’assurer que les catégories sont affichées dans un ordre cohérent et logique.\nPour convertir une variable au format category, on utilise la méthode astype().\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", None, \"train\", \"validation\"],\n    }\n)\nprint(df.dtypes)\n\nvar1          float64\nvar2            int64\nexperiment     object\ndtype: object\n\n\n\ndf['experiment'] = df['experiment'].astype('category')\n\nprint(df.dtypes)\n\nvar1           float64\nvar2             int64\nexperiment    category\ndtype: object\n\n\nCette conversion nous donne accès à quelques méthodes bien pratiques, spécifiques au traitement des variables catégorielles. Il peut par exemple être utile de renommer les catégories pour des raisons de clarté ou de standardisation.\n\ndf['experiment'] = df['experiment'].cat.rename_categories({'test': 'Test', 'train': 'Train', 'validation': 'Validation'})\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\n\n\n\n\n0\n1.3\n4\nTest\n\n\n1\n5.6\n9\nTrain\n\n\n2\nNaN\n-2\nTest\n\n\n3\nNaN\n-4\nNaN\n\n\n4\n0.0\n-8\nTrain\n\n\n5\nNaN\n0\nValidation\n\n\n\n\n\n\n\nParfois, l’ordre des catégories est significatif, et on peut vouloir le modifier. En particulier dans le cadre de la visualisation, car les modalités seront par défaut affichées dans l’ordre spécifié.\n\ndf_cat = df['experiment'].cat.reorder_categories(['Test', 'Train', 'Validation'], ordered=True)\ndf.groupby(\"experiment\").mean().plot(kind='bar')\n\n/tmp/ipykernel_2611/419168969.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  df.groupby(\"experiment\").mean().plot(kind='bar')\n\n\n\n\n\n\n\n\n\n\n\n\nLes données temporelles sont souvent présentes dans les données tabulaires afin d’identifier temporellement les observations recueillies. Pandas offre des fonctionnalités pour manipuler ces types de données, notamment grâce au type datetime64 qui permet une manipulation précise des dates et des heures.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2023-01-01\", \"2023-01-02\"],\n        \"sample\": [\"sample1\", \"sample1\", \"sample2\", \"sample2\"]\n    }\n)\n\ndf.dtypes\n\nvar1       int64\nvar2       int64\ndate      object\nsample    object\ndtype: object\n\n\nPour manipuler les données temporelles, il est nécessaire de convertir les chaînes de caractères en objets datetime. Pandas le fait via la fonction to_datetime().\n\ndf['date'] = pd.to_datetime(df['date'])\n\ndf.dtypes\n\nvar1               int64\nvar2               int64\ndate      datetime64[ns]\nsample            object\ndtype: object\n\n\nUne fois converties, les dates peuvent être formatées, comparées et utilisées dans des calculs. En particulier, Pandas comprend à présent l’“ordre” des dates présentes dans les données, et permet donc le filtrage sur des périodes données.\n\ndf[(df['date'] &gt;= \"2022-01-01\") & (df['date'] &lt; \"2022-01-03\")]\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n\n\n\n\n\nOn peut également vouloir réaliser des filtrages moins précis, faisant intervenir l’année ou le mois. Pandas permet d’extraire facilement des composants spécifiques de la date, comme l’année, le mois, le jour, l’heure, etc.\n\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\n\ndf[df['year'] == 2023]\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\nyear\nmonth\nday\n\n\n\n\n2\n9\n11\n2023-01-01\nsample2\n2023\n1\n1\n\n\n3\n13\n15\n2023-01-02\nsample2\n2023\n1\n2\n\n\n\n\n\n\n\nEnfin, les calculs faisant intervenir des dates deviennent possible. On peut ajouter ou soustraire des périodes temporelles à des dates, et les comparer entre elles. Les fonctions utilisées sont issues de Pandas, mais sont très semblables dans leur fonctionnement à celles du module time de Python.\nOn peut par exemple ajouter des intervalles de temps, ou bien calculer des écarts à une date de référence.\n\ndf['date_plus_one'] = df['date'] + pd.Timedelta(days=1)\ndf['date_diff'] = df['date'] - pd.to_datetime('2022-01-01')\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\nyear\nmonth\nday\ndate_plus_one\ndate_diff\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n2022\n1\n1\n2022-01-02\n0 days\n\n\n1\n5\n7\n2022-01-02\nsample1\n2022\n1\n2\n2022-01-03\n1 days\n\n\n2\n9\n11\n2023-01-01\nsample2\n2023\n1\n1\n2023-01-02\n365 days\n\n\n3\n13\n15\n2023-01-02\nsample2\n2023\n1\n2\n2023-01-03\n366 days\n\n\n\n\n\n\n\n\n\n\n\nDans le cadre d’une analyse de données, il est courant de vouloir combiner différentes sources de données. Cette combinaison peut se faire verticalement (un DataFrame par dessus l’autre), par exemple lorsque l’on souhaite combiner deux millésimes d’une même enquête afin de les analyser conjointement. La combinaison peut également se faire horizontalement (côte à côte) selon une ou plusieurs clé(s) de jointure, souvent dans le but d’enrichir une source de données à partir d’une autre source portant sur les mêmes unités statistiques.\n\n\nLa concaténation verticale de tables se fait à l’aide de la fonction concat() de Pandas.\n\ndf1 = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5],\n        \"var2\": [3, 7],\n        \"date\": [\"2022-01-01\", \"2022-01-02\"],\n        \"sample\": [\"sample1\", \"sample1\"]\n    }\n)\n\ndf2 = pd.DataFrame(\n    data = {\n        \"var1\": [9, 13],\n        \"date\": [\"2023-01-01\", \"2023-01-02\"],\n        \"var2\": [11, 15],\n        \"sample\": [\"sample2\", \"sample2\"]\n    }\n)\n\ndf_concat = pd.concat([df1, df2])\n\ndf_concat\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n0\n9\n11\n2023-01-01\nsample2\n\n\n1\n13\n15\n2023-01-02\nsample2\n\n\n\n\n\n\n\nNotons que l’ordre des variables dans les deux DataFrames n’est pas important. Pandas ne juxtapose pas “bêtement” les deux DataFrames, il fait une correspondance des schémas pour faire correspondre les variables par nom. Si deux variables ont le même nom mais pas le même type - par exemple dans le cas où une variable numérique aurait été interprétée comme des strings - Pandas va résoudre le problème en prenant le dénominateur commun, c’est à dire en général convertir en strings (type object).\nPar contre, la concaténation précédente laisse apparaître un problème de répétition au niveau de l’index. C’est logique : on n’a pas spécifié d’index pour nos deux DataFrames initiaux, qui ont donc le même index de position ([0, 1]). Dans ce cas (où l’index n’est pas important), on peut passer le paramètre ignore_index=True pour reconstruire de zéro l’index final.\n\ndf_concat = pd.concat([df1, df2], ignore_index=True)\n\ndf_concat\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n2\n9\n11\n2023-01-01\nsample2\n\n\n3\n13\n15\n2023-01-02\nsample2\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstruction itérative d’un DataFrame\n\n\n\nOn pourrait avoir l’idée d’utiliser pd.concat() pour construire un DataFrame de manière itérative, en ajoutant à chaque itération d’une boucle une nouvelle ligne au DataFrame existant. Ce n’est néanmoins pas une bonne idée : comme nous l’avons vu, un DataFrame est représenté dans la mémoire commme une juxtaposition de Series. Ainsi, ajouter une colonne à un DataFrame est peu coûteux, mais ajouter une ligne implique de modifier chaque élément constituant du DataFrame. Pour construire un DataFrame, il est donc plutôt conseillé de stocker les lignes dans une liste de listes (une par colonne) ou un dictionnaire, puis d’appeler pd.DataFrame() pour construire le DataFrame, comme nous l’avons fait au début de ce tutoriel.\n\n\n\n\n\nLa fusion de tables est une opération qui permet d’associer des lignes de deux DataFrames différents en se basant sur une ou plusieurs clés communes, similaire aux jointures dans les bases de données SQL. Différents types de jointure sont possible selon les données que l’on souhaite conserver, dont les principaux sont représentés sur le graphique suivant.\n\nSource : lien\nEn Pandas, les jointures se font avec la fonction merge(). Pour réaliser une jointure, on doit spécifier (au minimum) deux informations :\n\nle type de jointure : par défaut, Pandas effectue une jointure de type inner. Le paramètre how permet de spécifier d’autres types de jointure ;\nla clé de jointure. Par défaut, Pandas essaie de joindre les deux DataFrames à partir de leurs index. En pratique, on spécifie souvent une variable présente dans le DataFrames comme clé de jointure (paramètre on si la variable porte le même nom dans les deux DataFrame, ou left_on et right_on sinon).\n\nAnalysons la différence entre les différents types de jointure à travers des exemples.\n\ndf_a = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K3', 'K4'],\n    'A': ['A0', 'A1', 'A2', 'A3', 'A4'],\n    'B': ['B0', 'B1', 'B2', 'B3', 'A4']\n})\n\ndf_b = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K5', 'K6'],\n    'C': ['C0', 'C1', 'C2', 'C5', 'C6'],\n    'D': ['D0', 'D1', 'D2', 'D5', 'D6']\n})\n\ndisplay(df_a)\ndisplay(df_b)\n\n\n\n\n\n\n\n\nkey\nA\nB\n\n\n\n\n0\nK0\nA0\nB0\n\n\n1\nK1\nA1\nB1\n\n\n2\nK2\nA2\nB2\n\n\n3\nK3\nA3\nB3\n\n\n4\nK4\nA4\nA4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkey\nC\nD\n\n\n\n\n0\nK0\nC0\nD0\n\n\n1\nK1\nC1\nD1\n\n\n2\nK2\nC2\nD2\n\n\n3\nK5\nC5\nD5\n\n\n4\nK6\nC6\nD6\n\n\n\n\n\n\n\nLa jointure de type inner conserve les observations dont la clé est présente dans les deux DataFrame.\n\ndf_merged_inner = pd.merge(df_a, df_b, on='key')\ndf_merged_inner\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n\n\n\n\n\n\n\n\n\n\n\nJointures inner\n\n\n\nLa jointure de type inner est la plus intuitive : elle ne crée généralement pas de valeurs manquantes et permet donc de travailler directement sur la table fusionnée. Mais attention : si beaucoup de clés ne sont pas présentes dans les deux DataFrames à la fois, une jointure inner peut aboutit à des pertes importantes de données, et donc à des résultats finaux biaisés. Dans ce cas, il vaut mieux choisir une jointure à gauche ou à droite, selon la source que l’on cherche à enrichir et pour laquelle il est donc le plus important de limiter les pertes de données.\n\n\nUne jointure de type left conserve toutes les observations contenues dans le DataFrame de gauche (premier DataFrame spécifié dans pd.merge()). Par conséquent, si des clés sont présentes dans le DataFrame de gauche mais pas dans celui de droite, le DataFrame final contient des valeurs manquantes au niveau de ces observations (pour les variables du DataFrame de droite).\n\ndf_merged_left = pd.merge(df_a, df_b, how=\"left\", on='key')\ndf_merged_left\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n3\nK3\nA3\nB3\nNaN\nNaN\n\n\n4\nK4\nA4\nA4\nNaN\nNaN\n\n\n\n\n\n\n\nLa jointure de type outer contient toutes les observations et variables contenues dans les deux DataFrame. Ainsi, l’information retenue est maximale, mais en contrepartie les valeurs manquantes peuvent être assez nombreuses. Il sera donc nécessaire de bien traiter les valeurs manquantes avant de procéder aux analyses.\n\ndf_merged_outer = pd.merge(df_a, df_b, how=\"outer\", on='key')\ndf_merged_outer\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n3\nK3\nA3\nB3\nNaN\nNaN\n\n\n4\nK4\nA4\nA4\nNaN\nNaN\n\n\n5\nK5\nNaN\nNaN\nC5\nD5\n\n\n6\nK6\nNaN\nNaN\nC6\nD6\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1/ Qu’est-ce qu’un DataFrame dans le contexte de Pandas et à quel type de structure de données peut-on le comparer dans le langage Python ?\n2/ Quelle est la différence fondamentale entre un array Numpy et une Pandas Series ?\n3/ Quel est le lien entre Series et DataFrame dans Pandas ?\n4/ Comment sont structurées les données dans un DataFrame Pandas ?\n5/ Quel est le rôle de l’index dans un DataFrame Pandas et comment peut-il être utilisé lors de la manipulation des données ?\n6/ Quelles méthodes pouvez-vous utiliser pour explorer un DataFrame inconnu et en apprendre davantage sur son contenu et sa structure ?\n7/ Dans Pandas, quelle est la différence entre assigner le résultat d’une opération à une nouvelle variable et utiliser une méthode avec l’argument inplace=True ?\n8/ Comment s’applique le principe de la vectorisation dans Pandas et pourquoi est-ce avantageux pour manipuler les données ?\n9/ Comment Pandas représente-t-il les valeurs manquantes et quel impact cela a-t-il sur les calculs et les transformations de données ?\n10/ Quelle est la différence entre concaténer deux DataFrames et les joindre via une jointure, et quand utiliseriez-vous l’une plutôt que l’autre ?\n\n\n\n\nAfficher la solution\n\n\n1/ Un DataFrame dans Pandas est une structure de données bidimensionnelle, comparable à un tableau ou une feuille de calcul Excel. Dans le contexte Python, on peut le comparer à un dictionnaire d’arrays NumPy, où les clés sont les noms des colonnes et les valeurs sont les colonnes elles-mêmes.\n2/ La différence principale entre un array NumPy et une Series Pandas est que la Series peut contenir des données étiquetées, c’est-à-dire qu’elle a un index qui lui est associé, permettant des accès et des manipulations par label.\n3/ Un DataFrame est essentiellement une collection de Series. Chaque colonne d’un DataFrame est une Series, et toutes ces Series partagent le même index, qui correspond aux étiquettes des lignes du DataFrame.\n4/ Les données dans un DataFrame Pandas sont structurées en colonnes et en lignes. Chaque colonne peut contenir un type de données différent (numérique, chaîne de caractères, booléen, etc.), et chaque ligne représente une observation.\n5/ L’index dans un DataFrame Pandas sert à identifier de manière unique chaque ligne du DataFrame. Il permet d’accéder rapidement aux lignes, de réaliser des jointures, de trier les données et de faciliter les opérations de regroupement.\n6/ Pour explorer un DataFrame inconnu, on peut utiliser df.head() pour voir les premières lignes, df.tail() pour les dernières, df.info() pour obtenir un résumé des types de données et des valeurs manquantes, et df.describe() pour des statistiques descriptives.\n7/ Assigner le résultat d’une opération à une nouvelle variable crée une copie du DataFrame avec les modifications appliquées. Utiliser une méthode avec inplace=True modifie le DataFrame original sans créer de copie, ce qui peut être plus efficace en termes de mémoire.\n8/ Pandas représente les valeurs manquantes avec l’objet nan (Not a Number) de Numpy pour les données numériques et avec None ou pd.NaT pour les dates/temps. Ces valeurs manquantes sont généralement ignorées dans les calculs de fonctions statistiques, ce qui peut affecter les résultats si elles ne sont pas traitées correctement.\n9/ Concaténer consiste à assembler des DataFrames en les empilant verticalement ou en les alignant horizontalement, principalement utilisé lorsque les DataFrames ont le même schéma ou lorsque vous souhaitez empiler les données. Les jointures, inspirées des opérations JOIN en SQL, combinent les DataFrames sur la base de valeurs de clés communes et sont utilisées pour enrichir un ensemble de données avec des informations d’un autre ensemble.\n\n\n\n\n\n\nDans la cellule suivante, nous avons récupéré des données de caisses sur les ventes de différentes enseignes. Les données sont cependant présentées de deux manières différentes, dans un cas sous forme d’observations (chaque liste contient les données d’une ligne), dans l’autre sous forme de variables (chaque liste contient les données d’une colonne).\n\ndata_list1 = [\n    ['Carrefour', '01.1.1', 3, 1.50],\n    ['Casino', '02.1.1', 2, 2.30],\n    ['Lidl', '01.1.1', 7, 0.99],\n    ['Carrefour', '03.1.1', 5, 5.00],\n    ['Casino', '01.1.1', 10, 1.20],\n    ['Lidl', '02.1.1', 1, 3.10]\n]\n\ndata_list2 = [\n    ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    [3, 2, 7, 5, 10, 1],\n    [1.50, 2.30, 0.99, 5.00, 1.20, 3.10]\n]\n\nL’objectif est de construire dans les deux cas un même DataFrame qui contient chacune des 6 observations et des 4 variables, avec les mêmes noms dans les deux DataFrame. A chaque cas va correspondre une structure de données plus adaptée en entrée, dictionnaire ou liste de listes… faîtes le bon choix ! On vérifiera que les deux DataFrames sont identiques à l’aide de la méthode equals().\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndata_list1 = [\n    ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    [3, 2, 7, 5, 10, 1],\n    [1.50, 2.30, 0.99, 5.00, 1.20, 3.10]\n]\n\ndata_list2 = [\n    ['Carrefour', '01.1.1', 3, 1.50],\n    ['Casino', '02.1.1', 2, 2.30],\n    ['Lidl', '01.1.1', 7, 0.99],\n    ['Carrefour', '03.1.1', 5, 5.00],\n    ['Casino', '01.1.1', 10, 1.20],\n    ['Lidl', '02.1.1', 1, 3.10]\n]\n\n# Si les données sont sous forme de colonnes : à partir d'un dictionnaire\ndata_dict = {\n    'enseigne': data_list1[0],\n    'produit': data_list1[1],\n    'quantite': data_list1[2],\n    'prix': data_list1[3]\n}\n\ndf_from_dict = pd.DataFrame(data_dict)\n\n# Si les données sont sous forme de lignes : à partir d'une liste de listes\ncolumns = ['enseigne', 'produit', 'quantite', 'prix']\ndf_from_list = pd.DataFrame(data_list2, columns=columns)\n\n# Vérification\ndf_from_dict.equals(df_from_list)\n\nTrue\n\n\n\n\n\n\n\nUn DataFrame Pandas est créé avec des données de caisse (mêmes données que l’exercice précédent).\n\ndata = {\n    'enseigne': ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    'produit': ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    'quantite': [3, 2, 7, 5, 10, 1],\n    'prix': [1.50, 2.30, 0.99, 5.00, 1.20, 3.10],\n    'date_heure': pd.to_datetime([\"2022-01-01 14:05\", \"2022-01-02 09:30\", \n                                  \"2022-01-03 17:45\", \"2022-01-04 08:20\", \n                                  \"2022-01-05 19:00\", \"2022-01-06 16:30\"])\n}\n\ndf = pd.DataFrame(data)\n\nUtilisez les méthodes loc et iloc pour sélectionner des données spécifiques :\n\nSélectionner les données de la première ligne.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.iloc[0])\n\nenseigne                Carrefour\nproduit                    01.1.1\nquantite                        3\nprix                          1.5\ndate_heure    2022-01-01 14:05:00\nName: 0, dtype: object\n\n\n\n\n\nSélectionner toutes les données de la colonne “prix”.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[:, 'prix'])\n\n0    1.50\n1    2.30\n2    0.99\n3    5.00\n4    1.20\n5    3.10\nName: prix, dtype: float64\n\n\n\n\n\nSélectionner les lignes correspondant à l’enseigne “Carrefour” uniquement.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['enseigne'] == 'Carrefour'])\n\n    enseigne produit  quantite  prix          date_heure\n0  Carrefour  01.1.1         3   1.5 2022-01-01 14:05:00\n3  Carrefour  03.1.1         5   5.0 2022-01-04 08:20:00\n\n\n\n\n\nSélectionner les quantités achetées pour les produits classifiés “01.1.1” (Pain).\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['produit'] == '01.1.1', 'quantite'])\n\n0     3\n2     7\n4    10\nName: quantite, dtype: int64\n\n\n\n\n\nSélectionner les données des colonnes “enseigne” et “prix” pour toutes les lignes.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[:, ['enseigne', 'prix']])\n\n    enseigne  prix\n0  Carrefour  1.50\n1     Casino  2.30\n2       Lidl  0.99\n3  Carrefour  5.00\n4     Casino  1.20\n5       Lidl  3.10\n\n\n\n\n\nSélectionner les lignes où la quantité achetée est supérieure à 5.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['quantite'] &gt; 5])\n\n  enseigne produit  quantite  prix          date_heure\n2     Lidl  01.1.1         7  0.99 2022-01-03 17:45:00\n4   Casino  01.1.1        10  1.20 2022-01-05 19:00:00\n\n\n\n\n\nFiltrer pour sélectionner toutes les transactions qui ont eu lieu après 15h.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['date_heure'].dt.hour &gt; 15])\n\n  enseigne produit  quantite  prix          date_heure\n2     Lidl  01.1.1         7  0.99 2022-01-03 17:45:00\n4   Casino  01.1.1        10  1.20 2022-01-05 19:00:00\n5     Lidl  02.1.1         1  3.10 2022-01-06 16:30:00\n\n\n\n\n\nSélectionner les transactions qui ont eu lieu le “2022-01-03”.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['date_heure'].dt.date == pd.to_datetime('2022-01-03').date()])\n\n  enseigne produit  quantite  prix          date_heure\n2     Lidl  01.1.1         7  0.99 2022-01-03 17:45:00\n\n\n\n\n\n\n\nLe fichier des prénoms contient des données sur les prénoms attribués aux enfants nés en France entre 1900 et 2021. Ces données sont disponibles au niveau France, par département et par région, à l’adresse suivante : https://www.insee.fr/fr/statistiques/2540004?sommaire=4767262. L’objectif de ce tutoriel est de proposer une analyse de ce fichier, du nettoyage des données au statistiques sur les prénoms.\n\n\n\nImportez les données dans un DataFrame en utilisant cette URL.\nVisualisez un échantillon des données. Repérez-vous d’éventuelles anomalies ?\nAffichez les principales informations du DataFrame. Repérez d’éventuelles variables dont le type serait incorrect, ou bien d’éventuelles valeurs manquantes.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nurl = \"https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\"\ndf_prenoms = pd.read_csv(url, sep=\";\")\n\ndf_prenoms.head(10)\ndf_prenoms.sample(n=50)\n\ndf_prenoms.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 686538 entries, 0 to 686537\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   sexe      686538 non-null  int64 \n 1   preusuel  686536 non-null  object\n 2   annais    686538 non-null  object\n 3   nombre    686538 non-null  int64 \ndtypes: int64(2), object(2)\nmemory usage: 21.0+ MB\n\n\n\n\n\n\n\n\nL’output de la méthode info() suggère des valeurs manquantes dans la colonne des prénoms. Affichez ces lignes. Vérifiez que ces valeurs manquantes sont correctement spécifiées.\nL’output de méthode head() montre une modalité récurrente “_PRENOMS_RARES” dans la colonne des prénoms. Quelle proportion des individus de la base cela concerne-t-il ? Convertir ces valeurs en np.nan.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df_prenoms[df_prenoms[\"preusuel\"].isna()])\nprop_rares = df_prenoms.groupby(\"preusuel\")[\"nombre\"].sum()[\"_PRENOMS_RARES\"] / df_prenoms[\"nombre\"].sum()\nprint(prop_rares)  # ~ 2 % de la base\ndf_prenoms = df_prenoms.replace('_PRENOMS_RARES', np.nan)\n\n        sexe preusuel annais  nombre\n579411     2      NaN   2003       3\n579412     2      NaN   XXXX      29\n0.01965912697163539\n\n\n\n\n\nOn remarque que les prénoms de personnes dont l’année de naissance n’est pas connue sont regroupés sous la modalité XXXX. Quelle proportion des individus de la base cela concerne-t-il ? Convertir ces valeurs en np.nan.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprop_xxxx = df_prenoms.groupby(\"annais\")[\"nombre\"].sum()[\"XXXX\"] / df_prenoms[\"nombre\"].sum()\nprint(prop_xxxx)  # ~ 1 % de la base\ndf_prenoms = df_prenoms.replace('XXXX', np.nan)\n\n0.010007438242954967\n\n\n\n\n\nSupprimer les lignes contenant des valeurs manquantes de l’échantillon.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms = df_prenoms.dropna()\n\n\n\n\nConvertissez la colonne annais en type numérique et la colonne sexe en type catégoriel.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms['annais'] = pd.to_numeric(df_prenoms['annais'])\ndf_prenoms['sexe'] = df_prenoms['sexe'].astype('category')\n\n\n\n\nVérifiez avec la méthode info() que le nettoyage a été correctement appliqué.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 648369 entries, 122 to 686536\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype   \n---  ------    --------------   -----   \n 0   sexe      648369 non-null  category\n 1   preusuel  648369 non-null  object  \n 2   annais    648369 non-null  int64   \n 3   nombre    648369 non-null  int64   \ndtypes: category(1), int64(2), object(1)\nmemory usage: 20.4+ MB\n\n\n\n\n\n\n\n\nLa documentation du fichier nous informe qu’on peut considérer les données comme quasi-exhaustives à partir de 1946. Pour cette partie seulement, filtrer les données pour ne conserver que les données ultérieures.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms_post_1946 = df_prenoms[df_prenoms[\"annais\"] &gt;= 1946]\n\n\n\n\nCalculez le nombre total de naissances par sexe.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nbirths_per_sex = df_prenoms_post_1946.groupby('sexe')['nombre'].sum()\nprint(births_per_sex)\n\nsexe\n1    30872950\n2    29314697\nName: nombre, dtype: int64\n\n\n/tmp/ipykernel_2611/1314444992.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  births_per_sex = df_prenoms_post_1946.groupby('sexe')['nombre'].sum()\n\n\n\n\n\nIdentifiez les cinq années ayant le plus grand nombre de naissances.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ntop5_years = df_prenoms_post_1946.groupby('annais')['nombre'].sum().nlargest(5)\nprint(top5_years)\n\nannais\n1964    902522\n1971    899440\n1972    893901\n1963    893425\n1949    890585\nName: nombre, dtype: int64\n\n\n\n\n\n\n\n\nIdentifiez le nombre total de prénoms uniques dans le DataFrame.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ntotal_unique_names = df_prenoms['preusuel'].nunique()\nprint(total_unique_names)\n\n34175\n\n\n\n\n\nCompter le nombre de personnes possédant un prénom d’une seule lettre.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nsingle_letter_names = df_prenoms[df_prenoms['preusuel'].str.len() == 1]['nombre'].sum()\nprint(single_letter_names)\n\n209\n\n\n\n\n\nCréez une “fonction de popularité” qui, pour un prénom donné, affiche l’année où il a été le plus donné ainsi que le nombre de fois où il a été donné cette année-là.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndef popularite_par_annee(df, prenom):\n    # Filtrer le DataFrame pour ne garder que les lignes correspondant au prénom donné\n    df_prenom = df[df['preusuel'] == prenom]\n\n    # Grouper par année, sommer les naissances et identifier l'année avec le maximum de naissances\n    df_agg = df_prenom.groupby('annais')['nombre'].sum()\n    annee_max = df_agg.idxmax()\n    n_max = df_agg[annee_max]\n\n    print(f\"Le prénom '{prenom}' a été le plus donné en {annee_max}, avec {n_max} naissances.\")\n\n# Test de la fonction avec un exemple\npopularite_par_annee(df_prenoms, 'ALFRED')\n\nLe prénom 'ALFRED' a été le plus donné en 1910, avec 1994 naissances.\n\n\n\n\n\nCréez une fonction qui, pour un sexe donné, renvoie un DataFrame contenant le prénom le plus donné pour chaque décennie.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndef popularite_par_decennie(df, sexe):\n    # Filtrage sur le sexe\n    df_sub = df[df[\"sexe\"] == sexe]\n\n    # Calcul de la variable décennie\n    df_sub[\"decennie\"] = (df_sub[\"annais\"] // 10) * 10\n\n    # Calculer la somme des naissances pour chaque prénom et chaque décennie\n    df_counts_decennie = df_sub.groupby([\"preusuel\", \"decennie\"])[\"nombre\"].sum().reset_index()\n\n    # Trouver l'indice du prénom le plus fréquent pour chaque décennie\n    idx = df_counts_decennie.groupby(\"decennie\")[\"nombre\"].idxmax()\n\n    # Utiliser l'indice pour obtenir les lignes correspondantes du DataFrame df_counts_decennie\n    df_popularite_decennie = df_counts_decennie.loc[idx].set_index(\"decennie\")\n\n    return df_popularite_decennie\n\n# Test de la fonction avec un exemple\npopularite_par_decennie(df_prenoms, sexe=2)\n\n/tmp/ipykernel_2611/1907896397.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_sub[\"decennie\"] = (df_sub[\"annais\"] // 10) * 10\n\n\n\n\n\n\n\n\n\npreusuel\nnombre\n\n\ndecennie\n\n\n\n\n\n\n1900\nMARIE\n490609\n\n\n1910\nMARIE\n329246\n\n\n1920\nMARIE\n322486\n\n\n1930\nMARIE\n247784\n\n\n1940\nMARIE\n265690\n\n\n1950\nMARIE\n217042\n\n\n1960\nSYLVIE\n204773\n\n\n1970\nSANDRINE\n146395\n\n\n1980\nAURÉLIE\n113344\n\n\n1990\nLAURA\n70049\n\n\n2000\nLÉA\n77504\n\n\n2010\nEMMA\n49094\n\n\n2020\nJADE\n7618\n\n\n\n\n\n\n\n\n\n\n\n\n\nL’objectif de cet exercice est de calculer une empreinte carbone par habitant au niveau communal. Pour cela, il va falloir combiner deux sources de données :\n\nles populations légales au niveau des communes, issues du recensement de la population (source)\nles émissions de gaz à effet de serre estimées au niveau communal par l’ADEME (source)\n\nCet exercice constitue une version simplifiée d’un TP complet pour la pratique de Pandas proposé par Lino Galiana dans son cours à l’ENSAE.\n\n\n\nImportez le fichier CSV communes.csv.\nUtilisez les méthodes .sample(), .info() et .describe() pour obtenir un aperçu des données.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_pop_communes = pd.read_csv(\"data/communes.csv\", sep=\";\")\n\ndf_pop_communes.sample(10)\ndf_pop_communes.info()\ndf_pop_communes.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 34995 entries, 0 to 34994\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   DEPCOM  34995 non-null  object\n 1   COM     34995 non-null  object\n 2   PMUN    34995 non-null  int64 \n 3   PCAP    34995 non-null  int64 \n 4   PTOT    34995 non-null  int64 \ndtypes: int64(3), object(2)\nmemory usage: 1.3+ MB\n\n\n\n\n\n\n\n\n\nPMUN\nPCAP\nPTOT\n\n\n\n\ncount\n34995.000000\n34995.000000\n34995.000000\n\n\nmean\n1900.966967\n35.340849\n1936.307815\n\n\nstd\n8583.400244\n133.285462\n8696.358429\n\n\nmin\n0.000000\n0.000000\n0.000000\n\n\n25%\n199.000000\n4.000000\n203.000000\n\n\n50%\n457.000000\n9.000000\n468.000000\n\n\n75%\n1159.000000\n24.000000\n1184.000000\n\n\nmax\n479553.000000\n5256.000000\n484809.000000\n\n\n\n\n\n\n\n\n\n\nIdentifiez et retirez les lignes correspondant aux communes sans population.\nSupprimez les colonnes “PMUN” et “PCAP”, non pertinentes pour l’analyse.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nn_communes_0_pop = df_pop_communes[df_pop_communes[\"PTOT\"] == 0].shape[0]\nprint(n_communes_0_pop)\ndf_pop_communes = df_pop_communes[df_pop_communes[\"PTOT\"] &gt; 0]\n\ndf_pop_communes = df_pop_communes.drop(columns=[\"PMUN\", \"PCAP\"])\n\n6\n\n\n\n\nLes communes qui ont les noms les plus longs sont-elles aussi les communes les moins peuplées ? Pour le savoir : - Créez une nouvelle variable qui contient le nombre de caractères de chaque commune à l’aide de la méthode str.len() - Calculez la corrélation entre cette variable et la population totale avec la méthode corr()\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_pop_communes_stats = df_pop_communes.copy()\ndf_pop_communes_stats['longueur'] = df_pop_communes_stats['COM'].str.len()\ndf_pop_communes_stats['longueur'].corr(df_pop_communes_stats['PTOT'])\n\nnp.float64(0.0037878701156295307)\n\n\n\n\n\n\n\n\nImportez les données d’émission depuis cette URL\nUtilisez les méthodes .sample(), .info() et .describe() pour obtenir un aperçu des données.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nurl_ademe = \"https://data.ademe.fr/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/data-files/IGT%20-%20Pouvoir%20de%20r%C3%A9chauffement%20global.csv\"\ndf_emissions = pd.read_csv(url_ademe)\n\ndf_emissions.sample(10)\ndf_emissions.info()\ndf_emissions.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35798 entries, 0 to 35797\nData columns (total 12 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   INSEE commune                    35798 non-null  object \n 1   Commune                          35798 non-null  object \n 2   Agriculture                      35736 non-null  float64\n 3   Autres transports                9979 non-null   float64\n 4   Autres transports international  2891 non-null   float64\n 5   CO2 biomasse hors-total          35798 non-null  float64\n 6   Déchets                          35792 non-null  float64\n 7   Energie                          34490 non-null  float64\n 8   Industrie hors-énergie           34490 non-null  float64\n 9   Résidentiel                      35792 non-null  float64\n 10  Routier                          35778 non-null  float64\n 11  Tertiaire                        35798 non-null  float64\ndtypes: float64(10), object(2)\nmemory usage: 3.3+ MB\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\n\n\n\n\ncount\n35736.000000\n9979.000000\n2.891000e+03\n35798.000000\n35792.000000\n3.449000e+04\n3.449000e+04\n35792.000000\n35778.000000\n35798.000000\n\n\nmean\n2459.975760\n654.919940\n7.692345e+03\n1774.381550\n410.806329\n6.625698e+02\n2.423128e+03\n1783.677872\n3535.501245\n1105.165915\n\n\nstd\n2926.957701\n9232.816833\n1.137643e+05\n7871.341922\n4122.472608\n2.645571e+04\n5.670374e+04\n8915.902379\n9663.156628\n5164.182507\n\n\nmin\n0.003432\n0.000204\n3.972950e-04\n3.758088\n0.132243\n2.354558e+00\n1.052998e+00\n1.027266\n0.555092\n0.000000\n\n\n25%\n797.682631\n52.560412\n1.005097e+01\n197.951108\n25.655166\n2.354558e+00\n6.911213e+00\n96.052911\n419.700460\n94.749885\n\n\n50%\n1559.381285\n106.795928\n1.992434e+01\n424.849988\n54.748653\n4.709115e+00\n1.382243e+01\n227.091193\n1070.895593\n216.297718\n\n\n75%\n3007.883903\n237.341501\n3.298311e+01\n1094.749825\n110.820941\n5.180027e+01\n1.520467e+02\n749.469293\n3098.612157\n576.155869\n\n\nmax\n98949.317760\n513140.971691\n3.303394e+06\n576394.181208\n275500.374439\n2.535858e+06\n6.765119e+06\n410675.902028\n586054.672836\n288175.400126\n\n\n\n\n\n\n\n\n\n\nY a-t-il des lignes avec des valeurs manquantes pour toutes les colonnes d’émission ? Vérifiez-le à l’aide des méthodes isnull() et all().\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions_num = df_emissions.select_dtypes(['number'])\nonly_nan = df_emissions_num[df_emissions_num.isnull().all(axis=1)]\nonly_nan.shape[0]\n\n0\n\n\n\n\n\nCréez une nouvelle colonne qui donne les émissions totales par commune\nAfficher les 10 communes les plus émettrices. Qu’observez-vous dans les résultats ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions['emissions_totales'] = df_emissions.sum(axis = 1, numeric_only = True)\n\ndf_emissions.sort_values(by=\"emissions_totales\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\n\n\n\n\n4382\n13039\nFOS-SUR-MER\n305.092893\n1893.383189\n1.722723e+04\n50891.367548\n275500.374439\n2.296711e+06\n6.765119e+06\n9466.388806\n74631.401993\n42068.140058\n9.533813e+06\n\n\n22671\n59183\nDUNKERQUE\n811.390947\n3859.548994\n3.327586e+05\n71922.181764\n23851.780482\n1.934988e+06\n5.997333e+06\n113441.727216\n94337.865738\n70245.678455\n8.643550e+06\n\n\n4398\n13056\nMARTIGUES\n855.299300\n2712.749275\n3.043476e+04\n35925.561051\n44597.426397\n1.363402e+06\n2.380185e+06\n22530.797276\n84624.862481\n44394.822725\n4.009663e+06\n\n\n30560\n76476\nPORT-JEROME-SUR-SEINE\n2736.931327\n121.160849\n2.086403e+04\n22846.964780\n78.941581\n1.570236e+06\n2.005643e+06\n21072.566129\n9280.824961\n15270.357772\n3.668151e+06\n\n\n31108\n77291\nLE MESNIL-AMELOT\n782.183307\n133834.090767\n3.303394e+06\n3330.404124\n111.613197\n8.240952e+02\n2.418925e+03\n1404.400153\n11712.541682\n13680.471909\n3.471492e+06\n\n\n31099\n77282\nMAUREGARD\n733.910161\n133699.072712\n3.303394e+06\n193.323752\n44.301447\n2.354558e+00\n6.911213e+00\n468.995242\n2106.579416\n160.309150\n3.440809e+06\n\n\n30438\n76351\nLE HAVRE\n1168.274940\n17358.962736\n2.109460e+06\n141492.414415\n17641.705314\n2.653841e+05\n4.183445e+05\n195864.092574\n111174.296228\n95695.476436\n3.373584e+06\n\n\n30428\n76341\nHARFLEUR\n751.297090\n157.179958\nNaN\n10591.477221\n67.467130\n2.535858e+06\n5.107387e+03\n8739.638694\n29761.043310\n5277.162755\n2.596310e+06\n\n\n31111\n77294\nMITRY-MORY\n1912.746387\n89815.529858\n2.202275e+06\n17540.442778\n159.163608\n3.510646e+03\n1.364685e+04\n26418.982148\n72891.937473\n15163.398499\n2.443335e+06\n\n\n1987\n06088\nNICE\n305.445236\n225204.545951\n1.003572e+06\n169338.333391\n124232.948837\n1.186697e+04\n3.589365e+04\n252857.325855\n352836.864314\n171766.435376\n2.347875e+06\n\n\n\n\n\n\n\n\n\n\nIl semble que les postes majeurs d’émissions soient “Industrie hors-énergie” et “Autres transports international”. Pour vérifier si cette conjecture tient, calculer la corrélation entre les émissions totales et les postes sectoriels d’émissions à l’aide de la méthode corrwith().\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions.corrwith(df_emissions[\"emissions_totales\"], numeric_only=True)\n\nAgriculture                        0.032843\nAutres transports                  0.283310\nAutres transports international    0.463660\nCO2 biomasse hors-total            0.466285\nDéchets                            0.409822\nEnergie                            0.711808\nIndustrie hors-énergie             0.835432\nRésidentiel                        0.444557\nRoutier                            0.454902\nTertiaire                          0.488895\nemissions_totales                  1.000000\ndtype: float64\n\n\n\n\n\nExtraire du code commune le numéro de département dans une nouvelle variable\nCalculer les émissions totales par département\nAfficher les 10 principaux départements émetteurs. Les résultats sont-ils logiques par rapport à l’analyse au niveau communal ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions[\"dep\"] = df_emissions[\"INSEE commune\"].str[:2]\ndf_emissions.groupby(\"dep\").agg({\"emissions_totales\": \"sum\"}).sort_values(by=\"emissions_totales\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nemissions_totales\n\n\ndep\n\n\n\n\n\n13\n2.657388e+07\n\n\n59\n2.607500e+07\n\n\n76\n2.159825e+07\n\n\n77\n1.818622e+07\n\n\n69\n1.250800e+07\n\n\n62\n1.207887e+07\n\n\n44\n1.053212e+07\n\n\n38\n1.014781e+07\n\n\n57\n1.010131e+07\n\n\n33\n9.352481e+06\n\n\n\n\n\n\n\n\n\n\n\n\nPour effectuer une jointure, il est toujours préférable d’avoir une clé de jointure, i.e. une colonne commune aux deux sources, qui identifie uniquement les unités statistiques. L’objet de cette partie est de trouver la clé de jointure pertinente.\n\nVérifiez si la variable contenant les noms de commune contient des doublons\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndoublons = df_pop_communes.groupby('COM').count()['DEPCOM']\ndoublons = doublons[doublons&gt;1]\ndoublons = doublons.reset_index()\ndoublons\n\n\n\n\n\n\n\n\nCOM\nDEPCOM\n\n\n\n\n0\nAbancourt\n2\n\n\n1\nAboncourt\n2\n\n\n2\nAbzac\n2\n\n\n3\nAchères\n2\n\n\n4\nAiglun\n2\n\n\n...\n...\n...\n\n\n1451\nÉtaules\n2\n\n\n1452\nÉterpigny\n2\n\n\n1453\nÉtréchy\n3\n\n\n1454\nÉtrépilly\n2\n\n\n1455\nŒuilly\n2\n\n\n\n\n1456 rows × 2 columns\n\n\n\n\n\n\nFiltrez dans le DataFrame initial les communes dont le nom est dupliqué, et triez-le par code commune. Les doublons semblent-ils problématiques ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_pop_communes_doublons = df_pop_communes[df_pop_communes[\"COM\"].isin(doublons[\"COM\"])]\ndf_pop_communes_doublons.sort_values('COM')\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\n\n\n\n\n22473\n60001\nAbancourt\n659\n\n\n21825\n59001\nAbancourt\n476\n\n\n20791\n57001\nAboncourt\n354\n\n\n19453\n54003\nAboncourt\n105\n\n\n12327\n33001\nAbzac\n1963\n\n\n...\n...\n...\n...\n\n\n34450\n91226\nÉtréchy\n6634\n\n\n30189\n77173\nÉtrépilly\n899\n\n\n680\n02297\nÉtrépilly\n119\n\n\n1192\n02565\nŒuilly\n293\n\n\n18782\n51410\nŒuilly\n658\n\n\n\n\n3720 rows × 3 columns\n\n\n\n\n\n\nVérifiez que les codes commune identifient de manière unique la commune associée\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n(df_pop_communes_doublons.groupby(\"DEPCOM\")[\"COM\"].nunique() != 1).sum()\n\nnp.int64(0)\n\n\n\n\n\nAffichez les communes présentes dans les données communales mais pas dans les données d’émissions, et inversement. Qu’en concluez-vous ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n## Observations qui sont dans les pop légales mais pas dans les données d'émissions\ndf_pop_communes[~df_pop_communes[\"DEPCOM\"].isin(df_emissions[\"INSEE commune\"])]\n\n## Observations qui sont dans les données d'émissions mais pas dans les pop légales\ndf_emissions[~df_emissions[\"INSEE commune\"].isin(df_pop_communes[\"DEPCOM\"])]\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\ndep\n\n\n\n\n53\n01059\nBRENAZ\n2059.625278\nNaN\nNaN\n97.460907\n60.369788\n2.354558\n6.911213\n37.806309\n442.992259\n43.546665\n2751.066976\n01\n\n\n83\n01091\nCHATILLON-EN-MICHAILLE\n2716.023992\n154.607070\nNaN\n4479.397305\n26.211975\n489.748010\n1437.532377\n2884.723545\n24426.607714\n2852.127766\n39466.979755\n01\n\n\n89\n01097\nCHAVORNAY\n502.135035\nNaN\nNaN\n119.257319\n28.696758\n2.354558\n6.911213\n90.061423\n187.213742\n103.842046\n1040.472094\n01\n\n\n112\n01122\nCORMARANCHE-EN-BUGEY\n1020.579097\nNaN\nNaN\n548.434440\n134.359486\n35.318366\n103.668200\n323.757897\n1147.594565\n383.306355\n3697.018406\n01\n\n\n130\n01144\nDOMMARTIN\n3514.482852\nNaN\nNaN\n524.037265\n159.287551\nNaN\nNaN\n348.829080\n1529.911692\n422.067671\n6498.616112\n01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35189\n89484\nVOLGRE\n383.961261\nNaN\nNaN\n954.348314\n46.681823\nNaN\nNaN\n424.365746\n10724.104395\n168.922776\n12702.384315\n89\n\n\n35262\n90073\nMOVAL\n281.860724\n57.129390\nNaN\n576.938906\n56.600057\n2.354558\n6.911213\n295.469174\n1439.904381\n205.016539\n2922.184943\n90\n\n\n35348\n91182\nCOURCOURONNES\n24.548795\n103.360309\nNaN\n9623.065698\n111.241872\n1276.170296\n3745.877636\n9978.002088\n57834.224552\n10532.120761\n93228.612007\n91\n\n\n35360\n91222\nESTOUCHES\n1790.002871\nNaN\nNaN\n113.797978\n30.548162\n2.354558\n6.911213\n71.011704\n523.293194\n110.541533\n2648.461213\n91\n\n\n35687\n95259\nGADANCOURT\n312.298700\nNaN\nNaN\n142.113291\n11.372909\nNaN\nNaN\n32.440647\n2060.981036\n41.153991\n2600.360573\n95\n\n\n\n\n922 rows × 14 columns\n\n\n\n\n\n\n\n\n\nJoindre les deux DataFrames à l’aide de la fonction à partir du code commune. Attention : les variables ne s’appellent pas de la même manière des deux côtés !\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions_pop = pd.merge(df_pop_communes, df_emissions, how=\"inner\", left_on=\"DEPCOM\", right_on=\"INSEE commune\")\ndf_emissions_pop\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\ndep\n\n\n\n\n0\n01001\nL' Abergement-Clémenciat\n794\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n5724.424941\n01\n\n\n1\n01002\nL' Abergement-de-Varey\n249\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n1332.811619\n01\n\n\n2\n01004\nAmbérieu-en-Bugey\n14428\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n63259.689119\n01\n\n\n3\n01005\nAmbérieux-en-Dombes\n1723\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n6792.867439\n01\n\n\n4\n01006\nAmbléon\n117\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n1068.584766\n01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n34871\n95676\nVillers-en-Arthies\n513\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n2625.668140\n95\n\n\n34872\n95678\nVilliers-Adam\n870\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n22708.808792\n95\n\n\n34873\n95680\nVilliers-le-Bel\n27808\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n59484.157091\n95\n\n\n34874\n95682\nVilliers-le-Sec\n188\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n6351.999447\n95\n\n\n34875\n95690\nWy-dit-Joli-Village\n340\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n2506.319181\n95\n\n\n\n\n34876 rows × 17 columns\n\n\n\n\n\n\nCalculer une empreinte carbone pour chaque commune, correspondant aux émissions totales de la commune divisées par sa population totale.\nAffichez les 10 communes avec les empreintes carbones les plus élevées.\nLes résultats sont-ils identiques à ceux avec les émissions totales ? Qu’en concluez-vous ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions_pop[\"empreinte_carbone\"] = df_emissions_pop[\"emissions_totales\"] / df_emissions_pop[\"PTOT\"]\ndf_emissions_pop.sort_values(\"empreinte_carbone\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\ndep\nempreinte_carbone\n\n\n\n\n30289\n77282\nMauregard\n353\n77282\nMAUREGARD\n733.910161\n133699.072712\n3.303394e+06\n193.323752\n44.301447\n2.354558e+00\n6.911213e+00\n468.995242\n2106.579416\n160.309150\n3.440809e+06\n77\n9747.335479\n\n\n30298\n77291\nLe Mesnil-Amelot\n1019\n77291\nLE MESNIL-AMELOT\n782.183307\n133834.090767\n3.303394e+06\n3330.404124\n111.613197\n8.240952e+02\n2.418925e+03\n1404.400153\n11712.541682\n13680.471909\n3.471492e+06\n77\n3406.763878\n\n\n22513\n60049\nBazancourt\n138\n60049\nBAZANCOURT\n4931.402275\nNaN\nNaN\n130.528462\n16.794877\n2.354558e+00\n3.016750e+05\n56.170228\n180.537059\n60.773916\n3.070535e+05\n60\n2225.025699\n\n\n26698\n68064\nChalampé\n969\n68064\nCHALAMPE\n9.216396\n647.802699\n3.558269e+01\n6332.112195\n70576.619047\n2.455804e+03\n1.042746e+06\n1097.958606\n2810.388658\n1362.287485\n1.128073e+06\n68\n1164.162333\n\n\n5501\n16357\nSaint-Vallier\n137\n16357\nSAINT-VALLIER\n1946.660150\nNaN\nNaN\n178.823635\n18.910767\n2.354558e+00\n1.513620e+05\n73.973099\n714.562143\n68.430473\n1.543657e+05\n16\n1126.757043\n\n\n21085\n57314\nHéming\n500\n57314\nHEMING\n509.670358\n167.168713\n8.175536e+00\n1141.352892\n68.237452\n3.343472e+02\n5.114259e+05\n276.118642\n3622.271599\n850.150203\n5.184033e+05\n57\n1036.806699\n\n\n14762\n39236\nFrancheville\n56\n39236\nFRANCHEVILLE\n817.850772\nNaN\nNaN\n63.254271\n5.157482\n2.354558e+00\n4.797800e+04\n23.798701\n103.848909\n18.662856\n4.901293e+04\n39\n875.230849\n\n\n18517\n51377\nMontépreux\n45\n51377\nMONTEPREUX\n3184.753959\nNaN\nNaN\n195.644289\n5.289725\n5.886394e+01\n2.928200e+04\n26.790561\n191.338795\n19.141391\n3.296382e+04\n51\n732.529393\n\n\n13138\n34278\nSaint-Michel\n49\n34278\nSAINT-MICHEL\n4491.844291\nNaN\nNaN\n145.718340\n34.912656\n2.354558e+00\n2.514989e+04\n23.599874\n450.893244\n23.448204\n3.032267e+04\n34\n618.829907\n\n\n4333\n13039\nFos-sur-Mer\n15654\n13039\nFOS-SUR-MER\n305.092893\n1893.383189\n1.722723e+04\n50891.367548\n275500.374439\n2.296711e+06\n6.765119e+06\n9466.388806\n74631.401993\n42068.140058\n9.533813e+06\n13\n609.033668\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous avez à disposition dans le dossier data/ deux jeux de données CSV :\n\nserie_glaces_valeurs.csv contient les valeurs mensuelles de l’indice de prix de production de l’industrie française des glaces et sorbets\nserie_glaces_metadonnees.csv contient les métadonnées associées, notamment les codes indiquant le statut des données.\n\nL’objectif est d’utiliser Pandas pour calculer :\n\nl’évolution de l’indice entre chaque période (mois)\nl’évolution de l’indice en glissement annuel (entre un mois donné et le même mois l’année suivante).\n\n\n\n\nImportez les deux fichiers CSV dans des DataFrames. Attention, dans les deux cas, il y a des lignes superflues avant les données, qu’il faudra sauter à l’aide du paramètre skiprows de la fonction read_csv().\nDonnez des noms simples et pertinents aux différentes variables.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_valeurs = pd.read_csv('data/serie_glaces_valeurs.csv', delimiter=';',\n                         skiprows=4, names=[\"periode\", \"indice\", \"code\"])\ndf_metadata = pd.read_csv('data/serie_glaces_metadonnees.csv', delimiter=';',\n                          skiprows=5, names=[\"code\", \"signification\"])\n\n\n\n\n\n\n\nFusionner les deux DataFrames afin de récupérer la signification des codes présents dans les données.\nFiltrer les données de sorte à ne conserver que les données de type “Valeur normale”.\nSupprimer les colonnes liées aux codes, dont nous n’avons plus besoin pour la suite.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_merged = pd.merge(df_valeurs, df_metadata, how='left', on='code')\n\ndf_clean = df_merged[df_merged['code'] == \"A\"]\ndf_clean = df_clean[[\"periode\", \"indice\"]]\n\n\n\n\n\n\nVérifiez si les types des variables sont pertinents selon leur nature. Sinon, convertissez-les avec les fonctions idoines.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_clean.info()\ndf_clean['periode'] = pd.to_datetime(df_clean['periode'])\ndf_clean['indice'] = pd.to_numeric(df_clean['indice'])\ndf_clean.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 198 entries, 3 to 200\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   periode  198 non-null    object\n 1   indice   198 non-null    object\ndtypes: object(2)\nmemory usage: 4.6+ KB\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 198 entries, 3 to 200\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype         \n---  ------   --------------  -----         \n 0   periode  198 non-null    datetime64[ns]\n 1   indice   198 non-null    float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 4.6 KB\n\n\n\n\n\n\n\n\nUtilisez la méthode shift() pour créer une nouvelle colonne qui contiendra l’indice du trimestre précédent\nCalculez la différence entre l’indice actuel et l’indice décalé pour obtenir l’évolution (en pourcentage) d’un trimestre à l’autre\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_clean['indice_prec'] = df_clean['indice'].shift(1)\ndf_clean['evo'] = ((df_clean['indice'] - df_clean['indice_prec']) / df_clean['indice_prec']) * 100\n\n## Méthode alternative\ndf_clean['evo_alt'] = df_clean['indice'].pct_change(periods=1) * 100\n\n\n\n\n\n\nComme vous avez pu le voir dans la solution de l’exercice précédent, la méthode pct_change() permet précisément de calculer une évolution entre deux périodes. Utiliser cette méthode pour calculer une évolution (en pourcentage) en glissement annuel pour chaque mois.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_clean[\"evo_glissement_annuel\"] = df_clean['indice'].pct_change(periods=12) * 100\ndf_clean.head(20)\n\n\n\n\n\n\n\n\nperiode\nindice\nindice_prec\nevo\nevo_alt\nevo_glissement_annuel\n\n\n\n\n3\n2023-06-01\n115.3\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2023-05-01\n112.4\n115.3\n-2.515178\n-2.515178\nNaN\n\n\n5\n2023-04-01\n115.5\n112.4\n2.758007\n2.758007\nNaN\n\n\n6\n2023-03-01\n112.9\n115.5\n-2.251082\n-2.251082\nNaN\n\n\n7\n2023-02-01\n105.1\n112.9\n-6.908769\n-6.908769\nNaN\n\n\n8\n2023-01-01\n104.0\n105.1\n-1.046622\n-1.046622\nNaN\n\n\n9\n2022-12-01\n98.3\n104.0\n-5.480769\n-5.480769\nNaN\n\n\n10\n2022-11-01\n100.0\n98.3\n1.729400\n1.729400\nNaN\n\n\n11\n2022-10-01\n98.2\n100.0\n-1.800000\n-1.800000\nNaN\n\n\n12\n2022-09-01\n98.9\n98.2\n0.712831\n0.712831\nNaN\n\n\n13\n2022-08-01\n99.3\n98.9\n0.404449\n0.404449\nNaN\n\n\n14\n2022-07-01\n97.2\n99.3\n-2.114804\n-2.114804\nNaN\n\n\n15\n2022-06-01\n97.3\n97.2\n0.102881\n0.102881\n-15.611448\n\n\n16\n2022-05-01\n95.0\n97.3\n-2.363823\n-2.363823\n-15.480427\n\n\n17\n2022-04-01\n96.0\n95.0\n1.052632\n1.052632\n-16.883117\n\n\n18\n2022-03-01\n94.3\n96.0\n-1.770833\n-1.770833\n-16.474756\n\n\n19\n2022-02-01\n94.0\n94.3\n-0.318134\n-0.318134\n-10.561370\n\n\n20\n2022-01-01\n94.6\n94.0\n0.638298\n0.638298\n-9.038462\n\n\n21\n2021-12-01\n92.6\n94.6\n-2.114165\n-2.114165\n-5.798576\n\n\n22\n2021-11-01\n92.3\n92.6\n-0.323974\n-0.323974\n-7.700000",
    "crumbs": [
      "Manipulation de données",
      "Traiter des données tabulaires avec Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#structures-de-données",
    "href": "source/manipulation/pandas/tutorial.html#structures-de-données",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "Pour bien comprendre le fonctionnement de Pandas, il faut s’intéresser à ses objets fondamentaux. On va donc d’abord étudier les Series, dont la concaténation permet de construire un DataFrame.\n\n\nUne Series est un conteneur de données unidimensionnel pouvant accueillir n’importe quel type de données (entiers, strings, objets Python…). Une Series est néanmoins d’un type donné : une Series ne contenant que des entiers sera de type int, et une Series contenant des objets de différente nature sera de type object. Construisons notre première Series à partir d’une liste pour vérifier ce comportement.\n\nl = [1, \"X\", 3]\ns = pd.Series(l)\nprint(s)\n\n0    1\n1    X\n2    3\ndtype: object\n\n\nOn peut notamment accéder aux données d’une Series par position, comme pour une liste ou un array.\n\nprint(s[1])\n\nX\n\n\nA priori, on ne voit pas beaucoup de différence entre une Series et un array NumPy à 1 dimension. Pourtant, il existe une différence de taille qui est la présence d’un index : les observations ont un label associé. Lorsqu’on crée une Series sans rien spécifier, l’index est automatiquement fixé aux entiers de 0 à n-1 (avec n le nombre d’éléments de la Series). Mais il est possible de passer un index spécifique (ex : des dates, des noms de communes, etc.).\n\ns = pd.Series(l, index=[\"a\", \"b\", \"c\"])\nprint(s)\n\na    1\nb    X\nc    3\ndtype: object\n\n\nCe qui permet d’accéder aux données par label :\n\ns[\"b\"]\n\n'X'\n\n\nCette différence apparaît secondaire à première vue, mais deviendra essentielle pour la construction du DataFrame. Pour le reste, les Series se comportent de manière très proche des arrays NumPy : les calculs sont vectorisés, on peut directement faire la somme de deux Series, etc. D’ailleurs, on peut très facilement convertir une Series en array via l’attribut values. Ce qui, naturellement, fait perdre l’index…\n\ns = pd.Series(l, index=[\"a\", \"b\", \"c\"])\ns.values\n\narray([1, 'X', 3], dtype=object)\n\n\n\n\n\nFondamentalement, un DataFrame consiste en une collection de Series, alignées par les index. Cette concaténation construit donc une table de données, dont les Series correspondent aux colonnes, et dont l’index identifie les lignes. La figure suivante (source) permet de bien comprendre cette structure de données.\n\n\n\n\n\nUn DataFrame peut être construit de multiples manières. En pratique, on construit généralement un DataFrame directement à partir de fichiers de données tabulaires (ex : CSV, excel), rarement à la main. On illustrera donc seulement la méthode de construction manuelle la plus usuelle : à partir d’un dictionnaire de données.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\n0\n1.3\n-2\ntest\n2022-01-01\nsample1\n\n\n1\n5.6\n2\ntrain\n2022-01-02\nsample1\n\n\n2\nNaN\n5\ntest\n2022-01-03\nsample1\n\n\n3\nNaN\n-8\ntrain\n2022-01-04\nsample1\n\n\n4\n0.0\n3\ntrain\n2022-01-05\nsample1\n\n\n5\nNaN\n2\nvalidation\n2022-01-06\nsample1\n\n\n\n\n\n\n\nUn DataFrame Pandas dispose d’un ensemble d’attributs utiles que nous allons découvrir tout au long de ce tutoriel. Pour l’instant, intéressons-nous aux plus basiques : l’index et le nom des colonnes. Par défaut, l’index est initialisé comme pour les Series à la liste des positions des observations. On aurait pu spécifier un index alternatif lors de la construction du DataFrame en spécifiant l’argument index de la fonction pd.DataFrame.\n\ndf.index\n\nRangeIndex(start=0, stop=6, step=1)\n\n\n\ndf.columns\n\nIndex(['var1', 'var2', 'experiment', 'date', 'sample'], dtype='object')\n\n\nSouvent, plutôt que de spécifier un index à la main lors de la construction du DataFrame, on va vouloir utiliser une certaine colonne du DataFrame comme index. On utilise pour cela la méthode set_index associée aux DataFrames.\n\ndf = df.set_index(\"date\")\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\nsample1\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n2022-01-04\nNaN\n-8\ntrain\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\nL’attribut index a naturellement changé :\n\ndf.index\n\nIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04', '2022-01-05',\n       '2022-01-06'],\n      dtype='object', name='date')",
    "crumbs": [
      "Manipulation de données",
      "Traiter des données tabulaires avec Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#sélectionner-des-données",
    "href": "source/manipulation/pandas/tutorial.html#sélectionner-des-données",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "Lors de la manipulation des données tabulaires, il est fréquent de vouloir extraire des colonnes spécifiques d’un DataFrame. Cette extraction est simple avec Pandas grâce à l’utilisation des crochets.\n\n\n\n\nPour extraire une seule colonne, on peut utiliser la syntaxe suivante :\n\nselected_column = df[\"var1\"]\nselected_column\n\ndate\n2022-01-01    1.3\n2022-01-02    5.6\n2022-01-03    NaN\n2022-01-04    NaN\n2022-01-05    0.0\n2022-01-06    NaN\nName: var1, dtype: float64\n\n\nL’objet selected_column renvoie ici la colonne nommée var1 du DataFrame df. Mais de quel type est cet objet ? Pour répondre à cette question, on utilise la fonction type() :\n\ntype(selected_column)\n\npandas.core.series.Series\n\n\nComme on peut le voir, le résultat est une Series, qui est un objet unidimensionnel dans Pandas.\nUn autre attribut utile à connaître est shape. Il permet de connaître la dimension de l’objet. Pour une Series, shape retournera un tuple dont le premier élément indique le nombre de lignes.\n\nselected_column.shape\n\n(6,)\n\n\n\n\n\nPour extraire plusieurs colonnes, il suffit de passer une liste des noms des colonnes souhaitées :\n\nselected_columns = df[[\"var1\", \"var2\", \"experiment\"]]\nselected_columns\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\n\n\ndate\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\n\n\n2022-01-02\n5.6\n2\ntrain\n\n\n2022-01-03\nNaN\n5\ntest\n\n\n2022-01-04\nNaN\n-8\ntrain\n\n\n2022-01-05\n0.0\n3\ntrain\n\n\n2022-01-06\nNaN\n2\nvalidation\n\n\n\n\n\n\n\nCet extrait montre les colonnes var1, var2 et experiment du DataFrame df. Vérifions maintenant son type :\n\ntype(selected_columns)\n\npandas.core.frame.DataFrame\n\n\nLe résultat est un DataFrame, car il s’agit d’un objet bidimensionnel. On peut aussi vérifier sa forme avec l’attribut shape. Dans ce cas, le tuple renvoyé par shape contiendra deux éléments : le nombre de lignes et le nombre de colonnes.\n\nselected_columns.shape\n\n(6, 3)\n\n\n\n\n\n\n\n\nLorsqu’on veut sélectionner des lignes spécifiques dans un DataFrame, on peut se servir des deux principales méthodes : loc et iloc.\n\niloc permet de sélectionner des lignes et des colonnes par leur position, c’est-à-dire par des indices numériques.\n\nExemple, sélection des 3 premières lignes :\n\ndf.iloc[0:3, :]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\nsample1\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n\n\n\n\n\n\nloc quant à lui, fonctionne avec des labels. Si les index du DataFrame sont des numéros, ils ressemblent aux positions, mais ce n’est pas forcément le cas. Il est crucial de noter que, contrairement à iloc, avec loc, l’index de fin est inclus dans la sélection.\n\n\ndf.loc[\"2022-01-01\":\"2022-01-03\", :]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-01\n1.3\n-2\ntest\nsample1\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n\n\n\n\n\n\n\n\nEn pratique, plutôt que de sélectionner des lignes basées sur des positions ou des labels, on souhaite souvent filtrer un DataFrame selon certaines conditions. Dans ce cas, on se sert principalement de filtres booléens.\n\nInégalités : On peut vouloir garder seulement les lignes qui respectent une certaine condition.\n\nExemple, filtrer les lignes où la valeur de la colonne var2 est supérieure à 0 :\n\ndf[df['var2'] &gt;= 0]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-03\nNaN\n5\ntest\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\n\nAppartenance avec isin : Si on veut filtrer les données basées sur une liste de valeurs possibles, la méthode isin est très utile.\n\nExemple, pour garder uniquement les lignes où la colonne experiment a des valeurs ‘test’ ou ‘validation’ :\n\ndf[df['experiment'].isin(['train', 'validation'])]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-04\nNaN\n-8\ntrain\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1\n\n\n\n\n\n\n\nCes méthodes peuvent être combinées pour créer des conditions plus complexes. Il est aussi possible d’utiliser les opérateurs logiques (& pour “et”, | pour “ou”) pour combiner plusieurs conditions. Attention, il faut bien prendre soin d’encadrer chaque condition par des parenthèses lors de la combinaison.\nExemple, sélectionner les lignes où var2 est supérieur à 0 et experiment est égal à ‘test’ ou ‘validation’:\n\ndf[(df['var2'] &gt;= 0) & (df['experiment'].isin(['train', 'validation']))]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\ndate\n\n\n\n\n\n\n\n\n2022-01-02\n5.6\n2\ntrain\nsample1\n\n\n2022-01-05\n0.0\n3\ntrain\nsample1\n\n\n2022-01-06\nNaN\n2\nvalidation\nsample1",
    "crumbs": [
      "Manipulation de données",
      "Traiter des données tabulaires avec Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#explorer-des-données-tabulaires",
    "href": "source/manipulation/pandas/tutorial.html#explorer-des-données-tabulaires",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "En statistique publique, le point de départ n’est généralement pas la génération manuelle de données, mais plutôt des fichiers tabulaires préexistants. Ces fichiers, qu’ils soient issus d’enquêtes, de bases administratives ou d’autres sources, constituent la matière première pour toute analyse ultérieure. Pandas offre des outils puissants pour importer ces fichiers tabulaires et les explorer en vue de manipulations plus poussées.\n\n\n\n\nComme nous l’avons vu dans un précédent TP, le format CSV est l’un des formats les plus courants pour stocker des données tabulaires. Nous avons précédemment utilisé la librairie csv pour les manipuler comme des fichiers texte, mais ce n’était pas très pratique. Pour rappel, la syntaxe pour lire un fichier CSV et afficher les premières lignes était la suivante :\n\nimport csv\n\nrows = []\n\nwith open(\"data/departement2021.csv\") as file_in:\n    csv_reader = csv.reader(file_in)\n    for row in csv_reader:\n        rows.append(row)\n\nrows[:5]\n\n[['DEP', 'REG', 'CHEFLIEU', 'TNCC', 'NCC', 'NCCENR', 'LIBELLE'],\n ['01', '84', '01053', '5', 'AIN', 'Ain', 'Ain'],\n ['02', '32', '02408', '5', 'AISNE', 'Aisne', 'Aisne'],\n ['03', '84', '03190', '5', 'ALLIER', 'Allier', 'Allier'],\n ['04',\n  '93',\n  '04070',\n  '4',\n  'ALPES DE HAUTE PROVENCE',\n  'Alpes-de-Haute-Provence',\n  'Alpes-de-Haute-Provence']]\n\n\nAvec Pandas, il suffit d’utiliser la fonction read_csv() pour importer le fichier comme un DataFrame, puis la fonction head().\n\ndf_departements = pd.read_csv('data/departement2021.csv')\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\nIl est également possible d’importer un fichier CSV directement à partir d’une URL. C’est particulièrement pratique lorsque les données sont régulièrement mises à jour sur un site web et que l’on souhaite accéder à la version la plus récente sans avoir à télécharger manuellement le fichier à chaque fois. Prenons l’exemple d’un fichier CSV disponible sur le site de l’INSEE : le fichier des prénoms, issu des données de l’état civil. On note au passage une autre fonctionnalité bien pratique : le fichier CSV est compressé (format zip), mais Pandas est capable de le reconnaître et de le décompresser avant de l’importer.\n\n# Importer un fichier CSV depuis une URL\nurl = \"https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\"\ndf_prenoms_url = pd.read_csv(url, sep=\";\")\ndf_prenoms_url.head()\n\n\n\n\n\n\n\n\nsexe\npreusuel\nannais\nnombre\n\n\n\n\n0\n1\n_PRENOMS_RARES\n1900\n1249\n\n\n1\n1\n_PRENOMS_RARES\n1901\n1342\n\n\n2\n1\n_PRENOMS_RARES\n1902\n1330\n\n\n3\n1\n_PRENOMS_RARES\n1903\n1286\n\n\n4\n1\n_PRENOMS_RARES\n1904\n1430\n\n\n\n\n\n\n\nLorsqu’on travaille avec des fichiers CSV, il y a de nombreux arguments optionnels disponibles dans la fonction read_csv() qui permettent d’ajuster le processus d’importation en fonction des spécificités du fichier. Ces arguments peuvent notamment permettre de définir un délimiteur spécifique (comme ci-dessus pour le fichier des prénoms), de sauter certaines lignes en début de fichier, ou encore de définir les types de données pour chaque colonne, et bien d’autres. Tous ces paramètres et leur utilisation sont détaillés dans la documentation officielle.\n\n\n\nUne fois que les données ont été traitées et modifiées au sein de Pandas, il est courant de vouloir exporter le résultat sous forme de fichier CSV pour le partager, l’archiver ou l’utiliser dans d’autres outils. Pandas offre une méthode simple pour cette opération : to_csv(). Supposons par exemple que l’on souhaite exporter les données du DataFrame df_departements spécifiques aux cinq départements d’outre-mer.\n\ndf_departements_dom = df_departements[df_departements[\"DEP\"].isin([\"971\", \"972\", \"973\", \"974\", \"975\"])]\ndf_departements_dom.to_csv('output/departements2021_dom.csv')\n\nUn des arguments clés de la méthode to_csv() est index. Par défaut, index=True, ce qui signifie que l’index du DataFrame sera également écrit dans le fichier CSV. On peut le vérifier en imprimant les premières lignes de notre fichier CSV : Pandas a ajouté une colonne non-nommée, qui contient l’index des lignes retenues.\n\nwith open(\"output/departements2021_dom.csv\") as file_in:\n    for i in range(5):\n        row = next(file_in).strip()\n        print(row)\n\n,DEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n96,971,1,97105,3,GUADELOUPE,Guadeloupe,Guadeloupe\n97,972,2,97209,3,MARTINIQUE,Martinique,Martinique\n98,973,3,97302,3,GUYANE,Guyane,Guyane\n99,974,4,97411,0,LA REUNION,La Réunion,La Réunion\n\n\nDans certains cas, notamment lorsque l’index n’apporte pas d’information utile ou est simplement généré automatiquement par Pandas, on pourrait vouloir l’exclure du fichier exporté. Pour ce faire, on peut définir index=False.\n\ndf_departements_dom.to_csv('output/departements2021_dom_noindex.csv', index=False)\n\n\n\n\nLe format Parquet est un autre format pour le stockage de données tabulaires, de plus en plus fréquemment utilisé. Sans entrer dans les détails techniques, le format Parquet présente différentes caractéristiques qui en font un choix privilégié pour le stockage et le traitement de gros volumes de données. En raison de ces avantages, ce format est de plus en plus utilisé pour la mise à disposition de données à l’Insee. Il est donc essentiel de savoir importer et requêter des fichiers Parquet avec Pandas.\nImporter un fichier Parquet dans un DataFrame Pandas se fait tout aussi facilement que pour un fichier CSV. La fonction se nomme read_parquet().\n\ndf_departements = pd.read_parquet('data/departement2021.parquet')\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\n\n\nLà encore, tout se passe comme dans le monde des CSV : on utilise la méthode to_parquet() pour exporter un DataFrame dans un fichier Parquet. De même, on peut choisir d’exporter ou non l’index, à l’aide du paramètre index (qui vaut True par défaut).\n\ndf_departements_dom = df_departements[df_departements[\"DEP\"].isin([\"971\", \"972\", \"973\", \"974\", \"975\"])]\ndf_departements_dom.to_parquet('output/departements2021_dom.parquet', index=False)\n\nUne des grandes forces du format Parquet, en comparaison des formats texte comme le CSV, est sa capacité à stocker des méta-données, i.e. des données permettant de mieux comprendre les données contenues dans le fichier. En particulier, un fichier Parquet inclut dans ses méta-données le schéma des données (noms des variables, types des variables, etc.), ce qui en fait un format très adapté à la diffusion de données. Vérifions ce comportement en reprenant le DataFrame que nous avons défini précédemment.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf = df.assign(\n    experiment=pd.Categorical(df[\"experiment\"]),\n    date=pd.to_datetime(df[\"date\"])\n)\n\nOn utilise cette fois deux types de données spécifiques, pour les données catégorielles (category) et pour les données temporelles (datetime). On verra plus loin dans le tutoriel comment utiliser ces types. Pour l’instant, notons simplement que Pandas stocke ces types dans le schéma des données.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nVérifions à présent que l’export et le ré-import de ces données en Parquet préserve le schéma.\n\ndf.to_parquet(\"output/df_test_schema.parquet\", index=False)\ndf_test_schema_parquet = pd.read_parquet('output/df_test_schema.parquet')\n\ndf_test_schema_parquet.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nA l’inverse, un fichier CSV ne contenant par définition que du texte, ne permet pas de préserver ces données. Les variables dont nous avons spécifié le type sont importées comme des strings (type object en Pandas).\n\ndf.to_csv(\"output/df_test_schema.csv\", index=False)\ndf_test_schema_csv = pd.read_csv('output/df_test_schema.csv')\n\ndf_test_schema_csv.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   var1        3 non-null      float64\n 1   var2        6 non-null      int64  \n 2   experiment  6 non-null      object \n 3   date        6 non-null      object \n 4   sample      6 non-null      object \ndtypes: float64(1), int64(1), object(3)\nmemory usage: 368.0+ bytes\n\n\n\n\n\n\nLorsqu’on travaille avec des jeux de données volumineux, il est souvent utile de visualiser rapidement un échantillon des données pour avoir une idée de leur structure, de leur format ou encore pour détecter d’éventuels problèmes. Pandas offre plusieurs méthodes pour cela.\nLa méthode head() permet d’afficher les premières lignes du DataFrame. Par défaut, elle retourne les 5 premières lignes, mais on peut spécifier un autre nombre en argument si nécessaire.\n\ndf_departements.head()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\ndf_departements.head(10)\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n0\n01\n84\n01053\n5\nAIN\nAin\nAin\n\n\n1\n02\n32\n02408\n5\nAISNE\nAisne\nAisne\n\n\n2\n03\n84\n03190\n5\nALLIER\nAllier\nAllier\n\n\n3\n04\n93\n04070\n4\nALPES DE HAUTE PROVENCE\nAlpes-de-Haute-Provence\nAlpes-de-Haute-Provence\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n5\n06\n93\n06088\n4\nALPES MARITIMES\nAlpes-Maritimes\nAlpes-Maritimes\n\n\n6\n07\n84\n07186\n5\nARDECHE\nArdèche\nArdèche\n\n\n7\n08\n44\n08105\n4\nARDENNES\nArdennes\nArdennes\n\n\n8\n09\n76\n09122\n5\nARIEGE\nAriège\nAriège\n\n\n9\n10\n44\n10387\n5\nAUBE\nAube\nAube\n\n\n\n\n\n\n\nÀ l’inverse, la méthode tail() donne un aperçu des dernières lignes du DataFrame.\n\ndf_departements.tail()\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n96\n971\n1\n97105\n3\nGUADELOUPE\nGuadeloupe\nGuadeloupe\n\n\n97\n972\n2\n97209\n3\nMARTINIQUE\nMartinique\nMartinique\n\n\n98\n973\n3\n97302\n3\nGUYANE\nGuyane\nGuyane\n\n\n99\n974\n4\n97411\n0\nLA REUNION\nLa Réunion\nLa Réunion\n\n\n100\n976\n6\n97608\n0\nMAYOTTE\nMayotte\nMayotte\n\n\n\n\n\n\n\nL’affichage des premières ou dernières lignes peut parfois ne pas être représentatif de l’ensemble du jeu de données, lorsque les données sont triées par exemple. Afin de minimiser le risque d’obtenir un aperçu biaisé des données, on peut utiliser la méthode sample(), qui sélectionne un un échantillon aléatoire de lignes. Par défaut, elle retourne une seule ligne, mais on peut demander un nombre spécifique de lignes en utilisant l’argument n.\n\ndf_departements.sample(n=5)\n\n\n\n\n\n\n\n\nDEP\nREG\nCHEFLIEU\nTNCC\nNCC\nNCCENR\nLIBELLE\n\n\n\n\n79\n79\n75\n79191\n4\nDEUX SEVRES\nDeux-Sèvres\nDeux-Sèvres\n\n\n85\n85\n52\n85191\n3\nVENDEE\nVendée\nVendée\n\n\n88\n88\n44\n88160\n4\nVOSGES\nVosges\nVosges\n\n\n66\n66\n76\n66136\n4\nPYRENEES ORIENTALES\nPyrénées-Orientales\nPyrénées-Orientales\n\n\n4\n05\n93\n05061\n4\nHAUTES ALPES\nHautes-Alpes\nHautes-Alpes\n\n\n\n\n\n\n\n\n\n\nL’une des premières étapes lors de l’exploration de nouvelles données est de comprendre la structure générale du jeu de données. La méthode info() de Pandas offre une vue d’ensemble rapide des données, notamment en termes de types de données, de présence de valeurs manquantes et de mémoire utilisée.\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 6 entries, 0 to 5\nData columns (total 5 columns):\n #   Column      Non-Null Count  Dtype         \n---  ------      --------------  -----         \n 0   var1        3 non-null      float64       \n 1   var2        6 non-null      int64         \n 2   experiment  6 non-null      category      \n 3   date        6 non-null      datetime64[ns]\n 4   sample      6 non-null      object        \ndtypes: category(1), datetime64[ns](1), float64(1), int64(1), object(1)\nmemory usage: 458.0+ bytes\n\n\nPlusieurs éléments d’information clés peuvent être extraits de ce résultat :\n\nindex : le DataFrame a un RangeIndex, ce qui signifie que l’index est constitué d’une suite numérique simple. Ici, l’index va de 0 à 5, soit 6 entrées au total.\nschéma : la liste des colonnes est affichée avec des informations très utiles sur le schéma des données :\n\nNon-Null Count : le nombre de valeurs non-manquantes (non nan) dans la colonne. Si ce nombre est inférieur au nombre total d’entrées (dans notre cas, 6), cela signifie que la colonne contient des valeurs manquantes. Attention à l’ambiguité possible sur “null” : cela signifie bien les valeurs manquantes, pas les valeurs égales à 0. Ainsi, dans notre cas, le nombre de valeurs “non-null” pour la variable var1 est 5.\nDtype : Le type de données de la colonne, qui permet decomprendre la nature des informations stockées dans chaque colonne. Par exemple, float64 (nombres réels), int32 (nombres entiers), category (variable catégorielle), datetime64[ns] (information temporelle) et object (données textuelles ou mixtes).\n\n\nL’utilisation de info() est un moyen rapide et efficace d’obtenir une vue d’ensemble d’un DataFrame, d’identifier rapidement les colonnes contenant des valeurs manquantes et de comprendre la structure des données.\n\n\n\nEn complément des informations renvoyées par la méthode info(), on peut vouloir obtenir des statistiques descriptives simples afin de visualiser rapidement les distributions des variables. La méthode describe() permet d’avoir une vue synthétique de la distribution des données dans chaque colonne.\n\ndf.describe()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\ncount\n3.00000\n6.000000\n6\n\n\nmean\n2.30000\n-0.500000\n2022-01-03 12:00:00\n\n\nmin\n0.00000\n-8.000000\n2022-01-01 00:00:00\n\n\n25%\n0.65000\n-2.750000\n2022-01-02 06:00:00\n\n\n50%\n1.30000\n-1.500000\n2022-01-03 12:00:00\n\n\n75%\n3.45000\n2.000000\n2022-01-04 18:00:00\n\n\nmax\n5.60000\n8.000000\n2022-01-06 00:00:00\n\n\nstd\n2.93087\n5.468089\nNaN\n\n\n\n\n\n\n\nIl est à noter que describe() ne renvoie des statistiques que pour les colonnes numériques par défaut. Si l’on souhaite inclure des colonnes d’autres types, il est nécessaire de le préciser via l’argument include. Par exemple, df.describe(include='all') renverra des statistiques pour toutes les colonnes, y compris des métriques comme le nombre unique, la valeur la plus fréquente et la fréquence de la valeur la plus fréquente pour les colonnes non numériques.\n\ndf.describe(include='all')\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\ncount\n3.00000\n6.000000\n6\n6\n6\n\n\nunique\nNaN\nNaN\n3\nNaN\n1\n\n\ntop\nNaN\nNaN\ntrain\nNaN\nsample1\n\n\nfreq\nNaN\nNaN\n3\nNaN\n6\n\n\nmean\n2.30000\n-0.500000\nNaN\n2022-01-03 12:00:00\nNaN\n\n\nmin\n0.00000\n-8.000000\nNaN\n2022-01-01 00:00:00\nNaN\n\n\n25%\n0.65000\n-2.750000\nNaN\n2022-01-02 06:00:00\nNaN\n\n\n50%\n1.30000\n-1.500000\nNaN\n2022-01-03 12:00:00\nNaN\n\n\n75%\n3.45000\n2.000000\nNaN\n2022-01-04 18:00:00\nNaN\n\n\nmax\n5.60000\n8.000000\nNaN\n2022-01-06 00:00:00\nNaN\n\n\nstd\n2.93087\n5.468089\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\nNotons que, là encore, la variable count renvoie le nombre de valeurs non-manquantes dans chaque variable.",
    "crumbs": [
      "Manipulation de données",
      "Traiter des données tabulaires avec Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#principales-manipulations-de-données",
    "href": "source/manipulation/pandas/tutorial.html#principales-manipulations-de-données",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "Les opérations de transformation sur les données sont essentielles pour façonner, nettoyer et préparer les données en vue de leur analyse. Les transformations peuvent concerner l’ensemble du DataFrame, des colonnes spécifiques ou encore des lignes spécifiques.\n\n\nPour transformer un DataFrame complet (ou un sous-DataFrame), il est possible d’utiliser des fonctions vectorisées, qui permettent d’appliquer rapidement une opération à l’ensemble des éléments du DataFrame. Cela inclut un certain nombre de méthodes disponibles pour les Series, mais aussi les fonctions mathématiques de NumPy, etc.\nPar exemple, passer chaque valeur numérique d’un DataFrame à la puissance 2 :\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n    }\n)\n\ndf ** 2\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.69\n1\n\n\n1\n31.36\n64\n\n\n2\nNaN\n36\n\n\n3\nNaN\n36\n\n\n4\n0.00\n49\n\n\n5\nNaN\n36\n\n\n\n\n\n\n\nou les passer en valeur absolue :\n\nnp.abs(df)\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n8\n\n\n2\nNaN\n6\n\n\n3\nNaN\n6\n\n\n4\n0.0\n7\n\n\n5\nNaN\n6\n\n\n\n\n\n\n\nCertaines méthodes, disponibles pour les Series, peuvent aussi être utilisées pour transformer un DataFrame complet. Par exemple, la bien utile méthode replace(), qui permet de remplacer toutes les occurences d’une valeur donnée par une autre valeur. Par exemple, supposons que la valeur 0 dans la colonne var1 indique en fait une erreur de mesure. Il serait préférable de la remplacer par une valeur manquante.\n\ndf.replace(0, np.nan)\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n-8\n\n\n2\nNaN\n6\n\n\n3\nNaN\n-6\n\n\n4\nNaN\n7\n\n\n5\nNaN\n6\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssignation ou méthodes in place (en place) ?\n\n\n\nDans l’exemple précédent, l’application de la méthode replace() ne modifie pas directement le DataFrame. Pour que la modifiction soit persistente, une première possibilité est d’assigner le résultat à un objet :\n\ndf = df.replace(0, np.nan)\n\nUne seconde possibilité est, lorsque les méthodes le proposent, d’utiliser l’argument inplace. Lorsque inplace=True, l’opération est effectuée “en place”, et le DataFrame est donc modifié directement.\n\ndf.replace(0, np.nan, inplace=True)\n\nEn pratique, il est préférable de limiter les opérations inplace. Elles ne favorisent pas la reproductibilité des analyses, dans la mesure où la ré-exécution d’une même cellule va donner à chaque fois des résultats différents.\n\n\n\n\n\nDans certains cas, on ne va pas vouloir appliquer les transformations à l’ensemble des données, mais à des variables spécifiques. Les transformations qui sont possibles à l’échelle du DataFrame (fonctions vectorisées, méthodes comme replace(), etc.) restent naturellement possibles à l’échelle d’une colonne.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n    }\n)\n\nnp.abs(df[\"var2\"])\n\n0    5\n1    7\n2    1\n3    2\n4    8\n5    6\nName: var2, dtype: int64\n\n\n\ndf[\"var1\"].replace(0, np.nan)\n\n0    1.3\n1    5.6\n2    NaN\n3    NaN\n4    NaN\n5    NaN\nName: var1, dtype: float64\n\n\nMais il existe d’autres transformations que l’on applique généralement au niveau d’une ou de quelques colonnes. Par exemple, lorsque le schéma n’a pas été bien reconnu à l’import, il peut arriver que des variables numériques soient définies comme des string (type object en Pandas).\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan],\n        \"var2\": [\"1\", \"5\", \"18\"],\n    }\n)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   var1    2 non-null      float64\n 1   var2    3 non-null      object \ndtypes: float64(1), object(1)\nmemory usage: 176.0+ bytes\n\n\nDans ce cas, on peut utiliser la méthode astype pour convertir la colonne dans le type souhaité.\n\ndf['var2'] = df['var2'].astype(int)\n\ndf.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 3 entries, 0 to 2\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   var1    2 non-null      float64\n 1   var2    3 non-null      int64  \ndtypes: float64(1), int64(1)\nmemory usage: 176.0 bytes\n\n\nUne autre opération fréquente est le renommage d’une ou plusieurs colonnes. Pour cela, on peut utiliser la méthode rename(), à laquelle on passe un dictionnaire qui contient autant de couples clé-valeur que de variables à renommer, et dans lequel chaque couple clé-valeur est de la forme 'ancien_nom': 'nouveau_nom'.\n\ndf.rename(columns={'var2': 'age'})\n\n\n\n\n\n\n\n\nvar1\nage\n\n\n\n\n0\n1.3\n1\n\n\n1\n5.6\n5\n\n\n2\nNaN\n18\n\n\n\n\n\n\n\nEnfin, on peut souhaiter supprimer du DataFrame des colonnes qui ne sont pas ou plus utiles à l’analyse. Pour cela, on utilise la méthode drop(), à laquelle on passe soit un string (nom d’une colonne si l’on souhaite n’en supprimer qu’une seule) ou une liste de noms de colonne à supprimer.\n\ndf.drop(columns=['var1'])\n\n\n\n\n\n\n\n\nvar2\n\n\n\n\n0\n1\n\n\n1\n5\n\n\n2\n18\n\n\n\n\n\n\n\n\n\n\nEn statistiques, on applique généralement des tranformations faisant intervenir une ou plusieurs colonnes. Néanmoins, dans certains cas, il est nécessaire d’appliquer des transformations au niveau des lignes. Pour cela, on peut utiliser la méthode apply() de Pandas, appliquée à l’axe des lignes (axis=1). Illustrons son fonctionnement avec un cas simple. Pour cela, on génère d’abord des données.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\"],\n    }\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nOn applique maintenant la fonction apply() au DataFrame afin de calculer une nouvelle variable qui est la somme des deux existantes.\n\ndf['sum_row'] = df.apply(lambda row: row['var1'] + row['var2'], axis=1)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n\n\n1\n5\n7\n2022-01-02\n12\n\n\n2\n9\n11\n2022-01-03\n20\n\n\n3\n13\n15\n2022-01-04\n28\n\n\n\n\n\n\n\n\n\n\n\n\n\nLes fonctions lambda\n\n\n\nUne fonction lambda est une petite fonction anonyme. Elle peut prendre n’importe quel nombre d’arguments, mais ne peut avoir qu’une seule expression. Dans l’exemple ci-dessus, la fonction lambda prend une ligne en argument et renvoie la somme des colonnes var1 et var2 pour cette ligne.\nLes fonctions lambda permettent de définir simplement des fonctions “à la volée”, sans devoir leur donner un nom. Dans notre exemple, cela aurait été parfaitement équivalent au code suivant :\n\ndef sum_row(row):\n    return row['var1'] + row['var2']\n\ndf['sum_row'] = df.apply(sum_row, axis=1)\n\n\n\nBien que apply() offre une grande flexibilité, elle n’est pas la méthode la plus efficiente, notamment pour de grands jeux de données. Les opérations vectorisées sont toujours préférables car elles traitent les données en bloc plutôt que ligne par ligne. Dans notre cas, il aurait été bien entendu préférable de créer notre variable en utilisant des opérations sur les colonnes.\n\ndf['sum_row_vect'] = df['var1'] + df['var2']\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\nsum_row_vect\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n4\n\n\n1\n5\n7\n2022-01-02\n12\n12\n\n\n2\n9\n11\n2022-01-03\n20\n20\n\n\n3\n13\n15\n2022-01-04\n28\n28\n\n\n\n\n\n\n\nNéanmoins, on peut se retrouver dans certains (rares) cas où une opération ne peut pas être facilement vectorisée ou où la logique est complexe. Supposons par exemple que l’on souhaite combiner les valeurs de plusieurs colonnes en fonction de certaines conditions.\n\ndef combine_columns(row):\n    if row['var1'] &gt; 6:\n        return str(row['var2'])\n    else:\n        return str(row['var2']) + \"_\" + row['date']\n\ndf['combined_column'] = df.apply(combine_columns, axis=1)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsum_row\nsum_row_vect\ncombined_column\n\n\n\n\n0\n1\n3\n2022-01-01\n4\n4\n3_2022-01-01\n\n\n1\n5\n7\n2022-01-02\n12\n12\n7_2022-01-02\n\n\n2\n9\n11\n2022-01-03\n20\n20\n11\n\n\n3\n13\n15\n2022-01-04\n28\n28\n15\n\n\n\n\n\n\n\n\n\n\n\nLe tri des données est particulièrement utile pour l’exploration et la visualisation de données. Avec Pandas, on utilise la méthode sort_values() pour trier les valeurs d’un DataFrame selon une ou plusieurs colonnes.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\"],\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nPour trier les valeurs selon une seule colonne, il suffit de passer le nom de la colonne en paramètre.\n\ndf.sort_values(by='var1')\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n0\n1\n3\n2022-01-01\n\n\n1\n5\n7\n2022-01-02\n\n\n2\n9\n11\n2022-01-03\n\n\n3\n13\n15\n2022-01-04\n\n\n\n\n\n\n\nPar défaut, le tri est effectué dans l’ordre croissant. Pour trier les valeurs dans un ordre décroissant, il suffit de paramétrer ascending=False.\n\ndf.sort_values(by='var1', ascending=False)\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\n\n\n\n\n3\n13\n15\n2022-01-04\n\n\n2\n9\n11\n2022-01-03\n\n\n1\n5\n7\n2022-01-02\n\n\n0\n1\n3\n2022-01-01\n\n\n\n\n\n\n\nSi on souhaite trier le DataFrame sur plusieurs colonnes, on peut fournir une liste de noms de colonnes. On peut également choisir de trier de manière croissante pour certaines colonnes et décroissante pour d’autres.\n\n\n\nL’agrégation des données est un processus dans lequel les données vont être ventilées en groupes selon certains critères, puis agrégées selon une fonction d’agrégation appliquée indépendamment à chaque groupe. Cette opération est courante lors de l’analyse exploratoire ou lors du prétraitement des données pour la visualisation ou la modélisation statistique.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"train\", \"train\", \"validation\"],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2022-01-03\", \"2022-01-04\", \"2022-01-05\", \"2022-01-06\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf.head()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\ndate\nsample\n\n\n\n\n0\n1.3\n-9\ntest\n2022-01-01\nsample1\n\n\n1\n5.6\n7\ntrain\n2022-01-02\nsample1\n\n\n2\nNaN\n8\ntest\n2022-01-03\nsample1\n\n\n3\nNaN\n-3\ntrain\n2022-01-04\nsample1\n\n\n4\n0.0\n-2\ntrain\n2022-01-05\nsample1\n\n\n\n\n\n\n\n\n\nLa méthode groupBy de Pandas permet de diviser le DataFrame en sous-ensembles selon les valeurs d’une ou plusieurs colonnes, puis d’appliquer une fonction d’agrégation à chaque sous-ensemble. Elle renvoie un objet de type DataFrameGroupBy qui ne présente pas de grand intérêt en soi, mais constitue l’étape intermédiaire indispensable pour pouvoir ensuite appliquer une ou plusieurs fonction(s) d’agrégation aux différents groupes.\n\ndf.groupby('experiment')\n\n&lt;pandas.core.groupby.generic.DataFrameGroupBy object at 0x7f5ad8479930&gt;\n\n\n\n\n\nUne fois les données groupées, on peut appliquer des fonctions d’agrégation pour obtenir un résumé statistique. Pandas intègre un certain nombre de ces fonctions, dont la liste complète est détaillée dans la documentation. Voici quelques exemples d’utilisation de ces méthodes.\nPar exemple, compter le nombre d’occurrences dans chaque groupe.\n\ndf.groupby('experiment').size()\n\nexperiment\ntest          2\ntrain         3\nvalidation    1\ndtype: int64\n\n\nCalculer la somme d’une variable par groupe.\n\ndf.groupby('experiment')['var1'].sum()\n\nexperiment\ntest          1.3\ntrain         5.6\nvalidation    0.0\nName: var1, dtype: float64\n\n\nOu encore compter le nombre de valeurs unique d’une variable par groupe. Les possibilités sont nombreuses.\n\n# Pour le nombre de valeurs uniques de 'var2' dans chaque groupe\ndf.groupby('experiment')['var2'].nunique()\n\nexperiment\ntest          2\ntrain         3\nvalidation    1\nName: var2, dtype: int64\n\n\nLorsqu’on souhaite appliquer plusieurs fonctions d’agrégation à la fois ou des fonctions personnalisées, on utilise la méthode agg. Cette méthode accepte une liste de fonctions ou un dictionnaire qui associe les noms des colonnes aux fonctions à appliquer. Cela permet d’appliquer plus finement les fonctions d’agrégation.\n\ndf.groupby('experiment').agg({'var1': 'mean', 'var2': 'count'})\n\n\n\n\n\n\n\n\nvar1\nvar2\n\n\nexperiment\n\n\n\n\n\n\ntest\n1.3\n2\n\n\ntrain\n2.8\n3\n\n\nvalidation\nNaN\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\nLe chaînage de méthodes\n\n\n\nLes exemples précédents illustrent un concept important en Pandas : le chaînage de méthodes. Ce terme désigne la possibilité d’enchaîner les transformations appliquées à un DataFrame en lui appliquant à la chaîne des méthodes. A chaque méthode appliquée, un DataFrame intermédiaire est créé (mais non assigné à une variable), qui devient l’input de la méthode suivante.\nLe chaînage de méthodes permet de combiner plusieurs opérations en une seule expression de code. Cela peut améliorer l’efficacité en évitant les assignations intermédiaires et en rendant le code plus fluide et plus facile à lire. Cela favorise également un style de programmation fonctionnel où les données passent à travers une chaîne de transformations de manière fluide.\n\n\n\n\n\nIl est intéressant de noter les effets du processus d’agrégation sur l’index du DataFrame. Le dernier exemple ci-dessus l’illustre bien : les groupes, i.e. les modalités de la variable utilisée pour effectuer l’agrégation, deviennent les valeurs de l’index.\nOn peut vouloir réutiliser cette information dans des analyses ultérieures, et donc la vouloir comme une colonne. Il suffit pour cela de réinitialiser l’index avec la méthode reset_index().\n\ndf_agg = df.groupby('experiment').agg({'var1': 'mean', 'var2': 'count'})\ndf_agg.reset_index()\n\n\n\n\n\n\n\n\nexperiment\nvar1\nvar2\n\n\n\n\n0\ntest\n1.3\n2\n\n\n1\ntrain\n2.8\n3\n\n\n2\nvalidation\nNaN\n1\n\n\n\n\n\n\n\n\n\n\n\nLes valeurs manquantes sont une réalité courante dans le traitement des données réelles et peuvent survenir pour diverses raisons, telles que des non-réponses à un questionnaire, des erreurs de saisie, des pertes de données lors de la transmission ou simplement parce que l’information n’est pas applicable. Pandas offre plusieurs outils pour gérer les valeurs manquantes.\n\n\nDans Pandas, les valeurs manquantes sont généralement représentées par np.nan, qui est un marqueur spécial fourni par la bibliothèque NumPy. S’il est préférable d’utiliser cet objet pour dénoter les valeurs manquantes, notons que l’objet None de Python est également compris comme une valeur manquante par Pandas.\nVérifions cette propriété. Pour identifier où se trouvent les valeurs manquantes, on utilise la fonction isna() qui retourne un DataFrame booléen indiquant True là où les valeurs sont NaN.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", None, \"train\", \"validation\"],\n        \"sample\": \"sample1\"\n    }\n)\n\ndf.isna()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\n\n\n0\nFalse\nFalse\nFalse\nFalse\n\n\n1\nFalse\nFalse\nFalse\nFalse\n\n\n2\nTrue\nFalse\nFalse\nFalse\n\n\n3\nTrue\nFalse\nTrue\nFalse\n\n\n4\nFalse\nFalse\nFalse\nFalse\n\n\n5\nTrue\nFalse\nFalse\nFalse\n\n\n\n\n\n\n\n\n\n\nLors de calculs statistiques, les valeurs manquantes sont généralement ignorées. Par exemple, la méthode .mean() calcule la moyenne des valeurs non manquantes.\n\ndf['var1'].mean()\n\nnp.float64(2.3)\n\n\nEn revanche, les calculs faisant intervenir plusieurs colonnes n’ignorent pas toujours les valeurs manquantes et peuvent souvent donner des résultats en NaN.\n\ndf['var3'] = df['var1'] + df['var2']\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nvar3\n\n\n\n\n0\n1.3\n8\ntest\nsample1\n9.3\n\n\n1\n5.6\n4\ntrain\nsample1\n9.6\n\n\n2\nNaN\n-3\ntest\nsample1\nNaN\n\n\n3\nNaN\n5\nNone\nsample1\nNaN\n\n\n4\n0.0\n-10\ntrain\nsample1\n-10.0\n\n\n5\nNaN\n-6\nvalidation\nsample1\nNaN\n\n\n\n\n\n\n\n\n\n\nLa méthode dropna() permet de supprimer les lignes (axis=0) ou les colonnes (axis=1) contenant des valeurs manquantes. Par défaut, toute ligne contenant au moins une valeur manquante est supprimée.\n\ndf.dropna()\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nvar3\n\n\n\n\n0\n1.3\n8\ntest\nsample1\n9.3\n\n\n1\n5.6\n4\ntrain\nsample1\n9.6\n\n\n4\n0.0\n-10\ntrain\nsample1\n-10.0\n\n\n\n\n\n\n\nEn modifiant le paramètre axis, on peut demander à ce que toute colonne contenant au moins une valeur manquante soit supprimée.\n\ndf.dropna(axis=1)\n\n\n\n\n\n\n\n\nvar2\nsample\n\n\n\n\n0\n8\nsample1\n\n\n1\n4\nsample1\n\n\n2\n-3\nsample1\n\n\n3\n5\nsample1\n\n\n4\n-10\nsample1\n\n\n5\n-6\nsample1\n\n\n\n\n\n\n\nEnfin, le paramètre how définit la modalité de supression. Par défaut, une ligne ou colonne est supprimée lorsqu’au moins une valeur est manquante (how=any), mais il est possible de ne supprimer la ligne/colonne que lorsque toutes les valeurs sont manquantes (how=all).\n\n\n\nPour gérer les valeurs manquantes dans un DataFrame, une approche commune est l’imputation, qui consiste à remplacer les valeurs manquantes par d’autres valeurs. La méthode fillna() permet d’effectuer cette opération de différentes manières. Une première possibilité est le remplacement par une valeur constante.\n\ndf['var1'].fillna(value=0)\n\n0    1.3\n1    5.6\n2    0.0\n3    0.0\n4    0.0\n5    0.0\nName: var1, dtype: float64\n\n\n\n\n\n\n\n\nChangement de représentation des valeurs manquantes\n\n\n\nOn peut parfois être tentant de changer la manifestation d’une valeur manquante pour des raisons de visibilité, par exemple en la remplaçant par une chaîne de caractères :\n\ndf['var1'].fillna(value=\"MISSING\")\n\n0        1.3\n1        5.6\n2    MISSING\n3    MISSING\n4        0.0\n5    MISSING\nName: var1, dtype: object\n\n\nEn pratique, cette façon de faire n’est pas recommandée. Il est en effet préférable de conserver la convention standard de Pandas (l’utilisation des np.nan), d’abord pour des questions de standardisation des pratiques qui facilitent la lecture et la maintenance du code, mais également parce que la convention standard est optimisée pour la performance et les calculs à partir de données contenant des valeurs manquantes.\n\n\nUne autre méthode d’imputation fréquente est d’utiliser une valeur statistique, comme la moyenne ou la médiane de la variable.\n\ndf['var1'].fillna(value=df['var1'].mean())\n\n0    1.3\n1    5.6\n2    2.3\n3    2.3\n4    0.0\n5    2.3\nName: var1, dtype: float64\n\n\n\n\n\n\n\n\nBiais d’imputation\n\n\n\nRemplacer les valeurs manquantes par une valeur constante, telle que zéro, la moyenne ou la médiane, peut être problématique. Si les données ne sont pas manquantes au hasard (Missing Not At Random - MNAR), cela peut introduire un biais dans l’analyse. Les variables MNAR sont des variables dont la probabilité d’être manquantes est liée à leur propre valeur ou à d’autres variables dans les données. Dans de tels cas, une imputation plus sophistiquée peut être nécessaire pour minimiser les distorsions. Nous en verrons un exemple en exercice de fin de tutoriel.\n\n\n\n\n\n\n\n\nLes données textuelles nécessitent souvent un nettoyage et une préparation avant l’analyse. Pandas fournit via la librairie de méthodes str un ensemble d’opérations vectorisées qui rendent la préparation des données textuelles à la fois simple et très efficace. Là encore, les possibilités sont multiples et détaillées dans la documentation. Nous présentons ici les méthodes les plus fréquemment utilisées dans l’analyse de données.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", \"test\", \"train\", \"validation\"],\n        \"sample\": [\"  sample1\", \"sample1\", \"sample2\", \"   sample2   \", \"sample2  \", \"sample1\"]\n    }\n)\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n\n\n1\n5.6\n-6\ntrain\nsample1\n\n\n2\nNaN\n-3\ntest\nsample2\n\n\n3\nNaN\n6\ntest\nsample2\n\n\n4\n0.0\n-9\ntrain\nsample2\n\n\n5\nNaN\n0\nvalidation\nsample1\n\n\n\n\n\n\n\nUne première opération fréquente consiste à extraire certains caractères d’une chaîne. On utilise pour cela la fonction (à la syntaxe un peu particulière) str[n:] Par exemple, si l’on veut extraire le dernier caractère de la variable sample afin de ne retenir que le chiffre de l’échantillon.\n\ndf[\"sample_n\"] = df[\"sample\"].str[-1:]\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-6\ntrain\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n\n\n\n4\n0.0\n-9\ntrain\nsample2\n\n\n\n5\nNaN\n0\nvalidation\nsample1\n1\n\n\n\n\n\n\n\nLe principe était le bon, mais la présence d’espaces superflus dans nos données textuelles (qui ne se voyaient pas à la visualisation du DataFrame !) a rendu l’opération plus difficile que prévue. C’est l’occasion d’introduire la famille de méthode strip (.str.strip(), .str.lstrip() et .str.rstrip()) qui respectivement retirent les espaces superflus des deux côtés ou d’un seul.\n\ndf[\"sample\"] = df[\"sample\"].str.strip()\ndf[\"sample_n\"] = df[\"sample\"].str[-1:]\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-6\ntrain\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n2\n\n\n4\n0.0\n-9\ntrain\nsample2\n2\n\n\n5\nNaN\n0\nvalidation\nsample1\n1\n\n\n\n\n\n\n\nOn peut également vouloir filtrer un DataFrame en fonction de la présence ou non d’une certaine chaîne (ou sous-chaîne) de caractères. On utilise pour cela la méthode .str.contains().\n\ndf[df['experiment'].str.contains('test')]\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n2\n\n\n\n\n\n\n\nEnfin, on peut vouloir remplacer une chaîne (ou sous-chaîne) de caractères par une autre, ce que permet la méthode str.replace().\n\ndf['experiment'] = df['experiment'].str.replace('validation', 'val')\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\nsample\nsample_n\n\n\n\n\n0\n1.3\n-3\ntest\nsample1\n1\n\n\n1\n5.6\n-6\ntrain\nsample1\n1\n\n\n2\nNaN\n-3\ntest\nsample2\n2\n\n\n3\nNaN\n6\ntest\nsample2\n2\n\n\n4\n0.0\n-9\ntrain\nsample2\n2\n\n\n5\nNaN\n0\nval\nsample1\n1\n\n\n\n\n\n\n\n\n\n\nLes données catégorielles sont des variables qui contiennent un nombre restreint de modalités. A l’instar de R avec la notion de factor, Pandas a un type de données spécial, category, qui est utile pour représenter des données catégorielles de manière plus efficace et plus informative. Les données catégorielles sont en effet optimisées pour certains types de données et peuvent accélérer les opérations comme le groupement et le tri. Elles sont également utiles pour la visualisation, car elles permettent d’assurer que les catégories sont affichées dans un ordre cohérent et logique.\nPour convertir une variable au format category, on utilise la méthode astype().\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1.3, 5.6, np.nan, np.nan, 0, np.nan],\n        \"var2\": np.random.randint(-10, 10, 6),\n        \"experiment\": [\"test\", \"train\", \"test\", None, \"train\", \"validation\"],\n    }\n)\nprint(df.dtypes)\n\nvar1          float64\nvar2            int64\nexperiment     object\ndtype: object\n\n\n\ndf['experiment'] = df['experiment'].astype('category')\n\nprint(df.dtypes)\n\nvar1           float64\nvar2             int64\nexperiment    category\ndtype: object\n\n\nCette conversion nous donne accès à quelques méthodes bien pratiques, spécifiques au traitement des variables catégorielles. Il peut par exemple être utile de renommer les catégories pour des raisons de clarté ou de standardisation.\n\ndf['experiment'] = df['experiment'].cat.rename_categories({'test': 'Test', 'train': 'Train', 'validation': 'Validation'})\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\nexperiment\n\n\n\n\n0\n1.3\n4\nTest\n\n\n1\n5.6\n9\nTrain\n\n\n2\nNaN\n-2\nTest\n\n\n3\nNaN\n-4\nNaN\n\n\n4\n0.0\n-8\nTrain\n\n\n5\nNaN\n0\nValidation\n\n\n\n\n\n\n\nParfois, l’ordre des catégories est significatif, et on peut vouloir le modifier. En particulier dans le cadre de la visualisation, car les modalités seront par défaut affichées dans l’ordre spécifié.\n\ndf_cat = df['experiment'].cat.reorder_categories(['Test', 'Train', 'Validation'], ordered=True)\ndf.groupby(\"experiment\").mean().plot(kind='bar')\n\n/tmp/ipykernel_2611/419168969.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  df.groupby(\"experiment\").mean().plot(kind='bar')\n\n\n\n\n\n\n\n\n\n\n\n\nLes données temporelles sont souvent présentes dans les données tabulaires afin d’identifier temporellement les observations recueillies. Pandas offre des fonctionnalités pour manipuler ces types de données, notamment grâce au type datetime64 qui permet une manipulation précise des dates et des heures.\n\ndf = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5, 9, 13],\n        \"var2\": [3, 7, 11, 15],\n        \"date\": [\"2022-01-01\", \"2022-01-02\", \"2023-01-01\", \"2023-01-02\"],\n        \"sample\": [\"sample1\", \"sample1\", \"sample2\", \"sample2\"]\n    }\n)\n\ndf.dtypes\n\nvar1       int64\nvar2       int64\ndate      object\nsample    object\ndtype: object\n\n\nPour manipuler les données temporelles, il est nécessaire de convertir les chaînes de caractères en objets datetime. Pandas le fait via la fonction to_datetime().\n\ndf['date'] = pd.to_datetime(df['date'])\n\ndf.dtypes\n\nvar1               int64\nvar2               int64\ndate      datetime64[ns]\nsample            object\ndtype: object\n\n\nUne fois converties, les dates peuvent être formatées, comparées et utilisées dans des calculs. En particulier, Pandas comprend à présent l’“ordre” des dates présentes dans les données, et permet donc le filtrage sur des périodes données.\n\ndf[(df['date'] &gt;= \"2022-01-01\") & (df['date'] &lt; \"2022-01-03\")]\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n\n\n\n\n\nOn peut également vouloir réaliser des filtrages moins précis, faisant intervenir l’année ou le mois. Pandas permet d’extraire facilement des composants spécifiques de la date, comme l’année, le mois, le jour, l’heure, etc.\n\ndf['year'] = df['date'].dt.year\ndf['month'] = df['date'].dt.month\ndf['day'] = df['date'].dt.day\n\ndf[df['year'] == 2023]\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\nyear\nmonth\nday\n\n\n\n\n2\n9\n11\n2023-01-01\nsample2\n2023\n1\n1\n\n\n3\n13\n15\n2023-01-02\nsample2\n2023\n1\n2\n\n\n\n\n\n\n\nEnfin, les calculs faisant intervenir des dates deviennent possible. On peut ajouter ou soustraire des périodes temporelles à des dates, et les comparer entre elles. Les fonctions utilisées sont issues de Pandas, mais sont très semblables dans leur fonctionnement à celles du module time de Python.\nOn peut par exemple ajouter des intervalles de temps, ou bien calculer des écarts à une date de référence.\n\ndf['date_plus_one'] = df['date'] + pd.Timedelta(days=1)\ndf['date_diff'] = df['date'] - pd.to_datetime('2022-01-01')\n\ndf\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\nyear\nmonth\nday\ndate_plus_one\ndate_diff\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n2022\n1\n1\n2022-01-02\n0 days\n\n\n1\n5\n7\n2022-01-02\nsample1\n2022\n1\n2\n2022-01-03\n1 days\n\n\n2\n9\n11\n2023-01-01\nsample2\n2023\n1\n1\n2023-01-02\n365 days\n\n\n3\n13\n15\n2023-01-02\nsample2\n2023\n1\n2\n2023-01-03\n366 days\n\n\n\n\n\n\n\n\n\n\n\nDans le cadre d’une analyse de données, il est courant de vouloir combiner différentes sources de données. Cette combinaison peut se faire verticalement (un DataFrame par dessus l’autre), par exemple lorsque l’on souhaite combiner deux millésimes d’une même enquête afin de les analyser conjointement. La combinaison peut également se faire horizontalement (côte à côte) selon une ou plusieurs clé(s) de jointure, souvent dans le but d’enrichir une source de données à partir d’une autre source portant sur les mêmes unités statistiques.\n\n\nLa concaténation verticale de tables se fait à l’aide de la fonction concat() de Pandas.\n\ndf1 = pd.DataFrame(\n    data = {\n        \"var1\": [1, 5],\n        \"var2\": [3, 7],\n        \"date\": [\"2022-01-01\", \"2022-01-02\"],\n        \"sample\": [\"sample1\", \"sample1\"]\n    }\n)\n\ndf2 = pd.DataFrame(\n    data = {\n        \"var1\": [9, 13],\n        \"date\": [\"2023-01-01\", \"2023-01-02\"],\n        \"var2\": [11, 15],\n        \"sample\": [\"sample2\", \"sample2\"]\n    }\n)\n\ndf_concat = pd.concat([df1, df2])\n\ndf_concat\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n0\n9\n11\n2023-01-01\nsample2\n\n\n1\n13\n15\n2023-01-02\nsample2\n\n\n\n\n\n\n\nNotons que l’ordre des variables dans les deux DataFrames n’est pas important. Pandas ne juxtapose pas “bêtement” les deux DataFrames, il fait une correspondance des schémas pour faire correspondre les variables par nom. Si deux variables ont le même nom mais pas le même type - par exemple dans le cas où une variable numérique aurait été interprétée comme des strings - Pandas va résoudre le problème en prenant le dénominateur commun, c’est à dire en général convertir en strings (type object).\nPar contre, la concaténation précédente laisse apparaître un problème de répétition au niveau de l’index. C’est logique : on n’a pas spécifié d’index pour nos deux DataFrames initiaux, qui ont donc le même index de position ([0, 1]). Dans ce cas (où l’index n’est pas important), on peut passer le paramètre ignore_index=True pour reconstruire de zéro l’index final.\n\ndf_concat = pd.concat([df1, df2], ignore_index=True)\n\ndf_concat\n\n\n\n\n\n\n\n\nvar1\nvar2\ndate\nsample\n\n\n\n\n0\n1\n3\n2022-01-01\nsample1\n\n\n1\n5\n7\n2022-01-02\nsample1\n\n\n2\n9\n11\n2023-01-01\nsample2\n\n\n3\n13\n15\n2023-01-02\nsample2\n\n\n\n\n\n\n\n\n\n\n\n\n\nConstruction itérative d’un DataFrame\n\n\n\nOn pourrait avoir l’idée d’utiliser pd.concat() pour construire un DataFrame de manière itérative, en ajoutant à chaque itération d’une boucle une nouvelle ligne au DataFrame existant. Ce n’est néanmoins pas une bonne idée : comme nous l’avons vu, un DataFrame est représenté dans la mémoire commme une juxtaposition de Series. Ainsi, ajouter une colonne à un DataFrame est peu coûteux, mais ajouter une ligne implique de modifier chaque élément constituant du DataFrame. Pour construire un DataFrame, il est donc plutôt conseillé de stocker les lignes dans une liste de listes (une par colonne) ou un dictionnaire, puis d’appeler pd.DataFrame() pour construire le DataFrame, comme nous l’avons fait au début de ce tutoriel.\n\n\n\n\n\nLa fusion de tables est une opération qui permet d’associer des lignes de deux DataFrames différents en se basant sur une ou plusieurs clés communes, similaire aux jointures dans les bases de données SQL. Différents types de jointure sont possible selon les données que l’on souhaite conserver, dont les principaux sont représentés sur le graphique suivant.\n\nSource : lien\nEn Pandas, les jointures se font avec la fonction merge(). Pour réaliser une jointure, on doit spécifier (au minimum) deux informations :\n\nle type de jointure : par défaut, Pandas effectue une jointure de type inner. Le paramètre how permet de spécifier d’autres types de jointure ;\nla clé de jointure. Par défaut, Pandas essaie de joindre les deux DataFrames à partir de leurs index. En pratique, on spécifie souvent une variable présente dans le DataFrames comme clé de jointure (paramètre on si la variable porte le même nom dans les deux DataFrame, ou left_on et right_on sinon).\n\nAnalysons la différence entre les différents types de jointure à travers des exemples.\n\ndf_a = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K3', 'K4'],\n    'A': ['A0', 'A1', 'A2', 'A3', 'A4'],\n    'B': ['B0', 'B1', 'B2', 'B3', 'A4']\n})\n\ndf_b = pd.DataFrame({\n    'key': ['K0', 'K1', 'K2', 'K5', 'K6'],\n    'C': ['C0', 'C1', 'C2', 'C5', 'C6'],\n    'D': ['D0', 'D1', 'D2', 'D5', 'D6']\n})\n\ndisplay(df_a)\ndisplay(df_b)\n\n\n\n\n\n\n\n\nkey\nA\nB\n\n\n\n\n0\nK0\nA0\nB0\n\n\n1\nK1\nA1\nB1\n\n\n2\nK2\nA2\nB2\n\n\n3\nK3\nA3\nB3\n\n\n4\nK4\nA4\nA4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkey\nC\nD\n\n\n\n\n0\nK0\nC0\nD0\n\n\n1\nK1\nC1\nD1\n\n\n2\nK2\nC2\nD2\n\n\n3\nK5\nC5\nD5\n\n\n4\nK6\nC6\nD6\n\n\n\n\n\n\n\nLa jointure de type inner conserve les observations dont la clé est présente dans les deux DataFrame.\n\ndf_merged_inner = pd.merge(df_a, df_b, on='key')\ndf_merged_inner\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n\n\n\n\n\n\n\n\n\n\n\nJointures inner\n\n\n\nLa jointure de type inner est la plus intuitive : elle ne crée généralement pas de valeurs manquantes et permet donc de travailler directement sur la table fusionnée. Mais attention : si beaucoup de clés ne sont pas présentes dans les deux DataFrames à la fois, une jointure inner peut aboutit à des pertes importantes de données, et donc à des résultats finaux biaisés. Dans ce cas, il vaut mieux choisir une jointure à gauche ou à droite, selon la source que l’on cherche à enrichir et pour laquelle il est donc le plus important de limiter les pertes de données.\n\n\nUne jointure de type left conserve toutes les observations contenues dans le DataFrame de gauche (premier DataFrame spécifié dans pd.merge()). Par conséquent, si des clés sont présentes dans le DataFrame de gauche mais pas dans celui de droite, le DataFrame final contient des valeurs manquantes au niveau de ces observations (pour les variables du DataFrame de droite).\n\ndf_merged_left = pd.merge(df_a, df_b, how=\"left\", on='key')\ndf_merged_left\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n3\nK3\nA3\nB3\nNaN\nNaN\n\n\n4\nK4\nA4\nA4\nNaN\nNaN\n\n\n\n\n\n\n\nLa jointure de type outer contient toutes les observations et variables contenues dans les deux DataFrame. Ainsi, l’information retenue est maximale, mais en contrepartie les valeurs manquantes peuvent être assez nombreuses. Il sera donc nécessaire de bien traiter les valeurs manquantes avant de procéder aux analyses.\n\ndf_merged_outer = pd.merge(df_a, df_b, how=\"outer\", on='key')\ndf_merged_outer\n\n\n\n\n\n\n\n\nkey\nA\nB\nC\nD\n\n\n\n\n0\nK0\nA0\nB0\nC0\nD0\n\n\n1\nK1\nA1\nB1\nC1\nD1\n\n\n2\nK2\nA2\nB2\nC2\nD2\n\n\n3\nK3\nA3\nB3\nNaN\nNaN\n\n\n4\nK4\nA4\nA4\nNaN\nNaN\n\n\n5\nK5\nNaN\nNaN\nC5\nD5\n\n\n6\nK6\nNaN\nNaN\nC6\nD6",
    "crumbs": [
      "Manipulation de données",
      "Traiter des données tabulaires avec Pandas"
    ]
  },
  {
    "objectID": "source/manipulation/pandas/tutorial.html#exercices",
    "href": "source/manipulation/pandas/tutorial.html#exercices",
    "title": "Traiter des données tabulaires avec Pandas",
    "section": "",
    "text": "1/ Qu’est-ce qu’un DataFrame dans le contexte de Pandas et à quel type de structure de données peut-on le comparer dans le langage Python ?\n2/ Quelle est la différence fondamentale entre un array Numpy et une Pandas Series ?\n3/ Quel est le lien entre Series et DataFrame dans Pandas ?\n4/ Comment sont structurées les données dans un DataFrame Pandas ?\n5/ Quel est le rôle de l’index dans un DataFrame Pandas et comment peut-il être utilisé lors de la manipulation des données ?\n6/ Quelles méthodes pouvez-vous utiliser pour explorer un DataFrame inconnu et en apprendre davantage sur son contenu et sa structure ?\n7/ Dans Pandas, quelle est la différence entre assigner le résultat d’une opération à une nouvelle variable et utiliser une méthode avec l’argument inplace=True ?\n8/ Comment s’applique le principe de la vectorisation dans Pandas et pourquoi est-ce avantageux pour manipuler les données ?\n9/ Comment Pandas représente-t-il les valeurs manquantes et quel impact cela a-t-il sur les calculs et les transformations de données ?\n10/ Quelle est la différence entre concaténer deux DataFrames et les joindre via une jointure, et quand utiliseriez-vous l’une plutôt que l’autre ?\n\n\n\n\nAfficher la solution\n\n\n1/ Un DataFrame dans Pandas est une structure de données bidimensionnelle, comparable à un tableau ou une feuille de calcul Excel. Dans le contexte Python, on peut le comparer à un dictionnaire d’arrays NumPy, où les clés sont les noms des colonnes et les valeurs sont les colonnes elles-mêmes.\n2/ La différence principale entre un array NumPy et une Series Pandas est que la Series peut contenir des données étiquetées, c’est-à-dire qu’elle a un index qui lui est associé, permettant des accès et des manipulations par label.\n3/ Un DataFrame est essentiellement une collection de Series. Chaque colonne d’un DataFrame est une Series, et toutes ces Series partagent le même index, qui correspond aux étiquettes des lignes du DataFrame.\n4/ Les données dans un DataFrame Pandas sont structurées en colonnes et en lignes. Chaque colonne peut contenir un type de données différent (numérique, chaîne de caractères, booléen, etc.), et chaque ligne représente une observation.\n5/ L’index dans un DataFrame Pandas sert à identifier de manière unique chaque ligne du DataFrame. Il permet d’accéder rapidement aux lignes, de réaliser des jointures, de trier les données et de faciliter les opérations de regroupement.\n6/ Pour explorer un DataFrame inconnu, on peut utiliser df.head() pour voir les premières lignes, df.tail() pour les dernières, df.info() pour obtenir un résumé des types de données et des valeurs manquantes, et df.describe() pour des statistiques descriptives.\n7/ Assigner le résultat d’une opération à une nouvelle variable crée une copie du DataFrame avec les modifications appliquées. Utiliser une méthode avec inplace=True modifie le DataFrame original sans créer de copie, ce qui peut être plus efficace en termes de mémoire.\n8/ Pandas représente les valeurs manquantes avec l’objet nan (Not a Number) de Numpy pour les données numériques et avec None ou pd.NaT pour les dates/temps. Ces valeurs manquantes sont généralement ignorées dans les calculs de fonctions statistiques, ce qui peut affecter les résultats si elles ne sont pas traitées correctement.\n9/ Concaténer consiste à assembler des DataFrames en les empilant verticalement ou en les alignant horizontalement, principalement utilisé lorsque les DataFrames ont le même schéma ou lorsque vous souhaitez empiler les données. Les jointures, inspirées des opérations JOIN en SQL, combinent les DataFrames sur la base de valeurs de clés communes et sont utilisées pour enrichir un ensemble de données avec des informations d’un autre ensemble.\n\n\n\n\n\n\nDans la cellule suivante, nous avons récupéré des données de caisses sur les ventes de différentes enseignes. Les données sont cependant présentées de deux manières différentes, dans un cas sous forme d’observations (chaque liste contient les données d’une ligne), dans l’autre sous forme de variables (chaque liste contient les données d’une colonne).\n\ndata_list1 = [\n    ['Carrefour', '01.1.1', 3, 1.50],\n    ['Casino', '02.1.1', 2, 2.30],\n    ['Lidl', '01.1.1', 7, 0.99],\n    ['Carrefour', '03.1.1', 5, 5.00],\n    ['Casino', '01.1.1', 10, 1.20],\n    ['Lidl', '02.1.1', 1, 3.10]\n]\n\ndata_list2 = [\n    ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    [3, 2, 7, 5, 10, 1],\n    [1.50, 2.30, 0.99, 5.00, 1.20, 3.10]\n]\n\nL’objectif est de construire dans les deux cas un même DataFrame qui contient chacune des 6 observations et des 4 variables, avec les mêmes noms dans les deux DataFrame. A chaque cas va correspondre une structure de données plus adaptée en entrée, dictionnaire ou liste de listes… faîtes le bon choix ! On vérifiera que les deux DataFrames sont identiques à l’aide de la méthode equals().\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndata_list1 = [\n    ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    [3, 2, 7, 5, 10, 1],\n    [1.50, 2.30, 0.99, 5.00, 1.20, 3.10]\n]\n\ndata_list2 = [\n    ['Carrefour', '01.1.1', 3, 1.50],\n    ['Casino', '02.1.1', 2, 2.30],\n    ['Lidl', '01.1.1', 7, 0.99],\n    ['Carrefour', '03.1.1', 5, 5.00],\n    ['Casino', '01.1.1', 10, 1.20],\n    ['Lidl', '02.1.1', 1, 3.10]\n]\n\n# Si les données sont sous forme de colonnes : à partir d'un dictionnaire\ndata_dict = {\n    'enseigne': data_list1[0],\n    'produit': data_list1[1],\n    'quantite': data_list1[2],\n    'prix': data_list1[3]\n}\n\ndf_from_dict = pd.DataFrame(data_dict)\n\n# Si les données sont sous forme de lignes : à partir d'une liste de listes\ncolumns = ['enseigne', 'produit', 'quantite', 'prix']\ndf_from_list = pd.DataFrame(data_list2, columns=columns)\n\n# Vérification\ndf_from_dict.equals(df_from_list)\n\nTrue\n\n\n\n\n\n\n\nUn DataFrame Pandas est créé avec des données de caisse (mêmes données que l’exercice précédent).\n\ndata = {\n    'enseigne': ['Carrefour', 'Casino', 'Lidl', 'Carrefour', 'Casino', 'Lidl'],\n    'produit': ['01.1.1', '02.1.1', '01.1.1', '03.1.1', '01.1.1', '02.1.1'],\n    'quantite': [3, 2, 7, 5, 10, 1],\n    'prix': [1.50, 2.30, 0.99, 5.00, 1.20, 3.10],\n    'date_heure': pd.to_datetime([\"2022-01-01 14:05\", \"2022-01-02 09:30\", \n                                  \"2022-01-03 17:45\", \"2022-01-04 08:20\", \n                                  \"2022-01-05 19:00\", \"2022-01-06 16:30\"])\n}\n\ndf = pd.DataFrame(data)\n\nUtilisez les méthodes loc et iloc pour sélectionner des données spécifiques :\n\nSélectionner les données de la première ligne.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.iloc[0])\n\nenseigne                Carrefour\nproduit                    01.1.1\nquantite                        3\nprix                          1.5\ndate_heure    2022-01-01 14:05:00\nName: 0, dtype: object\n\n\n\n\n\nSélectionner toutes les données de la colonne “prix”.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[:, 'prix'])\n\n0    1.50\n1    2.30\n2    0.99\n3    5.00\n4    1.20\n5    3.10\nName: prix, dtype: float64\n\n\n\n\n\nSélectionner les lignes correspondant à l’enseigne “Carrefour” uniquement.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['enseigne'] == 'Carrefour'])\n\n    enseigne produit  quantite  prix          date_heure\n0  Carrefour  01.1.1         3   1.5 2022-01-01 14:05:00\n3  Carrefour  03.1.1         5   5.0 2022-01-04 08:20:00\n\n\n\n\n\nSélectionner les quantités achetées pour les produits classifiés “01.1.1” (Pain).\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['produit'] == '01.1.1', 'quantite'])\n\n0     3\n2     7\n4    10\nName: quantite, dtype: int64\n\n\n\n\n\nSélectionner les données des colonnes “enseigne” et “prix” pour toutes les lignes.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[:, ['enseigne', 'prix']])\n\n    enseigne  prix\n0  Carrefour  1.50\n1     Casino  2.30\n2       Lidl  0.99\n3  Carrefour  5.00\n4     Casino  1.20\n5       Lidl  3.10\n\n\n\n\n\nSélectionner les lignes où la quantité achetée est supérieure à 5.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['quantite'] &gt; 5])\n\n  enseigne produit  quantite  prix          date_heure\n2     Lidl  01.1.1         7  0.99 2022-01-03 17:45:00\n4   Casino  01.1.1        10  1.20 2022-01-05 19:00:00\n\n\n\n\n\nFiltrer pour sélectionner toutes les transactions qui ont eu lieu après 15h.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['date_heure'].dt.hour &gt; 15])\n\n  enseigne produit  quantite  prix          date_heure\n2     Lidl  01.1.1         7  0.99 2022-01-03 17:45:00\n4   Casino  01.1.1        10  1.20 2022-01-05 19:00:00\n5     Lidl  02.1.1         1  3.10 2022-01-06 16:30:00\n\n\n\n\n\nSélectionner les transactions qui ont eu lieu le “2022-01-03”.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df.loc[df['date_heure'].dt.date == pd.to_datetime('2022-01-03').date()])\n\n  enseigne produit  quantite  prix          date_heure\n2     Lidl  01.1.1         7  0.99 2022-01-03 17:45:00\n\n\n\n\n\n\n\nLe fichier des prénoms contient des données sur les prénoms attribués aux enfants nés en France entre 1900 et 2021. Ces données sont disponibles au niveau France, par département et par région, à l’adresse suivante : https://www.insee.fr/fr/statistiques/2540004?sommaire=4767262. L’objectif de ce tutoriel est de proposer une analyse de ce fichier, du nettoyage des données au statistiques sur les prénoms.\n\n\n\nImportez les données dans un DataFrame en utilisant cette URL.\nVisualisez un échantillon des données. Repérez-vous d’éventuelles anomalies ?\nAffichez les principales informations du DataFrame. Repérez d’éventuelles variables dont le type serait incorrect, ou bien d’éventuelles valeurs manquantes.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nurl = \"https://www.insee.fr/fr/statistiques/fichier/2540004/nat2021_csv.zip\"\ndf_prenoms = pd.read_csv(url, sep=\";\")\n\ndf_prenoms.head(10)\ndf_prenoms.sample(n=50)\n\ndf_prenoms.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 686538 entries, 0 to 686537\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   sexe      686538 non-null  int64 \n 1   preusuel  686536 non-null  object\n 2   annais    686538 non-null  object\n 3   nombre    686538 non-null  int64 \ndtypes: int64(2), object(2)\nmemory usage: 21.0+ MB\n\n\n\n\n\n\n\n\nL’output de la méthode info() suggère des valeurs manquantes dans la colonne des prénoms. Affichez ces lignes. Vérifiez que ces valeurs manquantes sont correctement spécifiées.\nL’output de méthode head() montre une modalité récurrente “_PRENOMS_RARES” dans la colonne des prénoms. Quelle proportion des individus de la base cela concerne-t-il ? Convertir ces valeurs en np.nan.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprint(df_prenoms[df_prenoms[\"preusuel\"].isna()])\nprop_rares = df_prenoms.groupby(\"preusuel\")[\"nombre\"].sum()[\"_PRENOMS_RARES\"] / df_prenoms[\"nombre\"].sum()\nprint(prop_rares)  # ~ 2 % de la base\ndf_prenoms = df_prenoms.replace('_PRENOMS_RARES', np.nan)\n\n        sexe preusuel annais  nombre\n579411     2      NaN   2003       3\n579412     2      NaN   XXXX      29\n0.01965912697163539\n\n\n\n\n\nOn remarque que les prénoms de personnes dont l’année de naissance n’est pas connue sont regroupés sous la modalité XXXX. Quelle proportion des individus de la base cela concerne-t-il ? Convertir ces valeurs en np.nan.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nprop_xxxx = df_prenoms.groupby(\"annais\")[\"nombre\"].sum()[\"XXXX\"] / df_prenoms[\"nombre\"].sum()\nprint(prop_xxxx)  # ~ 1 % de la base\ndf_prenoms = df_prenoms.replace('XXXX', np.nan)\n\n0.010007438242954967\n\n\n\n\n\nSupprimer les lignes contenant des valeurs manquantes de l’échantillon.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms = df_prenoms.dropna()\n\n\n\n\nConvertissez la colonne annais en type numérique et la colonne sexe en type catégoriel.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms['annais'] = pd.to_numeric(df_prenoms['annais'])\ndf_prenoms['sexe'] = df_prenoms['sexe'].astype('category')\n\n\n\n\nVérifiez avec la méthode info() que le nettoyage a été correctement appliqué.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 648369 entries, 122 to 686536\nData columns (total 4 columns):\n #   Column    Non-Null Count   Dtype   \n---  ------    --------------   -----   \n 0   sexe      648369 non-null  category\n 1   preusuel  648369 non-null  object  \n 2   annais    648369 non-null  int64   \n 3   nombre    648369 non-null  int64   \ndtypes: category(1), int64(2), object(1)\nmemory usage: 20.4+ MB\n\n\n\n\n\n\n\n\nLa documentation du fichier nous informe qu’on peut considérer les données comme quasi-exhaustives à partir de 1946. Pour cette partie seulement, filtrer les données pour ne conserver que les données ultérieures.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_prenoms_post_1946 = df_prenoms[df_prenoms[\"annais\"] &gt;= 1946]\n\n\n\n\nCalculez le nombre total de naissances par sexe.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nbirths_per_sex = df_prenoms_post_1946.groupby('sexe')['nombre'].sum()\nprint(births_per_sex)\n\nsexe\n1    30872950\n2    29314697\nName: nombre, dtype: int64\n\n\n/tmp/ipykernel_2611/1314444992.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  births_per_sex = df_prenoms_post_1946.groupby('sexe')['nombre'].sum()\n\n\n\n\n\nIdentifiez les cinq années ayant le plus grand nombre de naissances.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ntop5_years = df_prenoms_post_1946.groupby('annais')['nombre'].sum().nlargest(5)\nprint(top5_years)\n\nannais\n1964    902522\n1971    899440\n1972    893901\n1963    893425\n1949    890585\nName: nombre, dtype: int64\n\n\n\n\n\n\n\n\nIdentifiez le nombre total de prénoms uniques dans le DataFrame.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ntotal_unique_names = df_prenoms['preusuel'].nunique()\nprint(total_unique_names)\n\n34175\n\n\n\n\n\nCompter le nombre de personnes possédant un prénom d’une seule lettre.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nsingle_letter_names = df_prenoms[df_prenoms['preusuel'].str.len() == 1]['nombre'].sum()\nprint(single_letter_names)\n\n209\n\n\n\n\n\nCréez une “fonction de popularité” qui, pour un prénom donné, affiche l’année où il a été le plus donné ainsi que le nombre de fois où il a été donné cette année-là.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndef popularite_par_annee(df, prenom):\n    # Filtrer le DataFrame pour ne garder que les lignes correspondant au prénom donné\n    df_prenom = df[df['preusuel'] == prenom]\n\n    # Grouper par année, sommer les naissances et identifier l'année avec le maximum de naissances\n    df_agg = df_prenom.groupby('annais')['nombre'].sum()\n    annee_max = df_agg.idxmax()\n    n_max = df_agg[annee_max]\n\n    print(f\"Le prénom '{prenom}' a été le plus donné en {annee_max}, avec {n_max} naissances.\")\n\n# Test de la fonction avec un exemple\npopularite_par_annee(df_prenoms, 'ALFRED')\n\nLe prénom 'ALFRED' a été le plus donné en 1910, avec 1994 naissances.\n\n\n\n\n\nCréez une fonction qui, pour un sexe donné, renvoie un DataFrame contenant le prénom le plus donné pour chaque décennie.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndef popularite_par_decennie(df, sexe):\n    # Filtrage sur le sexe\n    df_sub = df[df[\"sexe\"] == sexe]\n\n    # Calcul de la variable décennie\n    df_sub[\"decennie\"] = (df_sub[\"annais\"] // 10) * 10\n\n    # Calculer la somme des naissances pour chaque prénom et chaque décennie\n    df_counts_decennie = df_sub.groupby([\"preusuel\", \"decennie\"])[\"nombre\"].sum().reset_index()\n\n    # Trouver l'indice du prénom le plus fréquent pour chaque décennie\n    idx = df_counts_decennie.groupby(\"decennie\")[\"nombre\"].idxmax()\n\n    # Utiliser l'indice pour obtenir les lignes correspondantes du DataFrame df_counts_decennie\n    df_popularite_decennie = df_counts_decennie.loc[idx].set_index(\"decennie\")\n\n    return df_popularite_decennie\n\n# Test de la fonction avec un exemple\npopularite_par_decennie(df_prenoms, sexe=2)\n\n/tmp/ipykernel_2611/1907896397.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_sub[\"decennie\"] = (df_sub[\"annais\"] // 10) * 10\n\n\n\n\n\n\n\n\n\npreusuel\nnombre\n\n\ndecennie\n\n\n\n\n\n\n1900\nMARIE\n490609\n\n\n1910\nMARIE\n329246\n\n\n1920\nMARIE\n322486\n\n\n1930\nMARIE\n247784\n\n\n1940\nMARIE\n265690\n\n\n1950\nMARIE\n217042\n\n\n1960\nSYLVIE\n204773\n\n\n1970\nSANDRINE\n146395\n\n\n1980\nAURÉLIE\n113344\n\n\n1990\nLAURA\n70049\n\n\n2000\nLÉA\n77504\n\n\n2010\nEMMA\n49094\n\n\n2020\nJADE\n7618\n\n\n\n\n\n\n\n\n\n\n\n\n\nL’objectif de cet exercice est de calculer une empreinte carbone par habitant au niveau communal. Pour cela, il va falloir combiner deux sources de données :\n\nles populations légales au niveau des communes, issues du recensement de la population (source)\nles émissions de gaz à effet de serre estimées au niveau communal par l’ADEME (source)\n\nCet exercice constitue une version simplifiée d’un TP complet pour la pratique de Pandas proposé par Lino Galiana dans son cours à l’ENSAE.\n\n\n\nImportez le fichier CSV communes.csv.\nUtilisez les méthodes .sample(), .info() et .describe() pour obtenir un aperçu des données.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_pop_communes = pd.read_csv(\"data/communes.csv\", sep=\";\")\n\ndf_pop_communes.sample(10)\ndf_pop_communes.info()\ndf_pop_communes.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 34995 entries, 0 to 34994\nData columns (total 5 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   DEPCOM  34995 non-null  object\n 1   COM     34995 non-null  object\n 2   PMUN    34995 non-null  int64 \n 3   PCAP    34995 non-null  int64 \n 4   PTOT    34995 non-null  int64 \ndtypes: int64(3), object(2)\nmemory usage: 1.3+ MB\n\n\n\n\n\n\n\n\n\nPMUN\nPCAP\nPTOT\n\n\n\n\ncount\n34995.000000\n34995.000000\n34995.000000\n\n\nmean\n1900.966967\n35.340849\n1936.307815\n\n\nstd\n8583.400244\n133.285462\n8696.358429\n\n\nmin\n0.000000\n0.000000\n0.000000\n\n\n25%\n199.000000\n4.000000\n203.000000\n\n\n50%\n457.000000\n9.000000\n468.000000\n\n\n75%\n1159.000000\n24.000000\n1184.000000\n\n\nmax\n479553.000000\n5256.000000\n484809.000000\n\n\n\n\n\n\n\n\n\n\nIdentifiez et retirez les lignes correspondant aux communes sans population.\nSupprimez les colonnes “PMUN” et “PCAP”, non pertinentes pour l’analyse.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nn_communes_0_pop = df_pop_communes[df_pop_communes[\"PTOT\"] == 0].shape[0]\nprint(n_communes_0_pop)\ndf_pop_communes = df_pop_communes[df_pop_communes[\"PTOT\"] &gt; 0]\n\ndf_pop_communes = df_pop_communes.drop(columns=[\"PMUN\", \"PCAP\"])\n\n6\n\n\n\n\nLes communes qui ont les noms les plus longs sont-elles aussi les communes les moins peuplées ? Pour le savoir : - Créez une nouvelle variable qui contient le nombre de caractères de chaque commune à l’aide de la méthode str.len() - Calculez la corrélation entre cette variable et la population totale avec la méthode corr()\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_pop_communes_stats = df_pop_communes.copy()\ndf_pop_communes_stats['longueur'] = df_pop_communes_stats['COM'].str.len()\ndf_pop_communes_stats['longueur'].corr(df_pop_communes_stats['PTOT'])\n\nnp.float64(0.0037878701156295307)\n\n\n\n\n\n\n\n\nImportez les données d’émission depuis cette URL\nUtilisez les méthodes .sample(), .info() et .describe() pour obtenir un aperçu des données.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nurl_ademe = \"https://data.ademe.fr/data-fair/api/v1/datasets/igt-pouvoir-de-rechauffement-global/data-files/IGT%20-%20Pouvoir%20de%20r%C3%A9chauffement%20global.csv\"\ndf_emissions = pd.read_csv(url_ademe)\n\ndf_emissions.sample(10)\ndf_emissions.info()\ndf_emissions.describe()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35798 entries, 0 to 35797\nData columns (total 12 columns):\n #   Column                           Non-Null Count  Dtype  \n---  ------                           --------------  -----  \n 0   INSEE commune                    35798 non-null  object \n 1   Commune                          35798 non-null  object \n 2   Agriculture                      35736 non-null  float64\n 3   Autres transports                9979 non-null   float64\n 4   Autres transports international  2891 non-null   float64\n 5   CO2 biomasse hors-total          35798 non-null  float64\n 6   Déchets                          35792 non-null  float64\n 7   Energie                          34490 non-null  float64\n 8   Industrie hors-énergie           34490 non-null  float64\n 9   Résidentiel                      35792 non-null  float64\n 10  Routier                          35778 non-null  float64\n 11  Tertiaire                        35798 non-null  float64\ndtypes: float64(10), object(2)\nmemory usage: 3.3+ MB\n\n\n\n\n\n\n\n\n\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\n\n\n\n\ncount\n35736.000000\n9979.000000\n2.891000e+03\n35798.000000\n35792.000000\n3.449000e+04\n3.449000e+04\n35792.000000\n35778.000000\n35798.000000\n\n\nmean\n2459.975760\n654.919940\n7.692345e+03\n1774.381550\n410.806329\n6.625698e+02\n2.423128e+03\n1783.677872\n3535.501245\n1105.165915\n\n\nstd\n2926.957701\n9232.816833\n1.137643e+05\n7871.341922\n4122.472608\n2.645571e+04\n5.670374e+04\n8915.902379\n9663.156628\n5164.182507\n\n\nmin\n0.003432\n0.000204\n3.972950e-04\n3.758088\n0.132243\n2.354558e+00\n1.052998e+00\n1.027266\n0.555092\n0.000000\n\n\n25%\n797.682631\n52.560412\n1.005097e+01\n197.951108\n25.655166\n2.354558e+00\n6.911213e+00\n96.052911\n419.700460\n94.749885\n\n\n50%\n1559.381285\n106.795928\n1.992434e+01\n424.849988\n54.748653\n4.709115e+00\n1.382243e+01\n227.091193\n1070.895593\n216.297718\n\n\n75%\n3007.883903\n237.341501\n3.298311e+01\n1094.749825\n110.820941\n5.180027e+01\n1.520467e+02\n749.469293\n3098.612157\n576.155869\n\n\nmax\n98949.317760\n513140.971691\n3.303394e+06\n576394.181208\n275500.374439\n2.535858e+06\n6.765119e+06\n410675.902028\n586054.672836\n288175.400126\n\n\n\n\n\n\n\n\n\n\nY a-t-il des lignes avec des valeurs manquantes pour toutes les colonnes d’émission ? Vérifiez-le à l’aide des méthodes isnull() et all().\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions_num = df_emissions.select_dtypes(['number'])\nonly_nan = df_emissions_num[df_emissions_num.isnull().all(axis=1)]\nonly_nan.shape[0]\n\n0\n\n\n\n\n\nCréez une nouvelle colonne qui donne les émissions totales par commune\nAfficher les 10 communes les plus émettrices. Qu’observez-vous dans les résultats ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions['emissions_totales'] = df_emissions.sum(axis = 1, numeric_only = True)\n\ndf_emissions.sort_values(by=\"emissions_totales\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\n\n\n\n\n4382\n13039\nFOS-SUR-MER\n305.092893\n1893.383189\n1.722723e+04\n50891.367548\n275500.374439\n2.296711e+06\n6.765119e+06\n9466.388806\n74631.401993\n42068.140058\n9.533813e+06\n\n\n22671\n59183\nDUNKERQUE\n811.390947\n3859.548994\n3.327586e+05\n71922.181764\n23851.780482\n1.934988e+06\n5.997333e+06\n113441.727216\n94337.865738\n70245.678455\n8.643550e+06\n\n\n4398\n13056\nMARTIGUES\n855.299300\n2712.749275\n3.043476e+04\n35925.561051\n44597.426397\n1.363402e+06\n2.380185e+06\n22530.797276\n84624.862481\n44394.822725\n4.009663e+06\n\n\n30560\n76476\nPORT-JEROME-SUR-SEINE\n2736.931327\n121.160849\n2.086403e+04\n22846.964780\n78.941581\n1.570236e+06\n2.005643e+06\n21072.566129\n9280.824961\n15270.357772\n3.668151e+06\n\n\n31108\n77291\nLE MESNIL-AMELOT\n782.183307\n133834.090767\n3.303394e+06\n3330.404124\n111.613197\n8.240952e+02\n2.418925e+03\n1404.400153\n11712.541682\n13680.471909\n3.471492e+06\n\n\n31099\n77282\nMAUREGARD\n733.910161\n133699.072712\n3.303394e+06\n193.323752\n44.301447\n2.354558e+00\n6.911213e+00\n468.995242\n2106.579416\n160.309150\n3.440809e+06\n\n\n30438\n76351\nLE HAVRE\n1168.274940\n17358.962736\n2.109460e+06\n141492.414415\n17641.705314\n2.653841e+05\n4.183445e+05\n195864.092574\n111174.296228\n95695.476436\n3.373584e+06\n\n\n30428\n76341\nHARFLEUR\n751.297090\n157.179958\nNaN\n10591.477221\n67.467130\n2.535858e+06\n5.107387e+03\n8739.638694\n29761.043310\n5277.162755\n2.596310e+06\n\n\n31111\n77294\nMITRY-MORY\n1912.746387\n89815.529858\n2.202275e+06\n17540.442778\n159.163608\n3.510646e+03\n1.364685e+04\n26418.982148\n72891.937473\n15163.398499\n2.443335e+06\n\n\n1987\n06088\nNICE\n305.445236\n225204.545951\n1.003572e+06\n169338.333391\n124232.948837\n1.186697e+04\n3.589365e+04\n252857.325855\n352836.864314\n171766.435376\n2.347875e+06\n\n\n\n\n\n\n\n\n\n\nIl semble que les postes majeurs d’émissions soient “Industrie hors-énergie” et “Autres transports international”. Pour vérifier si cette conjecture tient, calculer la corrélation entre les émissions totales et les postes sectoriels d’émissions à l’aide de la méthode corrwith().\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions.corrwith(df_emissions[\"emissions_totales\"], numeric_only=True)\n\nAgriculture                        0.032843\nAutres transports                  0.283310\nAutres transports international    0.463660\nCO2 biomasse hors-total            0.466285\nDéchets                            0.409822\nEnergie                            0.711808\nIndustrie hors-énergie             0.835432\nRésidentiel                        0.444557\nRoutier                            0.454902\nTertiaire                          0.488895\nemissions_totales                  1.000000\ndtype: float64\n\n\n\n\n\nExtraire du code commune le numéro de département dans une nouvelle variable\nCalculer les émissions totales par département\nAfficher les 10 principaux départements émetteurs. Les résultats sont-ils logiques par rapport à l’analyse au niveau communal ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions[\"dep\"] = df_emissions[\"INSEE commune\"].str[:2]\ndf_emissions.groupby(\"dep\").agg({\"emissions_totales\": \"sum\"}).sort_values(by=\"emissions_totales\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nemissions_totales\n\n\ndep\n\n\n\n\n\n13\n2.657388e+07\n\n\n59\n2.607500e+07\n\n\n76\n2.159825e+07\n\n\n77\n1.818622e+07\n\n\n69\n1.250800e+07\n\n\n62\n1.207887e+07\n\n\n44\n1.053212e+07\n\n\n38\n1.014781e+07\n\n\n57\n1.010131e+07\n\n\n33\n9.352481e+06\n\n\n\n\n\n\n\n\n\n\n\n\nPour effectuer une jointure, il est toujours préférable d’avoir une clé de jointure, i.e. une colonne commune aux deux sources, qui identifie uniquement les unités statistiques. L’objet de cette partie est de trouver la clé de jointure pertinente.\n\nVérifiez si la variable contenant les noms de commune contient des doublons\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndoublons = df_pop_communes.groupby('COM').count()['DEPCOM']\ndoublons = doublons[doublons&gt;1]\ndoublons = doublons.reset_index()\ndoublons\n\n\n\n\n\n\n\n\nCOM\nDEPCOM\n\n\n\n\n0\nAbancourt\n2\n\n\n1\nAboncourt\n2\n\n\n2\nAbzac\n2\n\n\n3\nAchères\n2\n\n\n4\nAiglun\n2\n\n\n...\n...\n...\n\n\n1451\nÉtaules\n2\n\n\n1452\nÉterpigny\n2\n\n\n1453\nÉtréchy\n3\n\n\n1454\nÉtrépilly\n2\n\n\n1455\nŒuilly\n2\n\n\n\n\n1456 rows × 2 columns\n\n\n\n\n\n\nFiltrez dans le DataFrame initial les communes dont le nom est dupliqué, et triez-le par code commune. Les doublons semblent-ils problématiques ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_pop_communes_doublons = df_pop_communes[df_pop_communes[\"COM\"].isin(doublons[\"COM\"])]\ndf_pop_communes_doublons.sort_values('COM')\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\n\n\n\n\n22473\n60001\nAbancourt\n659\n\n\n21825\n59001\nAbancourt\n476\n\n\n20791\n57001\nAboncourt\n354\n\n\n19453\n54003\nAboncourt\n105\n\n\n12327\n33001\nAbzac\n1963\n\n\n...\n...\n...\n...\n\n\n34450\n91226\nÉtréchy\n6634\n\n\n30189\n77173\nÉtrépilly\n899\n\n\n680\n02297\nÉtrépilly\n119\n\n\n1192\n02565\nŒuilly\n293\n\n\n18782\n51410\nŒuilly\n658\n\n\n\n\n3720 rows × 3 columns\n\n\n\n\n\n\nVérifiez que les codes commune identifient de manière unique la commune associée\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n(df_pop_communes_doublons.groupby(\"DEPCOM\")[\"COM\"].nunique() != 1).sum()\n\nnp.int64(0)\n\n\n\n\n\nAffichez les communes présentes dans les données communales mais pas dans les données d’émissions, et inversement. Qu’en concluez-vous ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n## Observations qui sont dans les pop légales mais pas dans les données d'émissions\ndf_pop_communes[~df_pop_communes[\"DEPCOM\"].isin(df_emissions[\"INSEE commune\"])]\n\n## Observations qui sont dans les données d'émissions mais pas dans les pop légales\ndf_emissions[~df_emissions[\"INSEE commune\"].isin(df_pop_communes[\"DEPCOM\"])]\n\n\n\n\n\n\n\n\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\ndep\n\n\n\n\n53\n01059\nBRENAZ\n2059.625278\nNaN\nNaN\n97.460907\n60.369788\n2.354558\n6.911213\n37.806309\n442.992259\n43.546665\n2751.066976\n01\n\n\n83\n01091\nCHATILLON-EN-MICHAILLE\n2716.023992\n154.607070\nNaN\n4479.397305\n26.211975\n489.748010\n1437.532377\n2884.723545\n24426.607714\n2852.127766\n39466.979755\n01\n\n\n89\n01097\nCHAVORNAY\n502.135035\nNaN\nNaN\n119.257319\n28.696758\n2.354558\n6.911213\n90.061423\n187.213742\n103.842046\n1040.472094\n01\n\n\n112\n01122\nCORMARANCHE-EN-BUGEY\n1020.579097\nNaN\nNaN\n548.434440\n134.359486\n35.318366\n103.668200\n323.757897\n1147.594565\n383.306355\n3697.018406\n01\n\n\n130\n01144\nDOMMARTIN\n3514.482852\nNaN\nNaN\n524.037265\n159.287551\nNaN\nNaN\n348.829080\n1529.911692\n422.067671\n6498.616112\n01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n35189\n89484\nVOLGRE\n383.961261\nNaN\nNaN\n954.348314\n46.681823\nNaN\nNaN\n424.365746\n10724.104395\n168.922776\n12702.384315\n89\n\n\n35262\n90073\nMOVAL\n281.860724\n57.129390\nNaN\n576.938906\n56.600057\n2.354558\n6.911213\n295.469174\n1439.904381\n205.016539\n2922.184943\n90\n\n\n35348\n91182\nCOURCOURONNES\n24.548795\n103.360309\nNaN\n9623.065698\n111.241872\n1276.170296\n3745.877636\n9978.002088\n57834.224552\n10532.120761\n93228.612007\n91\n\n\n35360\n91222\nESTOUCHES\n1790.002871\nNaN\nNaN\n113.797978\n30.548162\n2.354558\n6.911213\n71.011704\n523.293194\n110.541533\n2648.461213\n91\n\n\n35687\n95259\nGADANCOURT\n312.298700\nNaN\nNaN\n142.113291\n11.372909\nNaN\nNaN\n32.440647\n2060.981036\n41.153991\n2600.360573\n95\n\n\n\n\n922 rows × 14 columns\n\n\n\n\n\n\n\n\n\nJoindre les deux DataFrames à l’aide de la fonction à partir du code commune. Attention : les variables ne s’appellent pas de la même manière des deux côtés !\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions_pop = pd.merge(df_pop_communes, df_emissions, how=\"inner\", left_on=\"DEPCOM\", right_on=\"INSEE commune\")\ndf_emissions_pop\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\ndep\n\n\n\n\n0\n01001\nL' Abergement-Clémenciat\n794\n01001\nL'ABERGEMENT-CLEMENCIAT\n3711.425991\nNaN\nNaN\n432.751835\n101.430476\n2.354558\n6.911213\n309.358195\n793.156501\n367.036172\n5724.424941\n01\n\n\n1\n01002\nL' Abergement-de-Varey\n249\n01002\nL'ABERGEMENT-DE-VAREY\n475.330205\nNaN\nNaN\n140.741660\n140.675439\n2.354558\n6.911213\n104.866444\n348.997893\n112.934207\n1332.811619\n01\n\n\n2\n01004\nAmbérieu-en-Bugey\n14428\n01004\nAMBERIEU-EN-BUGEY\n499.043526\n212.577908\nNaN\n10313.446515\n5314.314445\n998.332482\n2930.354461\n16616.822534\n15642.420313\n10732.376934\n63259.689119\n01\n\n\n3\n01005\nAmbérieux-en-Dombes\n1723\n01005\nAMBERIEUX-EN-DOMBES\n1859.160954\nNaN\nNaN\n1144.429311\n216.217508\n94.182310\n276.448534\n663.683146\n1756.341319\n782.404357\n6792.867439\n01\n\n\n4\n01006\nAmbléon\n117\n01006\nAMBLEON\n448.966808\nNaN\nNaN\n77.033834\n48.401549\nNaN\nNaN\n43.714019\n398.786800\n51.681756\n1068.584766\n01\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n34871\n95676\nVillers-en-Arthies\n513\n95676\nVILLERS-EN-ARTHIES\n1628.065094\nNaN\nNaN\n165.045396\n65.063617\n11.772789\n34.556067\n176.098160\n309.627908\n235.439109\n2625.668140\n95\n\n\n34872\n95678\nVilliers-Adam\n870\n95678\nVILLIERS-ADAM\n698.630772\nNaN\nNaN\n1331.126598\n111.480954\n2.354558\n6.911213\n1395.529811\n18759.370071\n403.404815\n22708.808792\n95\n\n\n34873\n95680\nVilliers-le-Bel\n27808\n95680\nVILLIERS-LE-BEL\n107.564967\nNaN\nNaN\n8367.174532\n225.622903\n534.484607\n1568.845431\n22613.830247\n12217.122402\n13849.512001\n59484.157091\n95\n\n\n34874\n95682\nVilliers-le-Sec\n188\n95682\nVILLIERS-LE-SEC\n1090.890170\nNaN\nNaN\n326.748418\n108.969749\n2.354558\n6.911213\n67.235487\n4663.232127\n85.657725\n6351.999447\n95\n\n\n34875\n95690\nWy-dit-Joli-Village\n340\n95690\nWY-DIT-JOLI-VILLAGE\n1495.103542\nNaN\nNaN\n125.236417\n97.728612\n4.709115\n13.822427\n117.450851\n504.400972\n147.867245\n2506.319181\n95\n\n\n\n\n34876 rows × 17 columns\n\n\n\n\n\n\nCalculer une empreinte carbone pour chaque commune, correspondant aux émissions totales de la commune divisées par sa population totale.\nAffichez les 10 communes avec les empreintes carbones les plus élevées.\nLes résultats sont-ils identiques à ceux avec les émissions totales ? Qu’en concluez-vous ?\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_emissions_pop[\"empreinte_carbone\"] = df_emissions_pop[\"emissions_totales\"] / df_emissions_pop[\"PTOT\"]\ndf_emissions_pop.sort_values(\"empreinte_carbone\", ascending=False).head(10)\n\n\n\n\n\n\n\n\nDEPCOM\nCOM\nPTOT\nINSEE commune\nCommune\nAgriculture\nAutres transports\nAutres transports international\nCO2 biomasse hors-total\nDéchets\nEnergie\nIndustrie hors-énergie\nRésidentiel\nRoutier\nTertiaire\nemissions_totales\ndep\nempreinte_carbone\n\n\n\n\n30289\n77282\nMauregard\n353\n77282\nMAUREGARD\n733.910161\n133699.072712\n3.303394e+06\n193.323752\n44.301447\n2.354558e+00\n6.911213e+00\n468.995242\n2106.579416\n160.309150\n3.440809e+06\n77\n9747.335479\n\n\n30298\n77291\nLe Mesnil-Amelot\n1019\n77291\nLE MESNIL-AMELOT\n782.183307\n133834.090767\n3.303394e+06\n3330.404124\n111.613197\n8.240952e+02\n2.418925e+03\n1404.400153\n11712.541682\n13680.471909\n3.471492e+06\n77\n3406.763878\n\n\n22513\n60049\nBazancourt\n138\n60049\nBAZANCOURT\n4931.402275\nNaN\nNaN\n130.528462\n16.794877\n2.354558e+00\n3.016750e+05\n56.170228\n180.537059\n60.773916\n3.070535e+05\n60\n2225.025699\n\n\n26698\n68064\nChalampé\n969\n68064\nCHALAMPE\n9.216396\n647.802699\n3.558269e+01\n6332.112195\n70576.619047\n2.455804e+03\n1.042746e+06\n1097.958606\n2810.388658\n1362.287485\n1.128073e+06\n68\n1164.162333\n\n\n5501\n16357\nSaint-Vallier\n137\n16357\nSAINT-VALLIER\n1946.660150\nNaN\nNaN\n178.823635\n18.910767\n2.354558e+00\n1.513620e+05\n73.973099\n714.562143\n68.430473\n1.543657e+05\n16\n1126.757043\n\n\n21085\n57314\nHéming\n500\n57314\nHEMING\n509.670358\n167.168713\n8.175536e+00\n1141.352892\n68.237452\n3.343472e+02\n5.114259e+05\n276.118642\n3622.271599\n850.150203\n5.184033e+05\n57\n1036.806699\n\n\n14762\n39236\nFrancheville\n56\n39236\nFRANCHEVILLE\n817.850772\nNaN\nNaN\n63.254271\n5.157482\n2.354558e+00\n4.797800e+04\n23.798701\n103.848909\n18.662856\n4.901293e+04\n39\n875.230849\n\n\n18517\n51377\nMontépreux\n45\n51377\nMONTEPREUX\n3184.753959\nNaN\nNaN\n195.644289\n5.289725\n5.886394e+01\n2.928200e+04\n26.790561\n191.338795\n19.141391\n3.296382e+04\n51\n732.529393\n\n\n13138\n34278\nSaint-Michel\n49\n34278\nSAINT-MICHEL\n4491.844291\nNaN\nNaN\n145.718340\n34.912656\n2.354558e+00\n2.514989e+04\n23.599874\n450.893244\n23.448204\n3.032267e+04\n34\n618.829907\n\n\n4333\n13039\nFos-sur-Mer\n15654\n13039\nFOS-SUR-MER\n305.092893\n1893.383189\n1.722723e+04\n50891.367548\n275500.374439\n2.296711e+06\n6.765119e+06\n9466.388806\n74631.401993\n42068.140058\n9.533813e+06\n13\n609.033668\n\n\n\n\n\n\n\n\n\n\n\n\n\nVous avez à disposition dans le dossier data/ deux jeux de données CSV :\n\nserie_glaces_valeurs.csv contient les valeurs mensuelles de l’indice de prix de production de l’industrie française des glaces et sorbets\nserie_glaces_metadonnees.csv contient les métadonnées associées, notamment les codes indiquant le statut des données.\n\nL’objectif est d’utiliser Pandas pour calculer :\n\nl’évolution de l’indice entre chaque période (mois)\nl’évolution de l’indice en glissement annuel (entre un mois donné et le même mois l’année suivante).\n\n\n\n\nImportez les deux fichiers CSV dans des DataFrames. Attention, dans les deux cas, il y a des lignes superflues avant les données, qu’il faudra sauter à l’aide du paramètre skiprows de la fonction read_csv().\nDonnez des noms simples et pertinents aux différentes variables.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_valeurs = pd.read_csv('data/serie_glaces_valeurs.csv', delimiter=';',\n                         skiprows=4, names=[\"periode\", \"indice\", \"code\"])\ndf_metadata = pd.read_csv('data/serie_glaces_metadonnees.csv', delimiter=';',\n                          skiprows=5, names=[\"code\", \"signification\"])\n\n\n\n\n\n\n\nFusionner les deux DataFrames afin de récupérer la signification des codes présents dans les données.\nFiltrer les données de sorte à ne conserver que les données de type “Valeur normale”.\nSupprimer les colonnes liées aux codes, dont nous n’avons plus besoin pour la suite.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_merged = pd.merge(df_valeurs, df_metadata, how='left', on='code')\n\ndf_clean = df_merged[df_merged['code'] == \"A\"]\ndf_clean = df_clean[[\"periode\", \"indice\"]]\n\n\n\n\n\n\nVérifiez si les types des variables sont pertinents selon leur nature. Sinon, convertissez-les avec les fonctions idoines.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_clean.info()\ndf_clean['periode'] = pd.to_datetime(df_clean['periode'])\ndf_clean['indice'] = pd.to_numeric(df_clean['indice'])\ndf_clean.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 198 entries, 3 to 200\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   periode  198 non-null    object\n 1   indice   198 non-null    object\ndtypes: object(2)\nmemory usage: 4.6+ KB\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 198 entries, 3 to 200\nData columns (total 2 columns):\n #   Column   Non-Null Count  Dtype         \n---  ------   --------------  -----         \n 0   periode  198 non-null    datetime64[ns]\n 1   indice   198 non-null    float64       \ndtypes: datetime64[ns](1), float64(1)\nmemory usage: 4.6 KB\n\n\n\n\n\n\n\n\nUtilisez la méthode shift() pour créer une nouvelle colonne qui contiendra l’indice du trimestre précédent\nCalculez la différence entre l’indice actuel et l’indice décalé pour obtenir l’évolution (en pourcentage) d’un trimestre à l’autre\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_clean['indice_prec'] = df_clean['indice'].shift(1)\ndf_clean['evo'] = ((df_clean['indice'] - df_clean['indice_prec']) / df_clean['indice_prec']) * 100\n\n## Méthode alternative\ndf_clean['evo_alt'] = df_clean['indice'].pct_change(periods=1) * 100\n\n\n\n\n\n\nComme vous avez pu le voir dans la solution de l’exercice précédent, la méthode pct_change() permet précisément de calculer une évolution entre deux périodes. Utiliser cette méthode pour calculer une évolution (en pourcentage) en glissement annuel pour chaque mois.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\ndf_clean[\"evo_glissement_annuel\"] = df_clean['indice'].pct_change(periods=12) * 100\ndf_clean.head(20)\n\n\n\n\n\n\n\n\nperiode\nindice\nindice_prec\nevo\nevo_alt\nevo_glissement_annuel\n\n\n\n\n3\n2023-06-01\n115.3\nNaN\nNaN\nNaN\nNaN\n\n\n4\n2023-05-01\n112.4\n115.3\n-2.515178\n-2.515178\nNaN\n\n\n5\n2023-04-01\n115.5\n112.4\n2.758007\n2.758007\nNaN\n\n\n6\n2023-03-01\n112.9\n115.5\n-2.251082\n-2.251082\nNaN\n\n\n7\n2023-02-01\n105.1\n112.9\n-6.908769\n-6.908769\nNaN\n\n\n8\n2023-01-01\n104.0\n105.1\n-1.046622\n-1.046622\nNaN\n\n\n9\n2022-12-01\n98.3\n104.0\n-5.480769\n-5.480769\nNaN\n\n\n10\n2022-11-01\n100.0\n98.3\n1.729400\n1.729400\nNaN\n\n\n11\n2022-10-01\n98.2\n100.0\n-1.800000\n-1.800000\nNaN\n\n\n12\n2022-09-01\n98.9\n98.2\n0.712831\n0.712831\nNaN\n\n\n13\n2022-08-01\n99.3\n98.9\n0.404449\n0.404449\nNaN\n\n\n14\n2022-07-01\n97.2\n99.3\n-2.114804\n-2.114804\nNaN\n\n\n15\n2022-06-01\n97.3\n97.2\n0.102881\n0.102881\n-15.611448\n\n\n16\n2022-05-01\n95.0\n97.3\n-2.363823\n-2.363823\n-15.480427\n\n\n17\n2022-04-01\n96.0\n95.0\n1.052632\n1.052632\n-16.883117\n\n\n18\n2022-03-01\n94.3\n96.0\n-1.770833\n-1.770833\n-16.474756\n\n\n19\n2022-02-01\n94.0\n94.3\n-0.318134\n-0.318134\n-10.561370\n\n\n20\n2022-01-01\n94.6\n94.0\n0.638298\n0.638298\n-9.038462\n\n\n21\n2021-12-01\n92.6\n94.6\n-2.114165\n-2.114165\n-5.798576\n\n\n22\n2021-11-01\n92.3\n92.6\n-0.323974\n-0.323974\n-7.700000",
    "crumbs": [
      "Manipulation de données",
      "Traiter des données tabulaires avec Pandas"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html",
    "href": "source/projects/meteo/tutorial.html",
    "title": "Projet 2 - Prédictions météorologiques",
    "section": "",
    "text": "Il y a certains jours où l’on serait bien resté en télétravail.. Parmi ceux-là, ces jours à la fois humides et venteux où il est impossible de maintenir une coiffure décente, malgré tous ses efforts. Pourrait-on utiliser Python pour prédire ce que les anglo-saxons nomment des bad hair day (“mauvais jour de cheveux”) ?\nL’objectif du projet est de construire un bad hair index (“indice de mauvais jour de cheveux”) à partir des données météorologiques et de représenter graphiquement l’évolution de cette indice afin de déterminer à l’avance les jours où l’on ferait mieux de rester bien au chaud. Afin d’obtenir les données adéquates, nous allons requêter des APIs.\nUne API (Interface de Programmation d’Application) est un ensemble de règles et de spécifications que les applications suivent pour communiquer entre elles. Elle permet à votre code d’accéder à des fonctionnalités externes ou à des données, comme celles de bases de données météorologiques ou de services de localisation. Lorsqu’on parle de requêtage d’une API, cela se fait généralement via le protocole HTTP, qui est le même protocole utilisé pour charger des pages web. Dans ce tutoriel, nous utiliserons le package requests, qui simplifie le processus de requêtage et de gestion de réponses HTTP.\nLes APIs que nous allons utiliser sont :\n\nNominatim : une API de géocodage proposée par OpenStreetMap qui nous permet de convertir un nom de lieu en coordonnées géographiques.\nOpen-Meteo Weather Forecast : une API qui fournit des prévisions météorologiques détaillées.\n\nCommençons par importer les packages dont nous aurons besoin au cours de ce projet.\n\nimport requests\nimport pandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport solutions\n\n\n\n\nL’API de prédiction d’open-meteo prend en entrée les coordonnées géographiques (latitude, longitude) du lieu où seront réalisées les prédictions. On pourrait récupérer manuellement les coordonnées du lieu qui nous intéresse, mais cela limiterait la reproductibilité de nos analyses avec d’autres lieux que celui choisi. On va donc utiliser une seconde API, Nominatim, pour obtenir ces coordonnées pour un lieu donné.\nLorsque l’on travaille à partir d’une API, la première étape est toujours de lire sa documentation. C’est elle qui indique à quelle adresse nous devons envoyer nos requêtes, sous quel format, et ce que va nous répondre l’API. Dans notre cas, la docuemntation de Nominatim se trouve à cette adresse. N’hésitez pas à la parcourir rapidement pour évaluer les possibilités de l’API.\n\n\nLa première caractéristique essentielle d’une API est le endpoint, c’est à dire l’URL à laquelle on va envoyer des requêtes. Dans notre cas, on va utiliser le endpoint /search dans la mesure où l’on veut trouver un objet géographique (des coordonnées) à partir d’un nom de localisation. La page de documentation associée à ce endpoint nous donne toutes les informations dont nous avons besoin :\n\nle format d’une requête est https://nominatim.openstreetmap.org/search?&lt;params&gt; où &lt;params&gt; doit être remplacé par les paramètres de la requête, séparés par le symbole &\ndans la section Structured Query, on voit que l’API admet comme paramètres country (pays) et city (ville), que l’on va utiliser pour paramétrer notre requête.\n\nDéfinissez une fonction build_request_nominatim qui construit le lien de la requête pour un pays et une ville donnée.\n\n\n\nurl_request_nominatim = solutions.build_request_nominatim(\"France\", \"Montrouge\")\nurl_request_nominatim\n\n\n\n\n\ndef build_request_nominatim(country, city):\n    # Votre code ici\n    return url_request\n\n\n# Vérification du résultat\nurl_request_nominatim = build_request_nominatim(\"France\", \"Montrouge\")\nurl_request_nominatim\n\n\n\n\n\nLa prochaine étape est d’envoyer notre requête paramétrisée à l’API. Pour la tester au préalable, on peut simplement mettre l’adresse dans un navigateur et voir ce que nous renvoie l’API. Si les résultats ont l’air cohérent, on peut continuer. Si l’API nous renvoie un code d’erreur, il y a sûrement une erreur à trouver dans la requête.\nPour effectuer cette requête à partir de Python afin d’en récupérer les résultats, on utilise la fonction requests.get() à laquelle on fournit comme seul paramètre l’URL de la requête. On obtient en retour un objet “réponse”, dont on peut extraire le contenu JSON sous forme d’un dictionnaire Python en lui appliquant la méthode .json(). Il faut alors parcourir le dictionnaire pour en extraire les informations pertinentes ; dans notre cas : la latitude et la longitude.\nDéfinissez une fonction get_lat_long qui récupère la latitude et la longitude (centrale) pour un pays et une ville donnée.\n\n\n\nlat, long = solutions.get_lat_long(query=url_request_nominatim)\nprint(lat, long)\nprint(type(lat))\nprint(type(long))\n\n\n\n\n\ndef get_lat_long(query):\n    # Votre code ici\n    return latitude, longitude\n\n\n# Vérification du résultat\nlat, long = get_lat_long(query=url_request_nominatim)\nprint(lat, long)\nprint(type(lat))\nprint(type(long))\n\n\n\n\n\n\nMaintenant que nous pouvons récupérer les coordonnées associées à une localisation donnée, nous pouvons requêter l’API open-meteo.com pour obtenir les données de prédiction météo associées à ces coordonnées. Là encore, la première étape est de s’intéresser à la documentation (page d’accueil, doc), qui nous fournit plusieurs informations :\n\nle endpoint pour l’API de prédiction est https://api.open-meteo.com/v1/forecast\nl’API attend en entrée une latitude et une latitude, ainsi que les variables météorologiques souhaitées. Pour notre problématique, nous allons récupérer des informations sur le taux d’humidité (relativehumidity_2m) et la vitesse du vent (windspeed_10m)\npar défaut, l’API renvoie des prédictions à 7 jours\n\n\n\nSachant toutes ces informations et en vous aidant de la documentation, définissez une fonction build_request_open_meteo qui construit le lien de la requête pour une latitude et une longitude donnée. Là encore, il est possible de tester la validité de la requête en exécutant le lien dans un navigateur et en vérifiant que les résultats retournés paraissent cohérents.\n\n\n\nurl_request_open_meteo = solutions.build_request_open_meteo(latitude=lat, longitude=long)\nurl_request_open_meteo\n\n\n\n\n\ndef build_request_open_meteo(latitude, longitude):\n    # Votre code ici\n    return url_request\n\n\n# Vérification du résultat\nurl_request_open_meteo = build_request_open_meteo(latitude=lat, longitude=long)\nurl_request_open_meteo\n\n\n\n\n\nA nouveau, on utilise la fonction requests.get() pour soumettre la requête à l’API. On obtient en retour un objet “réponse”, dont on peut extraire le contenu JSON sous forme d’un dictionnaire Python en lui appliquant la méthode .json().\nMais que se passe-t-il dans le cas où la requête soumise est invalide (faute de frappe, paramètres inexistants, etc.) ? Dans ce cas, l’API nous renvoie une erreur. L’objet réponse de la requête contient un attribut .status_code qui donne le code de réponse d’une requête. Le code 200 indique la réussite d’une requête ; tout autre code indique une erreur.\nDéfinissez une fonction get_meteo_data qui récupère le dictionnaire complet de données retourné par l’API suite à notre requête. Le comportement de la fonction doit cependant dépendre du code de réponse de la requête :\n\nsi le code vaut 200, la fonction renvoie le dictionnaire des prédictions ;\nsi le code est différent de 200, la fonction affiche le code d’erreur et renvoie None.\n\n\n\n\npredictions = solutions.get_meteo_data(url_request_open_meteo)\ntype(predictions)\n\n\nwrong_request = solutions.build_request_open_meteo(latitude=lat, longitude=\"dix-sept-virgule-quatre\")\noutput = solutions.get_meteo_data(wrong_request)\nprint(output)\n\n\n\n\n\ndef get_meteo_data(query):\n    # Votre code ici\n    return response.json()\n\n\n# Vérification du résultat\npredictions = get_meteo_data(url_request_open_meteo)\ntype(predictions)\n\n\n# Vérification du résultat\nwrong_request = build_request_open_meteo(latitude=lat, longitude=\"dix-sept-virgule-quatre\")\noutput = get_meteo_data(wrong_request)\nprint(output)\n\n\n\n\n\nAfin de bien comprendre la structure des données que nous avons récupérées, explorez le dictionnaire des prédictions retourné par l’API (clefs, différents niveaux, format des prédictions, format de la variable indiquant les dates/heures des prédictions, etc.)\n\n\nAfficher le code\n# Exploration des données\nprint(type(predictions))\nprint(predictions.keys())\nprint(type(predictions[\"hourly\"]))\nprint(predictions[\"hourly\"].keys())\nprint(type(predictions[\"hourly\"][\"time\"]))\nprint()\n\n# Afficher les données\nprint(predictions['hourly'][\"time\"][:5])\nprint(predictions['hourly'][\"time\"][-5:])\nprint()\nprint(predictions['hourly'][\"relativehumidity_2m\"][:5])\nprint(predictions['hourly'][\"windspeed_10m\"][:5])\n\n\n\n\n\n\nL’objectif de cette dernière partie est de calculer et représenter graphiquement le bad hair index. Rappelons que l’on définit cet indice comme le produit de l’humidité relative et de la vitesse du vent. Il s’agit d’une mesure ludique de la probabilité d’avoir une “mauvaise coiffure” en raison des conditions météorologiques.\n\n\nDéfinissez une fonction preprocess_predictions qui met en forme les prédictions issues de l’API sous forme d’un DataFrame Pandas en vue d’une analyse statistique. Les étapes à implémenter sont les suivantes :\n\nconvertir les données prédites en un DataFrame Pandas à 3 colonnes (date et heure de l’observation, humidité, vitesse du vent) ;\nconvertir la colonne de temps au format datetime (documentation)\najouter deux nouvelles variables indiquant le jour de l’observation et l’heure de l’observation\najouter une variable qui calcule le bad hair index\n\n\n\n\ndf_preds = solutions.preprocess_predictions(predictions)\ndf_preds.head()\n\n\n\n\n\ndef preprocess_predictions(predictions):\n    # Votre code ici\n    return df\n\n\n# Vérification du résultat\ndf_preds = preprocess_predictions(predictions)\ndf_preds.head()\n\n\n\n\n\nA des fins de représentation graphique, nous allons représenter le bad hair index agrégé à deux niveaux :\n\nmoyenne heure par heure. Cela permettra de répondre à la question : “à quel heure sera-t-il généralement préférable de rester à la maison la semaine prochaine ?”\nmoyenne jour par jour. Cela permettra de répondre à la question : “quel jour sera-t-il généralement préférable de rester à la maison la semaine prochaine ?”\n\nDéfinissez une fonction plot_agg_avg_bhi qui calcule l’indice agrégé dans chaque cas, et représente le résultat sous la forme d’un lineplot.\n\n\n\nsolutions.plot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\n\nsolutions.plot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\n\n\n\n\ndef plot_agg_avg_bhi(df_preds, agg_var=\"day\"):\n    # Votre code ici\n    return None\n\n\n# Vérification du résultat\nplot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\n\n# Vérification du résultat\nplot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\nQu’en concluez-vous pour la semaine à venir ?\n\n\n\n\nNotre outil de prévision des bad hair days fonctionne à merveille. Mais c’est bientôt les vacances, et un voyage à Berlin est prévu. Idéalement, on voudrait pouvoir utiliser notre outil pour n’importe quelle localité. Heureusement, on a défini à chaque étape des fonctions, ce qui va nous permettre de passer facilement à une fonction “chef d’orchestre” qui appelle toutes les autres pour une localité donnée.\nDéfinissez une fonction main qui représente le bad hair index pour un pays, une ville et un niveau d’agrégation donnés.\n\n\n\nsolutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\n\nsolutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")\n\n\n\n\n\ndef main(country, city, agg_var=\"day\"):\n    # Votre code ici\n    return None\n\n\n# Vérification du résultat\nmain(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\n\n# Vérification du résultat\nmain(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")",
    "crumbs": [
      "Projets",
      "Projet 2 - Prédictions météorologiques"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#contexte-du-projet",
    "href": "source/projects/meteo/tutorial.html#contexte-du-projet",
    "title": "Projet 2 - Prédictions météorologiques",
    "section": "",
    "text": "Il y a certains jours où l’on serait bien resté en télétravail.. Parmi ceux-là, ces jours à la fois humides et venteux où il est impossible de maintenir une coiffure décente, malgré tous ses efforts. Pourrait-on utiliser Python pour prédire ce que les anglo-saxons nomment des bad hair day (“mauvais jour de cheveux”) ?\nL’objectif du projet est de construire un bad hair index (“indice de mauvais jour de cheveux”) à partir des données météorologiques et de représenter graphiquement l’évolution de cette indice afin de déterminer à l’avance les jours où l’on ferait mieux de rester bien au chaud. Afin d’obtenir les données adéquates, nous allons requêter des APIs.\nUne API (Interface de Programmation d’Application) est un ensemble de règles et de spécifications que les applications suivent pour communiquer entre elles. Elle permet à votre code d’accéder à des fonctionnalités externes ou à des données, comme celles de bases de données météorologiques ou de services de localisation. Lorsqu’on parle de requêtage d’une API, cela se fait généralement via le protocole HTTP, qui est le même protocole utilisé pour charger des pages web. Dans ce tutoriel, nous utiliserons le package requests, qui simplifie le processus de requêtage et de gestion de réponses HTTP.\nLes APIs que nous allons utiliser sont :\n\nNominatim : une API de géocodage proposée par OpenStreetMap qui nous permet de convertir un nom de lieu en coordonnées géographiques.\nOpen-Meteo Weather Forecast : une API qui fournit des prévisions météorologiques détaillées.\n\nCommençons par importer les packages dont nous aurons besoin au cours de ce projet.\n\nimport requests\nimport pandas\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport solutions",
    "crumbs": [
      "Projets",
      "Projet 2 - Prédictions météorologiques"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#partie-1-récupération-des-coordonnées-géographiques-pour-une-localisation-donnée",
    "href": "source/projects/meteo/tutorial.html#partie-1-récupération-des-coordonnées-géographiques-pour-une-localisation-donnée",
    "title": "Projet 2 - Prédictions météorologiques",
    "section": "",
    "text": "L’API de prédiction d’open-meteo prend en entrée les coordonnées géographiques (latitude, longitude) du lieu où seront réalisées les prédictions. On pourrait récupérer manuellement les coordonnées du lieu qui nous intéresse, mais cela limiterait la reproductibilité de nos analyses avec d’autres lieux que celui choisi. On va donc utiliser une seconde API, Nominatim, pour obtenir ces coordonnées pour un lieu donné.\nLorsque l’on travaille à partir d’une API, la première étape est toujours de lire sa documentation. C’est elle qui indique à quelle adresse nous devons envoyer nos requêtes, sous quel format, et ce que va nous répondre l’API. Dans notre cas, la docuemntation de Nominatim se trouve à cette adresse. N’hésitez pas à la parcourir rapidement pour évaluer les possibilités de l’API.\n\n\nLa première caractéristique essentielle d’une API est le endpoint, c’est à dire l’URL à laquelle on va envoyer des requêtes. Dans notre cas, on va utiliser le endpoint /search dans la mesure où l’on veut trouver un objet géographique (des coordonnées) à partir d’un nom de localisation. La page de documentation associée à ce endpoint nous donne toutes les informations dont nous avons besoin :\n\nle format d’une requête est https://nominatim.openstreetmap.org/search?&lt;params&gt; où &lt;params&gt; doit être remplacé par les paramètres de la requête, séparés par le symbole &\ndans la section Structured Query, on voit que l’API admet comme paramètres country (pays) et city (ville), que l’on va utiliser pour paramétrer notre requête.\n\nDéfinissez une fonction build_request_nominatim qui construit le lien de la requête pour un pays et une ville donnée.\n\n\n\nurl_request_nominatim = solutions.build_request_nominatim(\"France\", \"Montrouge\")\nurl_request_nominatim\n\n\n\n\n\ndef build_request_nominatim(country, city):\n    # Votre code ici\n    return url_request\n\n\n# Vérification du résultat\nurl_request_nominatim = build_request_nominatim(\"France\", \"Montrouge\")\nurl_request_nominatim\n\n\n\n\n\nLa prochaine étape est d’envoyer notre requête paramétrisée à l’API. Pour la tester au préalable, on peut simplement mettre l’adresse dans un navigateur et voir ce que nous renvoie l’API. Si les résultats ont l’air cohérent, on peut continuer. Si l’API nous renvoie un code d’erreur, il y a sûrement une erreur à trouver dans la requête.\nPour effectuer cette requête à partir de Python afin d’en récupérer les résultats, on utilise la fonction requests.get() à laquelle on fournit comme seul paramètre l’URL de la requête. On obtient en retour un objet “réponse”, dont on peut extraire le contenu JSON sous forme d’un dictionnaire Python en lui appliquant la méthode .json(). Il faut alors parcourir le dictionnaire pour en extraire les informations pertinentes ; dans notre cas : la latitude et la longitude.\nDéfinissez une fonction get_lat_long qui récupère la latitude et la longitude (centrale) pour un pays et une ville donnée.\n\n\n\nlat, long = solutions.get_lat_long(query=url_request_nominatim)\nprint(lat, long)\nprint(type(lat))\nprint(type(long))\n\n\n\n\n\ndef get_lat_long(query):\n    # Votre code ici\n    return latitude, longitude\n\n\n# Vérification du résultat\nlat, long = get_lat_long(query=url_request_nominatim)\nprint(lat, long)\nprint(type(lat))\nprint(type(long))",
    "crumbs": [
      "Projets",
      "Projet 2 - Prédictions météorologiques"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#partie-2-récupération-des-prévisions-météorologiques",
    "href": "source/projects/meteo/tutorial.html#partie-2-récupération-des-prévisions-météorologiques",
    "title": "Projet 2 - Prédictions météorologiques",
    "section": "",
    "text": "Maintenant que nous pouvons récupérer les coordonnées associées à une localisation donnée, nous pouvons requêter l’API open-meteo.com pour obtenir les données de prédiction météo associées à ces coordonnées. Là encore, la première étape est de s’intéresser à la documentation (page d’accueil, doc), qui nous fournit plusieurs informations :\n\nle endpoint pour l’API de prédiction est https://api.open-meteo.com/v1/forecast\nl’API attend en entrée une latitude et une latitude, ainsi que les variables météorologiques souhaitées. Pour notre problématique, nous allons récupérer des informations sur le taux d’humidité (relativehumidity_2m) et la vitesse du vent (windspeed_10m)\npar défaut, l’API renvoie des prédictions à 7 jours\n\n\n\nSachant toutes ces informations et en vous aidant de la documentation, définissez une fonction build_request_open_meteo qui construit le lien de la requête pour une latitude et une longitude donnée. Là encore, il est possible de tester la validité de la requête en exécutant le lien dans un navigateur et en vérifiant que les résultats retournés paraissent cohérents.\n\n\n\nurl_request_open_meteo = solutions.build_request_open_meteo(latitude=lat, longitude=long)\nurl_request_open_meteo\n\n\n\n\n\ndef build_request_open_meteo(latitude, longitude):\n    # Votre code ici\n    return url_request\n\n\n# Vérification du résultat\nurl_request_open_meteo = build_request_open_meteo(latitude=lat, longitude=long)\nurl_request_open_meteo\n\n\n\n\n\nA nouveau, on utilise la fonction requests.get() pour soumettre la requête à l’API. On obtient en retour un objet “réponse”, dont on peut extraire le contenu JSON sous forme d’un dictionnaire Python en lui appliquant la méthode .json().\nMais que se passe-t-il dans le cas où la requête soumise est invalide (faute de frappe, paramètres inexistants, etc.) ? Dans ce cas, l’API nous renvoie une erreur. L’objet réponse de la requête contient un attribut .status_code qui donne le code de réponse d’une requête. Le code 200 indique la réussite d’une requête ; tout autre code indique une erreur.\nDéfinissez une fonction get_meteo_data qui récupère le dictionnaire complet de données retourné par l’API suite à notre requête. Le comportement de la fonction doit cependant dépendre du code de réponse de la requête :\n\nsi le code vaut 200, la fonction renvoie le dictionnaire des prédictions ;\nsi le code est différent de 200, la fonction affiche le code d’erreur et renvoie None.\n\n\n\n\npredictions = solutions.get_meteo_data(url_request_open_meteo)\ntype(predictions)\n\n\nwrong_request = solutions.build_request_open_meteo(latitude=lat, longitude=\"dix-sept-virgule-quatre\")\noutput = solutions.get_meteo_data(wrong_request)\nprint(output)\n\n\n\n\n\ndef get_meteo_data(query):\n    # Votre code ici\n    return response.json()\n\n\n# Vérification du résultat\npredictions = get_meteo_data(url_request_open_meteo)\ntype(predictions)\n\n\n# Vérification du résultat\nwrong_request = build_request_open_meteo(latitude=lat, longitude=\"dix-sept-virgule-quatre\")\noutput = get_meteo_data(wrong_request)\nprint(output)\n\n\n\n\n\nAfin de bien comprendre la structure des données que nous avons récupérées, explorez le dictionnaire des prédictions retourné par l’API (clefs, différents niveaux, format des prédictions, format de la variable indiquant les dates/heures des prédictions, etc.)\n\n\nAfficher le code\n# Exploration des données\nprint(type(predictions))\nprint(predictions.keys())\nprint(type(predictions[\"hourly\"]))\nprint(predictions[\"hourly\"].keys())\nprint(type(predictions[\"hourly\"][\"time\"]))\nprint()\n\n# Afficher les données\nprint(predictions['hourly'][\"time\"][:5])\nprint(predictions['hourly'][\"time\"][-5:])\nprint()\nprint(predictions['hourly'][\"relativehumidity_2m\"][:5])\nprint(predictions['hourly'][\"windspeed_10m\"][:5])",
    "crumbs": [
      "Projets",
      "Projet 2 - Prédictions météorologiques"
    ]
  },
  {
    "objectID": "source/projects/meteo/tutorial.html#partie-3-construction-et-visualisation-dun-bad-hair-index",
    "href": "source/projects/meteo/tutorial.html#partie-3-construction-et-visualisation-dun-bad-hair-index",
    "title": "Projet 2 - Prédictions météorologiques",
    "section": "",
    "text": "L’objectif de cette dernière partie est de calculer et représenter graphiquement le bad hair index. Rappelons que l’on définit cet indice comme le produit de l’humidité relative et de la vitesse du vent. Il s’agit d’une mesure ludique de la probabilité d’avoir une “mauvaise coiffure” en raison des conditions météorologiques.\n\n\nDéfinissez une fonction preprocess_predictions qui met en forme les prédictions issues de l’API sous forme d’un DataFrame Pandas en vue d’une analyse statistique. Les étapes à implémenter sont les suivantes :\n\nconvertir les données prédites en un DataFrame Pandas à 3 colonnes (date et heure de l’observation, humidité, vitesse du vent) ;\nconvertir la colonne de temps au format datetime (documentation)\najouter deux nouvelles variables indiquant le jour de l’observation et l’heure de l’observation\najouter une variable qui calcule le bad hair index\n\n\n\n\ndf_preds = solutions.preprocess_predictions(predictions)\ndf_preds.head()\n\n\n\n\n\ndef preprocess_predictions(predictions):\n    # Votre code ici\n    return df\n\n\n# Vérification du résultat\ndf_preds = preprocess_predictions(predictions)\ndf_preds.head()\n\n\n\n\n\nA des fins de représentation graphique, nous allons représenter le bad hair index agrégé à deux niveaux :\n\nmoyenne heure par heure. Cela permettra de répondre à la question : “à quel heure sera-t-il généralement préférable de rester à la maison la semaine prochaine ?”\nmoyenne jour par jour. Cela permettra de répondre à la question : “quel jour sera-t-il généralement préférable de rester à la maison la semaine prochaine ?”\n\nDéfinissez une fonction plot_agg_avg_bhi qui calcule l’indice agrégé dans chaque cas, et représente le résultat sous la forme d’un lineplot.\n\n\n\nsolutions.plot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\n\nsolutions.plot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\n\n\n\n\ndef plot_agg_avg_bhi(df_preds, agg_var=\"day\"):\n    # Votre code ici\n    return None\n\n\n# Vérification du résultat\nplot_agg_avg_bhi(df_preds, agg_var=\"day\")\n\n\n# Vérification du résultat\nplot_agg_avg_bhi(df_preds, agg_var=\"hour\")\n\nQu’en concluez-vous pour la semaine à venir ?\n\n\n\n\nNotre outil de prévision des bad hair days fonctionne à merveille. Mais c’est bientôt les vacances, et un voyage à Berlin est prévu. Idéalement, on voudrait pouvoir utiliser notre outil pour n’importe quelle localité. Heureusement, on a défini à chaque étape des fonctions, ce qui va nous permettre de passer facilement à une fonction “chef d’orchestre” qui appelle toutes les autres pour une localité donnée.\nDéfinissez une fonction main qui représente le bad hair index pour un pays, une ville et un niveau d’agrégation donnés.\n\n\n\nsolutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\n\nsolutions.main(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")\n\n\n\n\n\ndef main(country, city, agg_var=\"day\"):\n    # Votre code ici\n    return None\n\n\n# Vérification du résultat\nmain(country=\"Germany\", city=\"Berlin\", agg_var=\"day\")\n\n\n# Vérification du résultat\nmain(country=\"Germany\", city=\"Berlin\", agg_var=\"hour\")",
    "crumbs": [
      "Projets",
      "Projet 2 - Prédictions météorologiques"
    ]
  },
  {
    "objectID": "source/manipulation/numpy/tutorial.html",
    "href": "source/manipulation/numpy/tutorial.html",
    "title": "Calcul numérique avec NumPy",
    "section": "",
    "text": "En tant que statisticien, on est fréquemment amené à manipuler des séries de valeurs numériques, à partir desquelles on réalise diverses opérations mathématiques, des plus usuelles (moyenne, variance, etc.) aux plus complexes. On peut, comme on l’a fait dans les précédents tutoriels, utiliser les objets fondamentaux de Python, et en particulier les listes, pour réaliser de telles opérations. En pratique, on préférera utiliser la librairie de référence pour le calcul scientifique, NumPy, qui fournit à la fois des objets (les arrays) et des fonctions qui vont grandement nous simplifier la vie pour effectuer tous nos calculs en Python de manière efficiente.\n\n\nOn commence par importer la librairie NumPy. Comme expliqué dans un précédent tutoriel, l’usage est courant est de lui attribuer l’alias np.\n\nimport numpy as np\n\n\n\nPlutôt que de présenter de manière abstraite les avantages de NumPy, illustrons ces derniers à travers un exemple simple : la multiplication terme à terme de deux vecteurs.\nOn génère deux vecteurs contenant les entiers allant de \\(0\\) à \\(99999\\), que l’on multiplie terme à terme. On effectue cela d’abord via les listes Python (fonction mult_list), puis à l’aide de NumPy (fonction mult_np), et on compare les performances des deux méthodes.\n\ndef mult_list(n):\n    a = range(n)\n    b = range(n)\n\n    c = []\n    for i in range(len(a)):\n        mult = a[i] * b[i]\n        c.append(mult)\n        \n    return c\n\ndef mult_np(n):\n    a_np = np.arange(n)\n    b_np = np.arange(n)\n    \n    c_np = a_np * b_np\n\n    return c_np\n\n\nn = 100000\n\n\n# Vérification de la cohérence sur les 10 premiers éléments\nprint(mult_list(n)[:10])\nprint(mult_np(n)[:10])\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n[ 0  1  4  9 16 25 36 49 64 81]\n\n\n\n%%timeit -n10\n\nmult_list(n)  # Performance de la méthode liste\n\n16 ms ± 157 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%%timeit -n10\n\nmult_np(n)  # Performance de la méthode NumPy\n\n120 μs ± 21.1 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nCet exemple illustre à lui seul les principaux avantages de NumPy pour le calcul scientifique :\n\nles calculs sont vectorisés : multiplier deux arrays va naturellement effectuer la multiplication terme à terme, contrairement aux listes qui ne permettent pas cette opération. Les personnes travaillant avec R retrouveront là une propriété familière et bien pratique.\nconséquence de la vectorisation, la syntaxe est plus légère et plus claire : on voit directement l’opération qui est effectuée et on limite ainsi les risques d’erreur ;\nles calculs sont automatiquement optimisés par NumPy (via l’appel à du code C pré-compilé), réduisant très largement le temps mis par les opérations mathématiques (divisé par un facteur 10 dans notre exemple).\n\n\n\n\n\n\nToute la librairie NumPy est basée sur un objet fondamental : l’array. Un array est un objet qui contient une séquence de données, et présente deux caractéristiques principales :\n\nles données contenues dans un array doivent être de type homogène, là où une même liste peut contenir des objets de différente nature ;\nun array a une taille fixée à sa création, là où une liste peut grandir dynamiquement (en ajoutant des éléments via la méthode append par exemple).\n\nCe sont en grande partie ces deux contraintes qui rendent possible les gains de performance et la syntaxe lisible qu’offre NumPy.\n\n\n\nIl existe différentes manières de créer un array. La plus standard est de convertir une liste en array via la fonction array de NumPy.\n\nl = [1, 2, 3]\na = np.array(l)\nprint(a)\n\n[1 2 3]\n\n\nA première vue, la fonction print renvoie une représentation identique à celle d’une liste. Vérifions le type de notre objet.\n\ntype(a)\n\nnumpy.ndarray\n\n\nL’objet est de type ndarray, qui est le type standard correspondant à un array NumPy.\nOn a vu qu’un array avait pour propriété de contenir des données de type homogène ; en l’occurrence, des entiers. On peut vérifier le type des données contenues via l’attribut dtype d’un array.\n\na.dtype\n\ndtype('int64')\n\n\nMême si NumPy est avant tout une librairie dédiée au calcul numérique, il reste tout à fait possible de définir des arrays contenant des chaînes de caractères.\n\nb = np.array(['1', 'tigre'])\nb.dtype\n\ndtype('&lt;U5')\n\n\nLe dtype par défaut des arrays contenant des chaînes de caractères est un peu particulier, mais cela n’a pas d’importance en pratique. Retenez simplement sa forme.\nEnfin, question importante : que se passe-t-il si l’on essaie de définir un array contenant des objets de types hétérogènes ?\n\nc = np.array([1, 2, '3'])\nprint(c)\nprint(c.dtype)\n\n['1' '2' '3']\n&lt;U21\n\n\nRéponse : tous les objets sont convertis en chaîne de caractères par défaut.\n\n\n\nLes array correspondent en fait à des tableaux de données, c’est à dire qu’ils peuvent être uni- ou multi-dimensionnels. Un array de dimension 1 ressemble à un vecteur (ou une liste), un array de dimension 2 ressemble à une matrice, et ainsi de suite.\nOn peut afficher le nombre de dimensions d’un array via l’attribut ndim.\n\nc = np.array([1, 2, '3'])\nc.ndim\n\n1\n\n\nDe la même manière que l’on a créé un array de dimension 1 à partir d’une liste simple, on peut créer un array multi-dimensionnel à partir d’une liste de listes.\n\nd = np.array([[1, 2, 3], [4, 5, 6]])\nprint(d)\n\n[[1 2 3]\n [4 5 6]]\n\n\nOn a converti une liste contenant 2 sous-listes à 3 éléments chacune, ce qui donne un array à deux dimensions. Notons que l’appel de print affiche une matrice à deux lignes et trois colonnes.\n\nd.ndim\n\n2\n\n\nOn a bien affaire à un array à deux dimensions. Mais en pratique, lorsqu’on manipule des arrays multidimensionnels, on a aussi envie de connaître la taille de chacune des dimensions. En dimension 2, c’est le nombre de lignes et de colonnes. Pour cela, on utilise la méthode shape, qui renvoie un tuple contenant les tailles des différentes dimensions.\n\nd.shape\n\n(2, 3)\n\n\nLe premier chiffre donne le nombre de lignes, le second le nombre de colonnes. On reviendra par la suite sur l’ordre des dimensions à travers la notion d’axis.\n\n\n\nOn accède aux différents éléments d’un array de dimension 1 exactement de la même manière que ceux d’une liste.\n\na = np.array([1, 2, 3, 4, 5, 6])\n\nprint(a)\nprint()\nprint(a[1])\nprint()\nprint(a[2:5])\nprint()\nprint(a[-2])\n\n[1 2 3 4 5 6]\n\n2\n\n[3 4 5]\n\n5\n\n\nPour un array multidimensionnel, il faut spécifier le ou les éléments voulus sur chacune des dimensions de l’array, en les séparant par des virgules.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nprint(b)\nprint()\nprint(b[1, 3])\nprint()\nprint(b[1:3, 1:3])\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n8\n\n[[ 6  7]\n [10 11]]\n\n\nPour accéder à une ligne complète, on peut utiliser : sur la dimension des colonnes pour spécifier : “toutes les colonnes”. Et inversement pour récupérer une colonne complète.\n\nprint(b[1,:])\nprint()\nprint(b[:,2])\n\n[5 6 7 8]\n\n[ 3  7 11]\n\n\n\n\n\nLes éléments d’un array peuvent être modifiés. On combine pour cela la syntaxe d’indexation vue précédemment avec l’opérateur d’assignation =.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nb[1, 1] = 18\nprint(b)\n\n[[ 1  2  3  4]\n [ 5 18  7  8]\n [ 9 10 11 12]]\n\n\nOn peut également modifier des séries de nombres, voire des lignes/colonnes complètes, à condition d’assigner un élément de même taille.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nb[:, 2] = [-1, -1, -1]\nb\n\narray([[ 1,  2, -1,  4],\n       [ 5,  6, -1,  8],\n       [ 9, 10, -1, 12]])\n\n\nContrairement aux listes, on ne va généralement pas ajouter ou supprimer d’éléments à un array. La raison est que, comme indiqué précédemment, la taille d’un array est fixée à sa construction.\nSi l’on souhaite faire grandir un array, on va généralement le faire à partir d’une liste – qui elle peut grandir – que l’on convertit ensuite en array.\nSi l’on souhaite supprimer des éléments d’un array, on peut utiliser la syntaxe d’indexation étudiée dans la section précédente pour récupérer le sous-array qui nous intéresse, et assigner ce dernier à une nouvelle variable.\n\n\n\nUn gros avantage des arrays NumPy par rapport aux listes est qu’ils supportent les masques booléens, c’est à dire qu’on peut sélectionner des éléments d’un array en lui passant un array de même taille contenant des booléens.\n\na = np.array([1, 2, 3])\na[[True, True, False]]\n\narray([1, 2])\n\n\nCette propriété ouvre de nombreuses possibilités, dans la mesure où elle peut être combinée avec la propriété de vectorisation des arrays. Il devient ainsi très facile de sélectionner des éléments selon des conditions, même pour les arrays multidimensionnels.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\ncond = (b &gt; 6) & (b != 10)\n\nprint(cond)\nprint()\nprint(b[cond])\n\n[[False False False False]\n [False False  True  True]\n [ True False  True  True]]\n\n[ 7  8  9 11 12]\n\n\nEt l’on peut bien entendu exploiter ce mécanisme pour modifier des éléments selon une condition.\n\nb[cond] = -1\nprint(b)\n\n[[ 1  2  3  4]\n [ 5  6 -1 -1]\n [-1 10 -1 -1]]\n\n\nCe dernier exemple illustre par ailleurs une propriété importante en NumPy appelée broadcasting : lorsque l’on remplace plusieurs éléments d’un array par un élément de taille 1 (et non un array de même taille), tous les éléments sont remplacés par cette valeur.\n\n\n\n\n\n\nTout au début de ce tutoriel, nous avons vu que multiplier deux arrays via l’opérateur * effectuait une multiplication termes à termes des deux arrays, et ce de manière vectorisée. Les opérations élémentaires (+, -, * et /) s’appliquent de la même manière aux arrays multidimensionnels.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\nb = np.array([[3, 3, 1], [1, 3, 3]])\n\na * b\n\narray([[3, 6, 2],\n       [2, 6, 3]])\n\n\nNotons qu’on retrouve la propriété de broadcasting discutée dans la section précédente : lorsque l’on effectue une opération entre un array et un nombre de taille 1, l’opération est appliquée à chaque terme de l’array.\n\na * 4\n\narray([[4, 8, 8],\n       [8, 8, 4]])\n\n\n\n\n\nNumPy permet de réaliser simplement et de manière efficiente des opérations d’algèbre linéaire sur les arrays. L’ensemble des fonctions disponibles sont présentées dans la documentation officielle (en Anglais).\nPar exemple, l’opérateur @ permet de réaliser une multiplication matricielle (et non plus termes à termes comme le fait *).\n\na = np.array([[1, 2, 3], [3, 2, 1]])\nb = np.array([[2, 3], [1, 3], [3, 1]])\n\na @ b\n\narray([[13, 12],\n       [11, 16]])\n\n\n\n\n\nNumPy offre pléthore de fonctions mathématiques et statistiques, comme sum, mean, min, round, log, etc. Leur application à des objets unidimensionnels ne pose pas de problème particulier.\n\nprint(np.log(12))\nprint()\nprint(np.min([1, 2, 3]))\nprint()\nprint(np.mean([1, 2, 3]))\n\n2.4849066497880004\n\n1\n\n2.0\n\n\nEn revanche, dans le cas multidimensionnel, leur utilisation devient un peu plus subtile car on peut vouloir réaliser l’agrégation selon différentes dimensions. Si l’on ne spécifie rien, l’agrégation est effectuée sur tous les éléments de l’array.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a)\n\nnp.int64(10)\n\n\nMais comment faire si l’on veut sommer par ligne ? Ou bien par colonne ? C’est là qu’intervient un élément crucial et assez complexe des fonctions de NumPy : le paramètre axis, qui spécifie la dimension selon laquelle est effectuée l’opération.\nLorsqu’il n’est pas spécifié comme dans l’exemple précédent, il prend la valeur None par défaut.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a, axis=None)  # idem que np.sum(a)\n\nnp.int64(10)\n\n\nLa figure suivante permet de bien se représenter la manière dont fonctionnent les axes avec NumPy, afin de bien spécifier le sens attendu de l’agrégation.\n\n\n\naxis\n\n\nAinsi, si l’on souhaite calculer la somme de chaque colonne par exemple, il faut agréger selon l’axe \\(0\\).\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a, axis=0)\n\narray([3, 4, 3])\n\n\nEt inversement pour obtenir les sommes de chaque ligne.\n\nnp.sum(a, axis=1)\n\narray([5, 5])\n\n\nEnfin, notons que les fonctions mathématiques qui réalisent une agrégation sont généralement également disponibles comme méthodes d’un array. Elles fonctionnent de la même manière, au détail près qu’elles ne prennent pas l’array en argument dans la mesure où elles sont déjà “attachées” à celui-ci.\n\na.sum(axis=1)\n\narray([5, 5])\n\n\n\n\n\n\nNumPy est la librairie quasi-standard de calcul scientifique en Python. Elle est à privilégier dès lors que vous souhaitez effectuer des opérations sur des données numériques, a fortiori lorsqu’il s’agit d’opérations vectorisées et/ou mobilisant des objets multidimensionnels comme des matrices.\nLes possibilités offertes par NumPy sont gigantesques, et nous n’en avons vu qu’un aperçu. La documentation officielle présente l’ensemble de ces possibilités. Cette cheat sheet peut également s’avérer utile en cas d’oubli. Nous verrons également des fonctions supplémentaires à travers les exercices de fin de chapitre.\n\n\n\n\n\n\n\n1/ Quels sont les principaux avantages de NumPy ?\n2/ Quelles sont les deux caractéristiques principales d’un array NumPy ?\n3/ Que se passe-t-il si l’on essaie de définir un array contenant des objets de types hétérogènes ?\n4/ Quelle est la principale méthode pour créer un array ?\n5/ Quelles informations contient l’attribut shape d’un array ?\n6/ Peut-on ajouter un élément à un array ? Supprimer un élément ?\n7/ Qu’est-ce qu’un masque booléen et à quoi cela sert-il ?\n8/ Qu’est-ce que la propriété de broadcasting ?\n9/ A quoi sert le paramètre axis des fonctions mathématiques de NumPy ?\n\n\n\n\nAfficher la solution\n\n\n1/ Les calculs sont vectorisés, ce qui simplifie grandement la syntaxe et réduit donc les risques d’erreur. Par ailleurs, les calculs sont optimisés automatiquement par NumPy, ce qui accroît très fortement les performances.\n2/ Les données contenues dans un array doivent être de type homogène. Un array a une taille fixée lors de sa création.\n3/ Tous les objets sont interprétés comme des chaînes de caractères.\n4/ Créer une liste et la convertir ensuite en array via la fonction np.array.\n5/ L’attribut shape d’un array renvoie un tuple qui contient la taille de chaque dimension, et donc également le nombre de dimensions.\n6/ Il existe des fonctions qui effectuent ces opérations, mais elles ne sont pas très utilisées en pratique, dans la mesure où un array est de taille fixée lors de sa création.\n7/ Un masque booléen est un array de valeurs booléennes (True et False), que l’on va utiliser pour sélectionner des éléments d’un autre array. C’est notamment très pratique pour sélectionner des éléments selon une condition (test).\n8/ Lorsqu’on effectue une opération entre un array et une valeur de taille 1 (typiquement, un entier ou un réel), l’opération est appliquée à chaque élément de l’array.\n9/ Le paramètre axis sert à spécifier la dimension selon laquelle on souhaite performer une agrégation (fonction math, stat..).\n\n\n\n\n\n\nUn vecteur comprenant les entiers compris entre 10 et 20 est défini dans la cellule suivante. En utilisant l’indexation des arrays NumPy :\n\nsélectionner les éléments aux positions 1, 3 et 4\nsélectionner tous les éléments sauf le premier\nsélectionner tous les éléments sauf le premier et le dernier\nsélectionner les 3 premiers éléments\nsélectionner les 5 derniers éléments\nsélectionner tous les éléments pairs\nsélectionner tous les éléments en les triant dans l’ordre inverse (NB : la fonction np.flip permet de faire la même chose)\n\n\nX = np.arange(10, 21)\n\nprint(X)\n\n[10 11 12 13 14 15 16 17 18 19 20]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.arange(10, 21)\n\nprint(X[[1, 3, 4]])\nprint(X[1:])\nprint(X[1:-1])\nprint(X[:3])\nprint(X[-5:])\nprint(X[::2])\nprint(X[::-1])\n\n\n\n\n\nUne matrice de taille 5x5 comprenant tous les entiers compris entre 0 et 24 est définie dans la cellule suivante. En utilisant l’indexation des arrays NumPy :\n\nsélectionner la valeur \\(19\\)\nsélectionner la 2ème ligne\nsélectionner la 4ème colonne\nsélectionner la sous-matrice 3x3 centrale\nsélectionner les éléments diagonaux (NB : la fonction np.diag permet de réaliser la même opération de manière beaucoup plus simple)\n\n\nY = np.arange(0, 25).reshape((5, 5))\n\nprint(Y)\n\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nY = np.arange(0, 25).reshape((5, 5))\n\nprint(Y[3, 4])\nprint(Y[1, :])\nprint(Y[:, 3])\nprint(Y[1:4, 1:4])\nprint(Y[np.arange(0, 5), np.arange(0, 5)])\n\n\n\n\n\nDeux matrices carrées de taille 3x3 sont définies sous forme d’arrays NumPy dans la cellule suivante. A partir de ces matrices, réaliser les opérations mathématiques suivantes :\n\nmultiplier tous les éléments de X par 3\ndiviser les éléments de Y par ceux de X\npasser tous les éléments de Y au log\npasser tous les éléments de X au carré\nfaire une multiplication matricielle de X et Y\ntransposer la matrice Y\n\nNB : vous pourrez trouver les fonctions nécessaires dans la documentation ou via un moteur de recherche.\n\nX = np.array([[1,2,3],\n              [4,5,6],\n              [7,8,9]])\n\nY = np.array([[10,11,12],\n              [13,14,15],\n              [16,17,18]])\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.array([[1,2,3],\n              [4,5,6],\n              [7,8,9]])\n\nY = np.array([[10,11,12],\n              [13,14,15],\n              [16,17,18]])\n\nprint(3 * X)\nprint()\nprint(Y / X)\nprint()\nprint(np.log(Y))\nprint()\nprint(np.square(X))\nprint()\nprint(Y @ X)\nprint()\nprint(Y.T)\n\n\n\n\n\nDans le tutoriel, nous avons vu que la méthode standard pour créer un array NumPy consistait à initialiser une liste, que l’on convertit ensuite en array. On peut également utiliser des fonctions natives de NumPy qui créent des array d’une taille donnée, contenant des valeurs basiques (ex : valeurs “quasi-vides”, zéros, uns, une valeur spécifiée par l’utilisateur, etc.).\nPar exemple, pour créer une matrice à 3 lignes et deux colonnes contenant des zéros, la syntaxe est :\n\nnp.zeros((3, 2))\n\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.]])\n\n\nEn vous référant à la documentation de ces fonctions, générer :\n\nun vecteur (array à 1 dimension), contenant 18 fois la valeur \\(1\\) (fonction np.ones)\nun array à 3 dimensions, respectivement de tailles 2, 3 et 5, contenant uniquement des zéros (fonction np.zeros)\nune matrice (array à 2 dimensions), à 4 lignes et 3 colonnes, contenant uniquement la valeur 5 (fonction np.full)\nune matrice identité de taille 5, i.e. une matrice à 5 lignes et 5 colonnes, contenant des \\(1\\) sur sa diagonale et des \\(0\\) partout ailleurs (fonction np.eye)\nun vecteur contenant les entiers compris entre \\(0\\) à \\(99\\) inclus (fonction np.arange)\nun vecteur contenant les entiers pairs compris entre \\(0\\) à \\(99\\) inclus (fonction np.arange)\nun vecteur contenant 5 valeurs uniformément espacées entre \\(2\\) et \\(3\\) inclus (fonction np.linspace)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = np.ones((18,))\nprint(a)\nprint()\n\nb = np.zeros((2, 3, 5))\nprint(b)\nprint()\n\nc = np.full((4, 3), fill_value=5)\nprint(c)\nprint()\n\nd = np.eye(5)\nprint(d)\nprint()\n\ne = np.arange(0, 100)\nprint(e)\nprint()\n\nx = np.arange(0, 100, step=2)\nprint(x)\nprint()\n\ny = np.linspace(2.0, 3.0, num=5)\nprint(y)\nprint()\n\n\n\n\n\nEn vous référant à la documentation des fonctions de génération de nombres aléatoires de NumPy, générer un vecteur X de taille 10000, contenant des nombres tirés selon une loi normale de moyenne 0 et de variance 2.\nVérifiez ensuite à l’aide des fonctions mathématiques de NumPy que la moyenne et la variance de votre échantillon sont cohérents par rapport aux valeurs attendues.\nIndice : attention à la manière dont est spécifiée la variance dans la fonction NumPy de génération d’une loi normale.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.random.normal(0, np.sqrt(2), 10000)\n\nprint(np.mean(X), np.var(X))\n\n\n\n\n\nEn vous référant à la documentation des fonctions de génération de nombres aléatoires de NumPy, générer une matrice U de taille 1000 par 1000, contenant des nombres tirés selon une loi uniforme dans l’intervalle [-1, 1].\nEn utilisant la fonction np.all et un test booléen, vérifier que tous les nombres contenus dans U sont bien compris entre -1 et 1.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nN = 1000\nU = np.random.uniform(-1, 1, size=(N, N))\n\nnp.all((U &gt;= -1) & (U &lt;= 1))\n\n\n\n\n\nOn peut parfois avoir besoin de binariser une matrice numérique, c’est à dire de fixer un seuil au delà duquel les valeurs numériques sont fixées à 1, et à 0 en-dessous. NumPy propose plusieurs méthodes pour réaliser une telle opération, nous allons en voir deux.\nDans la cellule suivante, une matrice X à 6 lignes et 6 colonnes est générée, qui comprend des entiers aléatoirement choisis entre 0 et 49. Vous devez binariser cette matrice de deux manières différentes sans l’écraser (i.e. la matrice binaire doit être assignée à une autre variable que X et X ne doit pas être modifiée) :\n\npremière méthode : en utilisant la fonction np.zeros et les masques booléens\nseconde méthode : en utilisant la fonction np.where (cf. doc)\n\n\nX = np.random.randint(0, 50, size=(6, 6))\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.random.randint(0, 50, size=(6, 6))\n\n# Première possibilité : via les masques booléens\nA = np.zeros((6, 6))\nA[X &gt; 25] = 1\n\n# Deuxième possibilité : via la fonction np.where\nB = np.where(X &gt; 25, 1, 0)\n\nprint(X)\nprint()\nprint(A)\nprint()\nprint(B)\n\n\n\n\n\nL’objectif de cet exercice est de programmer seulement à l’aide d’objets et de fonctions de NumPy un touché-coulé très basique.\nUne grille de 5x5 est définie dans la cellule suivante comme un array, les valeurs \\(1\\) symbolisant la présence d’un bateau. Vous devez programmer une fonction shoot qui :\n\nprend en input une coordonnée \\(x\\) (indice de la ligne) et une cordonnée \\(y\\) (indice de la colonne)\nteste si au moins une valeur \\(1\\) est présente dans la grille :\n\nsi oui :\n\ns’il y a un bateau à l’adresse (x, y), remplacer la valeur \\(1\\) par \\(2\\) et print “Touché !”\nsinon, print “Raté !”\n\nsi non :\n\nprint “Fin de partie !”\n\n\n\nPuis réalisez quelques tests pour vous assurer que votre fonction marche comme attendu.\n\nX = np.array([[1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1],\n              [1, 0, 0, 0, 0], [0, 1, 1, 1, 1]])\nprint(X)\n\n[[1 1 1 0 0]\n [0 0 0 0 1]\n [1 0 0 0 1]\n [1 0 0 0 0]\n [0 1 1 1 1]]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.array([[1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1],\n              [1, 0, 0, 0, 0], [0, 1, 1, 1, 1]])\n\ndef shoot(x, y):\n    if np.any(X == 1):\n        if X[x, y] == 1:\n            print(\"Touché !\")\n            X[x, y] = 2\n        else:\n            print(\"Raté !\")\n        print(X)\n        print()\n    else:\n        print(\"Fin de partie !\")\n\nshoot(0, 1)\nshoot(1, 0)\nshoot(0, 2)\n\n\n\n\n\nEn statistique, il est fréquent de vouloir encoder numériquement un vecteur de catégories. Une manière fréquente d’encoder des catégories est le one hot encoding (OHE) : chaque valeur est représentée par un vecteur binaire, qui contient un \\(1\\) sur la colonne correspondant à la catégorie et des \\(0\\) partout ailleurs.\nDans la cellule suivante, on encode des PCS au format OHE grâce à une fonction du package scikit-learn. L’objectif de l’exercice est de reproduire cet encodage en utilisant uniquement des fonctions de la librairie NumPy.\nIndice : on pourra utiliser les fonctions np.unique, np.zeros et np.arange.\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nvalues = np.array([\"21\", \"46\", \"47\", \"23\", \"66\", \"82\", \"82\"])\n\nprint(OneHotEncoder().fit_transform(values.reshape((-1, 1))).todense())\n\n[[1. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 0. 1.]]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nvalues = np.array([\"21\", \"46\", \"47\", \"23\", \"66\", \"82\", \"82\"])\n\ncategories, pos = np.unique(values, return_inverse=True)\nn_values = values.shape[0]\nn_categories = categories.shape[0]\n\nohe = np.zeros((n_values, n_categories))\nohe[np.arange(n_values), pos] = 1\nohe",
    "crumbs": [
      "Manipulation de données",
      "Calcul numérique avec NumPy"
    ]
  },
  {
    "objectID": "source/manipulation/numpy/tutorial.html#numpy",
    "href": "source/manipulation/numpy/tutorial.html#numpy",
    "title": "Calcul numérique avec NumPy",
    "section": "",
    "text": "On commence par importer la librairie NumPy. Comme expliqué dans un précédent tutoriel, l’usage est courant est de lui attribuer l’alias np.\n\nimport numpy as np\n\n\n\nPlutôt que de présenter de manière abstraite les avantages de NumPy, illustrons ces derniers à travers un exemple simple : la multiplication terme à terme de deux vecteurs.\nOn génère deux vecteurs contenant les entiers allant de \\(0\\) à \\(99999\\), que l’on multiplie terme à terme. On effectue cela d’abord via les listes Python (fonction mult_list), puis à l’aide de NumPy (fonction mult_np), et on compare les performances des deux méthodes.\n\ndef mult_list(n):\n    a = range(n)\n    b = range(n)\n\n    c = []\n    for i in range(len(a)):\n        mult = a[i] * b[i]\n        c.append(mult)\n        \n    return c\n\ndef mult_np(n):\n    a_np = np.arange(n)\n    b_np = np.arange(n)\n    \n    c_np = a_np * b_np\n\n    return c_np\n\n\nn = 100000\n\n\n# Vérification de la cohérence sur les 10 premiers éléments\nprint(mult_list(n)[:10])\nprint(mult_np(n)[:10])\n\n[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n[ 0  1  4  9 16 25 36 49 64 81]\n\n\n\n%%timeit -n10\n\nmult_list(n)  # Performance de la méthode liste\n\n16 ms ± 157 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\n\n%%timeit -n10\n\nmult_np(n)  # Performance de la méthode NumPy\n\n120 μs ± 21.1 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n\n\nCet exemple illustre à lui seul les principaux avantages de NumPy pour le calcul scientifique :\n\nles calculs sont vectorisés : multiplier deux arrays va naturellement effectuer la multiplication terme à terme, contrairement aux listes qui ne permettent pas cette opération. Les personnes travaillant avec R retrouveront là une propriété familière et bien pratique.\nconséquence de la vectorisation, la syntaxe est plus légère et plus claire : on voit directement l’opération qui est effectuée et on limite ainsi les risques d’erreur ;\nles calculs sont automatiquement optimisés par NumPy (via l’appel à du code C pré-compilé), réduisant très largement le temps mis par les opérations mathématiques (divisé par un facteur 10 dans notre exemple).\n\n\n\n\n\n\nToute la librairie NumPy est basée sur un objet fondamental : l’array. Un array est un objet qui contient une séquence de données, et présente deux caractéristiques principales :\n\nles données contenues dans un array doivent être de type homogène, là où une même liste peut contenir des objets de différente nature ;\nun array a une taille fixée à sa création, là où une liste peut grandir dynamiquement (en ajoutant des éléments via la méthode append par exemple).\n\nCe sont en grande partie ces deux contraintes qui rendent possible les gains de performance et la syntaxe lisible qu’offre NumPy.\n\n\n\nIl existe différentes manières de créer un array. La plus standard est de convertir une liste en array via la fonction array de NumPy.\n\nl = [1, 2, 3]\na = np.array(l)\nprint(a)\n\n[1 2 3]\n\n\nA première vue, la fonction print renvoie une représentation identique à celle d’une liste. Vérifions le type de notre objet.\n\ntype(a)\n\nnumpy.ndarray\n\n\nL’objet est de type ndarray, qui est le type standard correspondant à un array NumPy.\nOn a vu qu’un array avait pour propriété de contenir des données de type homogène ; en l’occurrence, des entiers. On peut vérifier le type des données contenues via l’attribut dtype d’un array.\n\na.dtype\n\ndtype('int64')\n\n\nMême si NumPy est avant tout une librairie dédiée au calcul numérique, il reste tout à fait possible de définir des arrays contenant des chaînes de caractères.\n\nb = np.array(['1', 'tigre'])\nb.dtype\n\ndtype('&lt;U5')\n\n\nLe dtype par défaut des arrays contenant des chaînes de caractères est un peu particulier, mais cela n’a pas d’importance en pratique. Retenez simplement sa forme.\nEnfin, question importante : que se passe-t-il si l’on essaie de définir un array contenant des objets de types hétérogènes ?\n\nc = np.array([1, 2, '3'])\nprint(c)\nprint(c.dtype)\n\n['1' '2' '3']\n&lt;U21\n\n\nRéponse : tous les objets sont convertis en chaîne de caractères par défaut.\n\n\n\nLes array correspondent en fait à des tableaux de données, c’est à dire qu’ils peuvent être uni- ou multi-dimensionnels. Un array de dimension 1 ressemble à un vecteur (ou une liste), un array de dimension 2 ressemble à une matrice, et ainsi de suite.\nOn peut afficher le nombre de dimensions d’un array via l’attribut ndim.\n\nc = np.array([1, 2, '3'])\nc.ndim\n\n1\n\n\nDe la même manière que l’on a créé un array de dimension 1 à partir d’une liste simple, on peut créer un array multi-dimensionnel à partir d’une liste de listes.\n\nd = np.array([[1, 2, 3], [4, 5, 6]])\nprint(d)\n\n[[1 2 3]\n [4 5 6]]\n\n\nOn a converti une liste contenant 2 sous-listes à 3 éléments chacune, ce qui donne un array à deux dimensions. Notons que l’appel de print affiche une matrice à deux lignes et trois colonnes.\n\nd.ndim\n\n2\n\n\nOn a bien affaire à un array à deux dimensions. Mais en pratique, lorsqu’on manipule des arrays multidimensionnels, on a aussi envie de connaître la taille de chacune des dimensions. En dimension 2, c’est le nombre de lignes et de colonnes. Pour cela, on utilise la méthode shape, qui renvoie un tuple contenant les tailles des différentes dimensions.\n\nd.shape\n\n(2, 3)\n\n\nLe premier chiffre donne le nombre de lignes, le second le nombre de colonnes. On reviendra par la suite sur l’ordre des dimensions à travers la notion d’axis.\n\n\n\nOn accède aux différents éléments d’un array de dimension 1 exactement de la même manière que ceux d’une liste.\n\na = np.array([1, 2, 3, 4, 5, 6])\n\nprint(a)\nprint()\nprint(a[1])\nprint()\nprint(a[2:5])\nprint()\nprint(a[-2])\n\n[1 2 3 4 5 6]\n\n2\n\n[3 4 5]\n\n5\n\n\nPour un array multidimensionnel, il faut spécifier le ou les éléments voulus sur chacune des dimensions de l’array, en les séparant par des virgules.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nprint(b)\nprint()\nprint(b[1, 3])\nprint()\nprint(b[1:3, 1:3])\n\n[[ 1  2  3  4]\n [ 5  6  7  8]\n [ 9 10 11 12]]\n\n8\n\n[[ 6  7]\n [10 11]]\n\n\nPour accéder à une ligne complète, on peut utiliser : sur la dimension des colonnes pour spécifier : “toutes les colonnes”. Et inversement pour récupérer une colonne complète.\n\nprint(b[1,:])\nprint()\nprint(b[:,2])\n\n[5 6 7 8]\n\n[ 3  7 11]\n\n\n\n\n\nLes éléments d’un array peuvent être modifiés. On combine pour cela la syntaxe d’indexation vue précédemment avec l’opérateur d’assignation =.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nb[1, 1] = 18\nprint(b)\n\n[[ 1  2  3  4]\n [ 5 18  7  8]\n [ 9 10 11 12]]\n\n\nOn peut également modifier des séries de nombres, voire des lignes/colonnes complètes, à condition d’assigner un élément de même taille.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n\nb[:, 2] = [-1, -1, -1]\nb\n\narray([[ 1,  2, -1,  4],\n       [ 5,  6, -1,  8],\n       [ 9, 10, -1, 12]])\n\n\nContrairement aux listes, on ne va généralement pas ajouter ou supprimer d’éléments à un array. La raison est que, comme indiqué précédemment, la taille d’un array est fixée à sa construction.\nSi l’on souhaite faire grandir un array, on va généralement le faire à partir d’une liste – qui elle peut grandir – que l’on convertit ensuite en array.\nSi l’on souhaite supprimer des éléments d’un array, on peut utiliser la syntaxe d’indexation étudiée dans la section précédente pour récupérer le sous-array qui nous intéresse, et assigner ce dernier à une nouvelle variable.\n\n\n\nUn gros avantage des arrays NumPy par rapport aux listes est qu’ils supportent les masques booléens, c’est à dire qu’on peut sélectionner des éléments d’un array en lui passant un array de même taille contenant des booléens.\n\na = np.array([1, 2, 3])\na[[True, True, False]]\n\narray([1, 2])\n\n\nCette propriété ouvre de nombreuses possibilités, dans la mesure où elle peut être combinée avec la propriété de vectorisation des arrays. Il devient ainsi très facile de sélectionner des éléments selon des conditions, même pour les arrays multidimensionnels.\n\nb = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\ncond = (b &gt; 6) & (b != 10)\n\nprint(cond)\nprint()\nprint(b[cond])\n\n[[False False False False]\n [False False  True  True]\n [ True False  True  True]]\n\n[ 7  8  9 11 12]\n\n\nEt l’on peut bien entendu exploiter ce mécanisme pour modifier des éléments selon une condition.\n\nb[cond] = -1\nprint(b)\n\n[[ 1  2  3  4]\n [ 5  6 -1 -1]\n [-1 10 -1 -1]]\n\n\nCe dernier exemple illustre par ailleurs une propriété importante en NumPy appelée broadcasting : lorsque l’on remplace plusieurs éléments d’un array par un élément de taille 1 (et non un array de même taille), tous les éléments sont remplacés par cette valeur.\n\n\n\n\n\n\nTout au début de ce tutoriel, nous avons vu que multiplier deux arrays via l’opérateur * effectuait une multiplication termes à termes des deux arrays, et ce de manière vectorisée. Les opérations élémentaires (+, -, * et /) s’appliquent de la même manière aux arrays multidimensionnels.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\nb = np.array([[3, 3, 1], [1, 3, 3]])\n\na * b\n\narray([[3, 6, 2],\n       [2, 6, 3]])\n\n\nNotons qu’on retrouve la propriété de broadcasting discutée dans la section précédente : lorsque l’on effectue une opération entre un array et un nombre de taille 1, l’opération est appliquée à chaque terme de l’array.\n\na * 4\n\narray([[4, 8, 8],\n       [8, 8, 4]])\n\n\n\n\n\nNumPy permet de réaliser simplement et de manière efficiente des opérations d’algèbre linéaire sur les arrays. L’ensemble des fonctions disponibles sont présentées dans la documentation officielle (en Anglais).\nPar exemple, l’opérateur @ permet de réaliser une multiplication matricielle (et non plus termes à termes comme le fait *).\n\na = np.array([[1, 2, 3], [3, 2, 1]])\nb = np.array([[2, 3], [1, 3], [3, 1]])\n\na @ b\n\narray([[13, 12],\n       [11, 16]])\n\n\n\n\n\nNumPy offre pléthore de fonctions mathématiques et statistiques, comme sum, mean, min, round, log, etc. Leur application à des objets unidimensionnels ne pose pas de problème particulier.\n\nprint(np.log(12))\nprint()\nprint(np.min([1, 2, 3]))\nprint()\nprint(np.mean([1, 2, 3]))\n\n2.4849066497880004\n\n1\n\n2.0\n\n\nEn revanche, dans le cas multidimensionnel, leur utilisation devient un peu plus subtile car on peut vouloir réaliser l’agrégation selon différentes dimensions. Si l’on ne spécifie rien, l’agrégation est effectuée sur tous les éléments de l’array.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a)\n\nnp.int64(10)\n\n\nMais comment faire si l’on veut sommer par ligne ? Ou bien par colonne ? C’est là qu’intervient un élément crucial et assez complexe des fonctions de NumPy : le paramètre axis, qui spécifie la dimension selon laquelle est effectuée l’opération.\nLorsqu’il n’est pas spécifié comme dans l’exemple précédent, il prend la valeur None par défaut.\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a, axis=None)  # idem que np.sum(a)\n\nnp.int64(10)\n\n\nLa figure suivante permet de bien se représenter la manière dont fonctionnent les axes avec NumPy, afin de bien spécifier le sens attendu de l’agrégation.\n\n\n\naxis\n\n\nAinsi, si l’on souhaite calculer la somme de chaque colonne par exemple, il faut agréger selon l’axe \\(0\\).\n\na = np.array([[1, 2, 2], [2, 2, 1]])\n\nnp.sum(a, axis=0)\n\narray([3, 4, 3])\n\n\nEt inversement pour obtenir les sommes de chaque ligne.\n\nnp.sum(a, axis=1)\n\narray([5, 5])\n\n\nEnfin, notons que les fonctions mathématiques qui réalisent une agrégation sont généralement également disponibles comme méthodes d’un array. Elles fonctionnent de la même manière, au détail près qu’elles ne prennent pas l’array en argument dans la mesure où elles sont déjà “attachées” à celui-ci.\n\na.sum(axis=1)\n\narray([5, 5])\n\n\n\n\n\n\nNumPy est la librairie quasi-standard de calcul scientifique en Python. Elle est à privilégier dès lors que vous souhaitez effectuer des opérations sur des données numériques, a fortiori lorsqu’il s’agit d’opérations vectorisées et/ou mobilisant des objets multidimensionnels comme des matrices.\nLes possibilités offertes par NumPy sont gigantesques, et nous n’en avons vu qu’un aperçu. La documentation officielle présente l’ensemble de ces possibilités. Cette cheat sheet peut également s’avérer utile en cas d’oubli. Nous verrons également des fonctions supplémentaires à travers les exercices de fin de chapitre.",
    "crumbs": [
      "Manipulation de données",
      "Calcul numérique avec NumPy"
    ]
  },
  {
    "objectID": "source/manipulation/numpy/tutorial.html#exercices",
    "href": "source/manipulation/numpy/tutorial.html#exercices",
    "title": "Calcul numérique avec NumPy",
    "section": "",
    "text": "1/ Quels sont les principaux avantages de NumPy ?\n2/ Quelles sont les deux caractéristiques principales d’un array NumPy ?\n3/ Que se passe-t-il si l’on essaie de définir un array contenant des objets de types hétérogènes ?\n4/ Quelle est la principale méthode pour créer un array ?\n5/ Quelles informations contient l’attribut shape d’un array ?\n6/ Peut-on ajouter un élément à un array ? Supprimer un élément ?\n7/ Qu’est-ce qu’un masque booléen et à quoi cela sert-il ?\n8/ Qu’est-ce que la propriété de broadcasting ?\n9/ A quoi sert le paramètre axis des fonctions mathématiques de NumPy ?\n\n\n\n\nAfficher la solution\n\n\n1/ Les calculs sont vectorisés, ce qui simplifie grandement la syntaxe et réduit donc les risques d’erreur. Par ailleurs, les calculs sont optimisés automatiquement par NumPy, ce qui accroît très fortement les performances.\n2/ Les données contenues dans un array doivent être de type homogène. Un array a une taille fixée lors de sa création.\n3/ Tous les objets sont interprétés comme des chaînes de caractères.\n4/ Créer une liste et la convertir ensuite en array via la fonction np.array.\n5/ L’attribut shape d’un array renvoie un tuple qui contient la taille de chaque dimension, et donc également le nombre de dimensions.\n6/ Il existe des fonctions qui effectuent ces opérations, mais elles ne sont pas très utilisées en pratique, dans la mesure où un array est de taille fixée lors de sa création.\n7/ Un masque booléen est un array de valeurs booléennes (True et False), que l’on va utiliser pour sélectionner des éléments d’un autre array. C’est notamment très pratique pour sélectionner des éléments selon une condition (test).\n8/ Lorsqu’on effectue une opération entre un array et une valeur de taille 1 (typiquement, un entier ou un réel), l’opération est appliquée à chaque élément de l’array.\n9/ Le paramètre axis sert à spécifier la dimension selon laquelle on souhaite performer une agrégation (fonction math, stat..).\n\n\n\n\n\n\nUn vecteur comprenant les entiers compris entre 10 et 20 est défini dans la cellule suivante. En utilisant l’indexation des arrays NumPy :\n\nsélectionner les éléments aux positions 1, 3 et 4\nsélectionner tous les éléments sauf le premier\nsélectionner tous les éléments sauf le premier et le dernier\nsélectionner les 3 premiers éléments\nsélectionner les 5 derniers éléments\nsélectionner tous les éléments pairs\nsélectionner tous les éléments en les triant dans l’ordre inverse (NB : la fonction np.flip permet de faire la même chose)\n\n\nX = np.arange(10, 21)\n\nprint(X)\n\n[10 11 12 13 14 15 16 17 18 19 20]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.arange(10, 21)\n\nprint(X[[1, 3, 4]])\nprint(X[1:])\nprint(X[1:-1])\nprint(X[:3])\nprint(X[-5:])\nprint(X[::2])\nprint(X[::-1])\n\n\n\n\n\nUne matrice de taille 5x5 comprenant tous les entiers compris entre 0 et 24 est définie dans la cellule suivante. En utilisant l’indexation des arrays NumPy :\n\nsélectionner la valeur \\(19\\)\nsélectionner la 2ème ligne\nsélectionner la 4ème colonne\nsélectionner la sous-matrice 3x3 centrale\nsélectionner les éléments diagonaux (NB : la fonction np.diag permet de réaliser la même opération de manière beaucoup plus simple)\n\n\nY = np.arange(0, 25).reshape((5, 5))\n\nprint(Y)\n\n[[ 0  1  2  3  4]\n [ 5  6  7  8  9]\n [10 11 12 13 14]\n [15 16 17 18 19]\n [20 21 22 23 24]]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nY = np.arange(0, 25).reshape((5, 5))\n\nprint(Y[3, 4])\nprint(Y[1, :])\nprint(Y[:, 3])\nprint(Y[1:4, 1:4])\nprint(Y[np.arange(0, 5), np.arange(0, 5)])\n\n\n\n\n\nDeux matrices carrées de taille 3x3 sont définies sous forme d’arrays NumPy dans la cellule suivante. A partir de ces matrices, réaliser les opérations mathématiques suivantes :\n\nmultiplier tous les éléments de X par 3\ndiviser les éléments de Y par ceux de X\npasser tous les éléments de Y au log\npasser tous les éléments de X au carré\nfaire une multiplication matricielle de X et Y\ntransposer la matrice Y\n\nNB : vous pourrez trouver les fonctions nécessaires dans la documentation ou via un moteur de recherche.\n\nX = np.array([[1,2,3],\n              [4,5,6],\n              [7,8,9]])\n\nY = np.array([[10,11,12],\n              [13,14,15],\n              [16,17,18]])\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.array([[1,2,3],\n              [4,5,6],\n              [7,8,9]])\n\nY = np.array([[10,11,12],\n              [13,14,15],\n              [16,17,18]])\n\nprint(3 * X)\nprint()\nprint(Y / X)\nprint()\nprint(np.log(Y))\nprint()\nprint(np.square(X))\nprint()\nprint(Y @ X)\nprint()\nprint(Y.T)\n\n\n\n\n\nDans le tutoriel, nous avons vu que la méthode standard pour créer un array NumPy consistait à initialiser une liste, que l’on convertit ensuite en array. On peut également utiliser des fonctions natives de NumPy qui créent des array d’une taille donnée, contenant des valeurs basiques (ex : valeurs “quasi-vides”, zéros, uns, une valeur spécifiée par l’utilisateur, etc.).\nPar exemple, pour créer une matrice à 3 lignes et deux colonnes contenant des zéros, la syntaxe est :\n\nnp.zeros((3, 2))\n\narray([[0., 0.],\n       [0., 0.],\n       [0., 0.]])\n\n\nEn vous référant à la documentation de ces fonctions, générer :\n\nun vecteur (array à 1 dimension), contenant 18 fois la valeur \\(1\\) (fonction np.ones)\nun array à 3 dimensions, respectivement de tailles 2, 3 et 5, contenant uniquement des zéros (fonction np.zeros)\nune matrice (array à 2 dimensions), à 4 lignes et 3 colonnes, contenant uniquement la valeur 5 (fonction np.full)\nune matrice identité de taille 5, i.e. une matrice à 5 lignes et 5 colonnes, contenant des \\(1\\) sur sa diagonale et des \\(0\\) partout ailleurs (fonction np.eye)\nun vecteur contenant les entiers compris entre \\(0\\) à \\(99\\) inclus (fonction np.arange)\nun vecteur contenant les entiers pairs compris entre \\(0\\) à \\(99\\) inclus (fonction np.arange)\nun vecteur contenant 5 valeurs uniformément espacées entre \\(2\\) et \\(3\\) inclus (fonction np.linspace)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = np.ones((18,))\nprint(a)\nprint()\n\nb = np.zeros((2, 3, 5))\nprint(b)\nprint()\n\nc = np.full((4, 3), fill_value=5)\nprint(c)\nprint()\n\nd = np.eye(5)\nprint(d)\nprint()\n\ne = np.arange(0, 100)\nprint(e)\nprint()\n\nx = np.arange(0, 100, step=2)\nprint(x)\nprint()\n\ny = np.linspace(2.0, 3.0, num=5)\nprint(y)\nprint()\n\n\n\n\n\nEn vous référant à la documentation des fonctions de génération de nombres aléatoires de NumPy, générer un vecteur X de taille 10000, contenant des nombres tirés selon une loi normale de moyenne 0 et de variance 2.\nVérifiez ensuite à l’aide des fonctions mathématiques de NumPy que la moyenne et la variance de votre échantillon sont cohérents par rapport aux valeurs attendues.\nIndice : attention à la manière dont est spécifiée la variance dans la fonction NumPy de génération d’une loi normale.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.random.normal(0, np.sqrt(2), 10000)\n\nprint(np.mean(X), np.var(X))\n\n\n\n\n\nEn vous référant à la documentation des fonctions de génération de nombres aléatoires de NumPy, générer une matrice U de taille 1000 par 1000, contenant des nombres tirés selon une loi uniforme dans l’intervalle [-1, 1].\nEn utilisant la fonction np.all et un test booléen, vérifier que tous les nombres contenus dans U sont bien compris entre -1 et 1.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nN = 1000\nU = np.random.uniform(-1, 1, size=(N, N))\n\nnp.all((U &gt;= -1) & (U &lt;= 1))\n\n\n\n\n\nOn peut parfois avoir besoin de binariser une matrice numérique, c’est à dire de fixer un seuil au delà duquel les valeurs numériques sont fixées à 1, et à 0 en-dessous. NumPy propose plusieurs méthodes pour réaliser une telle opération, nous allons en voir deux.\nDans la cellule suivante, une matrice X à 6 lignes et 6 colonnes est générée, qui comprend des entiers aléatoirement choisis entre 0 et 49. Vous devez binariser cette matrice de deux manières différentes sans l’écraser (i.e. la matrice binaire doit être assignée à une autre variable que X et X ne doit pas être modifiée) :\n\npremière méthode : en utilisant la fonction np.zeros et les masques booléens\nseconde méthode : en utilisant la fonction np.where (cf. doc)\n\n\nX = np.random.randint(0, 50, size=(6, 6))\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.random.randint(0, 50, size=(6, 6))\n\n# Première possibilité : via les masques booléens\nA = np.zeros((6, 6))\nA[X &gt; 25] = 1\n\n# Deuxième possibilité : via la fonction np.where\nB = np.where(X &gt; 25, 1, 0)\n\nprint(X)\nprint()\nprint(A)\nprint()\nprint(B)\n\n\n\n\n\nL’objectif de cet exercice est de programmer seulement à l’aide d’objets et de fonctions de NumPy un touché-coulé très basique.\nUne grille de 5x5 est définie dans la cellule suivante comme un array, les valeurs \\(1\\) symbolisant la présence d’un bateau. Vous devez programmer une fonction shoot qui :\n\nprend en input une coordonnée \\(x\\) (indice de la ligne) et une cordonnée \\(y\\) (indice de la colonne)\nteste si au moins une valeur \\(1\\) est présente dans la grille :\n\nsi oui :\n\ns’il y a un bateau à l’adresse (x, y), remplacer la valeur \\(1\\) par \\(2\\) et print “Touché !”\nsinon, print “Raté !”\n\nsi non :\n\nprint “Fin de partie !”\n\n\n\nPuis réalisez quelques tests pour vous assurer que votre fonction marche comme attendu.\n\nX = np.array([[1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1],\n              [1, 0, 0, 0, 0], [0, 1, 1, 1, 1]])\nprint(X)\n\n[[1 1 1 0 0]\n [0 0 0 0 1]\n [1 0 0 0 1]\n [1 0 0 0 0]\n [0 1 1 1 1]]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nX = np.array([[1, 1, 1, 0, 0], [0, 0, 0, 0, 1], [1, 0, 0, 0, 1],\n              [1, 0, 0, 0, 0], [0, 1, 1, 1, 1]])\n\ndef shoot(x, y):\n    if np.any(X == 1):\n        if X[x, y] == 1:\n            print(\"Touché !\")\n            X[x, y] = 2\n        else:\n            print(\"Raté !\")\n        print(X)\n        print()\n    else:\n        print(\"Fin de partie !\")\n\nshoot(0, 1)\nshoot(1, 0)\nshoot(0, 2)\n\n\n\n\n\nEn statistique, il est fréquent de vouloir encoder numériquement un vecteur de catégories. Une manière fréquente d’encoder des catégories est le one hot encoding (OHE) : chaque valeur est représentée par un vecteur binaire, qui contient un \\(1\\) sur la colonne correspondant à la catégorie et des \\(0\\) partout ailleurs.\nDans la cellule suivante, on encode des PCS au format OHE grâce à une fonction du package scikit-learn. L’objectif de l’exercice est de reproduire cet encodage en utilisant uniquement des fonctions de la librairie NumPy.\nIndice : on pourra utiliser les fonctions np.unique, np.zeros et np.arange.\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nvalues = np.array([\"21\", \"46\", \"47\", \"23\", \"66\", \"82\", \"82\"])\n\nprint(OneHotEncoder().fit_transform(values.reshape((-1, 1))).todense())\n\n[[1. 0. 0. 0. 0. 0.]\n [0. 0. 1. 0. 0. 0.]\n [0. 0. 0. 1. 0. 0.]\n [0. 1. 0. 0. 0. 0.]\n [0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 0. 0. 1.]\n [0. 0. 0. 0. 0. 1.]]\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nvalues = np.array([\"21\", \"46\", \"47\", \"23\", \"66\", \"82\", \"82\"])\n\ncategories, pos = np.unique(values, return_inverse=True)\nn_values = values.shape[0]\nn_categories = categories.shape[0]\n\nohe = np.zeros((n_values, n_categories))\nohe[np.arange(n_values), pos] = 1\nohe",
    "crumbs": [
      "Manipulation de données",
      "Calcul numérique avec NumPy"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html",
    "href": "source/fundamentals/tests/tutorial.html",
    "title": "Tests logiques",
    "section": "",
    "text": "Dans le tutoriel précédent, nous avons évoqué – sans l’expliciter – la notion de test, à travers l’exemple des tests d’appartenance. A présent, nous allons entrer dans le détail du fonctionnement des tests logiques en Python. Ces derniers sont un outil essentiel dans la création de programmes permettant d’automatiser des opérations, dans la mesure où ils permettent d’exécuter – ou non – du code selon certaines conditions. Ils permettent donc à l’ordinateur de prendre des décisions selon des critères fixés par l’utilisateur.\n\n\nDans sa plus simple forme, un test en Python est une expression qui évalue à “vrai” ou “faux”. Par exemple, l’expression \\(3 &gt; 2\\) est vraie, le test associé renverra donc “vrai”. Pour ce type d’évaluation, Python dispose d’un type d’objets particulier : les Booléens. Contrairement aux types d’objet que nous avons déjà vus (int, float, str..), les Booléens ne peuvent prendre que deux valeurs : True et False.\n\ntype(True)\n\nbool\n\n\nComme n’importe quel objet, les Booléens peuvent être assignés à des variables.\n\na = False\nprint(a)\nprint(type(a))\n\nFalse\n&lt;class 'bool'&gt;\n\n\nLes valeurs True et False doivent être écrites de cette manière précisément (première lettre en majuscule, pas de guillemets). Elles ne peuvent par ailleurs pas être utilisées comme noms de variable afin de limiter les ambiguïtés.\n\na = true  # Python chercher la variable `true` mais elle n'existe pas\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 a = true  # Python chercher la variable `true` mais elle n'existe pas\n\nNameError: name 'true' is not defined\n\n\n\n\nTrue = 3\n\n\n  Cell In[4], line 1\n    True = 3\n    ^\nSyntaxError: cannot assign to True\n\n\n\n\n\n\n\nLes opérateurs de comparaison formalisent les opérations mathématiques de comparaison (égalité, non-égalité, inégalités). Ils comparent deux valeurs et renvoient une valeur booléenne.\n\n\n\nOpérateur\nSignification\n\n\n\n\n==\nEgal à\n\n\n!=\nNon égal à\n\n\n&lt;\nStrictement inférieur à\n\n\n&gt;\nStrictement supérieur à\n\n\n&lt;=\nInférieur ou égal à\n\n\n&gt;=\nSupérieur ou égal à\n\n\n\nIllustrons ces opérateurs à l’aide de quelques exemples.\n\n3 == 3\n\nTrue\n\n\n\n63 == 36\n\nFalse\n\n\n\n2 != 3\n\nTrue\n\n\n\n2 != 2\n\nFalse\n\n\n\n3 &gt; 2\n\nTrue\n\n\n\na = 36\na &lt;= a\n\nTrue\n\n\n\na &lt; a\n\nFalse\n\n\nTout semble fonctionner correctement pour des opérations mathématiques usuelles. Mais ces opérateurs fonctionnent en réalité sur n’importe quel type d’objet.\n\n'do re mi fa sol' == 'do re mi fa sol'\n\nTrue\n\n\n\n'do re mi fa sol' == 'Do Re Mi Fa Sol'\n\nFalse\n\n\n\n'canard' != 'abeille'\n\nTrue\n\n\n\nTrue == True\n\nTrue\n\n\n\nTrue == False\n\nFalse\n\n\n\n[1, 2, 3] == [1, 2, 3]\n\nTrue\n\n\n\n[1, 2] != [3, 4]\n\nTrue\n\n\nEnfin, il est possible de réaliser des comparaisons en chaîne. L’expression renvoie True à condition que chacune des comparaisons soit vraie.\n\n5 &lt; 7 &lt;= 8\n\nTrue\n\n\n\n5 &lt; 7 &lt;= 6\n\nFalse\n\n\n\n\n\nLes opérateurs booléens permettent de tester simultanément plusieurs expressions logiques. Fondamentalement, ces opérateurs prennent en entrée deux valeurs booléennes, et renvoient une unique valeur booléenne selon des règles de logique fixées. Ces règles sont énoncées dans des tables de vérité.\n\n\nLe premier opérateur booléen est and. Regardons sa table de vérité :\n\n\n\nExpression\nEvaluation\n\n\n\n\nTrue and True\nTrue\n\n\nTrue and False\nFalse\n\n\nFalse and True\nFalse\n\n\nFalse and False\nFalse\n\n\n\nVérifions ces règles en pratique à l’aide de quelques exemples.\n\nTrue and True\n\nTrue\n\n\n\nFalse and True\n\nFalse\n\n\nLes règles ont l’air de fonctionner sur les valeurs booléennes. Bien entendu, en pratique, on s’intéresse plutôt à évaluer de vraies expressions logiques. On peut donc utiliser ces opérateurs pour tester des expressions qui renvoient une valeur booléenne.\n\n(3 &gt; 2) and (5 &lt;= 9)\n\nTrue\n\n\n\na = (\"x\" != \"z\")\nb = (\"x\" == \"y\")\na and b\n\nFalse\n\n\nNotez l’usage des parenthèses pour délimiter les tests : elles ne sont pas obligatoires, mais fortement recommandées dans la mesure où elles améliorent grandement la lisibilité tes tests.\n\n\n\nLe second opérateur booléen est or. Sa table de vérité est la suivante :\n\n\n\nExpression\nEvaluation\n\n\n\n\nTrue or True\nTrue\n\n\nTrue or False\nTrue\n\n\nFalse or True\nTrue\n\n\nFalse or False\nFalse\n\n\n\n\nTrue or True\n\nTrue\n\n\n\nFalse or True\n\nTrue\n\n\n\n(3 &gt; 2) or (5 &lt;= 9)\n\nTrue\n\n\n\na = (\"x\" != \"z\")\nb = (\"x\" == \"y\")\na or b\n\nTrue\n\n\n\n\n\nLe dernier opérateur booléen est not. Sa table de vérité est la suivante :\n\n\n\nExpression\nEvaluation\n\n\n\n\nnot True\nFalse\n\n\nnot False\nTrue\n\n\n\n\nnot True\n\nFalse\n\n\n\nnot False\n\nTrue\n\n\n\nnot (3 + 3 == 6)\n\nFalse\n\n\n\nnot (7 &lt; 7)\n\nTrue\n\n\n\n\n\n\nToutes les expressions que nous avons vues précédemment sont des expressions booléennes : un test est effectué, et l’opération renvoie True or False selon que l’expression évaluée est vraie ou non. Dans le cadre d’un programme informatique qui réalise des opérations automatisées, on va vouloir les utiliser comme des conditions : si l’expression est vraie, alors l’ordinateur doit effectuer telle ou telle opération. Les structures conditionnelles permettent précisément cet usage.\nIllustrons ce principe en implémentant le programme suivant :\n\nSoit une variable x.\nSi x est supérieur à \\(5\\), alors imprimer dans la console le message “L’expression est vraie.”\nDans le cas contraire, imprimer dans la console le message “L’expression est fausse.”\n\nFaîtes varier la valeur de x pour vérifier le bon fonctionnement du test.\n\nx = 7\n\nif x &gt;= 5:\n    print(\"L'expression est vraie.\")\nelse:\n    print(\"L'expression est fausse.\")\n\nL'expression est vraie.\n\n\n\n\nL’exemple précédent illustre la syntaxe des structures conditionnelles en Python. Ces structures sont basées sur des blocs d’instructions, qui délimitent l’ensemble des instructions qui doivent être exécutées lorsqu’un test est vrai. Les structures conditionnelles ont trois règles :\n\nla ligne qui spécifie le test se termine par :\ntoutes les instructions qui doivent être exécutées si le test est vrai se situent à un même niveau d’indentation ;\nla structure conditionnelle se termine lorsque l’indentation revient à son niveau d’origine.\n\nNotons que les structures conditionnelles peuvent tout à fait être imbriquées, ce qu’illustre l’exemple suivant.\n\nx = 7\n\nif x &gt;= 5:\n    print(\"L'expression 1 est vraie.\")\n    if x &gt;= 12:\n        print(\"L'expression 2 est vraie.\")\n\nL'expression 1 est vraie.\n\n\nLorsque x = 7, le premier test renvoie True, le bloc d’instructions au niveau d’indentation 1 est donc exécuté ligne par ligne. Le second test renvoie quant à lui False, le bloc d’instructions au niveau d’indentation 2 n’est pas exécuté.\nFaîtes varier la valeur de x pour que les deux blocs soient exécutés.\n\n\n\nDans les structures conditionnelles, les tests peuvent être spécifiés à l’aide de trois instructions : if, else et elif. Les exemples précédents ont déjà illustré le fonctionnement des deux premières (et plus fréquentes) instructions.\nEn cas d’un test simple (une seule condition), on n’utilisera qu’une instruction if, dont le fonctionnement est simple : si la condition (test) renvoie True, alors le bloc d’instructions (indenté) qui suit est exécuté. Si la condition renvoie False, il ne se passe rien. Illustrons cela avec un test d’appartenance, dont nous avons vu des exemples dans le tutoriel précédent.\n\nclient = \"Isidore\"\n\nif client in [\"Alexandrine\", \"Achille\", \"Colette\"]:\n    print(\"Client connu.\")\n\nEn pratique, on souhaite souvent spécifier une alternative, lorsque la condition de l’instruction if renvoie False. L’instruction else permet de spécifier un bloc d’instructions alternatif.\n\nclient = \"Isidore\"\n\nif client in [\"Alexandrine\", \"Achille\", \"Colette\"]:\n    print(\"Client connu.\")\nelse:\n    print(\"Client inconnu.\")\n\nClient inconnu.\n\n\nEnfin, on peut vouloir spécifier plusieurs alternatives. Dans ce cas, on va utiliser des instructions elif. La première instruction elif ne va s’éxécuter que si le test de l’instruction if renvoie False. La seconde instruction elif ne va s’exécuter que si le test de la première instruction elif renvoie False, et ainsi de suite. Là encore, on peut spécifier une instruction finale else, qui ne s’exécute que si aucun des tests précédents n’a renvoyé True.\n\nclient = \"Isidore\"\n\nif client == \"Alexandrine\":\n    print(\"Bonjour Alexandrine.\")\nelif client == \"Achille\":\n    print(\"Bonjour Achille.\")\nelif client == \"Colette\":\n    print(\"Bonjour Colette.\")\nelse:\n    print(\"Bonjour cher inconnu.\")\n\nBonjour cher inconnu.\n\n\nNB : les instructions précédentes ont seulement valeur d’exemple. En pratique, il y a des manières beaucoup plus concises de coder un programme qui effectue les mêmes opérations.\n\n\n\n\n\n\n\n1/ Quelle est la particularité des Booléens par rapport aux autres types d’objets de base en Python ?\n2/ Quels sont les inputs et les outputs d’un opérateur de comparaison ?\n3/ Quels types d’objets peut-on comparer à l’aide d’un opérateur de comparaison ?\n4/ Quelle est la différence entre l’opérateur = et l’opérateur == ?\n5/ Quels sont les inputs et les outputs d’un opérateur booléen ?\n6/ Expliquer en français le principe de l’opérateur booléen and. Mêmes questions pour or et not.\n7/ Quelle est la différence entre expression booléenne et condition ?\n8/ Quelle est la structure d’une instruction conditionnelle ?\n9/ Peut-on imbriquer les instructions conditionnelles ?\n10/ Parmi les instructions if, else, et elif, lesquelles sont obligatoires et lesquelles sont facultatives ?\n\n\n\n\nAfficher la solution\n\n1/ Ils n’ont que deux valeurs : True et False. Les autres types ont une infinité de valeurs possibles.\n2/ Inputs : deux valeurs. Output : valeur booléenne.\n3/ Tous types d’objets. En pratique cependant, il n’y a pas beaucoup de sens à comparer des objets de type différent, le résultat sera généralement False.\n4/ L’opérateur = assigne une valeur à une variable. L’opérateur == teste l’égalité de deux objets.\n5/ Inputs : deux valeurs booléennes, ou deux expressions qui renvoient des booléens. Output : valeur booléenne.\n6/ L’opérateur and renvoie True si ses deux inputs valent True, et False dans tous les autres cas. L’opérateur or renvoie True si au moins un de ses deux inputs vaut True, et False dans le cas où ils valent tous les deux False. L’opérateur not renvoie False si son input est True, et True sinon.\n7/ Dans les deux cas, il s’agit de tests. On parle de condition lorsque les expressions sont utilisées dans le cadre des structures conditionnelles.\n8/ L’instruction conditionnelle commence par une instruction if, else ou elif, qui se termine par :. Vient ensuite, indenté de un niveau, un bloc d’opérations qui ne s’exécutent que si l’instruction vaut True. Le bloc se termine lorsque l’indentation revient à son niveau initial.\n9/ Oui, les instructions conditionnelles peuvent s’imbriquer à l’infini (en théorie) Il faut simplement faire attention à respecter les niveaux d’indentation.\n10/ Seule l’instruction if est obligatoire.\n\n\n\n\n\nPrédire le résultats des tests suivants, et vérifier vos prédictions :\n\n'Simon' in ['simon', 'oceane', 'veronique']\n[1, 2, 3] == ['1', '2', '3']\n'x' != 'x'\n(9 &gt; 5) and (3 == 5)\n(3 &gt; 2 and 5 &gt;= 1) or (5 &lt;= 9 and 6 &gt; 12)\nnot (9 &gt; 2*3)\nnot (9 &gt; (2*3))\nnot ((7 &gt; 8) or (5 &lt;= 5))\n(True and True) or (True == False)\n(not False) or (not True)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n'Simon' in ['simon', 'oceane', 'veronique'] : False\n[1, 2, 3] == ['1', '2', '3'] : False\n'x' != 'x' : False\n(9 &gt; 5) and (3 == 5) : False\n(3 &gt; 2 and 5 &gt;= 1) or (5 &lt;= 9 and 6 &gt; 12) : True\nnot (9 &gt; 2*3) : False\nnot (9 &gt; (2*3)) : False\nnot ((7 &gt; 8) or (5 &lt;= 5)) : False\n(True and True) or (True == False) : True\n(not False) or (not True) : True\n\n\n\n\n\n\nConsidérons le programme écrit dans la cellule suivante.\n\nx = 10\n\nif True:\n    print(\"Initialisation.\")\n    l = []\n    if x &gt; 8:\n        l.append(\"a\")\n    elif x &gt;= 2:\n        l.append(\"b\")\n    else:\n        l.append(\"c\")\n    if x - 6 &lt; 0:\n        print(\"Négatif.\")\n        \nprint(l)\n\nInitialisation.\n['a']\n\n\nPour les valeurs suivantes :\n\nx = 1\nx = 5\nx = 10\n\nprédire les résultats du programme :\n\nque vaut l à la fin du programme ?\nqu’est ce qui est imprimé dans la console au fil du programme ?\n\nVérifiez vos résultats.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nx = 1 : l = ['c'] et messages imprimés : ‘Initialisation’ et ‘Négatif’\nx = 5 : l = ['b'] et messages imprimés : ‘Initialisation’ et ‘Négatif’\nx = 10 : l = ['a'] et messages imprimés : ‘Initialisation’\n\n\n\n\n\n\nEcrire un programme qui réalise les opérations suivantes :\n\nDéfinir une liste qui contient 4 prénoms\nEcrire un test qui affiche le message (‘Trop de monde.’) si la liste contient plus de trois personnes\nSupprimer une personne de la liste (en utilisant la fonction del ou la méthode pop vues dans un tutoriel précédent)\nRéaliser le test à nouveau, il ne devrait plus y avoir d’output.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\npeople = [\"Romuald\", \"Ursula\", \"Jean-Vincent\", \"Philomène\"]\n\nif len(people) &gt; 3:\n    print('Trop de monde.')\n\nprint(people)    \npeople.remove(\"Jean-Vincent\")\nprint(people)\n\nif len(people) &gt; 3:\n    print('Trop de monde.')\n\n\n\n\n\nLa fonction input permet de demander à l’utilisateur d’entrer une valeur dans le cadre d’un programme Python. La syntaxe est la suivante : x = input(). Lorsque cette commande est exécutée, l’utilisateur doit rentrer une valeur, qui est alors assignée à la variable x.\nEn utilisant input et les instructions if, elif et else, coder le programme suivant :\n\ndemander une valeur à l’utilisateur, qui sera stockée dans une variable p\nsi p est strictement inférieur à \\(15\\), imprimer (avec la fonction print) le message “trop bas !”.\nsi p est strictement supérieur à \\(15\\), imprimer le message “trop haut !”.\nsi p est égal à \\(15\\), imprimer le message “dans le mille !”\n\nAttention, input renvoie par défaut une chaîne de caractère. Il faut donc convertir la valeur de p au format entier (via la fonction int) pour que le jeu fonctionne.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\np = input()\np = int(p)\n\nif p &lt; 15:\n    print(\"trop bas !\")\nelif p &gt; 15:\n    print(\"trop haut !\")\nelse:\n    print(\"dans le mille !\")\n\n\n\n\n\nEn Python, tous les objets s’évaluent à True or False dans le cadre d’un test conditionnel (if/else). La règle générale est que les objets qui sont zéro ou vides (ex : une liste vide, un dictionnaire vide) s’évaluent à False, et inversement. Mais il n’y a pas besoin de connaître ces règles par coeur : elles se retrouvent facilement en pratique ! Par exemple, on peut utiliser le test conditionnel suivant :\n\nif \"test\":\n    print(\"True.\")\nelse:\n    print(\"False.\")\n\nTrue.\n\n\nPrédire à quelle valeur booléenne vont s’évaluer les objets suivants, et vérifier à l’aide de la syntaxe précédente.\n\n0\n1\n12\n-1\n’’ (string vide)\n’ ’ (string contenant seulement un espace)\n[] (liste vide)\n[''] (liste contenant seulement un string vide)\n{}\n{-1}\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n0 : False\n1 : True\n12 : True\n-1: True\n'' (string vide): False\n' ' (string contenant seulement un espace): True\n[] (liste vide): False\n[''] (liste contenant seulement un string vide): True\n{}: False\n{-1}: True\n\n\n\n\n\n\nNous avons vu qu’il était possible de réaliser des comparaisons en chaîne, qui renvoient True à condition que chacune des comparaisons inclues soit vraie. Trouvez une manière de réécrire la comparaison en chaîne suivante à l’aide d’opérateurs booléens.\n5 &lt; 7 &lt;= 8 &lt; 18\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(5 &lt; 7 &lt;= 8 &lt; 18)\n\nprint(5 &lt; 7 and 7 &lt;= 8 and 8 &lt; 18)\nUne comparaison en chaîne peut se réécrire avec des opérateurs and. Logique : il faut que chaque comparaison soit vraie pour que l’ensemble le soit aussi. En pratique, la version avec les and est sans doute préférable pour la lisibilité.\n\n\n\n\n\nLes Booléens sont fortement liés au langage binaire, dans lequel le 1 correspond à “vrai” et le 0 à “faux”. On va vérifier si ce lien existe dans le contexte de Python. Pour ce faire :\n\ncalculer la “représentation en entier” de la valeur booléenne de votre choix à l’aide de la fonction int ;\nutiliser des booléens dans le cadre de calculs mathématiques pour vérifier leur comportement dans ce contexte.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(int(True))  \nUn Booléen évalué comme entier donne bien la valeur binaire associée.\nprint(True + 3)  \nLes Booléens se comportent comme leur valeur entière associée dans les calculs.\n\n\n\n\n\nQue renvoient les tests de comparaison de type inégalités appliqués à des chaînes de caractères ? Produire quelques exemples pour tester le comportement.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(\"a\" &gt; \"b\")\nprint(\"a\" &lt; \"b\")\nprint(\"abricot\" &gt; \"avocat\")\nprint(\"abricot\" &lt; \"avocat\")\nprint(\"1\" &gt; \"2\")\nprint(\"1\" &lt; \"2\")\nprint(\"A1\" &lt; \"A2\")\n\n\nLa relation d’ordre utilisée est l’ordre alphanumérique : chaque caractère est pris individuellement, et les ordres sont A &lt; Z et 1 &lt; 9.\n\n\n\nLes tests d’égalité entre nombres réels (type float en Python) peuvent être trompeurs. Pour vous en convaincre, effectuez le test suivant : (6 - 5.8) == 0.2\nPour comprendre le résultat du test, effectuer le calcul du membre de gauche du test seul. Que remarquez-vous ?\nImaginez (sans forcément l’implémenter) un autre test, basé sur des inégalités, qui permettrait de tester l’égalité approchée.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndiff = 3 - 2.7\n\nprint(diff == 0.3)\n\nprint(diff)\nEn Python, les nombres flottants sont toujours des valeurs approchées. On peut donc avoir ce genre de surprise dans les calculs.\ntolerance = 0.0001\nnew_test = (0.3 - tolerance) &lt; diff &lt; (0.3 + tolerance)\nprint(new_test)\nCe dernier test permet de tester l’égalité entre diff et 0.3 de manière approchée, en permettant une certaine tolérance dans la comparaison.",
    "crumbs": [
      "Fondamentaux du langage",
      "Tests logiques et conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#le-type-booléen",
    "href": "source/fundamentals/tests/tutorial.html#le-type-booléen",
    "title": "Tests logiques",
    "section": "",
    "text": "Dans sa plus simple forme, un test en Python est une expression qui évalue à “vrai” ou “faux”. Par exemple, l’expression \\(3 &gt; 2\\) est vraie, le test associé renverra donc “vrai”. Pour ce type d’évaluation, Python dispose d’un type d’objets particulier : les Booléens. Contrairement aux types d’objet que nous avons déjà vus (int, float, str..), les Booléens ne peuvent prendre que deux valeurs : True et False.\n\ntype(True)\n\nbool\n\n\nComme n’importe quel objet, les Booléens peuvent être assignés à des variables.\n\na = False\nprint(a)\nprint(type(a))\n\nFalse\n&lt;class 'bool'&gt;\n\n\nLes valeurs True et False doivent être écrites de cette manière précisément (première lettre en majuscule, pas de guillemets). Elles ne peuvent par ailleurs pas être utilisées comme noms de variable afin de limiter les ambiguïtés.\n\na = true  # Python chercher la variable `true` mais elle n'existe pas\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 a = true  # Python chercher la variable `true` mais elle n'existe pas\n\nNameError: name 'true' is not defined\n\n\n\n\nTrue = 3\n\n\n  Cell In[4], line 1\n    True = 3\n    ^\nSyntaxError: cannot assign to True",
    "crumbs": [
      "Fondamentaux du langage",
      "Tests logiques et conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#opérateurs-de-comparaison",
    "href": "source/fundamentals/tests/tutorial.html#opérateurs-de-comparaison",
    "title": "Tests logiques",
    "section": "",
    "text": "Les opérateurs de comparaison formalisent les opérations mathématiques de comparaison (égalité, non-égalité, inégalités). Ils comparent deux valeurs et renvoient une valeur booléenne.\n\n\n\nOpérateur\nSignification\n\n\n\n\n==\nEgal à\n\n\n!=\nNon égal à\n\n\n&lt;\nStrictement inférieur à\n\n\n&gt;\nStrictement supérieur à\n\n\n&lt;=\nInférieur ou égal à\n\n\n&gt;=\nSupérieur ou égal à\n\n\n\nIllustrons ces opérateurs à l’aide de quelques exemples.\n\n3 == 3\n\nTrue\n\n\n\n63 == 36\n\nFalse\n\n\n\n2 != 3\n\nTrue\n\n\n\n2 != 2\n\nFalse\n\n\n\n3 &gt; 2\n\nTrue\n\n\n\na = 36\na &lt;= a\n\nTrue\n\n\n\na &lt; a\n\nFalse\n\n\nTout semble fonctionner correctement pour des opérations mathématiques usuelles. Mais ces opérateurs fonctionnent en réalité sur n’importe quel type d’objet.\n\n'do re mi fa sol' == 'do re mi fa sol'\n\nTrue\n\n\n\n'do re mi fa sol' == 'Do Re Mi Fa Sol'\n\nFalse\n\n\n\n'canard' != 'abeille'\n\nTrue\n\n\n\nTrue == True\n\nTrue\n\n\n\nTrue == False\n\nFalse\n\n\n\n[1, 2, 3] == [1, 2, 3]\n\nTrue\n\n\n\n[1, 2] != [3, 4]\n\nTrue\n\n\nEnfin, il est possible de réaliser des comparaisons en chaîne. L’expression renvoie True à condition que chacune des comparaisons soit vraie.\n\n5 &lt; 7 &lt;= 8\n\nTrue\n\n\n\n5 &lt; 7 &lt;= 6\n\nFalse",
    "crumbs": [
      "Fondamentaux du langage",
      "Tests logiques et conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#opérateurs-booléens",
    "href": "source/fundamentals/tests/tutorial.html#opérateurs-booléens",
    "title": "Tests logiques",
    "section": "",
    "text": "Les opérateurs booléens permettent de tester simultanément plusieurs expressions logiques. Fondamentalement, ces opérateurs prennent en entrée deux valeurs booléennes, et renvoient une unique valeur booléenne selon des règles de logique fixées. Ces règles sont énoncées dans des tables de vérité.\n\n\nLe premier opérateur booléen est and. Regardons sa table de vérité :\n\n\n\nExpression\nEvaluation\n\n\n\n\nTrue and True\nTrue\n\n\nTrue and False\nFalse\n\n\nFalse and True\nFalse\n\n\nFalse and False\nFalse\n\n\n\nVérifions ces règles en pratique à l’aide de quelques exemples.\n\nTrue and True\n\nTrue\n\n\n\nFalse and True\n\nFalse\n\n\nLes règles ont l’air de fonctionner sur les valeurs booléennes. Bien entendu, en pratique, on s’intéresse plutôt à évaluer de vraies expressions logiques. On peut donc utiliser ces opérateurs pour tester des expressions qui renvoient une valeur booléenne.\n\n(3 &gt; 2) and (5 &lt;= 9)\n\nTrue\n\n\n\na = (\"x\" != \"z\")\nb = (\"x\" == \"y\")\na and b\n\nFalse\n\n\nNotez l’usage des parenthèses pour délimiter les tests : elles ne sont pas obligatoires, mais fortement recommandées dans la mesure où elles améliorent grandement la lisibilité tes tests.\n\n\n\nLe second opérateur booléen est or. Sa table de vérité est la suivante :\n\n\n\nExpression\nEvaluation\n\n\n\n\nTrue or True\nTrue\n\n\nTrue or False\nTrue\n\n\nFalse or True\nTrue\n\n\nFalse or False\nFalse\n\n\n\n\nTrue or True\n\nTrue\n\n\n\nFalse or True\n\nTrue\n\n\n\n(3 &gt; 2) or (5 &lt;= 9)\n\nTrue\n\n\n\na = (\"x\" != \"z\")\nb = (\"x\" == \"y\")\na or b\n\nTrue\n\n\n\n\n\nLe dernier opérateur booléen est not. Sa table de vérité est la suivante :\n\n\n\nExpression\nEvaluation\n\n\n\n\nnot True\nFalse\n\n\nnot False\nTrue\n\n\n\n\nnot True\n\nFalse\n\n\n\nnot False\n\nTrue\n\n\n\nnot (3 + 3 == 6)\n\nFalse\n\n\n\nnot (7 &lt; 7)\n\nTrue",
    "crumbs": [
      "Fondamentaux du langage",
      "Tests logiques et conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#structures-conditionnelles",
    "href": "source/fundamentals/tests/tutorial.html#structures-conditionnelles",
    "title": "Tests logiques",
    "section": "",
    "text": "Toutes les expressions que nous avons vues précédemment sont des expressions booléennes : un test est effectué, et l’opération renvoie True or False selon que l’expression évaluée est vraie ou non. Dans le cadre d’un programme informatique qui réalise des opérations automatisées, on va vouloir les utiliser comme des conditions : si l’expression est vraie, alors l’ordinateur doit effectuer telle ou telle opération. Les structures conditionnelles permettent précisément cet usage.\nIllustrons ce principe en implémentant le programme suivant :\n\nSoit une variable x.\nSi x est supérieur à \\(5\\), alors imprimer dans la console le message “L’expression est vraie.”\nDans le cas contraire, imprimer dans la console le message “L’expression est fausse.”\n\nFaîtes varier la valeur de x pour vérifier le bon fonctionnement du test.\n\nx = 7\n\nif x &gt;= 5:\n    print(\"L'expression est vraie.\")\nelse:\n    print(\"L'expression est fausse.\")\n\nL'expression est vraie.\n\n\n\n\nL’exemple précédent illustre la syntaxe des structures conditionnelles en Python. Ces structures sont basées sur des blocs d’instructions, qui délimitent l’ensemble des instructions qui doivent être exécutées lorsqu’un test est vrai. Les structures conditionnelles ont trois règles :\n\nla ligne qui spécifie le test se termine par :\ntoutes les instructions qui doivent être exécutées si le test est vrai se situent à un même niveau d’indentation ;\nla structure conditionnelle se termine lorsque l’indentation revient à son niveau d’origine.\n\nNotons que les structures conditionnelles peuvent tout à fait être imbriquées, ce qu’illustre l’exemple suivant.\n\nx = 7\n\nif x &gt;= 5:\n    print(\"L'expression 1 est vraie.\")\n    if x &gt;= 12:\n        print(\"L'expression 2 est vraie.\")\n\nL'expression 1 est vraie.\n\n\nLorsque x = 7, le premier test renvoie True, le bloc d’instructions au niveau d’indentation 1 est donc exécuté ligne par ligne. Le second test renvoie quant à lui False, le bloc d’instructions au niveau d’indentation 2 n’est pas exécuté.\nFaîtes varier la valeur de x pour que les deux blocs soient exécutés.\n\n\n\nDans les structures conditionnelles, les tests peuvent être spécifiés à l’aide de trois instructions : if, else et elif. Les exemples précédents ont déjà illustré le fonctionnement des deux premières (et plus fréquentes) instructions.\nEn cas d’un test simple (une seule condition), on n’utilisera qu’une instruction if, dont le fonctionnement est simple : si la condition (test) renvoie True, alors le bloc d’instructions (indenté) qui suit est exécuté. Si la condition renvoie False, il ne se passe rien. Illustrons cela avec un test d’appartenance, dont nous avons vu des exemples dans le tutoriel précédent.\n\nclient = \"Isidore\"\n\nif client in [\"Alexandrine\", \"Achille\", \"Colette\"]:\n    print(\"Client connu.\")\n\nEn pratique, on souhaite souvent spécifier une alternative, lorsque la condition de l’instruction if renvoie False. L’instruction else permet de spécifier un bloc d’instructions alternatif.\n\nclient = \"Isidore\"\n\nif client in [\"Alexandrine\", \"Achille\", \"Colette\"]:\n    print(\"Client connu.\")\nelse:\n    print(\"Client inconnu.\")\n\nClient inconnu.\n\n\nEnfin, on peut vouloir spécifier plusieurs alternatives. Dans ce cas, on va utiliser des instructions elif. La première instruction elif ne va s’éxécuter que si le test de l’instruction if renvoie False. La seconde instruction elif ne va s’exécuter que si le test de la première instruction elif renvoie False, et ainsi de suite. Là encore, on peut spécifier une instruction finale else, qui ne s’exécute que si aucun des tests précédents n’a renvoyé True.\n\nclient = \"Isidore\"\n\nif client == \"Alexandrine\":\n    print(\"Bonjour Alexandrine.\")\nelif client == \"Achille\":\n    print(\"Bonjour Achille.\")\nelif client == \"Colette\":\n    print(\"Bonjour Colette.\")\nelse:\n    print(\"Bonjour cher inconnu.\")\n\nBonjour cher inconnu.\n\n\nNB : les instructions précédentes ont seulement valeur d’exemple. En pratique, il y a des manières beaucoup plus concises de coder un programme qui effectue les mêmes opérations.",
    "crumbs": [
      "Fondamentaux du langage",
      "Tests logiques et conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/tests/tutorial.html#exercices",
    "href": "source/fundamentals/tests/tutorial.html#exercices",
    "title": "Tests logiques",
    "section": "",
    "text": "1/ Quelle est la particularité des Booléens par rapport aux autres types d’objets de base en Python ?\n2/ Quels sont les inputs et les outputs d’un opérateur de comparaison ?\n3/ Quels types d’objets peut-on comparer à l’aide d’un opérateur de comparaison ?\n4/ Quelle est la différence entre l’opérateur = et l’opérateur == ?\n5/ Quels sont les inputs et les outputs d’un opérateur booléen ?\n6/ Expliquer en français le principe de l’opérateur booléen and. Mêmes questions pour or et not.\n7/ Quelle est la différence entre expression booléenne et condition ?\n8/ Quelle est la structure d’une instruction conditionnelle ?\n9/ Peut-on imbriquer les instructions conditionnelles ?\n10/ Parmi les instructions if, else, et elif, lesquelles sont obligatoires et lesquelles sont facultatives ?\n\n\n\n\nAfficher la solution\n\n1/ Ils n’ont que deux valeurs : True et False. Les autres types ont une infinité de valeurs possibles.\n2/ Inputs : deux valeurs. Output : valeur booléenne.\n3/ Tous types d’objets. En pratique cependant, il n’y a pas beaucoup de sens à comparer des objets de type différent, le résultat sera généralement False.\n4/ L’opérateur = assigne une valeur à une variable. L’opérateur == teste l’égalité de deux objets.\n5/ Inputs : deux valeurs booléennes, ou deux expressions qui renvoient des booléens. Output : valeur booléenne.\n6/ L’opérateur and renvoie True si ses deux inputs valent True, et False dans tous les autres cas. L’opérateur or renvoie True si au moins un de ses deux inputs vaut True, et False dans le cas où ils valent tous les deux False. L’opérateur not renvoie False si son input est True, et True sinon.\n7/ Dans les deux cas, il s’agit de tests. On parle de condition lorsque les expressions sont utilisées dans le cadre des structures conditionnelles.\n8/ L’instruction conditionnelle commence par une instruction if, else ou elif, qui se termine par :. Vient ensuite, indenté de un niveau, un bloc d’opérations qui ne s’exécutent que si l’instruction vaut True. Le bloc se termine lorsque l’indentation revient à son niveau initial.\n9/ Oui, les instructions conditionnelles peuvent s’imbriquer à l’infini (en théorie) Il faut simplement faire attention à respecter les niveaux d’indentation.\n10/ Seule l’instruction if est obligatoire.\n\n\n\n\n\nPrédire le résultats des tests suivants, et vérifier vos prédictions :\n\n'Simon' in ['simon', 'oceane', 'veronique']\n[1, 2, 3] == ['1', '2', '3']\n'x' != 'x'\n(9 &gt; 5) and (3 == 5)\n(3 &gt; 2 and 5 &gt;= 1) or (5 &lt;= 9 and 6 &gt; 12)\nnot (9 &gt; 2*3)\nnot (9 &gt; (2*3))\nnot ((7 &gt; 8) or (5 &lt;= 5))\n(True and True) or (True == False)\n(not False) or (not True)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n'Simon' in ['simon', 'oceane', 'veronique'] : False\n[1, 2, 3] == ['1', '2', '3'] : False\n'x' != 'x' : False\n(9 &gt; 5) and (3 == 5) : False\n(3 &gt; 2 and 5 &gt;= 1) or (5 &lt;= 9 and 6 &gt; 12) : True\nnot (9 &gt; 2*3) : False\nnot (9 &gt; (2*3)) : False\nnot ((7 &gt; 8) or (5 &lt;= 5)) : False\n(True and True) or (True == False) : True\n(not False) or (not True) : True\n\n\n\n\n\n\nConsidérons le programme écrit dans la cellule suivante.\n\nx = 10\n\nif True:\n    print(\"Initialisation.\")\n    l = []\n    if x &gt; 8:\n        l.append(\"a\")\n    elif x &gt;= 2:\n        l.append(\"b\")\n    else:\n        l.append(\"c\")\n    if x - 6 &lt; 0:\n        print(\"Négatif.\")\n        \nprint(l)\n\nInitialisation.\n['a']\n\n\nPour les valeurs suivantes :\n\nx = 1\nx = 5\nx = 10\n\nprédire les résultats du programme :\n\nque vaut l à la fin du programme ?\nqu’est ce qui est imprimé dans la console au fil du programme ?\n\nVérifiez vos résultats.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\nx = 1 : l = ['c'] et messages imprimés : ‘Initialisation’ et ‘Négatif’\nx = 5 : l = ['b'] et messages imprimés : ‘Initialisation’ et ‘Négatif’\nx = 10 : l = ['a'] et messages imprimés : ‘Initialisation’\n\n\n\n\n\n\nEcrire un programme qui réalise les opérations suivantes :\n\nDéfinir une liste qui contient 4 prénoms\nEcrire un test qui affiche le message (‘Trop de monde.’) si la liste contient plus de trois personnes\nSupprimer une personne de la liste (en utilisant la fonction del ou la méthode pop vues dans un tutoriel précédent)\nRéaliser le test à nouveau, il ne devrait plus y avoir d’output.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\npeople = [\"Romuald\", \"Ursula\", \"Jean-Vincent\", \"Philomène\"]\n\nif len(people) &gt; 3:\n    print('Trop de monde.')\n\nprint(people)    \npeople.remove(\"Jean-Vincent\")\nprint(people)\n\nif len(people) &gt; 3:\n    print('Trop de monde.')\n\n\n\n\n\nLa fonction input permet de demander à l’utilisateur d’entrer une valeur dans le cadre d’un programme Python. La syntaxe est la suivante : x = input(). Lorsque cette commande est exécutée, l’utilisateur doit rentrer une valeur, qui est alors assignée à la variable x.\nEn utilisant input et les instructions if, elif et else, coder le programme suivant :\n\ndemander une valeur à l’utilisateur, qui sera stockée dans une variable p\nsi p est strictement inférieur à \\(15\\), imprimer (avec la fonction print) le message “trop bas !”.\nsi p est strictement supérieur à \\(15\\), imprimer le message “trop haut !”.\nsi p est égal à \\(15\\), imprimer le message “dans le mille !”\n\nAttention, input renvoie par défaut une chaîne de caractère. Il faut donc convertir la valeur de p au format entier (via la fonction int) pour que le jeu fonctionne.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\np = input()\np = int(p)\n\nif p &lt; 15:\n    print(\"trop bas !\")\nelif p &gt; 15:\n    print(\"trop haut !\")\nelse:\n    print(\"dans le mille !\")\n\n\n\n\n\nEn Python, tous les objets s’évaluent à True or False dans le cadre d’un test conditionnel (if/else). La règle générale est que les objets qui sont zéro ou vides (ex : une liste vide, un dictionnaire vide) s’évaluent à False, et inversement. Mais il n’y a pas besoin de connaître ces règles par coeur : elles se retrouvent facilement en pratique ! Par exemple, on peut utiliser le test conditionnel suivant :\n\nif \"test\":\n    print(\"True.\")\nelse:\n    print(\"False.\")\n\nTrue.\n\n\nPrédire à quelle valeur booléenne vont s’évaluer les objets suivants, et vérifier à l’aide de la syntaxe précédente.\n\n0\n1\n12\n-1\n’’ (string vide)\n’ ’ (string contenant seulement un espace)\n[] (liste vide)\n[''] (liste contenant seulement un string vide)\n{}\n{-1}\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n0 : False\n1 : True\n12 : True\n-1: True\n'' (string vide): False\n' ' (string contenant seulement un espace): True\n[] (liste vide): False\n[''] (liste contenant seulement un string vide): True\n{}: False\n{-1}: True\n\n\n\n\n\n\nNous avons vu qu’il était possible de réaliser des comparaisons en chaîne, qui renvoient True à condition que chacune des comparaisons inclues soit vraie. Trouvez une manière de réécrire la comparaison en chaîne suivante à l’aide d’opérateurs booléens.\n5 &lt; 7 &lt;= 8 &lt; 18\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(5 &lt; 7 &lt;= 8 &lt; 18)\n\nprint(5 &lt; 7 and 7 &lt;= 8 and 8 &lt; 18)\nUne comparaison en chaîne peut se réécrire avec des opérateurs and. Logique : il faut que chaque comparaison soit vraie pour que l’ensemble le soit aussi. En pratique, la version avec les and est sans doute préférable pour la lisibilité.\n\n\n\n\n\nLes Booléens sont fortement liés au langage binaire, dans lequel le 1 correspond à “vrai” et le 0 à “faux”. On va vérifier si ce lien existe dans le contexte de Python. Pour ce faire :\n\ncalculer la “représentation en entier” de la valeur booléenne de votre choix à l’aide de la fonction int ;\nutiliser des booléens dans le cadre de calculs mathématiques pour vérifier leur comportement dans ce contexte.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(int(True))  \nUn Booléen évalué comme entier donne bien la valeur binaire associée.\nprint(True + 3)  \nLes Booléens se comportent comme leur valeur entière associée dans les calculs.\n\n\n\n\n\nQue renvoient les tests de comparaison de type inégalités appliqués à des chaînes de caractères ? Produire quelques exemples pour tester le comportement.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(\"a\" &gt; \"b\")\nprint(\"a\" &lt; \"b\")\nprint(\"abricot\" &gt; \"avocat\")\nprint(\"abricot\" &lt; \"avocat\")\nprint(\"1\" &gt; \"2\")\nprint(\"1\" &lt; \"2\")\nprint(\"A1\" &lt; \"A2\")\n\n\nLa relation d’ordre utilisée est l’ordre alphanumérique : chaque caractère est pris individuellement, et les ordres sont A &lt; Z et 1 &lt; 9.\n\n\n\nLes tests d’égalité entre nombres réels (type float en Python) peuvent être trompeurs. Pour vous en convaincre, effectuez le test suivant : (6 - 5.8) == 0.2\nPour comprendre le résultat du test, effectuer le calcul du membre de gauche du test seul. Que remarquez-vous ?\nImaginez (sans forcément l’implémenter) un autre test, basé sur des inégalités, qui permettrait de tester l’égalité approchée.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndiff = 3 - 2.7\n\nprint(diff == 0.3)\n\nprint(diff)\nEn Python, les nombres flottants sont toujours des valeurs approchées. On peut donc avoir ce genre de surprise dans les calculs.\ntolerance = 0.0001\nnew_test = (0.3 - tolerance) &lt; diff &lt; (0.3 + tolerance)\nprint(new_test)\nCe dernier test permet de tester l’égalité entre diff et 0.3 de manière approchée, en permettant une certaine tolérance dans la comparaison.",
    "crumbs": [
      "Fondamentaux du langage",
      "Tests logiques et conditions"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html",
    "href": "source/fundamentals/data-structures2/tutorial.html",
    "title": "Structures de données 2 : dictionnaires et sets",
    "section": "",
    "text": "Dans le tutoriel précédent, nous avons manipulé des structures de données de type séquentielles : les listes et les tuples. A présent, nous allons découvrir les dictionnaires et les sets, qui sont des structures de données non-ordonnées : les objets ne sont plus stockés par position (ou index) mais par clé, c’est à dire un identifiant unique.\n\n\n\n\nLes dictionnaires sont des collections non-ordonnées de couples clé-valeur. Un dictionnaire se définit selon la syntaxe suivante : d = {'cle1': 'valeur1', 'cle2': 'valeur2'}.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire\n\n{'cafe': '500g', 'lait': '1,5L'}\n\n\n\ntype(inventaire)\n\ndict\n\n\nIl est possible de mettre autant de clés que l’on souhaite dans un dictionnaire. En revanche, les clés sont uniques, afin d’identifier de manière certaine la valeur associée. Si l’on essaye de définir un dictionnaire avec une clé dupliquée, Python ne renvoie pas d’erreur, mais seule la dernière clé dupliquée est prise en compte.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L', 'cafe': '300g'}\ninventaire\n\n{'cafe': '300g', 'lait': '1,5L'}\n\n\nQue peut contenir un dictionnaire ? Les clés peuvent être de différents types, mais on n’utilise en général que les chaînes de caractères ou bien les entiers. Les valeurs d’un dictionnaire peuvent quant à elles être n’importe quel type d’objet Python.\n\n\n\nComme les dictionnaires sont non-ordonnés, il n’y a pas de notion de position : on accède à une valeur par sa clé associée. Par exemple, pour récupérer la valeur ('1,5L') associée à la clé 'lait' :\n\ninventaire['lait']\n\n'1,5L'\n\n\nDes couples clé-valeur supplémentaires peuvent être ajoutés à un dictionnaire déjà existant, en utilisant la syntaxe de l’assignation de variable.\n\ninventaire[\"céréales\"] = \"250g\"\ninventaire\n\n{'cafe': '300g', 'lait': '1,5L', 'céréales': '250g'}\n\n\nA l’inverse des listes, les clés ne doivent pas nécessairement commencer à 0 et peuvent être n’importe quel nombre.\n\ndic1 = {12: \"Averyon\", 33: \"Gironde\"}\n\nprint(\"Le département 33 est la \" + dic1[33])  # Concaténation de strings !\n\nLe département 33 est la Gironde\n\n\nDe même, les valeurs peuvent être de différentes natures, y compris des conteneurs de données.\n\ndic2 = {\"gamme\" : \"do majeur\",\n        \"notes\": [\"do\", \"re\", \"mi\", \"fa\", \"sol\", \"la\", \"si\"]}\n\ndic2[\"notes\"]\n\n['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\n\nLes dictionnaires peuvent notamment contenir d’autres dictionnaires. Cela les rend particulièrement adaptés pour représenter des structures hiérarchiques de données.\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"mirande\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(cv[\"marc\"])\nprint(cv[\"marc\"][\"hobbies\"][0])\n\n{'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']}\ncouture\n\n\nRépétons-le : les dictionnaires n’ont pas de notion d’ordre. Ainsi, il n’y a pas de sens à requêter l’élément de position 0 d’un dictionnaire (sauf si la clé 0 existe..). Requêter une clé inexistante renvoie une erreur.\n\ndic1 = {12: \"Averyon\", 33: \"Gironde\"}\n\ndic1[0]\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[9], line 3\n      1 dic1 = {12: \"Averyon\", 33: \"Gironde\"}\n----&gt; 3 dic1[0]\n\nKeyError: 0\n\n\n\n\n\n\nIl est possible de modifier une valeur associée à une clé existante dans le dictionnaire. La nouvelle valeur peut être de type différent de l’originale.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire['cafe'] = {'arabica': '250g', 'robusta': '400g'}\ninventaire\n\n{'cafe': {'arabica': '250g', 'robusta': '400g'}, 'lait': '1,5L'}\n\n\n\n\n\nPour supprimer une clé (et la valeur associée), les mêmes opérations que celles qui permettent de supprimer des éléments dans une liste peuvent être utilisées.\n\n# Avec l'opérateur `del`\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ndel inventaire['lait']\ninventaire\n\n{'cafe': '500g'}\n\n\n\n# Avec la méthode `pop`\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire.pop('lait')\ninventaire\n\n{'cafe': '500g'}\n\n\n\n\n\nNous avons vu précédemment que le fait de requêter une clé qui n’existe pas renvoyait une erreur. La méthode .get() permet de requêter une clé sans être sûr de son existence, puisqu’elle ne renvoie aucune erreur dans ce cas, mais l’objet None, que nous verrons dans un prochain tutoriel.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire.get('miel')\n\nOn peut d’ailleurs spécifier une valeur par défaut lorsque la clé n’existe pas.\n\ninventaire.get('miel', 'introuvable')\n\n'introuvable'\n\n\nLes méthodes .keys(), .values() et .items() renvoient respectivement les clés, les valeurs, et les couples clés-valeurs d’un dictionnaire. Les objets retournés par ces méthodes sont un peu complexes, mais il est possible de les transformer en liste avec la fonction list pour pouvoir les requêter par position.\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"mirande\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"triathlon\"]}\n}\n\nlist(cv.keys())\n\n['marc', 'mirande']\n\n\n\nlist(cv.values())\n\n[{'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']},\n {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['triathlon']}]\n\n\n\nlist(cv.items())\n\n[('marc',\n  {'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']}),\n ('mirande',\n  {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['triathlon']})]\n\n\n\n\n\n\n\n\nLes sets sont des collections non-ordonnées d’éléments uniques. En cela, ils peuvent être vus comme des dictionnaires sans valeurs, dont on n’aurait conservé que les clés (uniques par définition dans un dictionnaire). Une autre analogie est celle des ensembles mathématiques, dont les éléments sont également non-ordonnés et uniques.\nDu fait de leur proximité avec les dictionnaires, les sets sont également définis par des accolades {}.\n\nx = {3, 2, 1}\nx\n\n{1, 2, 3}\n\n\n\ntype(x)\n\nset\n\n\nDe la même manière que les dictionnaires, les sets sont non-ordonnés, il n’y a donc pas de notion de position. Demander l’élément de position i, comme dans une liste, renvoie une erreur.\n\nx = {3, 2, 1}\nx[0]\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[20], line 2\n      1 x = {3, 2, 1}\n----&gt; 2 x[0]\n\nTypeError: 'set' object is not subscriptable\n\n\n\n\n\n\nIl est possible d’ajouter un élément à un set via la méthode add.\n\nx = {3, 2, 1}\nx.add(\"4\")\nx\n\n{1, 2, 3, '4'}\n\n\nAjouter un élément déjà existant ne change rien par définition.\n\nx = {3, 2, 1}\nx.add(2)\nx\n\n{1, 2, 3}\n\n\nIl est possible de retirer un élément d’un set via la méthode remove.\n\nx = {3, 2, 1}\nx.remove(2)\nx\n\n{1, 3}\n\n\n\n\n\nLes sets ne sont pas très souvent utilisés en pratique, mais ils s’avèrent bien utiles dans certaines situations précises. Du fait de l’unicité des éléments qu’ils contiennent, les sets permettent simplement et efficacement de supprimer les doublons dans un conteneur séquentiel, comme une liste.\nDéduplication\nSupposons que l’on veut supprimer les doublons dans une liste donnée. Par définition, le fait de transformer une liste en set supprime les doublons. Cependant, on a généralement envie de revenir à une liste, dans la mesure où les sets n’offrent pas la même flexibilité que les listes (par exemple, la possibilité de trouver un élément par position). Il est donc fréquent de faire la chaîne d’opération list -&gt; set -&gt; list pour dédupliquer une liste.\n\nl = [1, 2, 3, 3, 2, 1]\nl_dedup = list(set(l))\nl_dedup\n\n[1, 2, 3]\n\n\nOpérations ensemblistes\nComme les sets représentent programmatiquement les ensembles mathématiques, il n’est pas étonnant qu’ils permettent de réaliser des opérations ensemblistes élémentaires. Par exemple, l’union et l’intersection.\n\nl1 = [5, 3, 2, 3, 3, 5, 8, 9]\nl2 = [3, 7, 0, 0, 1, 9, 4, 6]\n\n\n# Union : éléments soit dans l1, soit dans l2, soit dans les deux\nl_union = list(set(l1) | set(l2))\nl_union\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n# Intersection : éléments à la fois dans l1 et dans l2\nl_inter = list(set(l1) & set(l2))\nl_inter\n\n[9, 3]\n\n\nTests d’appartenance\nLes sets sont également très utilisés pour réaliser des tests d’appartenance, dans la mesure où ils offrent de bien meilleures performances que les listes pour ce type de test.\nLa notion de test fera l’objet d’un prochain tutoriel. Pour l’heure, retenons qu’un test d’appartenance du type “est-ce que l’élément a est dans la liste l” s’écrit en Python a in l et renvoie True ou False selon que a est effectivement présent dans la liste l ou non.\n\nl = [1, 2, 3]\n2 in l\n\nTrue\n\n\n\n4 in l\n\nFalse\n\n\nMaintenant, imaginons que nous réalisions ce test sur une liste contenant des millions d’éléments. En exagérant, l’interpréteur Python devrait alors parcourir tous les éléments de la liste un à un jusqu’à trouver l’élément en question, ce qui peut prendre très longtemps.\nA l’inverse, comme les éléments d’un set sont uniques, Python peut facilement garder en mémoire la liste des éléments uniques contenus dans le set, et donc conclure très rapidement le test. Nous verrons une comparaison des performances dans un exercice de fin de tutoriel.\nNB : l’implémentation informatique des notions évoquées ci-dessus s’appelle une “table de hachage” (hash table). Le lecteur intéressé pourra trouver plus d’informations à propos de cette structure de données ici.\n\n\n\n\n\n\n\n1/ Peut-on accéder au iième élément d’un dictionnaire ? d’un set ?\n2/ Quels types d’objets peuvent être utilisés comme clés d’un dictionnaire ? Comme valeurs ?\n3/ Pour quels types de données a-t-on intérêt à utiliser un dictionnaire ?\n4/ Un dictionnaire peut-il avoir des doublons dans ses clés ?\n5/ Pourquoi peut-on dire qu’un set est un dictionnaire particulier ?\n6/ Pourquoi les sets sont-ils utilisés pour dédupliquer des listes ?\n7/ Pourquoi les sets sont-ils plus pertinents que les listes pour réaliser des tests d’appartenance ?\n\n\n\n\nAfficher la solution\n\n1/ Non, les dictionnaires et les sets sont des collections non-ordonnées d’objet.\n2/ Pour les valeurs : n’importe quel type d’objet. Pour les clés, on se restreint généralement aux chaînes de caractères et/ou entiers.\n3/ Des données de type hiérarchique.\n4/ Non, les clés sont uniques.\n5/ Un set ne comporte que des éléments uniques et s’écrit avec des accolades. Il peut donc être vu comme un dictionnaire particulier ne contenant que des clés.\n6/ Par définition, les éléments d’un set sont uniques. Transformer une liste en set supprime donc les doublons.\n7/ Du fait de l’unicité des éléments, Python peut garder en mémoire la position des différents éléments. Les tests d’appartenance sont donc fortement optimisés par rapport à lorsqu’on les effectue avec une liste.\n\n\n\n\n\nSoit le dictionnaire défini dans la cellule ci-dessous.\nAffichez à l’aide d’opérations print :\n\nla liste des noms des différentes classes\nla note de Miranda en histoire\nla liste des notes obtenues par Hypolyte\nla liste des noms des élèves de la 6emeB\nla liste des matières enseignées en 6eme A\nla liste de toutes les matières enseignées\nla liste des notes obtenues par les filles des deux classes\n\n\nresultats = {\n    \"6emeA\": {\"Miranda\" : {\"notes\": {\"physique\": 16, \"histoire\": 12}},\n              \"Celestin\": {\"notes\": {\"physique\": \"absent\", \"histoire\": 18}}\n             },\n    \"6emeB\": {\"Hypolyte\": {\"notes\": {\"maths\": 11, \"anglais\": 0}},\n              \"Josephine\": {\"notes\": {\"maths\": 16, \"anglais\": 20}}\n             }\n}\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(list(resultats.keys()))\n\nprint(resultats[\"6emeA\"][\"Miranda\"][\"notes\"][\"histoire\"])\n\nprint(list(resultats[\"6emeB\"][\"Hypolyte\"][\"notes\"].values()))\n\nprint(list(resultats[\"6emeB\"].keys()))\n\nprint(list(resultats[\"6emeA\"][\"Miranda\"][\"notes\"].keys()))\n\nprint(list(resultats[\"6emeA\"][\"Miranda\"][\"notes\"].keys()) \n      + list(resultats[\"6emeB\"][\"Josephine\"][\"notes\"].keys()))\n\nprint(list(resultats[\"6emeA\"][\"Miranda\"][\"notes\"].values()) \n      + list(resultats[\"6emeB\"][\"Josephine\"][\"notes\"].values()))\n\n\n\n\n\nDans les tutoriels précédents, nous avons vu la fonction len, qui permet de compter le nombre d’éléments d’une séquence. Est-ce que cette fonction fonctionne avec les dictionnaires ? Que compte-t-elle alors ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"miranda\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(len(cv))\nprint(len(cv[\"marc\"]))\nLa fonction len appliquée à un dictionnaire compte le nombre de clés.\n\n\n\n\n\nNous avons vu qu’on pouvait supprimer une clé d’un dictionnaire de deux manières différentes :\n\navec l’opérateur del : del mon_dict[clé]\navec la méthode pop : mon_dict.pop(clé)\n\nAu-delà de la syntaxe, quelles sont les deux différences majeures entre ces deux manières de supprimer une clé d’un dictionnaire ? N’hésitez pas à expérimenter avec des exemples de votre choix.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\n\nprint(inventaire.pop('cafe'))\nprint(inventaire.pop('orange', 'indisponible'))\n1ère différence : lorsqu’on supprime une clé existante avec la méthode pop, la valeur associée à la clé est retournée. L’opération del ne retourne rien (en fait, un objet de type None)\n2ème différence : la méthode pop permet de spécifier une valeur par défaut en cas de non-existence de la clé, et donc ne retourne pas d’erreur dans ce cas. L’opération del retourne nécessairement une erreur lorsque la clé n’existe pas.\n\n\n\n\n\nEn exploitant le fait que la méthode pop utilisée pour supprimer une clé d’un dictionnaire renvoie la valeur associée à cette clé, proposez une méthode pour renommer une clé d’un dictionnaire en une seule opération.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\n\ninventaire['eau'] = inventaire.pop('lait')\n\ninventaire\n\n\n\n\n\nSoit le dictionnaire suivant :\nanimaux = {'chats': 5, 'chiens': 12}\nQue vont retourner les tests d’appartenance suivants ? Vérifiez vos prédictions.\n\n'chats' in animaux.keys()\n'chats' in animaux.values()\n'chats' in animaux\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nanimaux = {'chats': 5, 'chiens': 12}\n\nprint(animaux.keys())\nprint('chats' in animaux.keys()) \n# True : 'chats' est bien dans les clés de `animaux`\n\nprint()\nprint(animaux.values())\nprint('chats' in animaux.values()) \n# False : 'chats' n'est pas une valeur de `animaux`\n\nprint()\nprint(animaux)\nprint('chats' in animaux) \n# True : ce test est strictement équivalent à 'chats' in animaux.keys()\n\n\n\n\n\nNous avons vu que l’opération del renvoyait une erreur lorsqu’on l’utilisait pour supprimer une clé inexistante d’un dictionnaire. A l’aide de vos nouvelles connaissances sur les tests d’appartenance, pouvez-vous imaginer une méthode (sans nécessairement l’implémenter) qui permettrait de traiter ce cas sans erreur ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\n\ncle = 'chocolat'\n\nif cle in inventaire.keys():\n    del inventaire[cle]\nOn utilise un test d’appartenance : si la clé existe dans les clés du dictionnaire, elle est supprimée. Sinon, il ne se passe rien. Cette syntaxe deviendra plus claire avec le prochain tutoriel.\n\n\n\n\n\nSoit la chaîne de caractères avec répétition suivante :\nx = \"cdabcdabcdabcdabcdabcdabcdabcdabcdab\"\nConstruisez une liste des caractères uniques se trouvant dans cette chaîne, classée par ordre alphabétique, soit :\nl = ['a', 'b', 'c', 'd']\nIndice : la procédure est semblable au fait de supprimer les doublons d’une liste.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = \"cdabcdabcdabcdabcdabcdabcdabcdabcdab\"\nl = list(set(x))\nl.sort()\nl\n\n\n\n\n\nSoit les deux chaînes de caractères suivantes.\ncyrano1 = 'C’est un roc ! … c’est un pic ! … c’est un cap !'\ncyrano2 = 'Que dis-je, c’est un cap ? … C’est une péninsule !'\nQuestion 1 : trouvez les caractères qui apparaissent à la fois dans les deux chaînes.\nQuestion 2 : trouvez les caractères qui apparaissent dans au moins un des deux textes.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ncyrano1 = 'C’est un roc ! … c’est un pic ! … c’est un cap !'\ncyrano2 = 'Que dis-je, c’est un cap ? … C’est une péninsule !'\n\n# Question 1\n\ninter = list(set(cyrano1) & set(cyrano2))\nprint(inter)\n\n# Question 2\n\nunion = list(set(cyrano1) | set(cyrano2))\nprint(union)\n\n\n\n\n\nLe code ci-dessous génère une liste avec les lettres a, b, c et d répétées 1 million de fois. Ensuite, il réalise un test d’appartenance d’une lettre qui n’existe pas dans la liste, et calcule le temps mis par l’interpréteur Python pour réaliser le test.\nEn reprenant cette syntaxe, comparez le temps mis par le même test d’appartenance lorsqu’on transforme la liste en set au préalable.\n\nx = ['a', 'b', 'c', 'd'] * 1000000\nprint(x[:10])\n\n%time 'e' in x\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\nCPU times: user 41.1 ms, sys: 145 μs, total: 41.2 ms\nWall time: 41.1 ms\n\n\nFalse\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = ['a', 'b', 'c', 'd'] * 1000000\nprint(x[:10])\n\nx_set = set(x)\nprint(x_set)\n\n%time 'e' in x\n%time 'e' in x_set\nLe test d’appartenance initial se chiffre en millisecondes. Celui réalisé sur le set se chiffre en microsecondes. Le test est beaucoup plus rapide lorsqu’on convertit en set au préalable.",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 2 : dictionnaires et sets"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html#dictionnaires",
    "href": "source/fundamentals/data-structures2/tutorial.html#dictionnaires",
    "title": "Structures de données 2 : dictionnaires et sets",
    "section": "",
    "text": "Les dictionnaires sont des collections non-ordonnées de couples clé-valeur. Un dictionnaire se définit selon la syntaxe suivante : d = {'cle1': 'valeur1', 'cle2': 'valeur2'}.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire\n\n{'cafe': '500g', 'lait': '1,5L'}\n\n\n\ntype(inventaire)\n\ndict\n\n\nIl est possible de mettre autant de clés que l’on souhaite dans un dictionnaire. En revanche, les clés sont uniques, afin d’identifier de manière certaine la valeur associée. Si l’on essaye de définir un dictionnaire avec une clé dupliquée, Python ne renvoie pas d’erreur, mais seule la dernière clé dupliquée est prise en compte.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L', 'cafe': '300g'}\ninventaire\n\n{'cafe': '300g', 'lait': '1,5L'}\n\n\nQue peut contenir un dictionnaire ? Les clés peuvent être de différents types, mais on n’utilise en général que les chaînes de caractères ou bien les entiers. Les valeurs d’un dictionnaire peuvent quant à elles être n’importe quel type d’objet Python.\n\n\n\nComme les dictionnaires sont non-ordonnés, il n’y a pas de notion de position : on accède à une valeur par sa clé associée. Par exemple, pour récupérer la valeur ('1,5L') associée à la clé 'lait' :\n\ninventaire['lait']\n\n'1,5L'\n\n\nDes couples clé-valeur supplémentaires peuvent être ajoutés à un dictionnaire déjà existant, en utilisant la syntaxe de l’assignation de variable.\n\ninventaire[\"céréales\"] = \"250g\"\ninventaire\n\n{'cafe': '300g', 'lait': '1,5L', 'céréales': '250g'}\n\n\nA l’inverse des listes, les clés ne doivent pas nécessairement commencer à 0 et peuvent être n’importe quel nombre.\n\ndic1 = {12: \"Averyon\", 33: \"Gironde\"}\n\nprint(\"Le département 33 est la \" + dic1[33])  # Concaténation de strings !\n\nLe département 33 est la Gironde\n\n\nDe même, les valeurs peuvent être de différentes natures, y compris des conteneurs de données.\n\ndic2 = {\"gamme\" : \"do majeur\",\n        \"notes\": [\"do\", \"re\", \"mi\", \"fa\", \"sol\", \"la\", \"si\"]}\n\ndic2[\"notes\"]\n\n['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\n\nLes dictionnaires peuvent notamment contenir d’autres dictionnaires. Cela les rend particulièrement adaptés pour représenter des structures hiérarchiques de données.\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"mirande\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(cv[\"marc\"])\nprint(cv[\"marc\"][\"hobbies\"][0])\n\n{'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']}\ncouture\n\n\nRépétons-le : les dictionnaires n’ont pas de notion d’ordre. Ainsi, il n’y a pas de sens à requêter l’élément de position 0 d’un dictionnaire (sauf si la clé 0 existe..). Requêter une clé inexistante renvoie une erreur.\n\ndic1 = {12: \"Averyon\", 33: \"Gironde\"}\n\ndic1[0]\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nCell In[9], line 3\n      1 dic1 = {12: \"Averyon\", 33: \"Gironde\"}\n----&gt; 3 dic1[0]\n\nKeyError: 0\n\n\n\n\n\n\nIl est possible de modifier une valeur associée à une clé existante dans le dictionnaire. La nouvelle valeur peut être de type différent de l’originale.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire['cafe'] = {'arabica': '250g', 'robusta': '400g'}\ninventaire\n\n{'cafe': {'arabica': '250g', 'robusta': '400g'}, 'lait': '1,5L'}\n\n\n\n\n\nPour supprimer une clé (et la valeur associée), les mêmes opérations que celles qui permettent de supprimer des éléments dans une liste peuvent être utilisées.\n\n# Avec l'opérateur `del`\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ndel inventaire['lait']\ninventaire\n\n{'cafe': '500g'}\n\n\n\n# Avec la méthode `pop`\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire.pop('lait')\ninventaire\n\n{'cafe': '500g'}\n\n\n\n\n\nNous avons vu précédemment que le fait de requêter une clé qui n’existe pas renvoyait une erreur. La méthode .get() permet de requêter une clé sans être sûr de son existence, puisqu’elle ne renvoie aucune erreur dans ce cas, mais l’objet None, que nous verrons dans un prochain tutoriel.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\ninventaire.get('miel')\n\nOn peut d’ailleurs spécifier une valeur par défaut lorsque la clé n’existe pas.\n\ninventaire.get('miel', 'introuvable')\n\n'introuvable'\n\n\nLes méthodes .keys(), .values() et .items() renvoient respectivement les clés, les valeurs, et les couples clés-valeurs d’un dictionnaire. Les objets retournés par ces méthodes sont un peu complexes, mais il est possible de les transformer en liste avec la fonction list pour pouvoir les requêter par position.\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"mirande\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"triathlon\"]}\n}\n\nlist(cv.keys())\n\n['marc', 'mirande']\n\n\n\nlist(cv.values())\n\n[{'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']},\n {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['triathlon']}]\n\n\n\nlist(cv.items())\n\n[('marc',\n  {'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']}),\n ('mirande',\n  {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['triathlon']})]",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 2 : dictionnaires et sets"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html#sets",
    "href": "source/fundamentals/data-structures2/tutorial.html#sets",
    "title": "Structures de données 2 : dictionnaires et sets",
    "section": "",
    "text": "Les sets sont des collections non-ordonnées d’éléments uniques. En cela, ils peuvent être vus comme des dictionnaires sans valeurs, dont on n’aurait conservé que les clés (uniques par définition dans un dictionnaire). Une autre analogie est celle des ensembles mathématiques, dont les éléments sont également non-ordonnés et uniques.\nDu fait de leur proximité avec les dictionnaires, les sets sont également définis par des accolades {}.\n\nx = {3, 2, 1}\nx\n\n{1, 2, 3}\n\n\n\ntype(x)\n\nset\n\n\nDe la même manière que les dictionnaires, les sets sont non-ordonnés, il n’y a donc pas de notion de position. Demander l’élément de position i, comme dans une liste, renvoie une erreur.\n\nx = {3, 2, 1}\nx[0]\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[20], line 2\n      1 x = {3, 2, 1}\n----&gt; 2 x[0]\n\nTypeError: 'set' object is not subscriptable\n\n\n\n\n\n\nIl est possible d’ajouter un élément à un set via la méthode add.\n\nx = {3, 2, 1}\nx.add(\"4\")\nx\n\n{1, 2, 3, '4'}\n\n\nAjouter un élément déjà existant ne change rien par définition.\n\nx = {3, 2, 1}\nx.add(2)\nx\n\n{1, 2, 3}\n\n\nIl est possible de retirer un élément d’un set via la méthode remove.\n\nx = {3, 2, 1}\nx.remove(2)\nx\n\n{1, 3}\n\n\n\n\n\nLes sets ne sont pas très souvent utilisés en pratique, mais ils s’avèrent bien utiles dans certaines situations précises. Du fait de l’unicité des éléments qu’ils contiennent, les sets permettent simplement et efficacement de supprimer les doublons dans un conteneur séquentiel, comme une liste.\nDéduplication\nSupposons que l’on veut supprimer les doublons dans une liste donnée. Par définition, le fait de transformer une liste en set supprime les doublons. Cependant, on a généralement envie de revenir à une liste, dans la mesure où les sets n’offrent pas la même flexibilité que les listes (par exemple, la possibilité de trouver un élément par position). Il est donc fréquent de faire la chaîne d’opération list -&gt; set -&gt; list pour dédupliquer une liste.\n\nl = [1, 2, 3, 3, 2, 1]\nl_dedup = list(set(l))\nl_dedup\n\n[1, 2, 3]\n\n\nOpérations ensemblistes\nComme les sets représentent programmatiquement les ensembles mathématiques, il n’est pas étonnant qu’ils permettent de réaliser des opérations ensemblistes élémentaires. Par exemple, l’union et l’intersection.\n\nl1 = [5, 3, 2, 3, 3, 5, 8, 9]\nl2 = [3, 7, 0, 0, 1, 9, 4, 6]\n\n\n# Union : éléments soit dans l1, soit dans l2, soit dans les deux\nl_union = list(set(l1) | set(l2))\nl_union\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n\n\n# Intersection : éléments à la fois dans l1 et dans l2\nl_inter = list(set(l1) & set(l2))\nl_inter\n\n[9, 3]\n\n\nTests d’appartenance\nLes sets sont également très utilisés pour réaliser des tests d’appartenance, dans la mesure où ils offrent de bien meilleures performances que les listes pour ce type de test.\nLa notion de test fera l’objet d’un prochain tutoriel. Pour l’heure, retenons qu’un test d’appartenance du type “est-ce que l’élément a est dans la liste l” s’écrit en Python a in l et renvoie True ou False selon que a est effectivement présent dans la liste l ou non.\n\nl = [1, 2, 3]\n2 in l\n\nTrue\n\n\n\n4 in l\n\nFalse\n\n\nMaintenant, imaginons que nous réalisions ce test sur une liste contenant des millions d’éléments. En exagérant, l’interpréteur Python devrait alors parcourir tous les éléments de la liste un à un jusqu’à trouver l’élément en question, ce qui peut prendre très longtemps.\nA l’inverse, comme les éléments d’un set sont uniques, Python peut facilement garder en mémoire la liste des éléments uniques contenus dans le set, et donc conclure très rapidement le test. Nous verrons une comparaison des performances dans un exercice de fin de tutoriel.\nNB : l’implémentation informatique des notions évoquées ci-dessus s’appelle une “table de hachage” (hash table). Le lecteur intéressé pourra trouver plus d’informations à propos de cette structure de données ici.",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 2 : dictionnaires et sets"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures2/tutorial.html#exercices",
    "href": "source/fundamentals/data-structures2/tutorial.html#exercices",
    "title": "Structures de données 2 : dictionnaires et sets",
    "section": "",
    "text": "1/ Peut-on accéder au iième élément d’un dictionnaire ? d’un set ?\n2/ Quels types d’objets peuvent être utilisés comme clés d’un dictionnaire ? Comme valeurs ?\n3/ Pour quels types de données a-t-on intérêt à utiliser un dictionnaire ?\n4/ Un dictionnaire peut-il avoir des doublons dans ses clés ?\n5/ Pourquoi peut-on dire qu’un set est un dictionnaire particulier ?\n6/ Pourquoi les sets sont-ils utilisés pour dédupliquer des listes ?\n7/ Pourquoi les sets sont-ils plus pertinents que les listes pour réaliser des tests d’appartenance ?\n\n\n\n\nAfficher la solution\n\n1/ Non, les dictionnaires et les sets sont des collections non-ordonnées d’objet.\n2/ Pour les valeurs : n’importe quel type d’objet. Pour les clés, on se restreint généralement aux chaînes de caractères et/ou entiers.\n3/ Des données de type hiérarchique.\n4/ Non, les clés sont uniques.\n5/ Un set ne comporte que des éléments uniques et s’écrit avec des accolades. Il peut donc être vu comme un dictionnaire particulier ne contenant que des clés.\n6/ Par définition, les éléments d’un set sont uniques. Transformer une liste en set supprime donc les doublons.\n7/ Du fait de l’unicité des éléments, Python peut garder en mémoire la position des différents éléments. Les tests d’appartenance sont donc fortement optimisés par rapport à lorsqu’on les effectue avec une liste.\n\n\n\n\n\nSoit le dictionnaire défini dans la cellule ci-dessous.\nAffichez à l’aide d’opérations print :\n\nla liste des noms des différentes classes\nla note de Miranda en histoire\nla liste des notes obtenues par Hypolyte\nla liste des noms des élèves de la 6emeB\nla liste des matières enseignées en 6eme A\nla liste de toutes les matières enseignées\nla liste des notes obtenues par les filles des deux classes\n\n\nresultats = {\n    \"6emeA\": {\"Miranda\" : {\"notes\": {\"physique\": 16, \"histoire\": 12}},\n              \"Celestin\": {\"notes\": {\"physique\": \"absent\", \"histoire\": 18}}\n             },\n    \"6emeB\": {\"Hypolyte\": {\"notes\": {\"maths\": 11, \"anglais\": 0}},\n              \"Josephine\": {\"notes\": {\"maths\": 16, \"anglais\": 20}}\n             }\n}\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(list(resultats.keys()))\n\nprint(resultats[\"6emeA\"][\"Miranda\"][\"notes\"][\"histoire\"])\n\nprint(list(resultats[\"6emeB\"][\"Hypolyte\"][\"notes\"].values()))\n\nprint(list(resultats[\"6emeB\"].keys()))\n\nprint(list(resultats[\"6emeA\"][\"Miranda\"][\"notes\"].keys()))\n\nprint(list(resultats[\"6emeA\"][\"Miranda\"][\"notes\"].keys()) \n      + list(resultats[\"6emeB\"][\"Josephine\"][\"notes\"].keys()))\n\nprint(list(resultats[\"6emeA\"][\"Miranda\"][\"notes\"].values()) \n      + list(resultats[\"6emeB\"][\"Josephine\"][\"notes\"].values()))\n\n\n\n\n\nDans les tutoriels précédents, nous avons vu la fonction len, qui permet de compter le nombre d’éléments d’une séquence. Est-ce que cette fonction fonctionne avec les dictionnaires ? Que compte-t-elle alors ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"miranda\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(len(cv))\nprint(len(cv[\"marc\"]))\nLa fonction len appliquée à un dictionnaire compte le nombre de clés.\n\n\n\n\n\nNous avons vu qu’on pouvait supprimer une clé d’un dictionnaire de deux manières différentes :\n\navec l’opérateur del : del mon_dict[clé]\navec la méthode pop : mon_dict.pop(clé)\n\nAu-delà de la syntaxe, quelles sont les deux différences majeures entre ces deux manières de supprimer une clé d’un dictionnaire ? N’hésitez pas à expérimenter avec des exemples de votre choix.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\n\nprint(inventaire.pop('cafe'))\nprint(inventaire.pop('orange', 'indisponible'))\n1ère différence : lorsqu’on supprime une clé existante avec la méthode pop, la valeur associée à la clé est retournée. L’opération del ne retourne rien (en fait, un objet de type None)\n2ème différence : la méthode pop permet de spécifier une valeur par défaut en cas de non-existence de la clé, et donc ne retourne pas d’erreur dans ce cas. L’opération del retourne nécessairement une erreur lorsque la clé n’existe pas.\n\n\n\n\n\nEn exploitant le fait que la méthode pop utilisée pour supprimer une clé d’un dictionnaire renvoie la valeur associée à cette clé, proposez une méthode pour renommer une clé d’un dictionnaire en une seule opération.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\n\ninventaire['eau'] = inventaire.pop('lait')\n\ninventaire\n\n\n\n\n\nSoit le dictionnaire suivant :\nanimaux = {'chats': 5, 'chiens': 12}\nQue vont retourner les tests d’appartenance suivants ? Vérifiez vos prédictions.\n\n'chats' in animaux.keys()\n'chats' in animaux.values()\n'chats' in animaux\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nanimaux = {'chats': 5, 'chiens': 12}\n\nprint(animaux.keys())\nprint('chats' in animaux.keys()) \n# True : 'chats' est bien dans les clés de `animaux`\n\nprint()\nprint(animaux.values())\nprint('chats' in animaux.values()) \n# False : 'chats' n'est pas une valeur de `animaux`\n\nprint()\nprint(animaux)\nprint('chats' in animaux) \n# True : ce test est strictement équivalent à 'chats' in animaux.keys()\n\n\n\n\n\nNous avons vu que l’opération del renvoyait une erreur lorsqu’on l’utilisait pour supprimer une clé inexistante d’un dictionnaire. A l’aide de vos nouvelles connaissances sur les tests d’appartenance, pouvez-vous imaginer une méthode (sans nécessairement l’implémenter) qui permettrait de traiter ce cas sans erreur ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ninventaire = {'cafe': '500g', 'lait': '1,5L'}\n\ncle = 'chocolat'\n\nif cle in inventaire.keys():\n    del inventaire[cle]\nOn utilise un test d’appartenance : si la clé existe dans les clés du dictionnaire, elle est supprimée. Sinon, il ne se passe rien. Cette syntaxe deviendra plus claire avec le prochain tutoriel.\n\n\n\n\n\nSoit la chaîne de caractères avec répétition suivante :\nx = \"cdabcdabcdabcdabcdabcdabcdabcdabcdab\"\nConstruisez une liste des caractères uniques se trouvant dans cette chaîne, classée par ordre alphabétique, soit :\nl = ['a', 'b', 'c', 'd']\nIndice : la procédure est semblable au fait de supprimer les doublons d’une liste.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = \"cdabcdabcdabcdabcdabcdabcdabcdabcdab\"\nl = list(set(x))\nl.sort()\nl\n\n\n\n\n\nSoit les deux chaînes de caractères suivantes.\ncyrano1 = 'C’est un roc ! … c’est un pic ! … c’est un cap !'\ncyrano2 = 'Que dis-je, c’est un cap ? … C’est une péninsule !'\nQuestion 1 : trouvez les caractères qui apparaissent à la fois dans les deux chaînes.\nQuestion 2 : trouvez les caractères qui apparaissent dans au moins un des deux textes.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ncyrano1 = 'C’est un roc ! … c’est un pic ! … c’est un cap !'\ncyrano2 = 'Que dis-je, c’est un cap ? … C’est une péninsule !'\n\n# Question 1\n\ninter = list(set(cyrano1) & set(cyrano2))\nprint(inter)\n\n# Question 2\n\nunion = list(set(cyrano1) | set(cyrano2))\nprint(union)\n\n\n\n\n\nLe code ci-dessous génère une liste avec les lettres a, b, c et d répétées 1 million de fois. Ensuite, il réalise un test d’appartenance d’une lettre qui n’existe pas dans la liste, et calcule le temps mis par l’interpréteur Python pour réaliser le test.\nEn reprenant cette syntaxe, comparez le temps mis par le même test d’appartenance lorsqu’on transforme la liste en set au préalable.\n\nx = ['a', 'b', 'c', 'd'] * 1000000\nprint(x[:10])\n\n%time 'e' in x\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\nCPU times: user 41.1 ms, sys: 145 μs, total: 41.2 ms\nWall time: 41.1 ms\n\n\nFalse\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = ['a', 'b', 'c', 'd'] * 1000000\nprint(x[:10])\n\nx_set = set(x)\nprint(x_set)\n\n%time 'e' in x\n%time 'e' in x_set\nLe test d’appartenance initial se chiffre en millisecondes. Celui réalisé sur le set se chiffre en microsecondes. Le test est beaucoup plus rapide lorsqu’on convertit en set au préalable.",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 2 : dictionnaires et sets"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html",
    "href": "source/manipulation/modules-files/tutorial.html",
    "title": "Manipulation de fichiers",
    "section": "",
    "text": "Dans les tutoriels précédents, nous avons utilisé systématiquement des variables pour stocker des données et réaliser des opérations sur celles-ci. Cette façon de faire peut suffire dans le cadre d’une session Python donnée, comme ici dans un notebook Jupyter ou bien dans un programme.\nMais que se passe-t-il par exemple si l’on souhaite conserver les sorties des calculs réalisés ou bien des données transformées une fois la session terminée ? Il nous faut alors sauvegarder ces éléments dans un fichier, à un endroit où ces données vont persister dans le temps en vue d’une utilisation ultérieure. Dans ce tutoriel, nous allons voir comment lire et écrire des fichiers avec Python.\n\n\nAvant de parler de manipulation de fichiers, nous devons faire un bref détour par le monde des modules et des packages (librairies).\nJusqu’à maintenant, nous avons essentiellement utilisé des objets et des instructions standards de Python, qui ne nécessitaient donc pas d’import tiers. Dans ce tutoriel et tous ceux qui vont suivre, nous allons réaliser des opérations plus complexes (interagir avec un système de fichiers, faire du calcul vectoriel, manipuler des données tabulaires, etc.) qu’il serait très coûteux, inefficient, et avec un potentiel d’erreur énorme, de coder à la main en utilisant les objets de base de Python.\nC’est pourquoi nous allons utiliser des packages, sortes de boîtes à outils remplies de fonctions et de classes développées par d’autres (souvent, de manière communautaire) et qui permettent de réaliser des opérations complexes à moindre coût.\n\n\nCommençons par quelques brefs éléments de terminologie pour bien se repérer dans l’écosystème Python :\n\nun module est un fichier texte (portant l’extension .py pour bien marquer le lien à Python) contenant un ensemble de définitions (de classes, de fonctions) et d’instructions, que l’on peut importer dans un environnement Python afin de les utiliser.\nun package est un ensemble de modules réunis dans un même répertoire\n\nPar exemple, nous allons voir en détails dans la prochaine partie l’utilisation de numpy. numpy est un package qui permet de faire du calcul scientifique sur des objets multidimensionnels. Pour ce faire, numpy met à disposition un nombre gigantesque de fonctions et d’outils. Toutes les mettre dans un seul et même module serait franchement illisible. Ainsi, numpy est structuré en différents modules qui groupent les fonctions réalisant des opérations similaires : les fonctions générant de l’aléatoire dans le module random, celles réalisant de l’algèbre linéaire dans le module linalg, etc.\n\n\n\nPour pouvoir exploiter les fonctions d’un module et les différents modules qui constituent un package, il nous faut en premier lieu les importer.\nLa syntaxe est très simple, illustrons là à travers un exemple.\n\nimport random\nrandom.randint(0, 100)\n\n48\n\n\nNous avons importé le module random (complet) de la librairie standard de Python via l’instruction import. Ensuite, nous avons fait appel à la fonction randint contenue dans le module random, qui renvoie un nombre aléatoire entre a et b ses paramètres.\nOn aurait pu également importer seulement la fonction randint en utilisant la syntaxe from module import fonction. Il n’est alors plus nécessaire de spécifier le nom du module lorsqu’on appelle la fonction.\n\nfrom random import randint\nrandint(0, 100)\n\n34\n\n\nNotons qu’une fois qu’un import est effectué, le module importé est disponible pour toute la durée de la session Python. Il n’y a donc pas besoin d’importer le module avant chaque utilisation d’une de ses fonctions, une fois au début de son notebook ou script suffit.\n\n\n\n\n\n\nTrop d’imports tue l’import\n\n\n\nIl arrive parfois de voir la syntaxe from module import * (* s’appelle le wildcard) qui a pour effet d’importer en mémoire toutes les fonctions du module. Si cela permet de gagner du temps, ce n’est pourtant pas une bonne pratique :\n\nd’une part, cela charge plus de code en mémoire qu’il n’est nécessaire pour notre application ;\nd’autre part, cela limite la lisibilité du code dans la mesure où l’on ne voit pas explicitement d’où ont été importées les fonctions qui sont utilisées dans le code.\n\n\n\n\n\n\nUn package est simplement une collection de modules, structurée selon une arborescence. La syntaxe pour importer un package est identique à celle pour importer un module.\nPar exemple, regardons à nouveau comment utiliser la fonction randint, mais cette fois celle du package numpy (qui fait la même chose).\n\nimport numpy\n\n\nnumpy.random.randint(0, 100)\n\n8\n\n\nOn a importé le package numpy, qui nous a permis d’accéder via son module random à la fonction randint. Là encore, on aurait pu importer directement la fonction.\n\nfrom numpy.random import randint\n\n\nrandint(0, 100)\n\n89\n\n\nEn pratique, la première syntaxe est préférable : il est toujours plus lisible de montrer explicitement d’où vient la fonction que l’on appelle. Pour réduire la verbosité, il est fréquent de donner un alias aux packages que l’on importe. Voici les trois plus fréquents, que l’on rencontrera très souvent dans les tutoriels du prochain chapitre sur la manipulation de données.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nOn peut alors utiliser ces alias pour appeler des modules et des fonctions.\n\nx = np.linspace(0, 10, 1000)\nplt.plot(x, np.sin(x))\n\n\n\n\n\n\n\n\n\n\n\nJusqu’à maintenant, nous avons pu importer sans problème les différents packages via l’instruction import. Mais comment ont-ils été installés ? Il faut distinguer deux cas de figure :\n\nun certain nombre de packages font partie de la bibilothèque standard, ce qui signifie qu’ils sont installés en même temps que Python. C’est par exemple le cas du package random utilisé plus haut, mais il en existe beaucoup d’autres ;\nles autres packages “tiers” sont développés par la communauté des utilisateurs de Python, et doivent être installés pour pouvoir être utilisés. C’est notamment le cas de numpy et pandas. Dans notre cas, nous n’avons pas eu à les installer car l’environnement fourni pour la formation contient déjà l’ensemble des packages nécessaires pour exécuter les différents chapitres.\n\nIllustrons l’installation de package à travers le package emoji, qui permet de représenter des émoticônes dans les sorties de Python. Pour le coup, celui-ci n’est pas encore installé ; essayer de l’importer produit une ModuleNotFoundError.\n\nimport emoji\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 import emoji\n\nModuleNotFoundError: No module named 'emoji'\n\n\n\nPour installer un package, la commande est simple : pip install nom_du_package. Sans rentrer dans les détails, pip est un gestionnaire de packages, installé avec Python, qui s’utilise en ligne de commande (i.e. dans un terminal). Pour pouvoir envoyer une commande au terminal depuis un notebook Jupyter, on rajoute un ! devant la commande.\n\n!pip install emoji\n\nCollecting emoji\n  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: typing-extensions&gt;=4.7.0 in /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages (from emoji) (4.12.2)\nDownloading emoji-2.12.1-py3-none-any.whl (431 kB)\nInstalling collected packages: emoji\nSuccessfully installed emoji-2.12.1\n\n\nIl est à présent possible d’importer le package et d’utiliser ses fonctions.\n\nimport emoji\n\nprint(emoji.emojize('Python est :thumbs_up:'))\n\nPython est 👍\n\n\n\n\n\n\n\n\npip et PyPI\n\n\n\npip est le gestionnaire de paquets standard pour Python. Il permet d’installer, de mettre à jour et de supprimer des packages Python trouvés dans le Python Package Index (PyPI), un répertoire de packages pour la programmation en Python. Ce répertoire contient un nombre gigantesque de projets (environ 500,000 à l’heure de l’écriture de ce tutoriel), des plus amateurs aux plus essentiels.\nDe manière générale, il est toujours préférable, avant de se lancer dans l’écriture d’une application “à la main”, de vérifier qu’un package faisant la même chose ou presque n’existe pas déjà. Une simple recherche google - de préférence en Anglais - contenant les mots-clés de ce que l’on cherche à faire permet souvent de s’en assurer.\n\n\n\n\n\n\n\n\nPour pouvoir lire et écrire des fichiers avec Python, il nous faut d’abord comprendre comment ceux-ci sont représentés sur le système de fichiers (file system) local, et comment Python interagit avec ce dernier.\nLe module pathlib\nPour ce faire, nous allons utiliser de manière répétée le module pathlib et en particulier la classe Path. Ce module permet d’interagir avec le système de fichiers sous forme d’objets, en manipulant des attributs et leurs méthodes. Pas de panique, nous avons vu tout ce qu’il nous fallait savoir à ce propos dans le précédent tutoriel.\n\nfrom pathlib import Path\n\nPropriétés d’un fichier\nUn fichier a deux propriétés :\n\nun nom de fichier\nun chemin (path), qui spécifie sa localisation dans le système de fichiers.\n\nA titre d’exemple, regardons les fichiers qui se trouvent dans notre répertoire courant (par défaut, le dossier dans lequel se trouve ce notebook). La méthode à utiliser s’appelle cwd, pour current working directory.\n\nPath.cwd()\n\nPosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files')\n\n\nLe chemin de notre répertoire courant est contenu dans un objet PosixPath, ce qui signifie simplement que pathlib a compris que nous étions sur un environnement de type Unix (les serveurs du SSP Cloud sont sous Linux). Si vous exécutiez ce notebook en local sur un ordinateur Windows, l’objet serait WindowsPath. Concrètement, cela ne change pas grand chose pour vous mais c’est en fait assez important : les systèmes de fichiers n’utilisent pas les mêmes conventions entre les différents environnements (ex : les séparateurs entre dossiers dans un chemin ne sont pas les mêmes), mais pathlib vous permet d’interagir avec ces différents systèmes de manière harmonisée.\nMaintenant, listons tous les fichiers contenus dans notre répertoire courant. On utilise pour cela une seconde méthode glob qui va simplement renvoyer tous les fichiers dont le nom a une certaine structure. Par exemple, .glob('*.txt') va récupérer tous les fichiers dont l’extension est .txt et .glob('test.*') va récupérer tous les fichiers dont le nom est test, quelle que soit leur extension. Ici, on récupère tous les fichiers en utilisant des wildcards * aux deux positions.\nCette méthode renvoie un objet un peu spécial (un générateur). Si vous vous rappelez bien, on avait déjà rencontré le même cas avec la fonction range. Il suffit d’appeler la fonction list sur le tout pour afficher les résultats de manière lisible.\n\nPath.cwd().glob('*.*')\n\n&lt;generator object Path.glob at 0x7ff043911620&gt;\n\n\n\nlist(Path.cwd().glob('*.*'))\n\n[PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/write_list.py'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/tutorial.quarto_ipynb'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/notes.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/notes_clean.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/tutorial.qmd'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/gamme.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/normalisation.py')]\n\n\nOn retrouve notre notebook, un fichier qui contient les solutions des exercices du tutoriel, et un certain nombre de fichiers texte qui vont servir d’exemples dans la suite du tutoriel. Si l’on prend le notebook par exemple, on distingue bien :\n\nson nom de fichier : tutorial.ipynb\nson chemin : /home/onyxia/work/\n\nChemins absolus et chemins relatifs\nIl y a deux manières possibles de spécifier le chemin d’un fichier :\n\nde manière absolue, le chemin commence alors par la racine (/ en Unix, C:\\ en Windows, etc.). Les chemins renvoyés ci-dessus sont donc absolus.\nde manière relative, i.e. relativement au répertoire courant du programme Python. Dès lors qu’un chemin ne commence pas par la racine, pathlib va le considérer relatif.\n\nCette distinction va s’avérer assez importante par la suite, lorsqu’il sera question de lire et d’écrire des fichiers.\nFormer des chemins\nEn pratique, ce qui nous intéresse est de pouvoir constituer nos propres chemins – qu’ils soient absolus ou relatifs au répertoire courant – afin de spécifier où se trouvent les fichiers que nous souhaitons lire ou bien où doivent se trouver les fichiers que l’on souhaite écrire.\npathlib offre une syntaxe très intuitive pour constituer des chemins, très similaire à la concaténation des chaînes de caractères que nous avons déjà vue. Au lieu d’un +, on va cette fois utiliser un / pour concaténer les différentes parties d’un chemin.\nPar exemple, essayons de reconstruire le chemin complet de ce notebook. On peut commencer par trouver le chemin du home directory, qui est le dossier standard dans lequel se trouvent tous les fichiers de l’utilisateur.\n\nPath.home()\n\nPosixPath('/home/runner')\n\n\nOn peut alors concaténer les différents sous-dossier et le nom de fichier du notebook pour obtenir le chemin complet vers celui-ci.\n\npath_nb = Path.home() / 'work' / 'tutorial.ipynb'\npath_nb\n\nPosixPath('/home/runner/work/tutorial.ipynb')\n\n\nOn retrouve bien exactement le même chemin que celui obtenu en listant les fichiers présents dans le répertoire courant.\nPlus sur pathlib\nNous n’avons vu qu’un aperçu des outils qu’offre le module pathlib pour interagir avec le système de fichiers local. La documentation officielle présente de manière exhaustive ces possibilités. Nous présenterons dans ce tutoriel et dans les suivants d’autres méthodes issues de cette librairie, à mesure que l’occasion se présente. Pour l’heure, nous en savons suffisamment pour lire et écrire des fichiers sur le système de fichiers.\n\n\n\nEn programmation, on est généralement amenés à manipuler deux grandes familles de fichiers bien différentes :\n\nles fichiers texte. Ils ne contiennent que des caractères textuels standards – techniquement, qui respectent le standard Unicode – sans informations de formatting (police, couleur, etc.). Les fichiers .txt ou encore les scripts Python finissant en .py sont des exemples de fichiers texte. Ces fichiers peuvent être lus avec n’importe quel éditeur de texte.\nles fichiers binaires. Ce sont en fait tous les autres types de fichiers : fichiers compressés (.zip, tar.gz, etc.), documents PDFs, images, programmes, etc. Ouvrir un tel fichier avec un éditeur de texte produit généralement une grande suite de caractères incompréhensibles, car la représentation textuelle n’est pas adaptée à ces données.\n\nComme vous pouvez l’imaginer, ces deux types de fichier se traitent avec des outils différents. Par ailleurs, du fait de la diversité des fichiers binaires, chacun de ses fichiers nécessite un traitement particulier. Dans un contexte de programmation, on est cependant principalement à manipuler du code, qui est une donnée textuelle. On va donc s’intéresser uniquement à l’écriture et à la lecture de fichiers texte dans ce tutoriel, mais il est important de savoir reconnaître des données binaires lorsqu’on est amené à en traiter.\n\n\n\nDemander à Python d’ouvrir un fichier revient à ouvrir une connexion entre l’environnement Python sur lequel vous êtes et le fichier. Tant que cette connexion est ouverte, il est possible de manipuler le fichier.\nPour ouvrir un fichier, on utilise la fonction open. On va par exemple ouvrir le fichier gamme.txt qui a été mis dans le répertoire courant.\n\npath_gamme = Path.cwd() / 'gamme.txt'\nfile_in = open(path_gamme, 'r')\nfile_in\n\n&lt;_io.TextIOWrapper name='/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/gamme.txt' mode='r' encoding='UTF-8'&gt;\n\n\nLa fonction open renvoie un objet de type _io.TextIOWrapper, qui spécifie le mode d’encodage du fichier et le mode d’ouverture.\nL’encodage et le décodage sont des sujets techniques, que nous n’aborderons pas dans ce tutoriel. Retenons simplement que le mode d’encodage par défaut est l’UTF-8, et qu’il n’y a jamais vraiment de bonne raison de choisir un autre mode.\nEn revanche, le mode d’ouverture est très important. Il y a trois modes principaux :\n\nr : lecture seule. Le fichier ne peut qu’être lu, mais pas modifié. C’est le mode par défaut lorsqu’on ne spécifie aucun mode.\nw : écriture. Il est possible dans ce mode d’écrire sur un fichier. Attention : si un fichier avec le même nom existe déjà, il sera automatiquement écrasé.\na : appending. Ce mode ne permet que de rajouter des lignes à la fin d’un fichier existant.\n\nUne fois le fichier ouvert, on peut réaliser des opérations sur ce fichier à l’aide de méthodes attachées à l’objet qui le représente. On verra dans la section suivante ce que fait la méthode readlines.\n\nfile_in.readlines()\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nUne fois les manipulations terminées, on ferme la connexion avec la méthode close. Il n’est alors plus possible de manipuler le fichier.\n\nfile_in.close()\n\nEn pratique, on oublie facilement de fermer la connexion à un fichier, ce qui peut créer des erreurs pénibles. Il existe une syntaxe qui permet d’éviter ce problème en utilisant un context manager qui gère toute la connexion pour nous.\n\nwith open(path_gamme, 'r') as file_in:\n    lines = file_in.readlines()\n    \nlines\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nCette syntaxe est beaucoup plus lisible : grâce à l’indentation, on voit clairement les opérations qui sont effectuées tant que le fichier est ouvert, et ce dernier est automatiquement fermé dès lors que l’on revient au niveau initial d’indentation. On préférera toujours utiliser cette syntaxe si possible, c’est une bonne pratique de programmation.\n\n\n\nUne fois un fichier ouvert, on peut vouloir lire son contenu. Il existe différentes manières de faire. Une méthode simple et élégante est de parcourir le fichier à l’aide d’une boucle, ce qui est rendu possible par le fait que l’objet Python représentant le fichier est itérable.\n\nwith open(path_gamme, 'r') as file_in:\n    for line in file_in:\n        print(line)\n\ndo\n\nre\n\nmi\n\nfa\n\nsol\n\nla\n\nsi\n\n\nDans notre exemple, nous avons simplement affiché les lignes, mais on peut faire de nombreuses choses à partir des données présentes dans le fichier texte : les stocker dans un objet Python, les utiliser pour faire des calculs, ne conserver que les lignes qui répondent à une condition donnée via une instruction if, etc.\nIl existe également des méthodes toutes faites pour lire le contenu d’un fichier. La plus basique est la méthode read, qui retourne l’ensemble du fichier comme une (potentiellement très longue) chaîne de caractères.\n\nwith open(path_gamme, 'r') as file_in:\n    txt = file_in.read()\n    \ntxt\n\n'do\\nre\\nmi\\nfa\\nsol\\nla\\nsi'\n\n\nC’est rarement très utile : on préfère en général récupérer individuellement les lignes d’un fichier. La méthode readlines parcourt le fichier complet, et renvoie une liste dont les éléments sont les lignes du fichier, dans l’ordre d’apparition.\n\nwith open(path_gamme, 'r') as file_in:\n    l = file_in.readlines()\n    \nl\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nNotons que chaque élément de la liste (sauf le dernier) se termine par le caractère spécial \\n (“retour à la ligne”) qui marque simplement la fin de chaque ligne dans un fichier texte. C’est la présence (cachée) de ce même caractère à la fin de chaque appel à la fonction print qui fait que l’on revient à la ligne à chaque fois que l’on utilise un print.\n\n\n\nL’écriture dans un fichier est très simple, elle s’effectue à l’aide de la méthode write. Par exemple, écrivons dans un fichier ligne à ligne les différents éléments contenus dans une liste.\n\nex = [\"ceci\", \"est\", \"un\", \"exemple\", \"très\", \"original\"]\n\nwith open(\"test.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem)\n\nTout semble s’être passé sans encombre. On peut vérifier que notre fichier a bien été crée via l’explorateur de fichier de Jupyter (sur la gauche) ou bien via la commande ls dans le terminal.\n\n!ls\n\ngamme.txt     notes.txt    test.txt  tutorial.quarto_ipynb\nnormalisation.py  notes_clean.txt  tutorial.qmd  write_list.py\n\n\nIl est bien là. Vérifions maintenant que son contenu est bien celui que l’on souhaitait.\n\nwith open(\"test.txt\", \"r\") as file_out:\n    print(file_out.read())\n\nceciestunexempletrèsoriginal\n\n\nLes différents éléments de notre liste se sont fusionnés en un seul bloc de texte ! C’est parce que, contrairement à la fonction print par exemple, la fonction write n’ajoute pas automatiquement le caractère de retour à la ligne. Il faut l’ajouter manuellement.\n\nwith open(\"test.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem + \"\\n\")\n        \nwith open(\"test.txt\", \"r\") as file_out:\n    print(file_out.read())\n\nceci\nest\nun\nexemple\ntrès\noriginal\n\n\n\nC’est beaucoup mieux.\nQuelques remarques supplémentaires sur l’écriture de fichiers :\n\nmieux vaut le répéter : utiliser le mode d’ouverture \\w pour un fichier écrase complètement son contenu. Lorsqu’on a réécrit notre fichier avec les sauts de ligne, on a complètement écrasé l’ancien.\npourquoi a-t-on pu mettre juste le nom du fichier dans la fonction open et pas un objet Path comprenant le chemin complet vers le fichier que l’on souhaitait créer ? C’est parce que Python l’a automatiquement interprété comme un chemin relatif (à notre répertoire courant) du fait de l’absence de racine.\non ne peut écrire dans un fichier que des éléments de type str (chaîne de caractère). Si un des éléments de la liste ci-dessus avait été de type int ou float par exemple, il aurait fallu le convertir via la fonction str() avant de l’écrire dans le fichier. Sinon, Python aurait renvoyé une erreur.\n\n\n\n\n\nJusqu’à présent dans ce tutoriel, nous avons exploré l’utilisation de packages/modules, qu’ils proviennent de la bibliothèque standard de Python ou soient développés par des tiers. Nous avons également abordé l’interaction avec le système de fichiers local. À présent, découvrons comment combiner ces compétences en écrivant et exécutant nos propres scripts et modules Python sous forme de fichiers .py.\n\n\nDans un environnement de notebook Jupyter (comme celui dans lequel vous vous trouvez), le code Python est exécuté de manière interactive, cellule par cellule. Cela est possible car un kernel (noyau) Python tourne en arrière-plan pendant tout le long de la session d’utilisation du notebook. Cependant, en dehors de Jupyter, le code est généralement écrit et exécuté sous forme de scripts. Un script Python est simplement un fichier texte portant l’extension .py et qui contient une série d’instructions Python qui vont être exécutées linéairement par l’interpréteur Python.\nLe fichier write_list.py reprend une cellule de code vue précédemment. Affichons son contenu.\n\nwith open('write_list.py', 'r') as script:\n    print(script.read())\n\nex = [\"ceci\", \"est\", \"un\", \"exemple\", \"très\", \"original\"]\n\nwith open(\"output_script.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem)\n\nprint(\"Succès !\")\n\n\n\nUn script Python s’exécute dans un terminal via la commande python nom_du_script.py. Pour l’exécuter depuis un notebook Jupyter, on rajoute là encore un ! en début de ligne.\n\n!python write_list.py\n\nSuccès !\n\n\nLe fichier output_script.txt a bien été créé en local (il faut parfois attendre un peu ou actualiser pour qu’il s’affiche) et le message attendu a été imprimé dans la sortie de la console.\n\n\n\n\n\n\nNotebook vs. scripts\n\n\n\nFaut-il préférer l’utilisation de notebooks Jupyter, comme dans le cadre de cette formation, ou bien préférer l’exécution via des scripts ? Il n’y a pas de réponse définitive à cette question :\n\nles notebooks permettent une exécution interactive, très pratique pour l’expérimentation ;\nles scripts rendent plus facile l’automatisation d’une procédure, dans la mesure où ils sont exécutés linéairement et sans requérir d’actions intermédiaires de la part de l’utilisateur.\n\nEn somme, les notebooks sont très utiles durant la phase de développement, mais on préfèrera les script dès lors qu’il est question d’automatiser des traitements ou de produire du code visant à tourner en production.\n\n\n\n\n\nComme nous l’avons vu, un script est un fichier .py destiné à être exécuté directement. Il contient généralement un flux de travail complet ou une tâche automatisée. Un module est également un fichier .py, mais qui contient des définitions de fonctions et/ou de classes destinées à être utilisées par d’autres scripts ou modules. Il n’est pas destiné à être exécuté seul mais importé ailleurs. Au début de ce tutoriel, nous avons utilisé des modules issus de packages écrits par d’autres. Voyons maintenant comment l’on peut écrire nos propres modules et les importer selon les mêmes principes.\nAffichons le contenu du fichier normalisation.py qui nous servira d’exemple.\n\nwith open('normalisation.py', 'r') as module:\n    print(module.read())\n\nimport numpy as np\n\n\ndef normalise(x):\n    \"\"\"Normalise un vecteur de valeurs à une moyenne de 0 et un écart-type de 1.\"\"\"\n    return (x - np.mean(x)) / np.std(x)\n\n\nif __name__ == \"__main__\":\n    vec = [2, 4, 6, 8, 10]\n    vec_norm = normalise(vec)\n    print(np.mean(vec), np.var(vec), np.mean(vec_norm), np.var(vec_norm))\n\n\n\nLa fonction contenue dans ce module peut être importée comme nous l’avons vu dans ce tutoriel. Notons que le module doit lui même importer les packages/modules nécessaires au bon fonctionnement des fonctions qu’il contient (en l’occurence, numpy).\nPour importer un module local, on utilise l’instruction import suivie du nom du fichier, sans l’extension. Toutes les fonctions définies dans le module peuvent alors être utilisées via la syntaxe nom_du_module.nom_de_la_fonction.\n\nimport normalisation\n\nx = [1, 2, 3, 4, 5]\nx_norm = normalisation.normalise(x)\n\nprint(x_norm)\n\n[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n\n\nComme expliqué en début de chapitre, on pourrait également importer la fonction directement afin de ne pas avoir à rappeler le nom du module qui la contient. C’est notamment pratique si cette fonction est amenée à être utilisée plusieurs fois dans un même notebook/script.\n\nfrom normalisation import normalise\n\nx = [1, 2, 3, 4, 5]\nx_norm = normalise(x)\n\nprint(x_norm)\n\n[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n\n\n\n\n\n\n\n\nLa fausse bonne idée : import *\n\n\n\nUne bonne pratique essentielle est de favoriser la lisibilité de son code. Dans les deux variantes d’import présentées ci-dessus, le code est lisible : on voit bien de quel module provient la fonction utilisée.\nEn revance, il n’est pas rare de voir dans du code Python l’instruction from mon_module import *, qui permet d’importer toutes les fonctions définies dans le fichier mon_module.py. C’est à proscrire dans la mesure du possible pour deux raisons :\n\nil devient difficile de déterminer de quel module ou package proviennent les fonctions utilisées ;\nsi des fonctions importées à partir de différents packages/modules ont le même nom, elles peuvent se remplacer et générer des erreurs pénibles à débugger.\n\nAfin de limiter la longueur de la ligne d’instruction en cas d’import de multiples fonctions, on peut adopter la syntaxe suivante :\n\nfrom mon_module import (\n    fonction1,\n    fonction2,\n    fonction3\n)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[34], line 1\n----&gt; 1 from mon_module import (\n      2     fonction1,\n      3     fonction2,\n      4     fonction3\n      5 )\n\nModuleNotFoundError: No module named 'mon_module'\n\n\n\n\n\nEnfin, notons qu’un fichier .py peut à la fois servir comme module et comme script. Pour différencier les deux usages, on utilise la variable __name__, qui est définie par défaut par Python dès lors que l’on utilise un fichier .py :\n\nsi le fichier est utilisé comme un module (ex : import mon_fichier), la variable __name__ vaut le nom du fichier (ex : mon_fichier)\nsi le fichier est utilisé comme un script (ex : python mon_fichier.py), la variable __name__ vaut __main__\n\nDans la cellule précédente, le fichier normalisation.py était importé comme un module. Dans ce cas, la variable __name__ vaut normalisation et c’est pourquoi le code sous la condition if n’a pas été exécuté. Lorsque le fichier est exécuté comme script, ce code est exécuté.\n\n!python normalisation.py\n\n6.0 8.0 0.0 0.9999999999999998\n\n\nIl est dont très fréquent de croiser la condition if __name__ == \"__main__\" dans les scripts Python, qui distingue l’usage comme module et l’usage comme script.\n\n\n\n\n\n\n\n1/ Qu’est-ce qu’un module ?\n2/ Qu’est ce qu’un package ?\n3/ Pourquoi n’est-ce pas une bonne pratique d’importer toutes les fonctions d’un module avec la syntaxe from module import *\n4/ Quels sont les avantages de la librairie pathlib ?\n5/ Quelles sont les deux propriétés d’un fichier qui permettent de repérer sa position dans le système de fichiers ?\n6/ Qu’est-ce que le répertoire courant ?\n7/ Quelles sont les deux manières de spécifier un chemin ? Comment Python fait-il la différence entre les deux ?\n8/ Quels sont les deux grandes familles de fichiers que l’on est amenés à manipuler en programmation ?\n9/ Quels sont les différents modes d’ouverture d’un fichier ?\n10/ Pourquoi est-il préférable d’utiliser la syntaxe with open(...) as ... pour ouvrir un fichier ?\n11/ Pourquoi peut-on parcourir les lignes d’un fichier à l’aide d’une boucle ?\n12/ Quelle est la différence entre un module et un script ?\n\n\n\n\nAfficher la solution\n\n\n1/ un module est un fichier texte (portant l’extension .py pour bien marquer le lien à Python) contenant un ensemble de définitions (de classes, de fonctions) et d’instructions\n2/ Un package est une collection de modules.\n3/ Cela surcharge la mémoire si l’on a besoin que de quelques fonctions, et cela réduit la lisibilité puisqu’on ne sait pas directement de quel module provient quelle fonction.\n4/ Elle permet d’interagir avec le système de fichiers avec une syntaxe de POO unifiée, quel que soit l’environnement sur lequel on travaille.\n5/ Nom de fichier et chemin du dossier qui contient le fichier.\n6/ C’est le répertoire dans lequel la session Python courante est ouverte. Dans le cadre d’un notebook Jupyter, c’est par défaut le dossier qui le contient.\n7/ Chemin absolu (complet) et chemin relatif (relatif au répertoire courant). Un chemin absolu se reconnaît car il part toujours de la racine du système de fichiers.\n8/ Fichiers textes et fichiers binaires (tout ce qui n’est pas du texte).\n9/ r : lecture. w : écriture. a : appending\n10/ Cette syntaxe fait intervenir un context manager, qui gère la connexion au fichier (ouverture et fermeture) pour nous.\n11/ Car l’objet représentant le fichier en Python est un itérable.\n12/ Comme nous l’avons vu, un script est un fichier .py destiné à être exécuté directement. Il contient généralement un flux de travail complet ou une tâche automatisée. Un module est également un fichier .py, mais qui contient des définitions de fonctions et/ou de classes destinées à être utilisées par d’autres scripts ou modules. Il n’est pas destiné à être exécuté seul mais importé ailleurs.\n\n\n\n\n\n\nExercice inspiré de : python.sdv.univ-paris-diderot.fr\nLe fichier texte notes.txt se trouve dans votre répertoire courant. Il contient les notes obtenues par 50 élèves à un examen. Problème : toutes les notes ont été écrites sur une même ligne, avec un espace à chaque fois. Ouvrez ce fichier et calculez la moyenne et l’écart-type des notes.\nIndices :\n\nles chaînes de caractère ont une méthode split qui permet de séparer du texte selon un caractère donné\nil faudra convertir les notes au format numérique pour pouvoir leur appliquer des fonctions mathématiques\nvous pouvez utiliser les fonctions du package numpy pour calculer les statistiques demandées\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nimport numpy as np\n\nwith open(\"notes.txt\", \"r\") as file_in:\n    notes = file_in.read()\n\nnotes = notes.split()\nnotes_num = []\nfor n in notes:\n    notes_num.append(int(n))\n\nprint(np.mean(notes_num))\nprint(np.std(notes_num))\n\n\n\n\n\nExercice inspiré de : python.sdv.univ-paris-diderot.fr\nLe fichier texte notes_clean.txt se trouve dans votre répertoire courant. Il contient les notes obtenues par 50 élèves à un examen. Contrairement à l’exercice précédent, les notes sont cette fois bien écrites : une note par ligne.\nÉcrire un code qui :\n\nstocke chaque note au format int dans une liste\nréécrit les notes dans un fichier notes_mentions.txt avec sur chaque ligne la note, suivie d’un espace, suivi de la mention “admis” si la note est supérieure ou égale à 10, et “recalé” sinon.\n\nPar exemple, les trois premières lignes de ce nouveau fichier devraient être :\n5 recalé\n5 recalé\n18 admis\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nnotes = []\n\nwith open(\"notes_clean.txt\", \"r\") as file_in:\n    for n in file_in:\n        notes.append(int(n))\n        \nwith open(\"notes_mentions.txt\", \"w\") as file_out:\n    for n in notes:\n        if n &gt;= 10:\n            mention = \"admis\"\n        else:\n            mention = \"recalé\"\n        file_out.write(str(n) + \" \" + mention + \"\\n\")\n\n\n\n\n\n3 élèves n’avaient pas rendu leur copie dans les temps pour l’examen :\n\nMiranda a obtenu 16 et a rendu son devoir avec 3 jours de retard\nPaolo a obtenu 11 et a rendu son devoir avec 1 jour de retard\nIsidore a obtenu 3 et a rendu son devoir avec 5 jours de retard.\n\nChaque élève aura une note finale égale à la note obtenue moins le nombre de jours de retard. Une note ne pouvant être négative, elle sera remplacée par 0.\nLes informations nécessaires ont été placées dans une liste dans la cellule suivante. A l’aide d’une boucle sur cette liste, ajouter (sans réécrire complètement le fichier !). les notes au fichier notes_clean.txt (sans la mention).\nNB : si vous avez écrasé le contenu d’un fichier par erreur, vous pouvez retrouver les fichiers propres sur le dépôt GitHub associé à la formation.\n\nsupp = [(16, 3), (11, 1), (3, 5)]\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nsupp = [(16, 3), (11, 1), (3, 5)]\n\nwith open(\"notes_clean.txt\", \"a\") as file_out:\n    for elem in supp:\n        note_finale = elem[0] - elem[1]\n        note_finale = max(0, note_finale)\n        file_out.write(str(note_finale) + \"\\n\")\n\n\n\n\n\nÉcrire un programme qui réalise les opérations suivantes :\n\ndans le répertoire courant, lister les chemins des fichiers dont l’extension est .txt (la syntaxe a été vue dans la partie sur pathlib)\nfaire une boucle qui parcourt ces chemins et ouvre chaque fichier séquentiellement\npour chaque fichier, faire un test d’appartenance (rappel de la syntaxe : if pattern in string: ...) pour tester si le fichier contient le mot “sol”. Si c’est le cas, imprimer son chemin absolu dans la console (seul le chemin du fichier gamme.txt devrait donc apparaître)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nfrom pathlib import Path\n\ntxt_files_paths = list(Path.cwd().glob('*.txt'))\n\nfor path in txt_files_paths:\n    with open(path, \"r\") as file_in:\n        content = file_in.read()\n        if \"sol\" in content:\n            print(path)",
    "crumbs": [
      "Manipulation de données",
      "Manipulation de fichiers"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#quelques-notions-sur-les-modules-et-les-packages",
    "href": "source/manipulation/modules-files/tutorial.html#quelques-notions-sur-les-modules-et-les-packages",
    "title": "Manipulation de fichiers",
    "section": "",
    "text": "Avant de parler de manipulation de fichiers, nous devons faire un bref détour par le monde des modules et des packages (librairies).\nJusqu’à maintenant, nous avons essentiellement utilisé des objets et des instructions standards de Python, qui ne nécessitaient donc pas d’import tiers. Dans ce tutoriel et tous ceux qui vont suivre, nous allons réaliser des opérations plus complexes (interagir avec un système de fichiers, faire du calcul vectoriel, manipuler des données tabulaires, etc.) qu’il serait très coûteux, inefficient, et avec un potentiel d’erreur énorme, de coder à la main en utilisant les objets de base de Python.\nC’est pourquoi nous allons utiliser des packages, sortes de boîtes à outils remplies de fonctions et de classes développées par d’autres (souvent, de manière communautaire) et qui permettent de réaliser des opérations complexes à moindre coût.\n\n\nCommençons par quelques brefs éléments de terminologie pour bien se repérer dans l’écosystème Python :\n\nun module est un fichier texte (portant l’extension .py pour bien marquer le lien à Python) contenant un ensemble de définitions (de classes, de fonctions) et d’instructions, que l’on peut importer dans un environnement Python afin de les utiliser.\nun package est un ensemble de modules réunis dans un même répertoire\n\nPar exemple, nous allons voir en détails dans la prochaine partie l’utilisation de numpy. numpy est un package qui permet de faire du calcul scientifique sur des objets multidimensionnels. Pour ce faire, numpy met à disposition un nombre gigantesque de fonctions et d’outils. Toutes les mettre dans un seul et même module serait franchement illisible. Ainsi, numpy est structuré en différents modules qui groupent les fonctions réalisant des opérations similaires : les fonctions générant de l’aléatoire dans le module random, celles réalisant de l’algèbre linéaire dans le module linalg, etc.\n\n\n\nPour pouvoir exploiter les fonctions d’un module et les différents modules qui constituent un package, il nous faut en premier lieu les importer.\nLa syntaxe est très simple, illustrons là à travers un exemple.\n\nimport random\nrandom.randint(0, 100)\n\n48\n\n\nNous avons importé le module random (complet) de la librairie standard de Python via l’instruction import. Ensuite, nous avons fait appel à la fonction randint contenue dans le module random, qui renvoie un nombre aléatoire entre a et b ses paramètres.\nOn aurait pu également importer seulement la fonction randint en utilisant la syntaxe from module import fonction. Il n’est alors plus nécessaire de spécifier le nom du module lorsqu’on appelle la fonction.\n\nfrom random import randint\nrandint(0, 100)\n\n34\n\n\nNotons qu’une fois qu’un import est effectué, le module importé est disponible pour toute la durée de la session Python. Il n’y a donc pas besoin d’importer le module avant chaque utilisation d’une de ses fonctions, une fois au début de son notebook ou script suffit.\n\n\n\n\n\n\nTrop d’imports tue l’import\n\n\n\nIl arrive parfois de voir la syntaxe from module import * (* s’appelle le wildcard) qui a pour effet d’importer en mémoire toutes les fonctions du module. Si cela permet de gagner du temps, ce n’est pourtant pas une bonne pratique :\n\nd’une part, cela charge plus de code en mémoire qu’il n’est nécessaire pour notre application ;\nd’autre part, cela limite la lisibilité du code dans la mesure où l’on ne voit pas explicitement d’où ont été importées les fonctions qui sont utilisées dans le code.\n\n\n\n\n\n\nUn package est simplement une collection de modules, structurée selon une arborescence. La syntaxe pour importer un package est identique à celle pour importer un module.\nPar exemple, regardons à nouveau comment utiliser la fonction randint, mais cette fois celle du package numpy (qui fait la même chose).\n\nimport numpy\n\n\nnumpy.random.randint(0, 100)\n\n8\n\n\nOn a importé le package numpy, qui nous a permis d’accéder via son module random à la fonction randint. Là encore, on aurait pu importer directement la fonction.\n\nfrom numpy.random import randint\n\n\nrandint(0, 100)\n\n89\n\n\nEn pratique, la première syntaxe est préférable : il est toujours plus lisible de montrer explicitement d’où vient la fonction que l’on appelle. Pour réduire la verbosité, il est fréquent de donner un alias aux packages que l’on importe. Voici les trois plus fréquents, que l’on rencontrera très souvent dans les tutoriels du prochain chapitre sur la manipulation de données.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nOn peut alors utiliser ces alias pour appeler des modules et des fonctions.\n\nx = np.linspace(0, 10, 1000)\nplt.plot(x, np.sin(x))\n\n\n\n\n\n\n\n\n\n\n\nJusqu’à maintenant, nous avons pu importer sans problème les différents packages via l’instruction import. Mais comment ont-ils été installés ? Il faut distinguer deux cas de figure :\n\nun certain nombre de packages font partie de la bibilothèque standard, ce qui signifie qu’ils sont installés en même temps que Python. C’est par exemple le cas du package random utilisé plus haut, mais il en existe beaucoup d’autres ;\nles autres packages “tiers” sont développés par la communauté des utilisateurs de Python, et doivent être installés pour pouvoir être utilisés. C’est notamment le cas de numpy et pandas. Dans notre cas, nous n’avons pas eu à les installer car l’environnement fourni pour la formation contient déjà l’ensemble des packages nécessaires pour exécuter les différents chapitres.\n\nIllustrons l’installation de package à travers le package emoji, qui permet de représenter des émoticônes dans les sorties de Python. Pour le coup, celui-ci n’est pas encore installé ; essayer de l’importer produit une ModuleNotFoundError.\n\nimport emoji\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[9], line 1\n----&gt; 1 import emoji\n\nModuleNotFoundError: No module named 'emoji'\n\n\n\nPour installer un package, la commande est simple : pip install nom_du_package. Sans rentrer dans les détails, pip est un gestionnaire de packages, installé avec Python, qui s’utilise en ligne de commande (i.e. dans un terminal). Pour pouvoir envoyer une commande au terminal depuis un notebook Jupyter, on rajoute un ! devant la commande.\n\n!pip install emoji\n\nCollecting emoji\n  Downloading emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: typing-extensions&gt;=4.7.0 in /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages (from emoji) (4.12.2)\nDownloading emoji-2.12.1-py3-none-any.whl (431 kB)\nInstalling collected packages: emoji\nSuccessfully installed emoji-2.12.1\n\n\nIl est à présent possible d’importer le package et d’utiliser ses fonctions.\n\nimport emoji\n\nprint(emoji.emojize('Python est :thumbs_up:'))\n\nPython est 👍\n\n\n\n\n\n\n\n\npip et PyPI\n\n\n\npip est le gestionnaire de paquets standard pour Python. Il permet d’installer, de mettre à jour et de supprimer des packages Python trouvés dans le Python Package Index (PyPI), un répertoire de packages pour la programmation en Python. Ce répertoire contient un nombre gigantesque de projets (environ 500,000 à l’heure de l’écriture de ce tutoriel), des plus amateurs aux plus essentiels.\nDe manière générale, il est toujours préférable, avant de se lancer dans l’écriture d’une application “à la main”, de vérifier qu’un package faisant la même chose ou presque n’existe pas déjà. Une simple recherche google - de préférence en Anglais - contenant les mots-clés de ce que l’on cherche à faire permet souvent de s’en assurer.",
    "crumbs": [
      "Manipulation de données",
      "Manipulation de fichiers"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#manipulation-de-fichiers-1",
    "href": "source/manipulation/modules-files/tutorial.html#manipulation-de-fichiers-1",
    "title": "Manipulation de fichiers",
    "section": "",
    "text": "Pour pouvoir lire et écrire des fichiers avec Python, il nous faut d’abord comprendre comment ceux-ci sont représentés sur le système de fichiers (file system) local, et comment Python interagit avec ce dernier.\nLe module pathlib\nPour ce faire, nous allons utiliser de manière répétée le module pathlib et en particulier la classe Path. Ce module permet d’interagir avec le système de fichiers sous forme d’objets, en manipulant des attributs et leurs méthodes. Pas de panique, nous avons vu tout ce qu’il nous fallait savoir à ce propos dans le précédent tutoriel.\n\nfrom pathlib import Path\n\nPropriétés d’un fichier\nUn fichier a deux propriétés :\n\nun nom de fichier\nun chemin (path), qui spécifie sa localisation dans le système de fichiers.\n\nA titre d’exemple, regardons les fichiers qui se trouvent dans notre répertoire courant (par défaut, le dossier dans lequel se trouve ce notebook). La méthode à utiliser s’appelle cwd, pour current working directory.\n\nPath.cwd()\n\nPosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files')\n\n\nLe chemin de notre répertoire courant est contenu dans un objet PosixPath, ce qui signifie simplement que pathlib a compris que nous étions sur un environnement de type Unix (les serveurs du SSP Cloud sont sous Linux). Si vous exécutiez ce notebook en local sur un ordinateur Windows, l’objet serait WindowsPath. Concrètement, cela ne change pas grand chose pour vous mais c’est en fait assez important : les systèmes de fichiers n’utilisent pas les mêmes conventions entre les différents environnements (ex : les séparateurs entre dossiers dans un chemin ne sont pas les mêmes), mais pathlib vous permet d’interagir avec ces différents systèmes de manière harmonisée.\nMaintenant, listons tous les fichiers contenus dans notre répertoire courant. On utilise pour cela une seconde méthode glob qui va simplement renvoyer tous les fichiers dont le nom a une certaine structure. Par exemple, .glob('*.txt') va récupérer tous les fichiers dont l’extension est .txt et .glob('test.*') va récupérer tous les fichiers dont le nom est test, quelle que soit leur extension. Ici, on récupère tous les fichiers en utilisant des wildcards * aux deux positions.\nCette méthode renvoie un objet un peu spécial (un générateur). Si vous vous rappelez bien, on avait déjà rencontré le même cas avec la fonction range. Il suffit d’appeler la fonction list sur le tout pour afficher les résultats de manière lisible.\n\nPath.cwd().glob('*.*')\n\n&lt;generator object Path.glob at 0x7ff043911620&gt;\n\n\n\nlist(Path.cwd().glob('*.*'))\n\n[PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/write_list.py'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/tutorial.quarto_ipynb'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/notes.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/notes_clean.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/tutorial.qmd'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/gamme.txt'),\n PosixPath('/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/normalisation.py')]\n\n\nOn retrouve notre notebook, un fichier qui contient les solutions des exercices du tutoriel, et un certain nombre de fichiers texte qui vont servir d’exemples dans la suite du tutoriel. Si l’on prend le notebook par exemple, on distingue bien :\n\nson nom de fichier : tutorial.ipynb\nson chemin : /home/onyxia/work/\n\nChemins absolus et chemins relatifs\nIl y a deux manières possibles de spécifier le chemin d’un fichier :\n\nde manière absolue, le chemin commence alors par la racine (/ en Unix, C:\\ en Windows, etc.). Les chemins renvoyés ci-dessus sont donc absolus.\nde manière relative, i.e. relativement au répertoire courant du programme Python. Dès lors qu’un chemin ne commence pas par la racine, pathlib va le considérer relatif.\n\nCette distinction va s’avérer assez importante par la suite, lorsqu’il sera question de lire et d’écrire des fichiers.\nFormer des chemins\nEn pratique, ce qui nous intéresse est de pouvoir constituer nos propres chemins – qu’ils soient absolus ou relatifs au répertoire courant – afin de spécifier où se trouvent les fichiers que nous souhaitons lire ou bien où doivent se trouver les fichiers que l’on souhaite écrire.\npathlib offre une syntaxe très intuitive pour constituer des chemins, très similaire à la concaténation des chaînes de caractères que nous avons déjà vue. Au lieu d’un +, on va cette fois utiliser un / pour concaténer les différentes parties d’un chemin.\nPar exemple, essayons de reconstruire le chemin complet de ce notebook. On peut commencer par trouver le chemin du home directory, qui est le dossier standard dans lequel se trouvent tous les fichiers de l’utilisateur.\n\nPath.home()\n\nPosixPath('/home/runner')\n\n\nOn peut alors concaténer les différents sous-dossier et le nom de fichier du notebook pour obtenir le chemin complet vers celui-ci.\n\npath_nb = Path.home() / 'work' / 'tutorial.ipynb'\npath_nb\n\nPosixPath('/home/runner/work/tutorial.ipynb')\n\n\nOn retrouve bien exactement le même chemin que celui obtenu en listant les fichiers présents dans le répertoire courant.\nPlus sur pathlib\nNous n’avons vu qu’un aperçu des outils qu’offre le module pathlib pour interagir avec le système de fichiers local. La documentation officielle présente de manière exhaustive ces possibilités. Nous présenterons dans ce tutoriel et dans les suivants d’autres méthodes issues de cette librairie, à mesure que l’occasion se présente. Pour l’heure, nous en savons suffisamment pour lire et écrire des fichiers sur le système de fichiers.\n\n\n\nEn programmation, on est généralement amenés à manipuler deux grandes familles de fichiers bien différentes :\n\nles fichiers texte. Ils ne contiennent que des caractères textuels standards – techniquement, qui respectent le standard Unicode – sans informations de formatting (police, couleur, etc.). Les fichiers .txt ou encore les scripts Python finissant en .py sont des exemples de fichiers texte. Ces fichiers peuvent être lus avec n’importe quel éditeur de texte.\nles fichiers binaires. Ce sont en fait tous les autres types de fichiers : fichiers compressés (.zip, tar.gz, etc.), documents PDFs, images, programmes, etc. Ouvrir un tel fichier avec un éditeur de texte produit généralement une grande suite de caractères incompréhensibles, car la représentation textuelle n’est pas adaptée à ces données.\n\nComme vous pouvez l’imaginer, ces deux types de fichier se traitent avec des outils différents. Par ailleurs, du fait de la diversité des fichiers binaires, chacun de ses fichiers nécessite un traitement particulier. Dans un contexte de programmation, on est cependant principalement à manipuler du code, qui est une donnée textuelle. On va donc s’intéresser uniquement à l’écriture et à la lecture de fichiers texte dans ce tutoriel, mais il est important de savoir reconnaître des données binaires lorsqu’on est amené à en traiter.\n\n\n\nDemander à Python d’ouvrir un fichier revient à ouvrir une connexion entre l’environnement Python sur lequel vous êtes et le fichier. Tant que cette connexion est ouverte, il est possible de manipuler le fichier.\nPour ouvrir un fichier, on utilise la fonction open. On va par exemple ouvrir le fichier gamme.txt qui a été mis dans le répertoire courant.\n\npath_gamme = Path.cwd() / 'gamme.txt'\nfile_in = open(path_gamme, 'r')\nfile_in\n\n&lt;_io.TextIOWrapper name='/home/runner/work/formation-python-initiation/formation-python-initiation/source/manipulation/modules-files/gamme.txt' mode='r' encoding='UTF-8'&gt;\n\n\nLa fonction open renvoie un objet de type _io.TextIOWrapper, qui spécifie le mode d’encodage du fichier et le mode d’ouverture.\nL’encodage et le décodage sont des sujets techniques, que nous n’aborderons pas dans ce tutoriel. Retenons simplement que le mode d’encodage par défaut est l’UTF-8, et qu’il n’y a jamais vraiment de bonne raison de choisir un autre mode.\nEn revanche, le mode d’ouverture est très important. Il y a trois modes principaux :\n\nr : lecture seule. Le fichier ne peut qu’être lu, mais pas modifié. C’est le mode par défaut lorsqu’on ne spécifie aucun mode.\nw : écriture. Il est possible dans ce mode d’écrire sur un fichier. Attention : si un fichier avec le même nom existe déjà, il sera automatiquement écrasé.\na : appending. Ce mode ne permet que de rajouter des lignes à la fin d’un fichier existant.\n\nUne fois le fichier ouvert, on peut réaliser des opérations sur ce fichier à l’aide de méthodes attachées à l’objet qui le représente. On verra dans la section suivante ce que fait la méthode readlines.\n\nfile_in.readlines()\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nUne fois les manipulations terminées, on ferme la connexion avec la méthode close. Il n’est alors plus possible de manipuler le fichier.\n\nfile_in.close()\n\nEn pratique, on oublie facilement de fermer la connexion à un fichier, ce qui peut créer des erreurs pénibles. Il existe une syntaxe qui permet d’éviter ce problème en utilisant un context manager qui gère toute la connexion pour nous.\n\nwith open(path_gamme, 'r') as file_in:\n    lines = file_in.readlines()\n    \nlines\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nCette syntaxe est beaucoup plus lisible : grâce à l’indentation, on voit clairement les opérations qui sont effectuées tant que le fichier est ouvert, et ce dernier est automatiquement fermé dès lors que l’on revient au niveau initial d’indentation. On préférera toujours utiliser cette syntaxe si possible, c’est une bonne pratique de programmation.\n\n\n\nUne fois un fichier ouvert, on peut vouloir lire son contenu. Il existe différentes manières de faire. Une méthode simple et élégante est de parcourir le fichier à l’aide d’une boucle, ce qui est rendu possible par le fait que l’objet Python représentant le fichier est itérable.\n\nwith open(path_gamme, 'r') as file_in:\n    for line in file_in:\n        print(line)\n\ndo\n\nre\n\nmi\n\nfa\n\nsol\n\nla\n\nsi\n\n\nDans notre exemple, nous avons simplement affiché les lignes, mais on peut faire de nombreuses choses à partir des données présentes dans le fichier texte : les stocker dans un objet Python, les utiliser pour faire des calculs, ne conserver que les lignes qui répondent à une condition donnée via une instruction if, etc.\nIl existe également des méthodes toutes faites pour lire le contenu d’un fichier. La plus basique est la méthode read, qui retourne l’ensemble du fichier comme une (potentiellement très longue) chaîne de caractères.\n\nwith open(path_gamme, 'r') as file_in:\n    txt = file_in.read()\n    \ntxt\n\n'do\\nre\\nmi\\nfa\\nsol\\nla\\nsi'\n\n\nC’est rarement très utile : on préfère en général récupérer individuellement les lignes d’un fichier. La méthode readlines parcourt le fichier complet, et renvoie une liste dont les éléments sont les lignes du fichier, dans l’ordre d’apparition.\n\nwith open(path_gamme, 'r') as file_in:\n    l = file_in.readlines()\n    \nl\n\n['do\\n', 're\\n', 'mi\\n', 'fa\\n', 'sol\\n', 'la\\n', 'si']\n\n\nNotons que chaque élément de la liste (sauf le dernier) se termine par le caractère spécial \\n (“retour à la ligne”) qui marque simplement la fin de chaque ligne dans un fichier texte. C’est la présence (cachée) de ce même caractère à la fin de chaque appel à la fonction print qui fait que l’on revient à la ligne à chaque fois que l’on utilise un print.\n\n\n\nL’écriture dans un fichier est très simple, elle s’effectue à l’aide de la méthode write. Par exemple, écrivons dans un fichier ligne à ligne les différents éléments contenus dans une liste.\n\nex = [\"ceci\", \"est\", \"un\", \"exemple\", \"très\", \"original\"]\n\nwith open(\"test.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem)\n\nTout semble s’être passé sans encombre. On peut vérifier que notre fichier a bien été crée via l’explorateur de fichier de Jupyter (sur la gauche) ou bien via la commande ls dans le terminal.\n\n!ls\n\ngamme.txt     notes.txt    test.txt  tutorial.quarto_ipynb\nnormalisation.py  notes_clean.txt  tutorial.qmd  write_list.py\n\n\nIl est bien là. Vérifions maintenant que son contenu est bien celui que l’on souhaitait.\n\nwith open(\"test.txt\", \"r\") as file_out:\n    print(file_out.read())\n\nceciestunexempletrèsoriginal\n\n\nLes différents éléments de notre liste se sont fusionnés en un seul bloc de texte ! C’est parce que, contrairement à la fonction print par exemple, la fonction write n’ajoute pas automatiquement le caractère de retour à la ligne. Il faut l’ajouter manuellement.\n\nwith open(\"test.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem + \"\\n\")\n        \nwith open(\"test.txt\", \"r\") as file_out:\n    print(file_out.read())\n\nceci\nest\nun\nexemple\ntrès\noriginal\n\n\n\nC’est beaucoup mieux.\nQuelques remarques supplémentaires sur l’écriture de fichiers :\n\nmieux vaut le répéter : utiliser le mode d’ouverture \\w pour un fichier écrase complètement son contenu. Lorsqu’on a réécrit notre fichier avec les sauts de ligne, on a complètement écrasé l’ancien.\npourquoi a-t-on pu mettre juste le nom du fichier dans la fonction open et pas un objet Path comprenant le chemin complet vers le fichier que l’on souhaitait créer ? C’est parce que Python l’a automatiquement interprété comme un chemin relatif (à notre répertoire courant) du fait de l’absence de racine.\non ne peut écrire dans un fichier que des éléments de type str (chaîne de caractère). Si un des éléments de la liste ci-dessus avait été de type int ou float par exemple, il aurait fallu le convertir via la fonction str() avant de l’écrire dans le fichier. Sinon, Python aurait renvoyé une erreur.",
    "crumbs": [
      "Manipulation de données",
      "Manipulation de fichiers"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#exécuter-du-code-depuis-des-fichiers-.py",
    "href": "source/manipulation/modules-files/tutorial.html#exécuter-du-code-depuis-des-fichiers-.py",
    "title": "Manipulation de fichiers",
    "section": "",
    "text": "Jusqu’à présent dans ce tutoriel, nous avons exploré l’utilisation de packages/modules, qu’ils proviennent de la bibliothèque standard de Python ou soient développés par des tiers. Nous avons également abordé l’interaction avec le système de fichiers local. À présent, découvrons comment combiner ces compétences en écrivant et exécutant nos propres scripts et modules Python sous forme de fichiers .py.\n\n\nDans un environnement de notebook Jupyter (comme celui dans lequel vous vous trouvez), le code Python est exécuté de manière interactive, cellule par cellule. Cela est possible car un kernel (noyau) Python tourne en arrière-plan pendant tout le long de la session d’utilisation du notebook. Cependant, en dehors de Jupyter, le code est généralement écrit et exécuté sous forme de scripts. Un script Python est simplement un fichier texte portant l’extension .py et qui contient une série d’instructions Python qui vont être exécutées linéairement par l’interpréteur Python.\nLe fichier write_list.py reprend une cellule de code vue précédemment. Affichons son contenu.\n\nwith open('write_list.py', 'r') as script:\n    print(script.read())\n\nex = [\"ceci\", \"est\", \"un\", \"exemple\", \"très\", \"original\"]\n\nwith open(\"output_script.txt\", \"w\") as file_out:\n    for elem in ex:\n        file_out.write(elem)\n\nprint(\"Succès !\")\n\n\n\nUn script Python s’exécute dans un terminal via la commande python nom_du_script.py. Pour l’exécuter depuis un notebook Jupyter, on rajoute là encore un ! en début de ligne.\n\n!python write_list.py\n\nSuccès !\n\n\nLe fichier output_script.txt a bien été créé en local (il faut parfois attendre un peu ou actualiser pour qu’il s’affiche) et le message attendu a été imprimé dans la sortie de la console.\n\n\n\n\n\n\nNotebook vs. scripts\n\n\n\nFaut-il préférer l’utilisation de notebooks Jupyter, comme dans le cadre de cette formation, ou bien préférer l’exécution via des scripts ? Il n’y a pas de réponse définitive à cette question :\n\nles notebooks permettent une exécution interactive, très pratique pour l’expérimentation ;\nles scripts rendent plus facile l’automatisation d’une procédure, dans la mesure où ils sont exécutés linéairement et sans requérir d’actions intermédiaires de la part de l’utilisateur.\n\nEn somme, les notebooks sont très utiles durant la phase de développement, mais on préfèrera les script dès lors qu’il est question d’automatiser des traitements ou de produire du code visant à tourner en production.\n\n\n\n\n\nComme nous l’avons vu, un script est un fichier .py destiné à être exécuté directement. Il contient généralement un flux de travail complet ou une tâche automatisée. Un module est également un fichier .py, mais qui contient des définitions de fonctions et/ou de classes destinées à être utilisées par d’autres scripts ou modules. Il n’est pas destiné à être exécuté seul mais importé ailleurs. Au début de ce tutoriel, nous avons utilisé des modules issus de packages écrits par d’autres. Voyons maintenant comment l’on peut écrire nos propres modules et les importer selon les mêmes principes.\nAffichons le contenu du fichier normalisation.py qui nous servira d’exemple.\n\nwith open('normalisation.py', 'r') as module:\n    print(module.read())\n\nimport numpy as np\n\n\ndef normalise(x):\n    \"\"\"Normalise un vecteur de valeurs à une moyenne de 0 et un écart-type de 1.\"\"\"\n    return (x - np.mean(x)) / np.std(x)\n\n\nif __name__ == \"__main__\":\n    vec = [2, 4, 6, 8, 10]\n    vec_norm = normalise(vec)\n    print(np.mean(vec), np.var(vec), np.mean(vec_norm), np.var(vec_norm))\n\n\n\nLa fonction contenue dans ce module peut être importée comme nous l’avons vu dans ce tutoriel. Notons que le module doit lui même importer les packages/modules nécessaires au bon fonctionnement des fonctions qu’il contient (en l’occurence, numpy).\nPour importer un module local, on utilise l’instruction import suivie du nom du fichier, sans l’extension. Toutes les fonctions définies dans le module peuvent alors être utilisées via la syntaxe nom_du_module.nom_de_la_fonction.\n\nimport normalisation\n\nx = [1, 2, 3, 4, 5]\nx_norm = normalisation.normalise(x)\n\nprint(x_norm)\n\n[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n\n\nComme expliqué en début de chapitre, on pourrait également importer la fonction directement afin de ne pas avoir à rappeler le nom du module qui la contient. C’est notamment pratique si cette fonction est amenée à être utilisée plusieurs fois dans un même notebook/script.\n\nfrom normalisation import normalise\n\nx = [1, 2, 3, 4, 5]\nx_norm = normalise(x)\n\nprint(x_norm)\n\n[-1.41421356 -0.70710678  0.          0.70710678  1.41421356]\n\n\n\n\n\n\n\n\nLa fausse bonne idée : import *\n\n\n\nUne bonne pratique essentielle est de favoriser la lisibilité de son code. Dans les deux variantes d’import présentées ci-dessus, le code est lisible : on voit bien de quel module provient la fonction utilisée.\nEn revance, il n’est pas rare de voir dans du code Python l’instruction from mon_module import *, qui permet d’importer toutes les fonctions définies dans le fichier mon_module.py. C’est à proscrire dans la mesure du possible pour deux raisons :\n\nil devient difficile de déterminer de quel module ou package proviennent les fonctions utilisées ;\nsi des fonctions importées à partir de différents packages/modules ont le même nom, elles peuvent se remplacer et générer des erreurs pénibles à débugger.\n\nAfin de limiter la longueur de la ligne d’instruction en cas d’import de multiples fonctions, on peut adopter la syntaxe suivante :\n\nfrom mon_module import (\n    fonction1,\n    fonction2,\n    fonction3\n)\n\n\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[34], line 1\n----&gt; 1 from mon_module import (\n      2     fonction1,\n      3     fonction2,\n      4     fonction3\n      5 )\n\nModuleNotFoundError: No module named 'mon_module'\n\n\n\n\n\nEnfin, notons qu’un fichier .py peut à la fois servir comme module et comme script. Pour différencier les deux usages, on utilise la variable __name__, qui est définie par défaut par Python dès lors que l’on utilise un fichier .py :\n\nsi le fichier est utilisé comme un module (ex : import mon_fichier), la variable __name__ vaut le nom du fichier (ex : mon_fichier)\nsi le fichier est utilisé comme un script (ex : python mon_fichier.py), la variable __name__ vaut __main__\n\nDans la cellule précédente, le fichier normalisation.py était importé comme un module. Dans ce cas, la variable __name__ vaut normalisation et c’est pourquoi le code sous la condition if n’a pas été exécuté. Lorsque le fichier est exécuté comme script, ce code est exécuté.\n\n!python normalisation.py\n\n6.0 8.0 0.0 0.9999999999999998\n\n\nIl est dont très fréquent de croiser la condition if __name__ == \"__main__\" dans les scripts Python, qui distingue l’usage comme module et l’usage comme script.",
    "crumbs": [
      "Manipulation de données",
      "Manipulation de fichiers"
    ]
  },
  {
    "objectID": "source/manipulation/modules-files/tutorial.html#exercices",
    "href": "source/manipulation/modules-files/tutorial.html#exercices",
    "title": "Manipulation de fichiers",
    "section": "",
    "text": "1/ Qu’est-ce qu’un module ?\n2/ Qu’est ce qu’un package ?\n3/ Pourquoi n’est-ce pas une bonne pratique d’importer toutes les fonctions d’un module avec la syntaxe from module import *\n4/ Quels sont les avantages de la librairie pathlib ?\n5/ Quelles sont les deux propriétés d’un fichier qui permettent de repérer sa position dans le système de fichiers ?\n6/ Qu’est-ce que le répertoire courant ?\n7/ Quelles sont les deux manières de spécifier un chemin ? Comment Python fait-il la différence entre les deux ?\n8/ Quels sont les deux grandes familles de fichiers que l’on est amenés à manipuler en programmation ?\n9/ Quels sont les différents modes d’ouverture d’un fichier ?\n10/ Pourquoi est-il préférable d’utiliser la syntaxe with open(...) as ... pour ouvrir un fichier ?\n11/ Pourquoi peut-on parcourir les lignes d’un fichier à l’aide d’une boucle ?\n12/ Quelle est la différence entre un module et un script ?\n\n\n\n\nAfficher la solution\n\n\n1/ un module est un fichier texte (portant l’extension .py pour bien marquer le lien à Python) contenant un ensemble de définitions (de classes, de fonctions) et d’instructions\n2/ Un package est une collection de modules.\n3/ Cela surcharge la mémoire si l’on a besoin que de quelques fonctions, et cela réduit la lisibilité puisqu’on ne sait pas directement de quel module provient quelle fonction.\n4/ Elle permet d’interagir avec le système de fichiers avec une syntaxe de POO unifiée, quel que soit l’environnement sur lequel on travaille.\n5/ Nom de fichier et chemin du dossier qui contient le fichier.\n6/ C’est le répertoire dans lequel la session Python courante est ouverte. Dans le cadre d’un notebook Jupyter, c’est par défaut le dossier qui le contient.\n7/ Chemin absolu (complet) et chemin relatif (relatif au répertoire courant). Un chemin absolu se reconnaît car il part toujours de la racine du système de fichiers.\n8/ Fichiers textes et fichiers binaires (tout ce qui n’est pas du texte).\n9/ r : lecture. w : écriture. a : appending\n10/ Cette syntaxe fait intervenir un context manager, qui gère la connexion au fichier (ouverture et fermeture) pour nous.\n11/ Car l’objet représentant le fichier en Python est un itérable.\n12/ Comme nous l’avons vu, un script est un fichier .py destiné à être exécuté directement. Il contient généralement un flux de travail complet ou une tâche automatisée. Un module est également un fichier .py, mais qui contient des définitions de fonctions et/ou de classes destinées à être utilisées par d’autres scripts ou modules. Il n’est pas destiné à être exécuté seul mais importé ailleurs.\n\n\n\n\n\n\nExercice inspiré de : python.sdv.univ-paris-diderot.fr\nLe fichier texte notes.txt se trouve dans votre répertoire courant. Il contient les notes obtenues par 50 élèves à un examen. Problème : toutes les notes ont été écrites sur une même ligne, avec un espace à chaque fois. Ouvrez ce fichier et calculez la moyenne et l’écart-type des notes.\nIndices :\n\nles chaînes de caractère ont une méthode split qui permet de séparer du texte selon un caractère donné\nil faudra convertir les notes au format numérique pour pouvoir leur appliquer des fonctions mathématiques\nvous pouvez utiliser les fonctions du package numpy pour calculer les statistiques demandées\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nimport numpy as np\n\nwith open(\"notes.txt\", \"r\") as file_in:\n    notes = file_in.read()\n\nnotes = notes.split()\nnotes_num = []\nfor n in notes:\n    notes_num.append(int(n))\n\nprint(np.mean(notes_num))\nprint(np.std(notes_num))\n\n\n\n\n\nExercice inspiré de : python.sdv.univ-paris-diderot.fr\nLe fichier texte notes_clean.txt se trouve dans votre répertoire courant. Il contient les notes obtenues par 50 élèves à un examen. Contrairement à l’exercice précédent, les notes sont cette fois bien écrites : une note par ligne.\nÉcrire un code qui :\n\nstocke chaque note au format int dans une liste\nréécrit les notes dans un fichier notes_mentions.txt avec sur chaque ligne la note, suivie d’un espace, suivi de la mention “admis” si la note est supérieure ou égale à 10, et “recalé” sinon.\n\nPar exemple, les trois premières lignes de ce nouveau fichier devraient être :\n5 recalé\n5 recalé\n18 admis\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nnotes = []\n\nwith open(\"notes_clean.txt\", \"r\") as file_in:\n    for n in file_in:\n        notes.append(int(n))\n        \nwith open(\"notes_mentions.txt\", \"w\") as file_out:\n    for n in notes:\n        if n &gt;= 10:\n            mention = \"admis\"\n        else:\n            mention = \"recalé\"\n        file_out.write(str(n) + \" \" + mention + \"\\n\")\n\n\n\n\n\n3 élèves n’avaient pas rendu leur copie dans les temps pour l’examen :\n\nMiranda a obtenu 16 et a rendu son devoir avec 3 jours de retard\nPaolo a obtenu 11 et a rendu son devoir avec 1 jour de retard\nIsidore a obtenu 3 et a rendu son devoir avec 5 jours de retard.\n\nChaque élève aura une note finale égale à la note obtenue moins le nombre de jours de retard. Une note ne pouvant être négative, elle sera remplacée par 0.\nLes informations nécessaires ont été placées dans une liste dans la cellule suivante. A l’aide d’une boucle sur cette liste, ajouter (sans réécrire complètement le fichier !). les notes au fichier notes_clean.txt (sans la mention).\nNB : si vous avez écrasé le contenu d’un fichier par erreur, vous pouvez retrouver les fichiers propres sur le dépôt GitHub associé à la formation.\n\nsupp = [(16, 3), (11, 1), (3, 5)]\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nsupp = [(16, 3), (11, 1), (3, 5)]\n\nwith open(\"notes_clean.txt\", \"a\") as file_out:\n    for elem in supp:\n        note_finale = elem[0] - elem[1]\n        note_finale = max(0, note_finale)\n        file_out.write(str(note_finale) + \"\\n\")\n\n\n\n\n\nÉcrire un programme qui réalise les opérations suivantes :\n\ndans le répertoire courant, lister les chemins des fichiers dont l’extension est .txt (la syntaxe a été vue dans la partie sur pathlib)\nfaire une boucle qui parcourt ces chemins et ouvre chaque fichier séquentiellement\npour chaque fichier, faire un test d’appartenance (rappel de la syntaxe : if pattern in string: ...) pour tester si le fichier contient le mot “sol”. Si c’est le cas, imprimer son chemin absolu dans la console (seul le chemin du fichier gamme.txt devrait donc apparaître)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nfrom pathlib import Path\n\ntxt_files_paths = list(Path.cwd().glob('*.txt'))\n\nfor path in txt_files_paths:\n    with open(path, \"r\") as file_in:\n        content = file_in.read()\n        if \"sol\" in content:\n            print(path)",
    "crumbs": [
      "Manipulation de données",
      "Manipulation de fichiers"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html",
    "href": "source/manipulation/csv-json-files/tutorial.html",
    "title": "Travailler avec des fichiers CSV et JSON",
    "section": "",
    "text": "Dans le précédent tutoriel, nous avons vu comment utiliser des fonctions provenant de modules, ainsi que comment lire et écrire des fichiers texte. Dans ce tutoriel, nous allons mettre à profit ces nouvelles compétences en nous intéressant à deux types de fichiers texte très fréquemment utilisés pour stocker et diffuser des données : les fichiers CSV et les fichiers JSON. Nous allons apprendre à manipuler ces deux types de fichiers grâce aux modules Python dédiés à leur traitement respectif : le module csv et le module json.\n\n\n\n\nCSV signifie comma-separated values, soit en bon français “valeurs séparées par des virgules”. Les fichiers CSV visent à reproduire la structure des données issues de tableurs type Excel de Microsoft ou Calc de LibreOffice, réduite à la stricte donnée textuelle (plus de formatage, plus de types de colonne, etc.).\nNous allons prendre pour exemple le fichier CSV qui contient la liste des départements en 2021, issue du Code Officiel Géographique (COG). Regardons les premières lignes de ce fichier à l’aide d’une commande shell pour avoir bien en tête la structure d’un tel fichier.\n\n!head -n 5 departement2021.csv\n\nDEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n01,84,01053,5,AIN,Ain,Ain\n02,32,02408,5,AISNE,Aisne,Aisne\n03,84,03190,5,ALLIER,Allier,Allier\n04,93,04070,4,ALPES DE HAUTE PROVENCE,Alpes-de-Haute-Provence,Alpes-de-Haute-Provence\n\n\nPour reprendre l’analogie avec un fichier issu d’un tableur, chaque ligne du fichier représente une ligne du tableur, et les cellules d’une ligne sont séparées par des virgules. La première ligne peut contenir un header (en-tête), c’est à dire le nom des colonnes, mais ce n’est pas toujours le cas.\nLes principaux avantages des fichiers CSV sont :\n\nleur simplicité : ils contiennent des données textuelles brutes, donc très légères et qui peuvent être éditées facilement via n’importe quel éditeur de texte ou langage de programmation\nleur universalité : ils sont très largement utilisés comme un format standard d’échanges de données\n\n\n\n\nLes données contenues dans un CSV étant des données textuelles, on peut se demander pourquoi l’on a besoin d’un module particulier pour les manipuler, et pourquoi les outils que l’on a vus dans le tutoriel précédent ne seraient pas suffisants. La raison principale est que les fichiers CSV ont tout de même quelques subtilités et normes, souvent invisibles à l’utilisateur, mais très importantes en pratique. Par exemple : si l’on veut séparer les différentes données selon les virgules, que se passe-t-il si les données textuelles elles-même contiennent des virgules ?\nC’est pour cette raison qu’on utilise le module csv pour interagir avec ce type de fichiers, afin de capitaliser sur le fait que d’autres se sont posés toutes ces questions, et donc de ne pas avoir à réinventer la roue à chaque import de fichier CSV.\nNotons qu’en pratique, on a plutôt tendance à manipuler ce type de données sous la forme de DataFrames (comme en R), afin de tirer parti de leur structure tabulaire. On étudiera dans un prochain tutoriel le package Pandas qui permet précisément de faire cela en Python. Néanmoins, il est toujours utile de savoir bien manipuler les données d’un CSV comme des données textuelles, et donc de connaître le module csv.\n\n\n\n\nimport csv\n\nLa syntaxe permettant de lire et manipuler des fichiers CSV en Python est très proche de celle pour les fichiers texte simples. La seule différence est que l’on doit créer un objet reader à partir de l’objet fichier pour pouvoir itérer sur les lignes.\n\nrows = []\n\nwith open(\"departement2021.csv\") as file_in:\n    csv_reader = csv.reader(file_in)\n    for row in csv_reader:\n        rows.append(row)\n\nrows[:4]\n\n[['DEP', 'REG', 'CHEFLIEU', 'TNCC', 'NCC', 'NCCENR', 'LIBELLE'],\n ['01', '84', '01053', '5', 'AIN', 'Ain', 'Ain'],\n ['02', '32', '02408', '5', 'AISNE', 'Aisne', 'Aisne'],\n ['03', '84', '03190', '5', 'ALLIER', 'Allier', 'Allier']]\n\n\nOn retrouve bien la même syntaxe que pour les fichiers texte simples : une fois le reader créé, on peut itérer sur les lignes et réaliser des opérations avec celles-ci ; par exemple, les stocker dans une liste comme ci-dessus.\nLorsqu’on a un fichier CSV avec des noms de colonne comme dans notre cas, il est intéressant de les utiliser pour manipuler la donnée nommée, plutôt que par position en utilisant une liste simple. On utilise pour cela un DictReader au lieu du reader. A présent, lorsqu’on itère sur l’objet DictReader créé, chaque ligne est un dictionnaire, donc la clé est le nom de la colonne et la valeur la donnée de la cellule.\nPour illustrer son intérêt, affichons les noms des départements donc le numéro de département est compris entre 20 et 29.\n\nwith open(\"departement2021.csv\") as file_in:\n    dict_reader = csv.DictReader(file_in)\n    for row in dict_reader:\n        if row[\"DEP\"].startswith(\"2\"):\n            print(row[\"LIBELLE\"])\n\nCôte-d'Or\nCôtes-d'Armor\nCreuse\nDordogne\nDoubs\nDrôme\nEure\nEure-et-Loir\nFinistère\nCorse-du-Sud\nHaute-Corse\n\n\nLe code est beaucoup plus lisible : on comprend facilement quelles données sont manipulées et de quelle manière.\n\n\n\nLa syntaxe pour l’écriture est là encore assez proche de celle pour les fichiers texte. La différence est que l’on traite des données en 2D (ligne x colonne), on ne peut donc plus passer seulement une chaîne de caractère à l’écriture, il faut passer une liste d’éléments.\n\nheader = [\"nom\", \"classe\", \"age\"]\nrow1 = [\"Maurice\", \"5èmeB\", 12]\nrow2 = [\"Manuela\", \"6èmeA\", 11]\n\nwith open(\"test.csv\", \"w\") as file_out:\n    csv_writer = csv.writer(file_out)\n    csv_writer.writerow(header)\n    csv_writer.writerow(row1)\n    csv_writer.writerow(row2)\n\nVérifions que notre fichier CSV brut ressemble bien à ce que nous attendions.\n\n# Commande shell pour afficher le contenu d'un fichier\n!cat test.csv\n\nnom,classe,age\nMaurice,5èmeB,12\nManuela,6èmeA,11\n\n\n\n\n\nComme dans un document de type tableur, la première ligne d’un fichier CSV contient généralement les noms des variables (colonnes). On appelle cette ligne le header. Cette ligne n’est pas obligatoire en théorie, mais elle est quand même bien pratique pour comprendre rapidement la nature des données qui se trouvent dans un fichier CSV. C’est donc une bonne pratique d’inclure un header lorsqu’on génère un fichier CSV.\nNous avons vu dans l’exemple précédent que l’écriture du header se faisait comme celle de n’importe quelle autre ligne de donnée. C’est lors de la lecture que les choses se compliquent, puisqu’il faut récupérer le header séparément des autres données si le fichier CSV en contient un. Utilisons le CSV généré à l’étape précédente pour illustrer cela.\n\ndata = []\nwith open(\"test.csv\", \"r\") as file_in:\n    csv_reader = csv.reader(file_in)\n    header = next(csv_reader)\n    for row in csv_reader:\n        data.append(row)\n\n\nprint(header)\n\n['nom', 'classe', 'age']\n\n\n\nprint(data)\n\n[['Maurice', '5èmeB', '12'], ['Manuela', '6èmeA', '11']]\n\n\nPour récupérer le header, on utilise la fonction next. C’est une fonction built-in qui va appeler la méthode __next__ de l’objet reader, qui permet d’itérer d’un pas sur le reader. Le premier appel à la fonction next renvoie donc la première ligne du document. Si un header est présent dans le fichier (ce dont il faut s’assurer), l’élément renvoyé est le header. On récupère ensuite classiquement le reste des données via une boucle sur l’objet reader, que l’on stocke dans une liste de listes (une liste par ligne).\n\n\n\nLe délimiteur correspond au caractère qui est utilisé pour délimiter les valeurs successives d’une ligne dans un fichier CSV.\nLe standard CSV utilise — comme son nom l’indique — la virgule comme délimiteur, mais cela est modifiable, et il n’est pas rare de tomber sur des fichiers CSV qui ont un autre délimiteur. Il faut dans ce cas aller regarder directement dans le texte brut quel est le délimiteur utilisé. On trouve par exemple souvent une délimitation par des tabs (le caractère est \\t), i.e. un nombre d’espaces donné, auquel cas le fichier peut avoir pour extension .tsv pour tab-separated value. Il faut alors spécifier le délimiteur avec le paramètre delimiter lorsqu’on crée le reader.\nEn pratique, comme pour l’encodage d’un fichier texte, il y a peu de raison valable pour changer de délimiteur. Même si des virgules apparaissent dans des valeurs du fichier — par exemple, dans une adresse — ces valeurs sont alors entourées par des guillemets, ce qui permet à la séparation des valeurs de se faire correctement dans la grande majorité des cas.\n\n\n\n\n\n\nLe JSON (JavaScript Object Notation) est un format de fichier très populaire pour écrire et échanger de la donnée sous la forme d’une chaîne de caractères unique et lisible par l’humain (human-readable) — du moins en théorie.\nComme son nom le suggère, le JSON est lié au langage JavaScript dans la mesure où il constitue un dérivé de la notation des objets dans ce langage. Le format est cependant désormais indépendant de tout langage de programmation, mais est très fréquemment utilisé dans différents langages.\nLe format JSON est particulièrement important pour les statisticiens et data scientists car il constitue le format quasi-standard de réponse des API. Le dialogue avec les API va au delà du programme de ce cours d’introduction. Cependant, les API tendant à se généraliser comme mode de communication standard pour l’échange de données, il est important de maîtriser les bases du format JSON afin de manipuler les réponses des API lorsqu’on doit interagir avec celles-ci.\nLe JSON stockant les objets sous forme de paires clé-valeur et où les valeurs peuvent être des arrays — un concept assez large en informatique qui inclut notamment les listes que nous connaissons — il ressemble fortement aux dictionnaires Python. Il constitue ainsi un format de fichier assez naturel pour sérialiser ces derniers, c’est à dire passer d’une structure de données en mémoire (ici, un dictionnaire) à une séquence d’octets qui peut être universellement lue par tout ordinateur. Regardons à titre d’exemple la représentation JSON d’un dictionnaire Python.\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"miranda\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(cv)\n\n{'marc': {'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']}, 'miranda': {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['trekking']}}\n\n\n\nimport json\n\nprint(json.dumps(cv))\n\n{\"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]}, \"miranda\": {\"poste\": \"ing\\u00e9nieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}}\n\n\nOn le voit : la représentation JSON est assez proche de celle du dictionnaire Python, avec quelques particularités. Dans ce cas par exemple, les caractères spéciaux comme les accents sont automatiquement encodés en Unicode.\n\n\n\nLe module json gère l’import de fichiers JSON et l’export d’objets Python au format JSON. Il s’occupe notamment de gérer les contraintes de conversion en JSON évoquées précédemment, comme celle des accents.\nEn particulier, le JSON peut stocker la majorité des types d’objets built-in de Python que nous avons vus jusqu’à présent (strings, valeurs numériques, Booléens, listes, dictionnaires, NoneType) et bien d’autres, mais il ne peut pas représenter des objets Python créés manuellement via des classes par exemple.\n\n\n\nCommençons cette fois par l’écriture. Comme nous l’avons vu dans l’exemple précédent, la fonction dumps (pour dump string) convertit une valeur Python sérialisable en sa représentation JSON sous forme de chaîne de caractères.\n\nx = \"test\"\njson.dumps(x)\n\n'\"test\"'\n\n\n\nx = [1, 2, 3]\njson.dumps(x)\n\n'[1, 2, 3]'\n\n\nEcrire un fichier JSON à partir de Python revient simplement à écrire cette représentation dans un fichier texte, auquel on donnera l’extension .json pour bien marquer qu’il s’agit d’un fichier texte particulier. Comme cette opération est très fréquente, il existe une fonction très proche, dump, qui effectue à la fois la conversion et l’écriture.\n\nwith open(\"cv.json\", \"w\") as file_out:\n    json.dump(cv, file_out)\n\n\n!cat cv.json\n\n{\"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]}, \"miranda\": {\"poste\": \"ing\\u00e9nieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}}\n\n\nEn une seule opération, on a sérialisé un dictionnaire Python (l’objet cv) dans un fichier JSON.\n\n\n\nLe module json propose les fonctions load et loads, qui réalisent respectivement les opérations opposées des fonctions dump et dumps :\n\nla fonction load permet d’importer du contenu JSON présent dans un fichier texte et de le convertir en un dictionnaire\nla fonction loads permet de convertir du contenu JSON présent dans une chaîne de caractères en un dictionnaire\n\nReprenons le CV que nous avons sérialisé précédemment au format JSON pour illustrer la lecture à partir d’un fichier.\n\nwith open(\"cv.json\", \"r\") as file_in:\n    data = json.load(file_in)\n    \ndata\n\n{'marc': {'poste': 'manager',\n  'experience': 7,\n  'hobbies': ['couture', 'frisbee']},\n 'miranda': {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['trekking']}}\n\n\nNous allons illustrer la lecture de contenu JSON à partir d’une chaîne de caractères à partir d’un exemple réaliste : celui du requêtage d’une API. Pour l’exemple, nous allons requêter la Base Adresse Nationale (BAN), qui permet de géolocaliser n’importe quelle adresse nationale.\nLe requêtage d’API en Python se fait très simplement grâce à la librairie requests. Regardons par exemple comment l’on peut récupérer en seulement deux lignes de code les informations géographiques sur toutes les voies qui contiennent le nom “comédie” en France.\n\nimport requests\n\n\nresponse = requests.get(\"https://api-adresse.data.gouv.fr/search/?q=comedie&type=street\")\nr_text = response.text\nprint(r_text[:150])\n\n{\"type\":\"FeatureCollection\",\"version\":\"draft\",\"features\":[{\"type\":\"Feature\",\"geometry\":{\"type\":\"Point\",\"coordinates\":[3.063832,50.635192]},\"properties\n\n\nL’API nous renvoie une réponse, dont on extrait le contenu textuel. Comme pour la très grande majorité des API, ce contenu est du JSON. On peut alors l’importer dans un dictionnaire Python via la fonction loads (pour load string) pour pouvoir manipuler la donnée qu’il contient.\n\nr_dict = json.loads(r_text)\n\n\nr_dict.keys()\n\ndict_keys(['type', 'version', 'features', 'attribution', 'licence', 'query', 'filters', 'limit'])\n\n\n\ntype(r_dict[\"features\"])\n\nlist\n\n\nLes résultats qui nous intéressent sont contenues dans la valeur du dictionnaire associée à la clé features, qui est une liste de dictionnaires, un par résultat.\n\nr_dict[\"features\"][0]\n\n{'type': 'Feature',\n 'geometry': {'type': 'Point', 'coordinates': [3.063832, 50.635192]},\n 'properties': {'label': 'Rue de la Vieille Comédie 59800 Lille',\n  'score': 0.7018699999999999,\n  'id': '59350_9149',\n  'name': 'Rue de la Vieille Comédie',\n  'postcode': '59800',\n  'citycode': '59350',\n  'oldcitycode': '59350',\n  'x': 704523.56,\n  'y': 7059804.63,\n  'city': 'Lille',\n  'oldcity': 'Lille',\n  'context': '59, Nord, Hauts-de-France',\n  'type': 'street',\n  'importance': 0.72057,\n  'street': 'Rue de la Vieille Comédie'}}\n\n\n\nr_dict[\"features\"][1]\n\n{'type': 'Feature',\n 'geometry': {'type': 'Point', 'coordinates': [3.879638, 43.608525]},\n 'properties': {'label': 'Place de la Comédie 34000 Montpellier',\n  'score': 0.70161,\n  'id': '34172_1485',\n  'name': 'Place de la Comédie',\n  'postcode': '34000',\n  'citycode': '34172',\n  'x': 771035.57,\n  'y': 6279225.95,\n  'city': 'Montpellier',\n  'context': '34, Hérault, Occitanie',\n  'type': 'street',\n  'importance': 0.71771,\n  'street': 'Place de la Comédie'}}\n\n\n\n\n\n\n\n\n\n1/ Qu’est ce qu’un fichier CSV ?\n2/ Quel sont les avantages du format CSV ?\n3/ Pourquoi utilise-t-on le module csv pour lire et écrire des fichiers CSV ?\n4/ Les données d’un fichier CSV sont-elles forcément séparées par des virgules ?\n5/ Qu’est-ce que le header d’un fichier CSV ? Existe-t-il nécessairement ?\n6/ Pourquoi le format JSON est très utilisé dans la manipulation de données ?\n7/ A quel objet Python ressemble du contenu au format JSON ?\n8/ Quels types d’objets Python peuvent être convertis en JSON ?\n9/ Qu’est ce que la sérialisation d’un objet Python ?\n10/ Quel est le principal point commun entre les fichiers CSV et les fichiers JSON ?\n11/ Un fichier dont l’extension est .json contient-il nécessairement du JSON ?\n\n\n\n\nAfficher la solution\n\n\n1/ Un CSV est un fichier texte qui représente l’information brute d’un document type tableur. Chaque ligne du fichier représente une ligne du tableur, et les cellules d’une ligne sont séparées par des virgules. La première ligne peut contenir un header (en-tête), c’est à dire le nom des colonnes, mais ce n’est pas toujours le cas.\n2/ Simplicité de lecture et d’édition, universalité.\n3/ Même si le format CSV est très simple, il présente certaines caractéristiques (délimiteur, caractère de fin de ligne, etc.) dont il faut tenir compte lorsqu’on lit ou édite du CSV. Le module csv fournit des fonctions qui tiennent compte de ces particularités.\n4/ Non, on peut en théorie séparer les données par n’importe quel caractère ou suite de caractères. En pratique, il faut suivre la convention dans la majorité des cas, qui est d’utiliser une virgule.\n5/ C’est la première ligne du fichier CSV, qui contient normalement les noms de variables, mais ce n’est pas toujours le cas.\n6/ C’est le format majoritaire de réponse des API, qui sont très utilisées pour la diffusion et l’échange de données.\n7/ Aux dictionnaires.\n8/ Tous les objets dits sérialisables, ce qui inclut la plupart des objets de base que l’on a vus, mais pas les objets créés manuellement via des classes.\n9/ La sérialisation d’un objet Python (sérialisable) consiste à convertir la donnée contenue dans cet objet en une séquence d’octets, c’est à dire en un message qui peut être compris par n’importe quel ordinateur.\n10/ Ce sont des fichiers texte.\n11/ Non, les fichiers JSON comme les fichiers CSV sont des fichiers texte. L’extension est une convention qui permet dans la grande majorité des cas de savoir ce que contient le fichier, mais elle ne peut pas le garantir.\n\n\n\n\n\n\nLa cellule suivante contient un dictionnaire. Le but de l’exercice est d’écrire ces données dans un fichier JSON, en triant les clés du dictionnaire par ordre alphabétique.\nIndice : la fonction dump du module json contient un paramètre permettant de trier les clés. Lisez la documentation de la fonction pour le déterminer.\n\ndata = {\"id\": 1, \"nom\": \"Isidore\", \"age\": 29}\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nimport json\n\ndata = {\"id\": 1, \"nom\": \"Isidore\", \"age\": 29}\n\nwith open(\"data_sorted.json\", \"w\") as file_out:\n    json.dump(data, file_out, sort_keys=True)\n\n\n\n\n\nNous avons vu que les objets que l’on crée manuellement via des classes ne sont généralement pas sérialisables. La cellule suivante en montre un exemple avec notre objet Citron utilisé dans le tutoriel sur la POO. Essayer de convertir directement l’objet en JSON renvoie une erreur.\nVous devez modifier le code suivant afin de pouvoir sérialiser l’objet. Pour cela, vous devez :\n\nconvertir l’instance mon_citron en utilisant la méthode built-in __dict__ que possèdent tous les objets Python\nconvertir le dictionnaire obtenu en JSON sous forme de chaîne de caractères\n\n\nimport json\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \nmon_citron = Citron(couleur=\"jaune\", qte_jus=45)\njson.dumps(mon_citron)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[26], line 11\n      8         self.jus = qte_jus\n     10 mon_citron = Citron(couleur=\"jaune\", qte_jus=45)\n---&gt; 11 json.dumps(mon_citron)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/__init__.py:231, in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\n    226 # cached encoder\n    227 if (not skipkeys and ensure_ascii and\n    228     check_circular and allow_nan and\n    229     cls is None and indent is None and separators is None and\n    230     default is None and not sort_keys and not kw):\n--&gt; 231     return _default_encoder.encode(obj)\n    232 if cls is None:\n    233     cls = JSONEncoder\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:199, in JSONEncoder.encode(self, o)\n    195         return encode_basestring(o)\n    196 # This doesn't pass the iterator directly to ''.join() because the\n    197 # exceptions aren't as detailed.  The list call should be roughly\n    198 # equivalent to the PySequence_Fast that ''.join() would do.\n--&gt; 199 chunks = self.iterencode(o, _one_shot=True)\n    200 if not isinstance(chunks, (list, tuple)):\n    201     chunks = list(chunks)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:257, in JSONEncoder.iterencode(self, o, _one_shot)\n    252 else:\n    253     _iterencode = _make_iterencode(\n    254         markers, self.default, _encoder, self.indent, floatstr,\n    255         self.key_separator, self.item_separator, self.sort_keys,\n    256         self.skipkeys, _one_shot)\n--&gt; 257 return _iterencode(o, 0)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:179, in JSONEncoder.default(self, o)\n    160 def default(self, o):\n    161     \"\"\"Implement this method in a subclass such that it returns\n    162     a serializable object for ``o``, or calls the base implementation\n    163     (to raise a ``TypeError``).\n   (...)\n    177 \n    178     \"\"\"\n--&gt; 179     raise TypeError(f'Object of type {o.__class__.__name__} '\n    180                     f'is not JSON serializable')\n\nTypeError: Object of type Citron is not JSON serializable\n\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nimport json\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \nmon_citron = Citron(couleur=\"jaune\", qte_jus=45)\nmon_citron_dict = mon_citron.__dict__\n\njson.dumps(mon_citron_dict)\n\n\n\n\n\nVotre répertoire courant contient le fichier nat2020.csv. Il s’agit du fichier des prénoms diffusé par l’Insee : il contient des données sur les prénoms attribués aux enfants nés en France entre 1900 et 2020.\nProblème : contrairement au standard CSV, le délimiteur utilisé n’est pas la virgule. Vous devez donc :\n\ntrouver le séparateur utilisé (via l’éditeur de texte Jupyter, via une commande shell, en testant avec le module csv en Python..) pour lire correctement le fichier\ngénérer un nouveau fichier CSV nat2020_corr.csv contenant les mêmes données, mais cette fois avec la virgule comme séparateur.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n# Trouvons à l'aide d'une commande shell le séparateur utilisé\n!head -n 3 nat2020.csv\n\nwith open('nat2020.csv', 'r') as file_in:\n    # Lecture du fichier CSV existant\n    reader = csv.reader(file_in, delimiter=';')\n    with open('nat2020_corr.csv', 'w') as file_out:\n        # Ecriture dans le nouveau fichier CSV\n        writer = csv.writer(file_out)  # Par défaut, le délimiteur est la virgule\n        for row in reader:\n            writer.writerow(row)\n            \n# Vérification à l'aide d'une commande shell\n!head -n 3 nat2020_corr.csv\n\n\n\n\n\nL’exercice consiste à effectuer une requête à l’API de la Base Adresse Nationale, et sauvegarder les résultats dans un fichier CSV. Voici les étapes à implémenter :\n\neffectuer une requête de nom de rue avec un mot clé comme dans le tutoriel (si vous souhaitez faire une requête plus complexe, vous pouvez regarder la documentation de l’API) et stocker les résultats dans un dictionnaire\ncréer un fichier CSV resultats_ban.csv dans lequel on va stocker les informations suivantes : ‘nom’, ‘ville’, ‘code_commune’, ‘longitude’, ‘latitude’\nà l’aide d’un objet writer et d’une boucle sur les résultats renvoyés par l’API, écrivez chaque ligne dans le CSV\n\nPar exemple, pour la requête de voie contenant le mot “comedie”, voici le CSV à obtenir :\nnom,ville,code_commune,longitude,latitude\nRue de la Vieille Comedie,Lille,59350,3.063832,50.635192\nPlace de la Comédie,Montpellier,34172,3.879638,43.608525\nRue de la Comédie,Cherbourg-en-Cotentin,50129,-1.629732,49.641574\nAllee de la Comedie,Villeneuve-d'Ascq,59009,3.162808,50.64628\nRue de l’Ancienne Comedie,Poitiers,86194,0.342649,46.580457\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nresponse = requests.get(\"https://api-adresse.data.gouv.fr/search/?q=comedie&type=street\")\nr_text = response.text\nr_dict = json.loads(r_text)\n\nwith open('resultats_ban.csv', 'w') as file_out:\n    header = ['nom', 'ville', 'code_commune', 'longitude', 'latitude']\n    csv_writer = csv.writer(file_out)\n    csv_writer.writerow(header)\n    for result in r_dict['features']:\n        nom = result['properties']['name']\n        commune = result['properties']['city']\n        code_commune = result['properties']['citycode']\n        long, lat = result['geometry']['coordinates']\n        row = [nom, commune, code_commune, long, lat]\n        csv_writer.writerow(row)\n\n\n\n\n\nL’objectif de cet exercice est de découper le fichier CSV des départements que nous avons utilisé dans le tutoriel en plusieurs petits CSV, un par région. Ce type d’opération peut être utile par exemple lorsqu’on travaille avec un fichier de très grande taille, qui ne passe pas en mémoire ; le découper en plusieurs fichiers que l’on traite indépendamment, lorsque cela est possible, permet de réduire la volumétrie.\nVoici la liste des opérations à effectuer :\n\ncréer un dossier dep dans le répertoire courant à l’aide du module pathlib (cf. tutoriel précédent)\navec un objet reader du module csv, faire une boucle sur les lignes du fichier CSV des départements. Attention à ne pas inclure le header, en utilisant la fonction next pour passer la première ligne. Pour chaque ligne suivante :\n\nrécupérer le code région (variable REG)\ngénérer le chemin du fichier CSV dep/{REG}.csv où {REG} est à remplacer par le code région de la ligne\nouvrir ce fichier CSV en mode append pour écrire la ligne à la fin du fichier\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nfrom pathlib import Path\n\npath_dep = Path(\"dep/\")\npath_dep.mkdir(exist_ok=True)\n\nwith open('departement2021.csv', 'r') as file_in:\n    csv_reader = csv.reader(file_in)\n    next(csv_reader)  # Passe le header\n    for row in csv_reader:\n        reg = row[1]\n        filename = reg + '.csv'\n        path_reg_file = path_dep / filename  # Chemin du fichier csv region\n        with open(path_reg_file, 'a') as file_reg_in:\n                writer = csv.writer(file_reg_in)\n                writer.writerow(row)\n\n\n\n\n\nDans l’exercice précédent, nous avons découpé le fichier CSV des départements français en plusieurs fichiers CSV, un par région. Mais nous n’avons pas inclus dans les différents fichiers le header, i.e. la première ligne qui contient les noms de colonnes. On va donc l’ajouter manuellement à chacun des fichiers CSV créés lors de l’exercice précédent.\nVoici la liste des opérations à effectuer :\n\nlire le fichier des départements complet et récupérer le header dans une liste avec la fonction next\nenregistrer dans une liste les chemins des différents fichiers CSV contenus dans le dossier dep avec la méthode glob de pathlib (cf. tutoriel précédent)\npour chaque chemin :\n\nouvrir le fichier CSV déjà existant, et récupérer les données sous forme d’une liste de listes (une liste par ligne)\nouvrir le fichier CSV en écriture pour le réinitialiser, écrire le header en premier lieu, puis écrire les données que l’on a au préalable sauvegardées dans une liste de liste\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nfrom pathlib import Path\n\nwith open('departement2021.csv', 'r') as file_in:\n    csv_reader = csv.reader(file_in)\n    header = next(csv_reader)\n\ndep_files_paths = list(Path(\"dep/\").glob('*.csv'))\n\nfor path in dep_files_paths:\n    # Lecture du fichier existant, dont on stocke les lignes dans une liste\n    with open(path, 'r') as file_dep_in:\n        reader = csv.reader(file_dep_in)\n        dep_rows = []\n        for row in reader:\n            dep_rows.append(row)\n    # On réécrit le fichier de sortie, en rajoutant au préalable le header\n    with open(path, 'w') as file_dep_out:\n        writer = csv.writer(file_dep_out)\n        writer.writerow(header)\n        for row in dep_rows:\n            writer.writerow(row)",
    "crumbs": [
      "Manipulation de données",
      "Travailler avec des fichiers CSV et JSON"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html#manipuler-des-fichiers-csv",
    "href": "source/manipulation/csv-json-files/tutorial.html#manipuler-des-fichiers-csv",
    "title": "Travailler avec des fichiers CSV et JSON",
    "section": "",
    "text": "CSV signifie comma-separated values, soit en bon français “valeurs séparées par des virgules”. Les fichiers CSV visent à reproduire la structure des données issues de tableurs type Excel de Microsoft ou Calc de LibreOffice, réduite à la stricte donnée textuelle (plus de formatage, plus de types de colonne, etc.).\nNous allons prendre pour exemple le fichier CSV qui contient la liste des départements en 2021, issue du Code Officiel Géographique (COG). Regardons les premières lignes de ce fichier à l’aide d’une commande shell pour avoir bien en tête la structure d’un tel fichier.\n\n!head -n 5 departement2021.csv\n\nDEP,REG,CHEFLIEU,TNCC,NCC,NCCENR,LIBELLE\n01,84,01053,5,AIN,Ain,Ain\n02,32,02408,5,AISNE,Aisne,Aisne\n03,84,03190,5,ALLIER,Allier,Allier\n04,93,04070,4,ALPES DE HAUTE PROVENCE,Alpes-de-Haute-Provence,Alpes-de-Haute-Provence\n\n\nPour reprendre l’analogie avec un fichier issu d’un tableur, chaque ligne du fichier représente une ligne du tableur, et les cellules d’une ligne sont séparées par des virgules. La première ligne peut contenir un header (en-tête), c’est à dire le nom des colonnes, mais ce n’est pas toujours le cas.\nLes principaux avantages des fichiers CSV sont :\n\nleur simplicité : ils contiennent des données textuelles brutes, donc très légères et qui peuvent être éditées facilement via n’importe quel éditeur de texte ou langage de programmation\nleur universalité : ils sont très largement utilisés comme un format standard d’échanges de données\n\n\n\n\nLes données contenues dans un CSV étant des données textuelles, on peut se demander pourquoi l’on a besoin d’un module particulier pour les manipuler, et pourquoi les outils que l’on a vus dans le tutoriel précédent ne seraient pas suffisants. La raison principale est que les fichiers CSV ont tout de même quelques subtilités et normes, souvent invisibles à l’utilisateur, mais très importantes en pratique. Par exemple : si l’on veut séparer les différentes données selon les virgules, que se passe-t-il si les données textuelles elles-même contiennent des virgules ?\nC’est pour cette raison qu’on utilise le module csv pour interagir avec ce type de fichiers, afin de capitaliser sur le fait que d’autres se sont posés toutes ces questions, et donc de ne pas avoir à réinventer la roue à chaque import de fichier CSV.\nNotons qu’en pratique, on a plutôt tendance à manipuler ce type de données sous la forme de DataFrames (comme en R), afin de tirer parti de leur structure tabulaire. On étudiera dans un prochain tutoriel le package Pandas qui permet précisément de faire cela en Python. Néanmoins, il est toujours utile de savoir bien manipuler les données d’un CSV comme des données textuelles, et donc de connaître le module csv.\n\n\n\n\nimport csv\n\nLa syntaxe permettant de lire et manipuler des fichiers CSV en Python est très proche de celle pour les fichiers texte simples. La seule différence est que l’on doit créer un objet reader à partir de l’objet fichier pour pouvoir itérer sur les lignes.\n\nrows = []\n\nwith open(\"departement2021.csv\") as file_in:\n    csv_reader = csv.reader(file_in)\n    for row in csv_reader:\n        rows.append(row)\n\nrows[:4]\n\n[['DEP', 'REG', 'CHEFLIEU', 'TNCC', 'NCC', 'NCCENR', 'LIBELLE'],\n ['01', '84', '01053', '5', 'AIN', 'Ain', 'Ain'],\n ['02', '32', '02408', '5', 'AISNE', 'Aisne', 'Aisne'],\n ['03', '84', '03190', '5', 'ALLIER', 'Allier', 'Allier']]\n\n\nOn retrouve bien la même syntaxe que pour les fichiers texte simples : une fois le reader créé, on peut itérer sur les lignes et réaliser des opérations avec celles-ci ; par exemple, les stocker dans une liste comme ci-dessus.\nLorsqu’on a un fichier CSV avec des noms de colonne comme dans notre cas, il est intéressant de les utiliser pour manipuler la donnée nommée, plutôt que par position en utilisant une liste simple. On utilise pour cela un DictReader au lieu du reader. A présent, lorsqu’on itère sur l’objet DictReader créé, chaque ligne est un dictionnaire, donc la clé est le nom de la colonne et la valeur la donnée de la cellule.\nPour illustrer son intérêt, affichons les noms des départements donc le numéro de département est compris entre 20 et 29.\n\nwith open(\"departement2021.csv\") as file_in:\n    dict_reader = csv.DictReader(file_in)\n    for row in dict_reader:\n        if row[\"DEP\"].startswith(\"2\"):\n            print(row[\"LIBELLE\"])\n\nCôte-d'Or\nCôtes-d'Armor\nCreuse\nDordogne\nDoubs\nDrôme\nEure\nEure-et-Loir\nFinistère\nCorse-du-Sud\nHaute-Corse\n\n\nLe code est beaucoup plus lisible : on comprend facilement quelles données sont manipulées et de quelle manière.\n\n\n\nLa syntaxe pour l’écriture est là encore assez proche de celle pour les fichiers texte. La différence est que l’on traite des données en 2D (ligne x colonne), on ne peut donc plus passer seulement une chaîne de caractère à l’écriture, il faut passer une liste d’éléments.\n\nheader = [\"nom\", \"classe\", \"age\"]\nrow1 = [\"Maurice\", \"5èmeB\", 12]\nrow2 = [\"Manuela\", \"6èmeA\", 11]\n\nwith open(\"test.csv\", \"w\") as file_out:\n    csv_writer = csv.writer(file_out)\n    csv_writer.writerow(header)\n    csv_writer.writerow(row1)\n    csv_writer.writerow(row2)\n\nVérifions que notre fichier CSV brut ressemble bien à ce que nous attendions.\n\n# Commande shell pour afficher le contenu d'un fichier\n!cat test.csv\n\nnom,classe,age\nMaurice,5èmeB,12\nManuela,6èmeA,11\n\n\n\n\n\nComme dans un document de type tableur, la première ligne d’un fichier CSV contient généralement les noms des variables (colonnes). On appelle cette ligne le header. Cette ligne n’est pas obligatoire en théorie, mais elle est quand même bien pratique pour comprendre rapidement la nature des données qui se trouvent dans un fichier CSV. C’est donc une bonne pratique d’inclure un header lorsqu’on génère un fichier CSV.\nNous avons vu dans l’exemple précédent que l’écriture du header se faisait comme celle de n’importe quelle autre ligne de donnée. C’est lors de la lecture que les choses se compliquent, puisqu’il faut récupérer le header séparément des autres données si le fichier CSV en contient un. Utilisons le CSV généré à l’étape précédente pour illustrer cela.\n\ndata = []\nwith open(\"test.csv\", \"r\") as file_in:\n    csv_reader = csv.reader(file_in)\n    header = next(csv_reader)\n    for row in csv_reader:\n        data.append(row)\n\n\nprint(header)\n\n['nom', 'classe', 'age']\n\n\n\nprint(data)\n\n[['Maurice', '5èmeB', '12'], ['Manuela', '6èmeA', '11']]\n\n\nPour récupérer le header, on utilise la fonction next. C’est une fonction built-in qui va appeler la méthode __next__ de l’objet reader, qui permet d’itérer d’un pas sur le reader. Le premier appel à la fonction next renvoie donc la première ligne du document. Si un header est présent dans le fichier (ce dont il faut s’assurer), l’élément renvoyé est le header. On récupère ensuite classiquement le reste des données via une boucle sur l’objet reader, que l’on stocke dans une liste de listes (une liste par ligne).\n\n\n\nLe délimiteur correspond au caractère qui est utilisé pour délimiter les valeurs successives d’une ligne dans un fichier CSV.\nLe standard CSV utilise — comme son nom l’indique — la virgule comme délimiteur, mais cela est modifiable, et il n’est pas rare de tomber sur des fichiers CSV qui ont un autre délimiteur. Il faut dans ce cas aller regarder directement dans le texte brut quel est le délimiteur utilisé. On trouve par exemple souvent une délimitation par des tabs (le caractère est \\t), i.e. un nombre d’espaces donné, auquel cas le fichier peut avoir pour extension .tsv pour tab-separated value. Il faut alors spécifier le délimiteur avec le paramètre delimiter lorsqu’on crée le reader.\nEn pratique, comme pour l’encodage d’un fichier texte, il y a peu de raison valable pour changer de délimiteur. Même si des virgules apparaissent dans des valeurs du fichier — par exemple, dans une adresse — ces valeurs sont alors entourées par des guillemets, ce qui permet à la séparation des valeurs de se faire correctement dans la grande majorité des cas.",
    "crumbs": [
      "Manipulation de données",
      "Travailler avec des fichiers CSV et JSON"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html#manipuler-des-fichiers-json",
    "href": "source/manipulation/csv-json-files/tutorial.html#manipuler-des-fichiers-json",
    "title": "Travailler avec des fichiers CSV et JSON",
    "section": "",
    "text": "Le JSON (JavaScript Object Notation) est un format de fichier très populaire pour écrire et échanger de la donnée sous la forme d’une chaîne de caractères unique et lisible par l’humain (human-readable) — du moins en théorie.\nComme son nom le suggère, le JSON est lié au langage JavaScript dans la mesure où il constitue un dérivé de la notation des objets dans ce langage. Le format est cependant désormais indépendant de tout langage de programmation, mais est très fréquemment utilisé dans différents langages.\nLe format JSON est particulièrement important pour les statisticiens et data scientists car il constitue le format quasi-standard de réponse des API. Le dialogue avec les API va au delà du programme de ce cours d’introduction. Cependant, les API tendant à se généraliser comme mode de communication standard pour l’échange de données, il est important de maîtriser les bases du format JSON afin de manipuler les réponses des API lorsqu’on doit interagir avec celles-ci.\nLe JSON stockant les objets sous forme de paires clé-valeur et où les valeurs peuvent être des arrays — un concept assez large en informatique qui inclut notamment les listes que nous connaissons — il ressemble fortement aux dictionnaires Python. Il constitue ainsi un format de fichier assez naturel pour sérialiser ces derniers, c’est à dire passer d’une structure de données en mémoire (ici, un dictionnaire) à une séquence d’octets qui peut être universellement lue par tout ordinateur. Regardons à titre d’exemple la représentation JSON d’un dictionnaire Python.\n\ncv = {\n    \"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]},\n    \"miranda\": {\"poste\": \"ingénieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}\n}\n\nprint(cv)\n\n{'marc': {'poste': 'manager', 'experience': 7, 'hobbies': ['couture', 'frisbee']}, 'miranda': {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['trekking']}}\n\n\n\nimport json\n\nprint(json.dumps(cv))\n\n{\"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]}, \"miranda\": {\"poste\": \"ing\\u00e9nieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}}\n\n\nOn le voit : la représentation JSON est assez proche de celle du dictionnaire Python, avec quelques particularités. Dans ce cas par exemple, les caractères spéciaux comme les accents sont automatiquement encodés en Unicode.\n\n\n\nLe module json gère l’import de fichiers JSON et l’export d’objets Python au format JSON. Il s’occupe notamment de gérer les contraintes de conversion en JSON évoquées précédemment, comme celle des accents.\nEn particulier, le JSON peut stocker la majorité des types d’objets built-in de Python que nous avons vus jusqu’à présent (strings, valeurs numériques, Booléens, listes, dictionnaires, NoneType) et bien d’autres, mais il ne peut pas représenter des objets Python créés manuellement via des classes par exemple.\n\n\n\nCommençons cette fois par l’écriture. Comme nous l’avons vu dans l’exemple précédent, la fonction dumps (pour dump string) convertit une valeur Python sérialisable en sa représentation JSON sous forme de chaîne de caractères.\n\nx = \"test\"\njson.dumps(x)\n\n'\"test\"'\n\n\n\nx = [1, 2, 3]\njson.dumps(x)\n\n'[1, 2, 3]'\n\n\nEcrire un fichier JSON à partir de Python revient simplement à écrire cette représentation dans un fichier texte, auquel on donnera l’extension .json pour bien marquer qu’il s’agit d’un fichier texte particulier. Comme cette opération est très fréquente, il existe une fonction très proche, dump, qui effectue à la fois la conversion et l’écriture.\n\nwith open(\"cv.json\", \"w\") as file_out:\n    json.dump(cv, file_out)\n\n\n!cat cv.json\n\n{\"marc\": {\"poste\": \"manager\", \"experience\": 7, \"hobbies\": [\"couture\", \"frisbee\"]}, \"miranda\": {\"poste\": \"ing\\u00e9nieure\", \"experience\": 5, \"hobbies\": [\"trekking\"]}}\n\n\nEn une seule opération, on a sérialisé un dictionnaire Python (l’objet cv) dans un fichier JSON.\n\n\n\nLe module json propose les fonctions load et loads, qui réalisent respectivement les opérations opposées des fonctions dump et dumps :\n\nla fonction load permet d’importer du contenu JSON présent dans un fichier texte et de le convertir en un dictionnaire\nla fonction loads permet de convertir du contenu JSON présent dans une chaîne de caractères en un dictionnaire\n\nReprenons le CV que nous avons sérialisé précédemment au format JSON pour illustrer la lecture à partir d’un fichier.\n\nwith open(\"cv.json\", \"r\") as file_in:\n    data = json.load(file_in)\n    \ndata\n\n{'marc': {'poste': 'manager',\n  'experience': 7,\n  'hobbies': ['couture', 'frisbee']},\n 'miranda': {'poste': 'ingénieure', 'experience': 5, 'hobbies': ['trekking']}}\n\n\nNous allons illustrer la lecture de contenu JSON à partir d’une chaîne de caractères à partir d’un exemple réaliste : celui du requêtage d’une API. Pour l’exemple, nous allons requêter la Base Adresse Nationale (BAN), qui permet de géolocaliser n’importe quelle adresse nationale.\nLe requêtage d’API en Python se fait très simplement grâce à la librairie requests. Regardons par exemple comment l’on peut récupérer en seulement deux lignes de code les informations géographiques sur toutes les voies qui contiennent le nom “comédie” en France.\n\nimport requests\n\n\nresponse = requests.get(\"https://api-adresse.data.gouv.fr/search/?q=comedie&type=street\")\nr_text = response.text\nprint(r_text[:150])\n\n{\"type\":\"FeatureCollection\",\"version\":\"draft\",\"features\":[{\"type\":\"Feature\",\"geometry\":{\"type\":\"Point\",\"coordinates\":[3.063832,50.635192]},\"properties\n\n\nL’API nous renvoie une réponse, dont on extrait le contenu textuel. Comme pour la très grande majorité des API, ce contenu est du JSON. On peut alors l’importer dans un dictionnaire Python via la fonction loads (pour load string) pour pouvoir manipuler la donnée qu’il contient.\n\nr_dict = json.loads(r_text)\n\n\nr_dict.keys()\n\ndict_keys(['type', 'version', 'features', 'attribution', 'licence', 'query', 'filters', 'limit'])\n\n\n\ntype(r_dict[\"features\"])\n\nlist\n\n\nLes résultats qui nous intéressent sont contenues dans la valeur du dictionnaire associée à la clé features, qui est une liste de dictionnaires, un par résultat.\n\nr_dict[\"features\"][0]\n\n{'type': 'Feature',\n 'geometry': {'type': 'Point', 'coordinates': [3.063832, 50.635192]},\n 'properties': {'label': 'Rue de la Vieille Comédie 59800 Lille',\n  'score': 0.7018699999999999,\n  'id': '59350_9149',\n  'name': 'Rue de la Vieille Comédie',\n  'postcode': '59800',\n  'citycode': '59350',\n  'oldcitycode': '59350',\n  'x': 704523.56,\n  'y': 7059804.63,\n  'city': 'Lille',\n  'oldcity': 'Lille',\n  'context': '59, Nord, Hauts-de-France',\n  'type': 'street',\n  'importance': 0.72057,\n  'street': 'Rue de la Vieille Comédie'}}\n\n\n\nr_dict[\"features\"][1]\n\n{'type': 'Feature',\n 'geometry': {'type': 'Point', 'coordinates': [3.879638, 43.608525]},\n 'properties': {'label': 'Place de la Comédie 34000 Montpellier',\n  'score': 0.70161,\n  'id': '34172_1485',\n  'name': 'Place de la Comédie',\n  'postcode': '34000',\n  'citycode': '34172',\n  'x': 771035.57,\n  'y': 6279225.95,\n  'city': 'Montpellier',\n  'context': '34, Hérault, Occitanie',\n  'type': 'street',\n  'importance': 0.71771,\n  'street': 'Place de la Comédie'}}",
    "crumbs": [
      "Manipulation de données",
      "Travailler avec des fichiers CSV et JSON"
    ]
  },
  {
    "objectID": "source/manipulation/csv-json-files/tutorial.html#exercices",
    "href": "source/manipulation/csv-json-files/tutorial.html#exercices",
    "title": "Travailler avec des fichiers CSV et JSON",
    "section": "",
    "text": "1/ Qu’est ce qu’un fichier CSV ?\n2/ Quel sont les avantages du format CSV ?\n3/ Pourquoi utilise-t-on le module csv pour lire et écrire des fichiers CSV ?\n4/ Les données d’un fichier CSV sont-elles forcément séparées par des virgules ?\n5/ Qu’est-ce que le header d’un fichier CSV ? Existe-t-il nécessairement ?\n6/ Pourquoi le format JSON est très utilisé dans la manipulation de données ?\n7/ A quel objet Python ressemble du contenu au format JSON ?\n8/ Quels types d’objets Python peuvent être convertis en JSON ?\n9/ Qu’est ce que la sérialisation d’un objet Python ?\n10/ Quel est le principal point commun entre les fichiers CSV et les fichiers JSON ?\n11/ Un fichier dont l’extension est .json contient-il nécessairement du JSON ?\n\n\n\n\nAfficher la solution\n\n\n1/ Un CSV est un fichier texte qui représente l’information brute d’un document type tableur. Chaque ligne du fichier représente une ligne du tableur, et les cellules d’une ligne sont séparées par des virgules. La première ligne peut contenir un header (en-tête), c’est à dire le nom des colonnes, mais ce n’est pas toujours le cas.\n2/ Simplicité de lecture et d’édition, universalité.\n3/ Même si le format CSV est très simple, il présente certaines caractéristiques (délimiteur, caractère de fin de ligne, etc.) dont il faut tenir compte lorsqu’on lit ou édite du CSV. Le module csv fournit des fonctions qui tiennent compte de ces particularités.\n4/ Non, on peut en théorie séparer les données par n’importe quel caractère ou suite de caractères. En pratique, il faut suivre la convention dans la majorité des cas, qui est d’utiliser une virgule.\n5/ C’est la première ligne du fichier CSV, qui contient normalement les noms de variables, mais ce n’est pas toujours le cas.\n6/ C’est le format majoritaire de réponse des API, qui sont très utilisées pour la diffusion et l’échange de données.\n7/ Aux dictionnaires.\n8/ Tous les objets dits sérialisables, ce qui inclut la plupart des objets de base que l’on a vus, mais pas les objets créés manuellement via des classes.\n9/ La sérialisation d’un objet Python (sérialisable) consiste à convertir la donnée contenue dans cet objet en une séquence d’octets, c’est à dire en un message qui peut être compris par n’importe quel ordinateur.\n10/ Ce sont des fichiers texte.\n11/ Non, les fichiers JSON comme les fichiers CSV sont des fichiers texte. L’extension est une convention qui permet dans la grande majorité des cas de savoir ce que contient le fichier, mais elle ne peut pas le garantir.\n\n\n\n\n\n\nLa cellule suivante contient un dictionnaire. Le but de l’exercice est d’écrire ces données dans un fichier JSON, en triant les clés du dictionnaire par ordre alphabétique.\nIndice : la fonction dump du module json contient un paramètre permettant de trier les clés. Lisez la documentation de la fonction pour le déterminer.\n\ndata = {\"id\": 1, \"nom\": \"Isidore\", \"age\": 29}\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nimport json\n\ndata = {\"id\": 1, \"nom\": \"Isidore\", \"age\": 29}\n\nwith open(\"data_sorted.json\", \"w\") as file_out:\n    json.dump(data, file_out, sort_keys=True)\n\n\n\n\n\nNous avons vu que les objets que l’on crée manuellement via des classes ne sont généralement pas sérialisables. La cellule suivante en montre un exemple avec notre objet Citron utilisé dans le tutoriel sur la POO. Essayer de convertir directement l’objet en JSON renvoie une erreur.\nVous devez modifier le code suivant afin de pouvoir sérialiser l’objet. Pour cela, vous devez :\n\nconvertir l’instance mon_citron en utilisant la méthode built-in __dict__ que possèdent tous les objets Python\nconvertir le dictionnaire obtenu en JSON sous forme de chaîne de caractères\n\n\nimport json\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \nmon_citron = Citron(couleur=\"jaune\", qte_jus=45)\njson.dumps(mon_citron)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[26], line 11\n      8         self.jus = qte_jus\n     10 mon_citron = Citron(couleur=\"jaune\", qte_jus=45)\n---&gt; 11 json.dumps(mon_citron)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/__init__.py:231, in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\n    226 # cached encoder\n    227 if (not skipkeys and ensure_ascii and\n    228     check_circular and allow_nan and\n    229     cls is None and indent is None and separators is None and\n    230     default is None and not sort_keys and not kw):\n--&gt; 231     return _default_encoder.encode(obj)\n    232 if cls is None:\n    233     cls = JSONEncoder\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:199, in JSONEncoder.encode(self, o)\n    195         return encode_basestring(o)\n    196 # This doesn't pass the iterator directly to ''.join() because the\n    197 # exceptions aren't as detailed.  The list call should be roughly\n    198 # equivalent to the PySequence_Fast that ''.join() would do.\n--&gt; 199 chunks = self.iterencode(o, _one_shot=True)\n    200 if not isinstance(chunks, (list, tuple)):\n    201     chunks = list(chunks)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:257, in JSONEncoder.iterencode(self, o, _one_shot)\n    252 else:\n    253     _iterencode = _make_iterencode(\n    254         markers, self.default, _encoder, self.indent, floatstr,\n    255         self.key_separator, self.item_separator, self.sort_keys,\n    256         self.skipkeys, _one_shot)\n--&gt; 257 return _iterencode(o, 0)\n\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/json/encoder.py:179, in JSONEncoder.default(self, o)\n    160 def default(self, o):\n    161     \"\"\"Implement this method in a subclass such that it returns\n    162     a serializable object for ``o``, or calls the base implementation\n    163     (to raise a ``TypeError``).\n   (...)\n    177 \n    178     \"\"\"\n--&gt; 179     raise TypeError(f'Object of type {o.__class__.__name__} '\n    180                     f'is not JSON serializable')\n\nTypeError: Object of type Citron is not JSON serializable\n\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nimport json\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \nmon_citron = Citron(couleur=\"jaune\", qte_jus=45)\nmon_citron_dict = mon_citron.__dict__\n\njson.dumps(mon_citron_dict)\n\n\n\n\n\nVotre répertoire courant contient le fichier nat2020.csv. Il s’agit du fichier des prénoms diffusé par l’Insee : il contient des données sur les prénoms attribués aux enfants nés en France entre 1900 et 2020.\nProblème : contrairement au standard CSV, le délimiteur utilisé n’est pas la virgule. Vous devez donc :\n\ntrouver le séparateur utilisé (via l’éditeur de texte Jupyter, via une commande shell, en testant avec le module csv en Python..) pour lire correctement le fichier\ngénérer un nouveau fichier CSV nat2020_corr.csv contenant les mêmes données, mais cette fois avec la virgule comme séparateur.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n# Trouvons à l'aide d'une commande shell le séparateur utilisé\n!head -n 3 nat2020.csv\n\nwith open('nat2020.csv', 'r') as file_in:\n    # Lecture du fichier CSV existant\n    reader = csv.reader(file_in, delimiter=';')\n    with open('nat2020_corr.csv', 'w') as file_out:\n        # Ecriture dans le nouveau fichier CSV\n        writer = csv.writer(file_out)  # Par défaut, le délimiteur est la virgule\n        for row in reader:\n            writer.writerow(row)\n            \n# Vérification à l'aide d'une commande shell\n!head -n 3 nat2020_corr.csv\n\n\n\n\n\nL’exercice consiste à effectuer une requête à l’API de la Base Adresse Nationale, et sauvegarder les résultats dans un fichier CSV. Voici les étapes à implémenter :\n\neffectuer une requête de nom de rue avec un mot clé comme dans le tutoriel (si vous souhaitez faire une requête plus complexe, vous pouvez regarder la documentation de l’API) et stocker les résultats dans un dictionnaire\ncréer un fichier CSV resultats_ban.csv dans lequel on va stocker les informations suivantes : ‘nom’, ‘ville’, ‘code_commune’, ‘longitude’, ‘latitude’\nà l’aide d’un objet writer et d’une boucle sur les résultats renvoyés par l’API, écrivez chaque ligne dans le CSV\n\nPar exemple, pour la requête de voie contenant le mot “comedie”, voici le CSV à obtenir :\nnom,ville,code_commune,longitude,latitude\nRue de la Vieille Comedie,Lille,59350,3.063832,50.635192\nPlace de la Comédie,Montpellier,34172,3.879638,43.608525\nRue de la Comédie,Cherbourg-en-Cotentin,50129,-1.629732,49.641574\nAllee de la Comedie,Villeneuve-d'Ascq,59009,3.162808,50.64628\nRue de l’Ancienne Comedie,Poitiers,86194,0.342649,46.580457\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nresponse = requests.get(\"https://api-adresse.data.gouv.fr/search/?q=comedie&type=street\")\nr_text = response.text\nr_dict = json.loads(r_text)\n\nwith open('resultats_ban.csv', 'w') as file_out:\n    header = ['nom', 'ville', 'code_commune', 'longitude', 'latitude']\n    csv_writer = csv.writer(file_out)\n    csv_writer.writerow(header)\n    for result in r_dict['features']:\n        nom = result['properties']['name']\n        commune = result['properties']['city']\n        code_commune = result['properties']['citycode']\n        long, lat = result['geometry']['coordinates']\n        row = [nom, commune, code_commune, long, lat]\n        csv_writer.writerow(row)\n\n\n\n\n\nL’objectif de cet exercice est de découper le fichier CSV des départements que nous avons utilisé dans le tutoriel en plusieurs petits CSV, un par région. Ce type d’opération peut être utile par exemple lorsqu’on travaille avec un fichier de très grande taille, qui ne passe pas en mémoire ; le découper en plusieurs fichiers que l’on traite indépendamment, lorsque cela est possible, permet de réduire la volumétrie.\nVoici la liste des opérations à effectuer :\n\ncréer un dossier dep dans le répertoire courant à l’aide du module pathlib (cf. tutoriel précédent)\navec un objet reader du module csv, faire une boucle sur les lignes du fichier CSV des départements. Attention à ne pas inclure le header, en utilisant la fonction next pour passer la première ligne. Pour chaque ligne suivante :\n\nrécupérer le code région (variable REG)\ngénérer le chemin du fichier CSV dep/{REG}.csv où {REG} est à remplacer par le code région de la ligne\nouvrir ce fichier CSV en mode append pour écrire la ligne à la fin du fichier\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nfrom pathlib import Path\n\npath_dep = Path(\"dep/\")\npath_dep.mkdir(exist_ok=True)\n\nwith open('departement2021.csv', 'r') as file_in:\n    csv_reader = csv.reader(file_in)\n    next(csv_reader)  # Passe le header\n    for row in csv_reader:\n        reg = row[1]\n        filename = reg + '.csv'\n        path_reg_file = path_dep / filename  # Chemin du fichier csv region\n        with open(path_reg_file, 'a') as file_reg_in:\n                writer = csv.writer(file_reg_in)\n                writer.writerow(row)\n\n\n\n\n\nDans l’exercice précédent, nous avons découpé le fichier CSV des départements français en plusieurs fichiers CSV, un par région. Mais nous n’avons pas inclus dans les différents fichiers le header, i.e. la première ligne qui contient les noms de colonnes. On va donc l’ajouter manuellement à chacun des fichiers CSV créés lors de l’exercice précédent.\nVoici la liste des opérations à effectuer :\n\nlire le fichier des départements complet et récupérer le header dans une liste avec la fonction next\nenregistrer dans une liste les chemins des différents fichiers CSV contenus dans le dossier dep avec la méthode glob de pathlib (cf. tutoriel précédent)\npour chaque chemin :\n\nouvrir le fichier CSV déjà existant, et récupérer les données sous forme d’une liste de listes (une liste par ligne)\nouvrir le fichier CSV en écriture pour le réinitialiser, écrire le header en premier lieu, puis écrire les données que l’on a au préalable sauvegardées dans une liste de liste\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nfrom pathlib import Path\n\nwith open('departement2021.csv', 'r') as file_in:\n    csv_reader = csv.reader(file_in)\n    header = next(csv_reader)\n\ndep_files_paths = list(Path(\"dep/\").glob('*.csv'))\n\nfor path in dep_files_paths:\n    # Lecture du fichier existant, dont on stocke les lignes dans une liste\n    with open(path, 'r') as file_dep_in:\n        reader = csv.reader(file_dep_in)\n        dep_rows = []\n        for row in reader:\n            dep_rows.append(row)\n    # On réécrit le fichier de sortie, en rajoutant au préalable le header\n    with open(path, 'w') as file_dep_out:\n        writer = csv.writer(file_dep_out)\n        writer.writerow(header)\n        for row in dep_rows:\n            writer.writerow(row)",
    "crumbs": [
      "Manipulation de données",
      "Travailler avec des fichiers CSV et JSON"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html",
    "href": "source/fundamentals/oop/tutorial.html",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "Python est un langage dit “multi-paradigmes”, c’est à dire qu’il admet plusieurs manières de coder et de concevoir ses programmes. L’une d’entre elle est la programmation orientée objet (POO). La POO est un paradigme puissant, mais fait intervenir des concepts assez complexes (polymorphisme, héritage, etc.). Fort heureusement pour nous, Python n’impose pas de coder en POO. Cela étant, le fonctionnement interne de Python est fortement teinté de POO, et la plupart des packages les plus utilisés reposent à des degrés divers sur les objets. Nous allons donc étudier dans ce tutoriel les bases de la POO, afin de pouvoir être autonomes lorsque son usage est nécessaire.\n\n\nVous avez peut-être déjà entendu que Python était un langage de “programmation orientée objet”. La POO est un paradigme de programmation qui permet de structurer les programmes autour d’une abstraction, l’objet, qui contient des attributs (caractéristiques de l’objet) et des méthodes (fonctions propres à l’objet) qui agissent sur lui-même. Afin d’illustrer cette définition un peu abstraite , on peut prendre l’exemple (source) d’un objet “citron” qui contient les attributs “saveur” et “couleur”, et une méthode “presser” qui permet d’extraire son jus.\n\n\n\nEn Python, tout est un objet (au sens de la POO). Regardons ce que cela signifie en récupérant le type de différents objets que nous avons vus dans les précédents tutoriels.\n\nprint(type(1))\nprint(type(\"bonjour\"))\nprint(type([]))\nprint(type(()))\nprint(type({}))\n\ndef f(x):\n    print(x)\n          \nprint(type(f))\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n&lt;class 'list'&gt;\n&lt;class 'tuple'&gt;\n&lt;class 'dict'&gt;\n&lt;class 'function'&gt;\n\n\nCes éléments sont tous de type différent, mais ils ont un point commun : le terme class. De même que l’instruction def définit une fonction, l’instruction class définit une classe d’objets Python. Ainsi, chacun des objets utilisables en Python a une classe qui définit l’objet, ses attributs et ses méthodes.\n\n\n\nRegardons comment on peut utiliser l’instruction class pour définir notre objet “citron”.\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \n    def recup_qte_jus(self):\n        print(\"Il reste \" + str(self.jus) + \" mL de jus dans le citron.\")\n        \n    def extraire_jus(self, quantite):\n        if quantite &gt; self.jus:\n            print(\"Il n'y a pas assez de jus dans le citron pour la quantité demandée.\")\n        else:\n            self.jus = max(0, self.jus - quantite)  # évite toute valeur négative de `jus`\n\nAnalysons la syntaxe de construction d’une classe d’objets :\n\nl’instruction class définit la classe d’objets. Différents objets pourront être créés selon le modèle défini par cette classe. Par convention, le nom de la classe doit commencer par une majuscule.\nla classe spécifie un certains nombres de fonctions. Dans ce contexte particulier, on appelle ces fonctions “méthodes” : ce sont des fonctions spécifiques à la classe d’objets définie.\nune première méthode bien spécifique, nommée __init__, est appelée le constructeur. Elle permet de définir les attributs attachés à cette classe d’objets. Il est possible de passer des paramètres à la fonction (comme couleur et qte_jus) pour définir des attributs propres à une instance de l’objet (plus de détails sur cette notion dans la section suivante).\nle constructeur a un paramètre obligatoire : self. C’est une référence aux instances qui vont être créées à partir de cette classe. Notons la syntaxe qui définit un attribut : self.attribut = valeur.\nles autres méthodes sont définies par l’utilisateur. Elles prennent également le self en paramètre, ce qui leur permet d’effectuer des opérations sur / à partir des attributs. Comme ce sont des fonctions, elles peuvent également admettre d’autres paramètres. Ainsi, la fonction extraire_jus prend un paramètre quantite qui définit quelle quantité de jus on extrait du citron lorsqu’on le presse.\n\n\n\n\nLa classe peut être vue comme la recette qui permet de créer un objet : elle définit les attributs et les méthodes que possèderont tous les objets définis à partir de cette classe. Définir une classe comme ci-dessus revient simplement à mettre cette recette dans l’environnement Python. Pour créer un objet selon cette classe, il faut l’instancier.\n\ncitron1 = Citron(couleur=\"jaune\", qte_jus=45)\ncitron2 = Citron(couleur=\"vert\", qte_jus=32)\n\nprint(type(citron1))\nprint(type(citron2))\n\n&lt;class '__main__.Citron'&gt;\n&lt;class '__main__.Citron'&gt;\n\n\nOn a ici créé deux instances de la classe Citron. Ces deux instances sont autonomes : Python les voit comme deux objets bien distincts. Ils ont cependant été créés à partir de la même classe et ont donc le même type.\nCette distinction entre la classe et ses instances permet de mieux comprendre la signification du paramètre self. Il s’agit d’une référence aux instances qui vont être créées selon la classe, qui permet de spécifier leurs attributs et leurs méthodes. Lorsqu’on crée une instance donnée, celle-ci devient en quelque sorte le self.\n\n\n\nUn attribut est une variable associée à un objet. Un attribut peut contenir n’importe quel objet Python.\n\n\nUne fois que l’objet est instancié, il est possible d’accéder à ses attributs. La syntaxe est simple : instance.attribut.\n\nprint(citron1.couleur)\nprint(citron2.couleur)\nprint(citron1.jus)\nprint(citron2.jus)\n\njaune\nvert\n45\n32\n\n\nOn voit bien que les deux instances sont autonomes : bien qu’elles soient du même type, leurs attributs diffèrent.\n\n\n\nModifier un attribut d’une instance est très simple, la syntaxe est : instance.attribut = nouvelle_valeur.\n\ncitron2.couleur = \"rouge\"\nprint(citron2.couleur)\n\nrouge\n\n\nIl est également possible d’ajouter un attribut selon la même logique : instance.nouvel_attribut = valeur. Cependant, ce n’est pas une bonne pratique de programmation, la classe servant précisément à définir les attributs que peuvent admettre les objets d’une classe donnée. On préférera donc généralement définir les attributs au sein de la classe plutôt qu’en dehors.\n\n\n\nLes deux instances que nous avons créées permettent d’illustrer les différents types d’attributs :\n\nles attributs de classe. Ce sont les attributs qui ont la même valeur pour toute instance créée selon cette classe. Ici, c’est l’attribut saveur : tous les citrons sont acides, il n’y a donc pas lieu de permettre de modifier ce paramètre lors de l’instanciation. En toute rigueur, on aurait donc même pu définir cet attribut hors du constructeur.\nles attributs d’instance. Ce sont les attributs dont la valeur peut varier entre les différentes instances créées selon une même classe. Ici, ce sont les attributs couleur et jus : il existe des citrons de différentes couleurs, et des citrons plus ou moins gros, qui auront donc des quantités de jus différentes. C’est donc à l’utilisateur de définir ces attributs lors de l’instanciation.\n\n\n\n\n\nUne méthode est une fonction associée à un objet. Elle peut utiliser ses attributs, les modifier, et faire intervenir d’autres méthodes de l’objet.\n\n\nLa syntaxe pour appeler une méthode d’un objet instancié est la suivante : instance.methode(parametres).\n\ncitron1.recup_qte_jus()\n\nIl reste 45 mL de jus dans le citron.\n\n\nOn peut faire deux remarques sur cette syntaxe. La première est qu’une méthode est une fonction attachée à une instance d’un objet. Contrairement aux fonctions définies via l’instruction def, les méthodes n’ont pas d’existence propre en dehors de l’instance de l’objet. Dans notre cas, appeler la fonction recup_qte_jus() indépendamment de l’objet renvoie donc une erreur.\n\nrecup_qte_jus()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 recup_qte_jus()\n\nNameError: name 'recup_qte_jus' is not defined\n\n\n\nLa seconde remarque est qu’on ne spécifie plus le paramètre self lorsqu’on manipule une instance. L’instance est devenue le self (ou plutôt un self) elle-même. Le lien entre la méthode et son instance est déjà fait, puisqu’on ne peut pas utiliser la méthode sans appeler l’instance auparavant.\n\n\n\nTout l’intérêt des méthodes est qu’elles peuvent accéder aux attributs, et ainsi réaliser des opérations à partir de ceux-ci, mais également les modifier. Reprenons notre exemple pour illustrer cette possibilité.\n\ncitron1 = Citron(couleur=\"jaune\", qte_jus=45)\n\ncitron1.recup_qte_jus()\ncitron1.extraire_jus(12)\ncitron1.recup_qte_jus()\n\nIl reste 45 mL de jus dans le citron.\nIl reste 33 mL de jus dans le citron.\n\n\nLa méthode recup_qte_jus permet simplement d’afficher la valeur d’un attribut de manière formattée. La méthode extraire_jus en revanche modifie durablement la valeur de l’attribut jus, ce que montre le second appel à recup_qte_jus.\n\n\n\n\nL’exemple précédent est intéressant car il illustre à la fois un avantage et un inconvénient de la POO.\nLe fait que les objets possèdent des attributs permet de garder en mémoire l’état d’une ressource – dans notre exemple, la quantité de jus contenu dans un objet de classe Citron donné. Pour prendre des exemples plus réalistes, cette propriété est intéressante et utilisée dans plusieurs cas :\n\nl’entraînement d’un modèle de machine-learning. Il est fréquent d’entraîner un modèle une première fois, et de vouloir ensuite continuer l’entraînement plus longtemps, ou bien avec d’autres données. Sauvegarder l’état dans une instance de la classe Modele permet de faire cela. C’est pourquoi la plupart des packages de machine-learning en Python sont fondés sur de la POO.\nle fonctionnement en continu d’une application web. Une telle application doit garder des choses en mémoire pour fournir à l’utilisateur une expérience fluide : le fait que l’utilisateur se soit connecté, son historique, etc. Là encore, la plupart des frameworks web (Django, Flask..) reposent sur de la POO.\n\nDans le même temps, le fait d’utiliser des objets qui gardent en mémoire un état peut limiter la reproductibilité des analyses. Pour illustrer cela, revenons à l’exemple du tutoriel : exécutez plusieurs fois d’affilée la cellule suivante.\n\ncitron1.recup_qte_jus()\ncitron1.extraire_jus(12)\ncitron1.recup_qte_jus()\n\nIl reste 33 mL de jus dans le citron.\nIl reste 21 mL de jus dans le citron.\n\n\nLes trois exécutions donnent des résultats différents, alors que le code exécuté est strictement le même. Cela illustre bien le problème de reproductibilité : lorsqu’on utilise la POO, il faut bien faire attention à l’état des objets qui est conservé en mémoire, au risque de ne pas tomber sur les mêmes résultats lorsqu’on réplique une même analyse.\n\n\n\n\n\n\n1/ “En Python, tout est un objet” : qu’est-ce que cette phrase signifie ?\n2/ A quoi sert l’instruction class ?\n3/ A quoi sert le constructeur __init__ ?\n4/ A quoi sert le self ?\n5/ Quelle est la différence entre une classe et une instance ?\n6/ Qu’est-ce qu’un attribut ?\n7/ Quelle est la différence entre une méthode et une fonction ?\n8/ A quoi voit-on la différence entre un attribut et une méthode lorsqu’on les appelle ?\n9/ Peut-on modifier un attribut avec une méthode ? Peut-on modifier un attribut en dehors d’une méthode ?\n10/ Quand utilise-t-on généralement la POO ?\n\n\n\n\nAfficher la solution\n\n\n1/ Cela signifie que tous les objets Python (nombres, strings, listes, etc..) sont des objets au sens de la POO : ils ont des attributs et des méthodes, qui sont définis par une classe.\n2/ L’instruction class sert à définir une classe d’objets.\n3/ Le constructeur __init__ est un méthode spéciale qui permet à l’utilisateur de définir les attributs d’un objet.\n4/ Le self sert de référence à l’instance au sein de la classe. Il souligne qui va porter les attributs et les méthodes une fois l’objet instancié.\n5/ La classe est la “recette” qui définit toutes les caractéristiques de l’objet. Mais l’objet n’est vraiment créée que lorsque la classe est instanciée, c’est à dire lorsqu’on crée une instance selon cette classe.\n6/ Un attribut est une variable associée à un objet.\n7/ Une méthode est une fonction particulière : elle est associée à un objet et n’existe pas indépendamment de lui.\n8/ La présence de parenthèses permet de différencier l’appel d’un attribut et l’appel d’une méthode. Appel d’un attribut : instance.attribut Appel d’une méthode : instance.methode() avec d’éventuels paramètres.\n9/ Oui, c’est même un des usages principaux des méthodes. Mais on peut également modifier un attribut manuellement.\n10/ Lorsque l’on manipule des objets dont on souhaitent qu’ils conservent l’état d’une ressource au sein d’un programme.\n\n\n\n\n\n\nAdmettons que le jus contenu dans un citron soit une fonction proportionnelle de sa masse, défini de la manière suivante : \\(jus = \\frac {masse} {4}\\) où la masse est en grammes et le jus en mL.\nModifiez la classe Citron, reproduite dans la cellule suivante, de telle sorte que :\n\nlors de l’instanciation, l’utilisateur ne définit plus la quantité de jus, mais la masse du citron\nl’attribut jus est calculé selon la formule ci-dessus\nrajouter une méthode qui affiche “La masse du citron est x grammes.”\n\nInstanciez ensuite un nouveau citron est vérifiez que tout fonctionne comme prévu.\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \n    def recup_qte_jus(self):\n        print(\"Il reste \" + str(self.jus) + \" mL de jus dans le citron.\")\n        \n    def extraire_jus(self, quantite):\n        if quantite &gt; self.jus:\n            print(\"Il n'y a pas assez de jus dans le citron pour la quantité demandée.\")\n        else:\n            self.jus = max(0, self.jus - quantite)  # évite toute valeur négative de `jus`\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nclass Citron:\n\n    def __init__(self, couleur, masse):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.masse = masse\n        self.jus = masse / 4\n        \n    def recup_masse(self):\n        print(\"La masse du citron est \" + str(self.masse) + \" grammes.\")\n        \n    def recup_qte_jus(self):\n        print(\"Il reste \" + str(self.jus) + \" mL de jus dans le citron.\")\n        \n    def extraire_jus(self, quantite):\n        if quantite &gt; self.jus:\n            print(\"Il n'y a pas assez de jus dans le citron pour la quantité demandée.\")\n        else:\n            self.jus = max(0, self.jus - quantite)  # évite toute valeur négative de `jus`\n            \ncitron = Citron(\"jaune\", 500)\n\ncitron.recup_masse()\ncitron.recup_qte_jus()\n\n\n\n\n\nExercice librement inspiré de : https://github.com/Pierian-Data/Complete-Python-3-Bootcamp\nNous avons vu que la POO était particulièrement intéressante lorsque l’on souhaite manipuler des objets qui gardent l’état d’une ressource. C’est par exemple le cas d’un compte bancaire, qui garde un solde et permet ou non certaines opérations en fonction de ce solde.\nImplémenter une classe Compte avec :\n\ndeux attributs : titulaire (nom du client) et solde (solde en euros du compte)\nune méthode affiche_solde qui affiche : “Le solde du compte de nom_client est x euros.”\nune méthode depot qui admet un paramètre montant. Lorsqu’un dépôt est effectué, le solde du compte est incrémenté du montant du dépôt.\nune méthode retrait qui admet un paramètre montant. Lorsqu’un retrait est effectué :\n\nsi le montant est inférieur au solde : le solde est décrémenté du montant, est on affiche “Retrait accepté.”.\nsi le montant est supérieur au solde : on affiche “Retrait refusé : fonds insuffisants.” et le solde est inchangé\n\nune méthode transfert qui admet un paramètre montant et un paramètre destinataire qui admet une autre instance de la classe Compte (i.e. un autre client). Par exemple, client1.transfert(destinataire=client2, montant=1000) a pour effet de :\n\nsi le montant est inférieur au solde de client1 : le solde de client1 est décrémenté du montant, le solde de client2 est incrémenté du montant.\nsi le montant est supérieur au solde de client1 : on affiche “Transfert refusé : fonds insuffisants.” et les soldes des deux clients restent inchangés.\n\n\nCréer deux clients et tester que les différentes fonctionnalités à implémenter marchent comme prévu.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nclass Compte:\n    def __init__(self, titulaire, solde):\n        self.titulaire = titulaire\n        self.solde = solde\n        \n    def affiche_solde(self):\n        print(\"Le solde du compte de \" + self.titulaire + \" est \" + str(self.solde) + \" euros.\")\n        \n    def depot(self, montant):\n        self.solde += montant\n    \n    def retrait(self, montant):\n        if self.solde &gt;= montant:\n            self.solde -= montant\n            print(\"Retrait accepté.\")\n        else:\n            print(\"Retrait refusé : fonds insuffisants.\")\n            \n    def transfert(self, destinataire, montant):\n        if self.solde &gt;= montant:\n            destinataire.solde += montant\n            self.solde -= montant\n        else:\n            print(\"Transfert refusé : fonds insuffisants.\")\n            \nclient1 = Compte(\"Bernard\", 2000)\nclient2 = Compte(\"Bianca\", 5000)\n\nclient1.affiche_solde()\nclient2.affiche_solde()\n\nprint()  # saut de ligne\n\nclient1.depot(1000)\nclient1.affiche_solde() # +1000\n\nprint()\n\nclient2.retrait(6000)\nclient2.affiche_solde() # aucun changement\n\nprint()\n\nclient2.retrait(1000)\nclient2.affiche_solde() # -1000\n\nprint()\n\nclient2.transfert(client1, 5000)\nclient2.affiche_solde() # aucun changement\n\nprint()\n\nclient2.transfert(client1, 2000)\nclient2.affiche_solde() # - 2000\nclient1.affiche_solde() # + 2000",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#la-programmation-orientée-objet",
    "href": "source/fundamentals/oop/tutorial.html#la-programmation-orientée-objet",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "Vous avez peut-être déjà entendu que Python était un langage de “programmation orientée objet”. La POO est un paradigme de programmation qui permet de structurer les programmes autour d’une abstraction, l’objet, qui contient des attributs (caractéristiques de l’objet) et des méthodes (fonctions propres à l’objet) qui agissent sur lui-même. Afin d’illustrer cette définition un peu abstraite , on peut prendre l’exemple (source) d’un objet “citron” qui contient les attributs “saveur” et “couleur”, et une méthode “presser” qui permet d’extraire son jus.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#tout-est-un-objet",
    "href": "source/fundamentals/oop/tutorial.html#tout-est-un-objet",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "En Python, tout est un objet (au sens de la POO). Regardons ce que cela signifie en récupérant le type de différents objets que nous avons vus dans les précédents tutoriels.\n\nprint(type(1))\nprint(type(\"bonjour\"))\nprint(type([]))\nprint(type(()))\nprint(type({}))\n\ndef f(x):\n    print(x)\n          \nprint(type(f))\n\n&lt;class 'int'&gt;\n&lt;class 'str'&gt;\n&lt;class 'list'&gt;\n&lt;class 'tuple'&gt;\n&lt;class 'dict'&gt;\n&lt;class 'function'&gt;\n\n\nCes éléments sont tous de type différent, mais ils ont un point commun : le terme class. De même que l’instruction def définit une fonction, l’instruction class définit une classe d’objets Python. Ainsi, chacun des objets utilisables en Python a une classe qui définit l’objet, ses attributs et ses méthodes.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#définir-ses-propres-objets",
    "href": "source/fundamentals/oop/tutorial.html#définir-ses-propres-objets",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "Regardons comment on peut utiliser l’instruction class pour définir notre objet “citron”.\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \n    def recup_qte_jus(self):\n        print(\"Il reste \" + str(self.jus) + \" mL de jus dans le citron.\")\n        \n    def extraire_jus(self, quantite):\n        if quantite &gt; self.jus:\n            print(\"Il n'y a pas assez de jus dans le citron pour la quantité demandée.\")\n        else:\n            self.jus = max(0, self.jus - quantite)  # évite toute valeur négative de `jus`\n\nAnalysons la syntaxe de construction d’une classe d’objets :\n\nl’instruction class définit la classe d’objets. Différents objets pourront être créés selon le modèle défini par cette classe. Par convention, le nom de la classe doit commencer par une majuscule.\nla classe spécifie un certains nombres de fonctions. Dans ce contexte particulier, on appelle ces fonctions “méthodes” : ce sont des fonctions spécifiques à la classe d’objets définie.\nune première méthode bien spécifique, nommée __init__, est appelée le constructeur. Elle permet de définir les attributs attachés à cette classe d’objets. Il est possible de passer des paramètres à la fonction (comme couleur et qte_jus) pour définir des attributs propres à une instance de l’objet (plus de détails sur cette notion dans la section suivante).\nle constructeur a un paramètre obligatoire : self. C’est une référence aux instances qui vont être créées à partir de cette classe. Notons la syntaxe qui définit un attribut : self.attribut = valeur.\nles autres méthodes sont définies par l’utilisateur. Elles prennent également le self en paramètre, ce qui leur permet d’effectuer des opérations sur / à partir des attributs. Comme ce sont des fonctions, elles peuvent également admettre d’autres paramètres. Ainsi, la fonction extraire_jus prend un paramètre quantite qui définit quelle quantité de jus on extrait du citron lorsqu’on le presse.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#la-classe-et-ses-instances",
    "href": "source/fundamentals/oop/tutorial.html#la-classe-et-ses-instances",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "La classe peut être vue comme la recette qui permet de créer un objet : elle définit les attributs et les méthodes que possèderont tous les objets définis à partir de cette classe. Définir une classe comme ci-dessus revient simplement à mettre cette recette dans l’environnement Python. Pour créer un objet selon cette classe, il faut l’instancier.\n\ncitron1 = Citron(couleur=\"jaune\", qte_jus=45)\ncitron2 = Citron(couleur=\"vert\", qte_jus=32)\n\nprint(type(citron1))\nprint(type(citron2))\n\n&lt;class '__main__.Citron'&gt;\n&lt;class '__main__.Citron'&gt;\n\n\nOn a ici créé deux instances de la classe Citron. Ces deux instances sont autonomes : Python les voit comme deux objets bien distincts. Ils ont cependant été créés à partir de la même classe et ont donc le même type.\nCette distinction entre la classe et ses instances permet de mieux comprendre la signification du paramètre self. Il s’agit d’une référence aux instances qui vont être créées selon la classe, qui permet de spécifier leurs attributs et leurs méthodes. Lorsqu’on crée une instance donnée, celle-ci devient en quelque sorte le self.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#attributs",
    "href": "source/fundamentals/oop/tutorial.html#attributs",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "Un attribut est une variable associée à un objet. Un attribut peut contenir n’importe quel objet Python.\n\n\nUne fois que l’objet est instancié, il est possible d’accéder à ses attributs. La syntaxe est simple : instance.attribut.\n\nprint(citron1.couleur)\nprint(citron2.couleur)\nprint(citron1.jus)\nprint(citron2.jus)\n\njaune\nvert\n45\n32\n\n\nOn voit bien que les deux instances sont autonomes : bien qu’elles soient du même type, leurs attributs diffèrent.\n\n\n\nModifier un attribut d’une instance est très simple, la syntaxe est : instance.attribut = nouvelle_valeur.\n\ncitron2.couleur = \"rouge\"\nprint(citron2.couleur)\n\nrouge\n\n\nIl est également possible d’ajouter un attribut selon la même logique : instance.nouvel_attribut = valeur. Cependant, ce n’est pas une bonne pratique de programmation, la classe servant précisément à définir les attributs que peuvent admettre les objets d’une classe donnée. On préférera donc généralement définir les attributs au sein de la classe plutôt qu’en dehors.\n\n\n\nLes deux instances que nous avons créées permettent d’illustrer les différents types d’attributs :\n\nles attributs de classe. Ce sont les attributs qui ont la même valeur pour toute instance créée selon cette classe. Ici, c’est l’attribut saveur : tous les citrons sont acides, il n’y a donc pas lieu de permettre de modifier ce paramètre lors de l’instanciation. En toute rigueur, on aurait donc même pu définir cet attribut hors du constructeur.\nles attributs d’instance. Ce sont les attributs dont la valeur peut varier entre les différentes instances créées selon une même classe. Ici, ce sont les attributs couleur et jus : il existe des citrons de différentes couleurs, et des citrons plus ou moins gros, qui auront donc des quantités de jus différentes. C’est donc à l’utilisateur de définir ces attributs lors de l’instanciation.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#méthodes",
    "href": "source/fundamentals/oop/tutorial.html#méthodes",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "Une méthode est une fonction associée à un objet. Elle peut utiliser ses attributs, les modifier, et faire intervenir d’autres méthodes de l’objet.\n\n\nLa syntaxe pour appeler une méthode d’un objet instancié est la suivante : instance.methode(parametres).\n\ncitron1.recup_qte_jus()\n\nIl reste 45 mL de jus dans le citron.\n\n\nOn peut faire deux remarques sur cette syntaxe. La première est qu’une méthode est une fonction attachée à une instance d’un objet. Contrairement aux fonctions définies via l’instruction def, les méthodes n’ont pas d’existence propre en dehors de l’instance de l’objet. Dans notre cas, appeler la fonction recup_qte_jus() indépendamment de l’objet renvoie donc une erreur.\n\nrecup_qte_jus()\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 recup_qte_jus()\n\nNameError: name 'recup_qte_jus' is not defined\n\n\n\nLa seconde remarque est qu’on ne spécifie plus le paramètre self lorsqu’on manipule une instance. L’instance est devenue le self (ou plutôt un self) elle-même. Le lien entre la méthode et son instance est déjà fait, puisqu’on ne peut pas utiliser la méthode sans appeler l’instance auparavant.\n\n\n\nTout l’intérêt des méthodes est qu’elles peuvent accéder aux attributs, et ainsi réaliser des opérations à partir de ceux-ci, mais également les modifier. Reprenons notre exemple pour illustrer cette possibilité.\n\ncitron1 = Citron(couleur=\"jaune\", qte_jus=45)\n\ncitron1.recup_qte_jus()\ncitron1.extraire_jus(12)\ncitron1.recup_qte_jus()\n\nIl reste 45 mL de jus dans le citron.\nIl reste 33 mL de jus dans le citron.\n\n\nLa méthode recup_qte_jus permet simplement d’afficher la valeur d’un attribut de manière formattée. La méthode extraire_jus en revanche modifie durablement la valeur de l’attribut jus, ce que montre le second appel à recup_qte_jus.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#quand-utilise-t-on-la-poo",
    "href": "source/fundamentals/oop/tutorial.html#quand-utilise-t-on-la-poo",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "L’exemple précédent est intéressant car il illustre à la fois un avantage et un inconvénient de la POO.\nLe fait que les objets possèdent des attributs permet de garder en mémoire l’état d’une ressource – dans notre exemple, la quantité de jus contenu dans un objet de classe Citron donné. Pour prendre des exemples plus réalistes, cette propriété est intéressante et utilisée dans plusieurs cas :\n\nl’entraînement d’un modèle de machine-learning. Il est fréquent d’entraîner un modèle une première fois, et de vouloir ensuite continuer l’entraînement plus longtemps, ou bien avec d’autres données. Sauvegarder l’état dans une instance de la classe Modele permet de faire cela. C’est pourquoi la plupart des packages de machine-learning en Python sont fondés sur de la POO.\nle fonctionnement en continu d’une application web. Une telle application doit garder des choses en mémoire pour fournir à l’utilisateur une expérience fluide : le fait que l’utilisateur se soit connecté, son historique, etc. Là encore, la plupart des frameworks web (Django, Flask..) reposent sur de la POO.\n\nDans le même temps, le fait d’utiliser des objets qui gardent en mémoire un état peut limiter la reproductibilité des analyses. Pour illustrer cela, revenons à l’exemple du tutoriel : exécutez plusieurs fois d’affilée la cellule suivante.\n\ncitron1.recup_qte_jus()\ncitron1.extraire_jus(12)\ncitron1.recup_qte_jus()\n\nIl reste 33 mL de jus dans le citron.\nIl reste 21 mL de jus dans le citron.\n\n\nLes trois exécutions donnent des résultats différents, alors que le code exécuté est strictement le même. Cela illustre bien le problème de reproductibilité : lorsqu’on utilise la POO, il faut bien faire attention à l’état des objets qui est conservé en mémoire, au risque de ne pas tomber sur les mêmes résultats lorsqu’on réplique une même analyse.",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "source/fundamentals/oop/tutorial.html#exercices",
    "href": "source/fundamentals/oop/tutorial.html#exercices",
    "title": "Notions de programmation orientée objet",
    "section": "",
    "text": "1/ “En Python, tout est un objet” : qu’est-ce que cette phrase signifie ?\n2/ A quoi sert l’instruction class ?\n3/ A quoi sert le constructeur __init__ ?\n4/ A quoi sert le self ?\n5/ Quelle est la différence entre une classe et une instance ?\n6/ Qu’est-ce qu’un attribut ?\n7/ Quelle est la différence entre une méthode et une fonction ?\n8/ A quoi voit-on la différence entre un attribut et une méthode lorsqu’on les appelle ?\n9/ Peut-on modifier un attribut avec une méthode ? Peut-on modifier un attribut en dehors d’une méthode ?\n10/ Quand utilise-t-on généralement la POO ?\n\n\n\n\nAfficher la solution\n\n\n1/ Cela signifie que tous les objets Python (nombres, strings, listes, etc..) sont des objets au sens de la POO : ils ont des attributs et des méthodes, qui sont définis par une classe.\n2/ L’instruction class sert à définir une classe d’objets.\n3/ Le constructeur __init__ est un méthode spéciale qui permet à l’utilisateur de définir les attributs d’un objet.\n4/ Le self sert de référence à l’instance au sein de la classe. Il souligne qui va porter les attributs et les méthodes une fois l’objet instancié.\n5/ La classe est la “recette” qui définit toutes les caractéristiques de l’objet. Mais l’objet n’est vraiment créée que lorsque la classe est instanciée, c’est à dire lorsqu’on crée une instance selon cette classe.\n6/ Un attribut est une variable associée à un objet.\n7/ Une méthode est une fonction particulière : elle est associée à un objet et n’existe pas indépendamment de lui.\n8/ La présence de parenthèses permet de différencier l’appel d’un attribut et l’appel d’une méthode. Appel d’un attribut : instance.attribut Appel d’une méthode : instance.methode() avec d’éventuels paramètres.\n9/ Oui, c’est même un des usages principaux des méthodes. Mais on peut également modifier un attribut manuellement.\n10/ Lorsque l’on manipule des objets dont on souhaitent qu’ils conservent l’état d’une ressource au sein d’un programme.\n\n\n\n\n\n\nAdmettons que le jus contenu dans un citron soit une fonction proportionnelle de sa masse, défini de la manière suivante : \\(jus = \\frac {masse} {4}\\) où la masse est en grammes et le jus en mL.\nModifiez la classe Citron, reproduite dans la cellule suivante, de telle sorte que :\n\nlors de l’instanciation, l’utilisateur ne définit plus la quantité de jus, mais la masse du citron\nl’attribut jus est calculé selon la formule ci-dessus\nrajouter une méthode qui affiche “La masse du citron est x grammes.”\n\nInstanciez ensuite un nouveau citron est vérifiez que tout fonctionne comme prévu.\n\nclass Citron:\n\n    def __init__(self, couleur, qte_jus):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.jus = qte_jus\n        \n    def recup_qte_jus(self):\n        print(\"Il reste \" + str(self.jus) + \" mL de jus dans le citron.\")\n        \n    def extraire_jus(self, quantite):\n        if quantite &gt; self.jus:\n            print(\"Il n'y a pas assez de jus dans le citron pour la quantité demandée.\")\n        else:\n            self.jus = max(0, self.jus - quantite)  # évite toute valeur négative de `jus`\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nclass Citron:\n\n    def __init__(self, couleur, masse):\n        self.saveur = \"acide\"\n        self.couleur = couleur\n        self.masse = masse\n        self.jus = masse / 4\n        \n    def recup_masse(self):\n        print(\"La masse du citron est \" + str(self.masse) + \" grammes.\")\n        \n    def recup_qte_jus(self):\n        print(\"Il reste \" + str(self.jus) + \" mL de jus dans le citron.\")\n        \n    def extraire_jus(self, quantite):\n        if quantite &gt; self.jus:\n            print(\"Il n'y a pas assez de jus dans le citron pour la quantité demandée.\")\n        else:\n            self.jus = max(0, self.jus - quantite)  # évite toute valeur négative de `jus`\n            \ncitron = Citron(\"jaune\", 500)\n\ncitron.recup_masse()\ncitron.recup_qte_jus()\n\n\n\n\n\nExercice librement inspiré de : https://github.com/Pierian-Data/Complete-Python-3-Bootcamp\nNous avons vu que la POO était particulièrement intéressante lorsque l’on souhaite manipuler des objets qui gardent l’état d’une ressource. C’est par exemple le cas d’un compte bancaire, qui garde un solde et permet ou non certaines opérations en fonction de ce solde.\nImplémenter une classe Compte avec :\n\ndeux attributs : titulaire (nom du client) et solde (solde en euros du compte)\nune méthode affiche_solde qui affiche : “Le solde du compte de nom_client est x euros.”\nune méthode depot qui admet un paramètre montant. Lorsqu’un dépôt est effectué, le solde du compte est incrémenté du montant du dépôt.\nune méthode retrait qui admet un paramètre montant. Lorsqu’un retrait est effectué :\n\nsi le montant est inférieur au solde : le solde est décrémenté du montant, est on affiche “Retrait accepté.”.\nsi le montant est supérieur au solde : on affiche “Retrait refusé : fonds insuffisants.” et le solde est inchangé\n\nune méthode transfert qui admet un paramètre montant et un paramètre destinataire qui admet une autre instance de la classe Compte (i.e. un autre client). Par exemple, client1.transfert(destinataire=client2, montant=1000) a pour effet de :\n\nsi le montant est inférieur au solde de client1 : le solde de client1 est décrémenté du montant, le solde de client2 est incrémenté du montant.\nsi le montant est supérieur au solde de client1 : on affiche “Transfert refusé : fonds insuffisants.” et les soldes des deux clients restent inchangés.\n\n\nCréer deux clients et tester que les différentes fonctionnalités à implémenter marchent comme prévu.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nclass Compte:\n    def __init__(self, titulaire, solde):\n        self.titulaire = titulaire\n        self.solde = solde\n        \n    def affiche_solde(self):\n        print(\"Le solde du compte de \" + self.titulaire + \" est \" + str(self.solde) + \" euros.\")\n        \n    def depot(self, montant):\n        self.solde += montant\n    \n    def retrait(self, montant):\n        if self.solde &gt;= montant:\n            self.solde -= montant\n            print(\"Retrait accepté.\")\n        else:\n            print(\"Retrait refusé : fonds insuffisants.\")\n            \n    def transfert(self, destinataire, montant):\n        if self.solde &gt;= montant:\n            destinataire.solde += montant\n            self.solde -= montant\n        else:\n            print(\"Transfert refusé : fonds insuffisants.\")\n            \nclient1 = Compte(\"Bernard\", 2000)\nclient2 = Compte(\"Bianca\", 5000)\n\nclient1.affiche_solde()\nclient2.affiche_solde()\n\nprint()  # saut de ligne\n\nclient1.depot(1000)\nclient1.affiche_solde() # +1000\n\nprint()\n\nclient2.retrait(6000)\nclient2.affiche_solde() # aucun changement\n\nprint()\n\nclient2.retrait(1000)\nclient2.affiche_solde() # -1000\n\nprint()\n\nclient2.transfert(client1, 5000)\nclient2.affiche_solde() # aucun changement\n\nprint()\n\nclient2.transfert(client1, 2000)\nclient2.affiche_solde() # - 2000\nclient1.affiche_solde() # + 2000",
    "crumbs": [
      "Fondamentaux du langage",
      "Notions de programmation orientée objet"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Formation d’initiation à Python dans le SSP",
    "section": "",
    "text": "La formation SSPy propose une introduction à l’utilisation de Python dans le cadre des projet statistiques. Elle est particulièrement pensée pour les agents du service statistique public (SSP), avec des applications faisant intervenir dans la mesure du possible des données issues de la statistique publique française. Néanmoins, ses supports sont complètement open-source (dépôt GitHub) et elle peut donc être ré-utilisée dans n’importe quel cadre de formation à Python.\n\n\n\nPython, créé par le développeur néerlandais Guido van Rossum en 1991, est un langage de programmation dit de haut niveau connu pour sa syntaxe simple et lisible. Les principes fondateurs du langage sont résumés dans un manifeste appelé “Zen de Python”. Python est un langage particulièrement versatile, dans la mesure où il dispose d’une riche bibliothèque de packages et fédère des communautés diverses, le rendant idéal pour de nombreux domaines d’application.\n\n\n\nMalgré déjà plus de 30 années d’existence, Python reste un langage extrêmement dynamique. Plus que cela : non seulement fait-il déjà partie des langages les plus populaires, mais il est également celui qui connaît la plus forte croissance en termes de nombre d’utilisateurs d’année en année.\n\n\n\n\n\nUne des principales raison de cette forte croissance actuelle est la montée en puissance du domaine de la data science, au sein duquel Python s’est progressivement imposé comme le langage central. De nombreuses librairies phares dans le domaine de la manipulation de données, de la datavisualisation, du machine learning et du déploiement applicatif sont disponibles en Python. Cette adoption croissante dans divers secteurs en fait un choix privilégié pour unifier les pratiques via un langage commun, s’appliquant aussi bien aux métiers de la data science, au développement, qu’à la production informatique et statistique.\n\n\n\n\n\nSource : josephsalmon.eu\n\n\n\nPython et R sont souvent comparés en raison de leur large utilisation dans le domaine statistique. La différence fondamentale est que Python est un langage généraliste, tandis que R est spécifiquement orienté vers les statistiques. Néanmoins, en pratique, ils sont plutôt complémentaires que concurrents, et le choix entre les deux va souvent dépendre du cas d’usage : par exemple, là où l’écosystème du tidyverse en R n’a sans doute pas d’égal pour la manipulation de données, l’écosystème qui s’est développé en Python autour des techniques de machine learning (en particulier le package scikit-learn) ne possède pas d’équivalent direct dans le monde R. Enfin, les deux langages se ressemblent et la transition d’un langage à l’autre est donc accessible sans nécessiter un ré-apprentissage complet et coûteux.\n\n\n\n\n\n\nCette formation adopte un format d’e-formation tutorée. Elle se déroule sur une période étendue (plusieurs mois), avec un accent mis sur la pédagogie pratique. Un tutorat est également disponible via un Canal Tchap, où les participants peuvent poser leurs questions en continu, ainsi que lors de sessions de visioconférence périodiques.\n\n\n\nLa formation est hébergée sur la plateforme SSP Cloud développée par l’Insee. Cette plateforme, dédiée à l’expérimentation autour de la data science et au travail sur des données ouvertes, offre un environnement particulièrement adapté à la formation avec des environnements pré-configurés disposant de toute la puissance de calcul nécessaire à des traitements statistiques courants et innovants.\n\n\n\nLe programme de la formation est divisé en trois grandes parties :\n\nfondamentaux du langage Python : types de base, structures de données, instructions conditionnelles, fonctions, et une introduction à la programmation orientée-objet en Python ;\nmanipulation de données : manipulation de fichiers, travail avec des fichiers CSV et JSON, calcul numérique avec NumPy, traitement des données tabulaires avec Pandas, et une introduction à la visualisation de données en Python ;\nprojets d’application : construction d’un jeu de Puissance 4, prédictions météorologiques à l’aide de données issues d’API, et analyse du recensement de la population.\n\nChaque chapitre se termine sur une série d’exercices guidés qui visent à mettre en application directe les concepts étudiés dans le chapitre. Les projets d’application sont quant à eux plus exploratoires, et visent à mettre en application les concepts étudiés tout au long de la formation sur des cas d’usage réalistes.\n\n\n\n\n\n\nLes différents chapitres peuvent être lancés en un clic depuis l’espace formation du SSP Cloud. Lancer un chapitre revient à lancer un service jupyter-python sur le SSP Cloud, pré-configuré pour la formation et qui va s’ouvrir directement sur le notebook associé au chapitre.\n\n\n\n\n\n\n\n\n\n\nLa formation utilise le format de notebook interactif Jupyter, combinant du texte au format Markdown, du code Python, et du code HTML pour les visualisations et animations. Ce format est particulièrement adapté à la formation et aux phases d’expérimentation. Il permet par ailleurs de publier simplement à la fois les notebooks d’exercices et le site associé au cours.\n\n\n\n\n\n\n\n\nLa base du notebook est le kernel, visible en haut à droite (Python 3 (ipykernel)) et qui se lance automatiquement à l’ouverture d’un notebook. Concrètement, il s’agit d’un interpréteur Python qui tourne en continu en arrière-plan et qui permet d’exécuter dynamiquement des cellules de code Python. Ainsi, les objets créés dans une cellule sont persistés et peuvent être appelés dans une autre cellule, ce qui permet une exécution linéaire du notebook comme un script. Lorsque l’on souhaite nettoyer l’environnement de travail de tous les objets créés lors de la session, on peut le redémarrer (menu Kernel -&gt; Restart Kernel).\nLes cellules grisées correspondent aux cellules de code. Pour exécuter le contenu d’une cellule, il suffit de cliquer dessus puis d’utiliser les raccourcis clavier Ctrl + Entrée (exécute la cellule et reste sur la cellule active) ou Shift + Entrée (exécute la cellule et passe à la cellule suivante). Attention, exécuter une cellule revient à exécuter l’ensemble de son contenu. Si l’on souhaite exécuter ligne à ligne, on peut créer des nouvelles cellules (bouton ➕) et y insérer les différentes lignes de code. D’autres éditeurs de code (comme VSCode, disponible sur le SSP Cloud) permettent, comme RStudio par exemple, d’exécuter du code ligne à ligne, mais ils sont moins adaptés à la découverte de Python.\n\n\n\n\nLa survenue d’erreurs est tout à fait naturelle et attendue lors de l’apprentissage (et même après !) d’un langage informatique. La résolution de ces erreurs est vraiment l’occasion de comprendre comment fonctionne le langage et de devenir autonome dans sa pratique de celui-ci. Voici une proposition d’étapes à suivre (dans cet ordre) pour résoudre une erreur :\n\n1/ Bien lire les logs, i.e. les sorties renvoyées par Python en cas d’erreur. Souvent, elles sont informatives et peuvent contenir directement la réponse.\n2/ Chercher sur internet (de préférence en Anglais et sur Google). Par exemple, donner le nom de l’erreur et une partie informative du message d’erreur renvoyé par Python permet généralement de bien orienter les résultats vers ce que l’on cherche.\n3/ Souvent, la recherche amènera vers le forum Stackoverflow, destiné à cet usage. Si l’on ne trouve vraiment pas la réponse à son problème, on peut poster sur Stackoverflow en détaillant bien le problème rencontré de sorte à ce que les utilisateurs du forum puissent le reproduire et trouver une solution.\n4/ Les documentations officielles (de Python et des différents packages) sont souvent un peu arides, mais généralement exhaustives. Elles permettent notamment de bien comprendre la manière d’utiliser les différents objets. Par exemple pour les fonctions : ce qu’elles attendent en entrée, les paramètres et leur type, ce qu’elles renvoient en sortie, etc.\n\n\n\n\n\n\n\nTous les supports de formation restent accessibles sur le SSP Cloud après la formation. Le code qui génère les supports est disponible sur GitHub.\n\n\n\nPour approfondir sa connaissance du langage Python après cette formation d’introduction, rien de tel que la mise en pratique sur des sujets concrets ! Pour les modalités d’utilisation de Python dans le cadre des projets statistiques, cela va dépendre de l’organisation :\n\npour des projets open-data et inter-administrations, le SSP Cloud est une bonne alternative dans la mesure où les services Python y sont déjà pré-configurés et où un service de stockage de données y est proposé (cf. documentation pour plus de détails) ;\npour des projets internes à l’Insee, se référer à la documentation sur l’utilisation de Python en interne ;\npour des projets internes à d’autres administrations, se rapprocher de sa DSI pour connaître les modalités d’utilisation recommandées.\n\n\n\n\nLa suite “naturelle” de cette formation est le cours de Python pour la data science donné par Lino Galiana à l’ENSAE, également déployé dans l’espace formation du SSP Cloud. Le cours reprend là où cette formation s’arrête, et dresse un panorama très complet des différentes méthodes de data science qui peuvent être mobilisées en Python.\nPour approfondir l’approche plus algorithmique du code, l’Advent of Code propose, chaque mois de Décembre, un exercice par jour sous forme d’énigmes en deux parties, qui impliquent une résolution algorithmique. C’est une très bonne opportunité de développer à la fois ses réflexes algorithmiques et sa connaissance de Python. Attention : si les premiers jours restent accessibles, la difficulté des énigmes devient rapidement assez élevée.\n\n\n\n\nDeux canaux de contact sont disponibles :\n\npour les demandes pratiques liées à l’exécution de la formation : le Canal Tchap associé à la formation ;\npour toute autre demande : innovation@insee.fr"
  },
  {
    "objectID": "index.html#contexte",
    "href": "index.html#contexte",
    "title": "Formation d’initiation à Python dans le SSP",
    "section": "",
    "text": "La formation SSPy propose une introduction à l’utilisation de Python dans le cadre des projet statistiques. Elle est particulièrement pensée pour les agents du service statistique public (SSP), avec des applications faisant intervenir dans la mesure du possible des données issues de la statistique publique française. Néanmoins, ses supports sont complètement open-source (dépôt GitHub) et elle peut donc être ré-utilisée dans n’importe quel cadre de formation à Python.\n\n\n\nPython, créé par le développeur néerlandais Guido van Rossum en 1991, est un langage de programmation dit de haut niveau connu pour sa syntaxe simple et lisible. Les principes fondateurs du langage sont résumés dans un manifeste appelé “Zen de Python”. Python est un langage particulièrement versatile, dans la mesure où il dispose d’une riche bibliothèque de packages et fédère des communautés diverses, le rendant idéal pour de nombreux domaines d’application.\n\n\n\nMalgré déjà plus de 30 années d’existence, Python reste un langage extrêmement dynamique. Plus que cela : non seulement fait-il déjà partie des langages les plus populaires, mais il est également celui qui connaît la plus forte croissance en termes de nombre d’utilisateurs d’année en année.\n\n\n\n\n\nUne des principales raison de cette forte croissance actuelle est la montée en puissance du domaine de la data science, au sein duquel Python s’est progressivement imposé comme le langage central. De nombreuses librairies phares dans le domaine de la manipulation de données, de la datavisualisation, du machine learning et du déploiement applicatif sont disponibles en Python. Cette adoption croissante dans divers secteurs en fait un choix privilégié pour unifier les pratiques via un langage commun, s’appliquant aussi bien aux métiers de la data science, au développement, qu’à la production informatique et statistique.\n\n\n\n\n\nSource : josephsalmon.eu\n\n\n\nPython et R sont souvent comparés en raison de leur large utilisation dans le domaine statistique. La différence fondamentale est que Python est un langage généraliste, tandis que R est spécifiquement orienté vers les statistiques. Néanmoins, en pratique, ils sont plutôt complémentaires que concurrents, et le choix entre les deux va souvent dépendre du cas d’usage : par exemple, là où l’écosystème du tidyverse en R n’a sans doute pas d’égal pour la manipulation de données, l’écosystème qui s’est développé en Python autour des techniques de machine learning (en particulier le package scikit-learn) ne possède pas d’équivalent direct dans le monde R. Enfin, les deux langages se ressemblent et la transition d’un langage à l’autre est donc accessible sans nécessiter un ré-apprentissage complet et coûteux."
  },
  {
    "objectID": "index.html#modalités-de-formation",
    "href": "index.html#modalités-de-formation",
    "title": "Formation d’initiation à Python dans le SSP",
    "section": "",
    "text": "Cette formation adopte un format d’e-formation tutorée. Elle se déroule sur une période étendue (plusieurs mois), avec un accent mis sur la pédagogie pratique. Un tutorat est également disponible via un Canal Tchap, où les participants peuvent poser leurs questions en continu, ainsi que lors de sessions de visioconférence périodiques.\n\n\n\nLa formation est hébergée sur la plateforme SSP Cloud développée par l’Insee. Cette plateforme, dédiée à l’expérimentation autour de la data science et au travail sur des données ouvertes, offre un environnement particulièrement adapté à la formation avec des environnements pré-configurés disposant de toute la puissance de calcul nécessaire à des traitements statistiques courants et innovants.\n\n\n\nLe programme de la formation est divisé en trois grandes parties :\n\nfondamentaux du langage Python : types de base, structures de données, instructions conditionnelles, fonctions, et une introduction à la programmation orientée-objet en Python ;\nmanipulation de données : manipulation de fichiers, travail avec des fichiers CSV et JSON, calcul numérique avec NumPy, traitement des données tabulaires avec Pandas, et une introduction à la visualisation de données en Python ;\nprojets d’application : construction d’un jeu de Puissance 4, prédictions météorologiques à l’aide de données issues d’API, et analyse du recensement de la population.\n\nChaque chapitre se termine sur une série d’exercices guidés qui visent à mettre en application directe les concepts étudiés dans le chapitre. Les projets d’application sont quant à eux plus exploratoires, et visent à mettre en application les concepts étudiés tout au long de la formation sur des cas d’usage réalistes."
  },
  {
    "objectID": "index.html#en-pratique",
    "href": "index.html#en-pratique",
    "title": "Formation d’initiation à Python dans le SSP",
    "section": "",
    "text": "Les différents chapitres peuvent être lancés en un clic depuis l’espace formation du SSP Cloud. Lancer un chapitre revient à lancer un service jupyter-python sur le SSP Cloud, pré-configuré pour la formation et qui va s’ouvrir directement sur le notebook associé au chapitre.\n\n\n\n\n\n\n\n\n\n\nLa formation utilise le format de notebook interactif Jupyter, combinant du texte au format Markdown, du code Python, et du code HTML pour les visualisations et animations. Ce format est particulièrement adapté à la formation et aux phases d’expérimentation. Il permet par ailleurs de publier simplement à la fois les notebooks d’exercices et le site associé au cours.\n\n\n\n\n\n\n\n\nLa base du notebook est le kernel, visible en haut à droite (Python 3 (ipykernel)) et qui se lance automatiquement à l’ouverture d’un notebook. Concrètement, il s’agit d’un interpréteur Python qui tourne en continu en arrière-plan et qui permet d’exécuter dynamiquement des cellules de code Python. Ainsi, les objets créés dans une cellule sont persistés et peuvent être appelés dans une autre cellule, ce qui permet une exécution linéaire du notebook comme un script. Lorsque l’on souhaite nettoyer l’environnement de travail de tous les objets créés lors de la session, on peut le redémarrer (menu Kernel -&gt; Restart Kernel).\nLes cellules grisées correspondent aux cellules de code. Pour exécuter le contenu d’une cellule, il suffit de cliquer dessus puis d’utiliser les raccourcis clavier Ctrl + Entrée (exécute la cellule et reste sur la cellule active) ou Shift + Entrée (exécute la cellule et passe à la cellule suivante). Attention, exécuter une cellule revient à exécuter l’ensemble de son contenu. Si l’on souhaite exécuter ligne à ligne, on peut créer des nouvelles cellules (bouton ➕) et y insérer les différentes lignes de code. D’autres éditeurs de code (comme VSCode, disponible sur le SSP Cloud) permettent, comme RStudio par exemple, d’exécuter du code ligne à ligne, mais ils sont moins adaptés à la découverte de Python.\n\n\n\n\nLa survenue d’erreurs est tout à fait naturelle et attendue lors de l’apprentissage (et même après !) d’un langage informatique. La résolution de ces erreurs est vraiment l’occasion de comprendre comment fonctionne le langage et de devenir autonome dans sa pratique de celui-ci. Voici une proposition d’étapes à suivre (dans cet ordre) pour résoudre une erreur :\n\n1/ Bien lire les logs, i.e. les sorties renvoyées par Python en cas d’erreur. Souvent, elles sont informatives et peuvent contenir directement la réponse.\n2/ Chercher sur internet (de préférence en Anglais et sur Google). Par exemple, donner le nom de l’erreur et une partie informative du message d’erreur renvoyé par Python permet généralement de bien orienter les résultats vers ce que l’on cherche.\n3/ Souvent, la recherche amènera vers le forum Stackoverflow, destiné à cet usage. Si l’on ne trouve vraiment pas la réponse à son problème, on peut poster sur Stackoverflow en détaillant bien le problème rencontré de sorte à ce que les utilisateurs du forum puissent le reproduire et trouver une solution.\n4/ Les documentations officielles (de Python et des différents packages) sont souvent un peu arides, mais généralement exhaustives. Elles permettent notamment de bien comprendre la manière d’utiliser les différents objets. Par exemple pour les fonctions : ce qu’elles attendent en entrée, les paramètres et leur type, ce qu’elles renvoient en sortie, etc."
  },
  {
    "objectID": "index.html#et-après-la-formation",
    "href": "index.html#et-après-la-formation",
    "title": "Formation d’initiation à Python dans le SSP",
    "section": "",
    "text": "Tous les supports de formation restent accessibles sur le SSP Cloud après la formation. Le code qui génère les supports est disponible sur GitHub.\n\n\n\nPour approfondir sa connaissance du langage Python après cette formation d’introduction, rien de tel que la mise en pratique sur des sujets concrets ! Pour les modalités d’utilisation de Python dans le cadre des projets statistiques, cela va dépendre de l’organisation :\n\npour des projets open-data et inter-administrations, le SSP Cloud est une bonne alternative dans la mesure où les services Python y sont déjà pré-configurés et où un service de stockage de données y est proposé (cf. documentation pour plus de détails) ;\npour des projets internes à l’Insee, se référer à la documentation sur l’utilisation de Python en interne ;\npour des projets internes à d’autres administrations, se rapprocher de sa DSI pour connaître les modalités d’utilisation recommandées.\n\n\n\n\nLa suite “naturelle” de cette formation est le cours de Python pour la data science donné par Lino Galiana à l’ENSAE, également déployé dans l’espace formation du SSP Cloud. Le cours reprend là où cette formation s’arrête, et dresse un panorama très complet des différentes méthodes de data science qui peuvent être mobilisées en Python.\nPour approfondir l’approche plus algorithmique du code, l’Advent of Code propose, chaque mois de Décembre, un exercice par jour sous forme d’énigmes en deux parties, qui impliquent une résolution algorithmique. C’est une très bonne opportunité de développer à la fois ses réflexes algorithmiques et sa connaissance de Python. Attention : si les premiers jours restent accessibles, la difficulté des énigmes devient rapidement assez élevée."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Formation d’initiation à Python dans le SSP",
    "section": "",
    "text": "Deux canaux de contact sont disponibles :\n\npour les demandes pratiques liées à l’exécution de la formation : le Canal Tchap associé à la formation ;\npour toute autre demande : innovation@insee.fr"
  },
  {
    "objectID": "slides/index.html#python-en-résumé",
    "href": "slides/index.html#python-en-résumé",
    "title": "Introduction à Python",
    "section": "Python en résumé",
    "text": "Python en résumé\n\nCréé par Guido van Rossum en 1991\nLangage de haut-niveau\n\nSyntaxe simple et lisible\nPrincipes : “Zen de Python”\n\nLangage puissant\n\nVersatile : riche bibliothèque de packages\nFédère des communautés diverses"
  },
  {
    "objectID": "slides/index.html#pourquoi-se-former-à-python",
    "href": "slides/index.html#pourquoi-se-former-à-python",
    "title": "Introduction à Python",
    "section": "Pourquoi se former à Python ?",
    "text": "Pourquoi se former à Python ?\n\nUn langage extrêmement dynamique"
  },
  {
    "objectID": "slides/index.html#pourquoi-se-former-à-python-1",
    "href": "slides/index.html#pourquoi-se-former-à-python-1",
    "title": "Introduction à Python",
    "section": "Pourquoi se former à Python ?",
    "text": "Pourquoi se former à Python ?\n\nLangage central de l’écosystème data science\n\n\n\n\n\n\nSource : josephsalmon.eu"
  },
  {
    "objectID": "slides/index.html#pourquoi-se-former-à-python-2",
    "href": "slides/index.html#pourquoi-se-former-à-python-2",
    "title": "Introduction à Python",
    "section": "Pourquoi se former à Python ?",
    "text": "Pourquoi se former à Python ?\n\nUnifier les pratiques via un langage commun ?\n\nMétier : application des méthodes de data science\nDéveloppement : frameworks de développement applicatif\nProduction : adapté à la production informatique"
  },
  {
    "objectID": "slides/index.html#python-vs.-r",
    "href": "slides/index.html#python-vs.-r",
    "title": "Introduction à Python",
    "section": "Python vs. R ?",
    "text": "Python vs. R ?\n\nDifférence fondamentale\n\nR : langage statistique\nPython : langage généraliste\n\nPlutôt complémentaires que concurrents\n\nPréférer l’un ou l’autre selon le cas d’usage\n\nTransition d’un langage à l’autre accessible"
  },
  {
    "objectID": "slides/index.html#une-e-formation-tutorée",
    "href": "slides/index.html#une-e-formation-tutorée",
    "title": "Introduction à Python",
    "section": "Une “e-formation tutorée”",
    "text": "Une “e-formation tutorée”\n\nE-formation\n\nFormation sur un temps long\nPédagogie par la pratique\n\nTutorat\n\nCanal Tchap : pour poser toutes vos questions en continu\nVisio périodique (dates à définir) : questions de fond, déroulement pas à pas.."
  },
  {
    "objectID": "slides/index.html#hébergée-sur-le-ssp-cloud",
    "href": "slides/index.html#hébergée-sur-le-ssp-cloud",
    "title": "Introduction à Python",
    "section": "Hébergée sur le SSP Cloud",
    "text": "Hébergée sur le SSP Cloud\n\nPlateforme développée à l’Insee\n\nExpérimentation autour de la data science\nTravail sur données ouvertes\n\nEnvironnement particulièrement adapté à la formation\n\nPré-configuré\nReproductibilité"
  },
  {
    "objectID": "slides/index.html#programme-de-la-formation",
    "href": "slides/index.html#programme-de-la-formation",
    "title": "Introduction à Python",
    "section": "Programme de la formation",
    "text": "Programme de la formation\n\nTrois grandes parties\n\nFondamentaux du langage\nManipulation de données\nProjets\n\nApplications : cas d’usage de statistique publique"
  },
  {
    "objectID": "slides/index.html#les-notebooks-jupyter",
    "href": "slides/index.html#les-notebooks-jupyter",
    "title": "Introduction à Python",
    "section": "Les notebooks Jupyter",
    "text": "Les notebooks Jupyter\n\nUn format de type notebook (cahier) interactif qui combine\n\nDu texte Markdown (texte, équations, etc.)\nDu code Python\nDu code HTML (visualisations, animations..)\n\nParticulièrement adapté aux phases d’expérimentation"
  },
  {
    "objectID": "slides/index.html#démo",
    "href": "slides/index.html#démo",
    "title": "Introduction à Python",
    "section": "Démo",
    "text": "Démo\n\nSeul pré-requis : créer un compte sur le SSP Cloud"
  },
  {
    "objectID": "slides/index.html#comment-résoudre-les-bugs",
    "href": "slides/index.html#comment-résoudre-les-bugs",
    "title": "Introduction à Python",
    "section": "Comment résoudre les bugs ?",
    "text": "Comment résoudre les bugs ?\n\nEtapes de résolution\n\n1/ Bien lire les logs\n2/ Chercher sur internet (de préférence en Anglais et sur Google)\n3/ Sources fréquentes : documentations officielles et Stackoverflow\n4/ Poser une question détaillée (problème ET logs) sur le canal Tchap"
  },
  {
    "objectID": "slides/index.html#accès-aux-supports",
    "href": "slides/index.html#accès-aux-supports",
    "title": "Introduction à Python",
    "section": "Accès aux supports",
    "text": "Accès aux supports\n\nTous les supports de formation restent accessibles sur le SSP Cloud après la formation\nLe code qui génère les supports est disponible sur GitHub"
  },
  {
    "objectID": "slides/index.html#après-la-formation",
    "href": "slides/index.html#après-la-formation",
    "title": "Introduction à Python",
    "section": "Après la formation ?",
    "text": "Après la formation ?\n\nSuite logique : Python pour la data science (ENSAE)\nOrientation algorithmie : Advent of Code"
  },
  {
    "objectID": "slides/index.html#utiliser-python-dans-des-projets-statistiques",
    "href": "slides/index.html#utiliser-python-dans-des-projets-statistiques",
    "title": "Introduction à Python",
    "section": "Utiliser Python dans des projets statistiques",
    "text": "Utiliser Python dans des projets statistiques\n\nModalités selon la nature des données utilisées\n\nProjets open-data : SSP Cloud\nProjets internes : AUSV3 / LS3\n\n\n\n\n\nFormation “Introduction à Python”"
  },
  {
    "objectID": "source/manipulation/dataviz/tutorial.html",
    "href": "source/manipulation/dataviz/tutorial.html",
    "title": "Introduction à la visualisation de données",
    "section": "",
    "text": "La visualisation de données (ou dataviz) est un outil indispensable pour faciliter la compréhension des données et mettre en lumière des phénomènes à partir de celles-ci, ainsi que pour favoriser une communication efficace des résultats des analyses. C’est néanmoins un domaine qui dépasse largement la seule compétence technique : les meilleures visualisations sont celles qui sont adaptées à la donnée qu’elles représentent, et qui parviennent à raconter une histoire à partir de celles-ci (data storytelling). Ce tutoriel ne vise donc pas à présenter en détails le sujet, mais propose une introduction aux principaux outils existants en Python pour produire des visualisations de données.\nNous commencerons notre exploration par les graphiques intégrés dans Pandas, très simples et donc parfaits pour une analyse rapide des données. Puis, nous découvrirons Seaborn, une librairie qui permet de créer des visualisations attrayantes en très peu de lignes de code. Ces deux librairies sont basées sur Matplotlib, la très complète librairie de référence pour la visualisation en Python, qui permet des niveaux de personnalisation très avancés mais dont l’utilisation s’avère plus complexe, et ne sera donc pas directement abordée dans ce TP.\n\n\nComme nous l’avons vu dans le TP consacré, la librairie Pandas offre des outils nombreux et puissants pour manipuler les données tabulaires. Mais il est également équipé d’outils intégrés pour les visualiser. En particulier, la méthode .plot() permet de produire simplement des visualisations rapides des données analysées.\n\n\nLa méthode .plot(), intégrée aux Series et aux DataFrames, simplifie le processus de création de graphiques en permettant de générer des visualisations standards avec une ligne de code, directement à partir de la structure de donnée. En coulisse, .plot() fait appel à Matplotlib pour le rendu graphique, ce qui signifie que tout graphique généré par Pandas peut être personnalisé davantage avec les fonctions de Matplotlib. Cette intégration offre un équilibre entre la commodité pour des tâches de visualisation rapides et la puissance de Matplotlib pour des besoins de personnalisation plus poussés, faisant de .plot() le point de départ idéal pour la visualisation de données en Python.\n\n\n\nMême si la méthode .plot() permet de produire simplement et rapidement des graphiques, les possibilités sont très nombreuses et dépendent des données en entrée. Dans cette section, nous proposons quelques exemples standards pour comprendre le fonctionnement de la méthode. Pour découvrir plus de possibilités, on pourra s’inspirer des nombreux exemples de la documentation officielle.\nGénérons des données de synthèse imitant les données de caisse, qu’on utilisera comme base des graphiques.\n\nimport pandas as pd\nimport numpy as np\n\n\n# Configuration pour la reproductibilité\nnp.random.seed(0)\n\n# Générer une plage de dates sur un mois\ndates = pd.date_range(start='2023-01-01', end='2023-01-31', freq='D')\n\n# Simuler des données de caisse pour le mois\nN_POINTS = 1000\nmean_price = 10\nstd_dev_price = 4\nprices = np.random.normal(mean_price, std_dev_price, N_POINTS)\nquantities = 10 - 0.5 * prices + np.random.normal(0, 1.5, N_POINTS)\ndata = {\n    'Date': np.random.choice(dates, N_POINTS),\n    'Transaction_ID': np.arange(N_POINTS) + 1,\n    'COICOP': np.random.choice(['01.1.1', '02.1.1', '03.1.1', '04.1.1'], N_POINTS),\n    'Enseigne': np.random.choice(['Carrefour', 'Casino', 'Lidl', 'Monoprix'], N_POINTS),\n    'Prix': prices,\n    'Quantité': quantities\n}\n\n# Créer le DataFrame\ndf_caisse = pd.DataFrame(data)\n\n# Trier par date pour la cohérence\ndf_caisse = df_caisse.sort_values(by='Date').reset_index(drop=True)\n\n# Afficher les premières lignes des données de caisse\nprint(df_caisse.head())\n\n        Date  Transaction_ID  COICOP  Enseigne       Prix  Quantité\n0 2023-01-01             766  02.1.1      Lidl   5.588375  9.151826\n1 2023-01-01              32  03.1.1      Lidl  11.512650  4.450210\n2 2023-01-01             139  02.1.1  Monoprix  11.584027  6.314805\n3 2023-01-01             415  02.1.1    Casino  16.930885  0.861407\n4 2023-01-01             418  01.1.1    Casino  10.568247  2.590971\n\n\n\n\nLes nuages de point permettent de visualiser la relation entre deux variables numériques continues. Illustrons cela à travers la relation entre le prix et les quantités des transactions.\n\ndf_caisse.plot(x='Quantité', y='Prix', kind='scatter')\n\n\n\n\n\n\n\n\n\n\n\nLes diagrammes en bâtons sont idéaux pour la comparaison visuelle de différentes catégories. Ici, on utilise la méthode .value_counts() pour récupérer les fréquences de chaque modalité dans une Series, à laquelle on applique la méthode .plot() pour visualiser un diagramme à barres.\n\ndf_caisse['Enseigne'].value_counts().plot(kind='bar')\n\n\n\n\n\n\n\n\n\n\n\nLa boîte à moustache permet de visualiser rapidement les statistiques de dispersion d’une série statistique (médiane, quartiles, min, max) ainsi que la présence éventuelle de valeurs aberrantes\n\ndf_caisse['Prix'].plot(kind=\"box\")\n\n\n\n\n\n\n\n\n\n\n\nLes histogrammes aident à comprendre la distribution d’une variable numérique. Calculons l’histogramme des prix des transactions sur la période étudiée.\n\ndf_caisse['Prix'].plot(kind='hist', bins=20)\n\n\n\n\n\n\n\n\n\n\n\n\ndf_caisse.groupby('Date')['Quantité'].sum().plot(kind='line')\n\n\n\n\n\n\n\n\n\n\n\n\nComme évoqué précédemment, la fonctionnalité de graphiques intégrée à Pandas repose en fait sur la librairie Matplotlib, dans la mesure où la méthode .plot() de Pandas n’est qu’une surcouche (wrapper) autour de la fonction plot() de Matplotlib. En théorie, toutes les possibilités de personnalisation permises par Matplotlib le sont avec les graphiques créés par ce biais en Pandas. Pour y accéder, il faut importer Matplotlib en plus de Pandas.\n\nimport matplotlib.pyplot as plt\n\nIllustrons quelques possibilités de personnalisation en reprenant un des graphiques précédents.\n\ndf_caisse.plot(x='Quantité', y='Prix', kind='scatter', color=\"green\", alpha=0.6)\nplt.title('Relation entre le prix et la quantité des produits')\nplt.xlabel('Quantité vendue')\nplt.xlabel('Prix (en €)')\n\nText(0.5, 0, 'Prix (en €)')\n\n\n\n\n\n\n\n\n\n\n\n\nLà encore, de nombreuses autres possibilités sont décrites dans la documentation. Néanmoins, les fonctionnalités graphiques intégrées à Pandas restent avant tout faites pour de la visualisation rapide des données analysées. Pour des visualisations plus attrayantes sans avoir besoin de produire beaucoup plus de code, on préférera la librairie Seaborn.\n\n\n\n\nSeaborn est une bibliothèque de visualisation de données qui offre une interface de haut niveau pour créer des graphiques statistiques esthétiques. Elle est également construite sur Matplotlib et s’intègre bien avec les structures de données Pandas, permettant des visualisations plus élaborées que celles proposées nativement par Pandas sans pour autant exiger une quantité de code significative. Cela en fait un excellent choix pour aller au-delà des capacités graphiques de Pandas tout en évitant la complexité de Matplotlib.\nImportons le package Seaborn. L’usage courant est de lui donner l’alias sns pour éviter les redondances de code.\n\nimport seaborn as sns\n\n\n\nPour les mêmes graphiques que ceux réalisés précédemment avec Pandas, Seaborn offre des représentations beaucoup plus agréables à l’oeil. On en présente quelques unes dans la suite de ce tutoriel.\n\n\nOn peut facilement ajouter de l’information à un nuage de point, par exemple via la couleur des points ou leur style (taille, marqueur..). Analysons le nuage de points des prix en fonction de la quantité selon l’enseigne dans laquelle a eu lieu la transaction.\n\nsns.scatterplot(data=df_caisse, x='Prix', y='Quantité', hue='Enseigne', alpha=0.6)\n\n\n\n\n\n\n\n\n\n\n\nAvec Seaborn, on peut facilement ajouter une courbe d’estimation de densité à un histogramme. Cela permet de vérifier visuellement la normalité des données.\n\nsns.histplot(df_caisse['Prix'], kde=True, color='skyblue')\n\n\n\n\n\n\n\n\n\n\n\nLe pair plot permet d’analyser les relations entre deux variables continues en couplant un nuage de points et des courbes de densité.\n\nsubset = df_caisse[['Prix', 'Quantité', 'Enseigne']]\nsns.pairplot(subset, hue='Enseigne')\n\n\n\n\n\n\n\n\n\n\n\nSimilaire à la boîte à moustache, le violin plot ajoute une courbe d’estimation de densité afin de mieux visualiser les masses de la distribution.\n\nsns.violinplot(data=df_caisse, x='Enseigne', y='Prix', hue=\"Enseigne\")\n\n\n\n\n\n\n\n\n\n\n\n\nComme Pandas, les fonctionnalités graphiques de Seaborn sont basées sur celles de Matplotlib. Là encore, on peut donc personnaliser les graphiques en faisant appel aux fonctions plt.xxx de Matplotlib.\n\nsns.scatterplot(data=df_caisse, x='Prix', y='Quantité', hue='Enseigne', alpha=0.6)\nplt.title('Relation entre prix et quantité selon les enseignes')\n\nText(0.5, 1.0, 'Relation entre prix et quantité selon les enseignes')\n\n\n\n\n\n\n\n\n\n\n\n\nLes possibilités de Seaborn sont vraiment larges, et la gallerie d’exemples de Seaborn illustre de nombreuses possibilités visuellement agréables et faciles à reproduire. Pour des besoins plus avancés, on pourra s’orienter selon les cas vers d’autres librairies graphiques :\n\npour des possibilités de personnalisation maximales (au prix d’un certain coût d’apprentissage) : Matplotlib, la librairie fondamentale de visualisation en Python ;\npour les utilisateurs de R : plotnine, une librairie qui implémente la “grammaire graphique” propre à ggplot2 ;\npour de la visualisation interactive : plotly et bokeh sont les plus utilisées.",
    "crumbs": [
      "Manipulation de données",
      "Introduction à la visualisation de données"
    ]
  },
  {
    "objectID": "source/manipulation/dataviz/tutorial.html#pandas",
    "href": "source/manipulation/dataviz/tutorial.html#pandas",
    "title": "Introduction à la visualisation de données",
    "section": "",
    "text": "Comme nous l’avons vu dans le TP consacré, la librairie Pandas offre des outils nombreux et puissants pour manipuler les données tabulaires. Mais il est également équipé d’outils intégrés pour les visualiser. En particulier, la méthode .plot() permet de produire simplement des visualisations rapides des données analysées.\n\n\nLa méthode .plot(), intégrée aux Series et aux DataFrames, simplifie le processus de création de graphiques en permettant de générer des visualisations standards avec une ligne de code, directement à partir de la structure de donnée. En coulisse, .plot() fait appel à Matplotlib pour le rendu graphique, ce qui signifie que tout graphique généré par Pandas peut être personnalisé davantage avec les fonctions de Matplotlib. Cette intégration offre un équilibre entre la commodité pour des tâches de visualisation rapides et la puissance de Matplotlib pour des besoins de personnalisation plus poussés, faisant de .plot() le point de départ idéal pour la visualisation de données en Python.\n\n\n\nMême si la méthode .plot() permet de produire simplement et rapidement des graphiques, les possibilités sont très nombreuses et dépendent des données en entrée. Dans cette section, nous proposons quelques exemples standards pour comprendre le fonctionnement de la méthode. Pour découvrir plus de possibilités, on pourra s’inspirer des nombreux exemples de la documentation officielle.\nGénérons des données de synthèse imitant les données de caisse, qu’on utilisera comme base des graphiques.\n\nimport pandas as pd\nimport numpy as np\n\n\n# Configuration pour la reproductibilité\nnp.random.seed(0)\n\n# Générer une plage de dates sur un mois\ndates = pd.date_range(start='2023-01-01', end='2023-01-31', freq='D')\n\n# Simuler des données de caisse pour le mois\nN_POINTS = 1000\nmean_price = 10\nstd_dev_price = 4\nprices = np.random.normal(mean_price, std_dev_price, N_POINTS)\nquantities = 10 - 0.5 * prices + np.random.normal(0, 1.5, N_POINTS)\ndata = {\n    'Date': np.random.choice(dates, N_POINTS),\n    'Transaction_ID': np.arange(N_POINTS) + 1,\n    'COICOP': np.random.choice(['01.1.1', '02.1.1', '03.1.1', '04.1.1'], N_POINTS),\n    'Enseigne': np.random.choice(['Carrefour', 'Casino', 'Lidl', 'Monoprix'], N_POINTS),\n    'Prix': prices,\n    'Quantité': quantities\n}\n\n# Créer le DataFrame\ndf_caisse = pd.DataFrame(data)\n\n# Trier par date pour la cohérence\ndf_caisse = df_caisse.sort_values(by='Date').reset_index(drop=True)\n\n# Afficher les premières lignes des données de caisse\nprint(df_caisse.head())\n\n        Date  Transaction_ID  COICOP  Enseigne       Prix  Quantité\n0 2023-01-01             766  02.1.1      Lidl   5.588375  9.151826\n1 2023-01-01              32  03.1.1      Lidl  11.512650  4.450210\n2 2023-01-01             139  02.1.1  Monoprix  11.584027  6.314805\n3 2023-01-01             415  02.1.1    Casino  16.930885  0.861407\n4 2023-01-01             418  01.1.1    Casino  10.568247  2.590971\n\n\n\n\nLes nuages de point permettent de visualiser la relation entre deux variables numériques continues. Illustrons cela à travers la relation entre le prix et les quantités des transactions.\n\ndf_caisse.plot(x='Quantité', y='Prix', kind='scatter')\n\n\n\n\n\n\n\n\n\n\n\nLes diagrammes en bâtons sont idéaux pour la comparaison visuelle de différentes catégories. Ici, on utilise la méthode .value_counts() pour récupérer les fréquences de chaque modalité dans une Series, à laquelle on applique la méthode .plot() pour visualiser un diagramme à barres.\n\ndf_caisse['Enseigne'].value_counts().plot(kind='bar')\n\n\n\n\n\n\n\n\n\n\n\nLa boîte à moustache permet de visualiser rapidement les statistiques de dispersion d’une série statistique (médiane, quartiles, min, max) ainsi que la présence éventuelle de valeurs aberrantes\n\ndf_caisse['Prix'].plot(kind=\"box\")\n\n\n\n\n\n\n\n\n\n\n\nLes histogrammes aident à comprendre la distribution d’une variable numérique. Calculons l’histogramme des prix des transactions sur la période étudiée.\n\ndf_caisse['Prix'].plot(kind='hist', bins=20)\n\n\n\n\n\n\n\n\n\n\n\n\ndf_caisse.groupby('Date')['Quantité'].sum().plot(kind='line')\n\n\n\n\n\n\n\n\n\n\n\n\nComme évoqué précédemment, la fonctionnalité de graphiques intégrée à Pandas repose en fait sur la librairie Matplotlib, dans la mesure où la méthode .plot() de Pandas n’est qu’une surcouche (wrapper) autour de la fonction plot() de Matplotlib. En théorie, toutes les possibilités de personnalisation permises par Matplotlib le sont avec les graphiques créés par ce biais en Pandas. Pour y accéder, il faut importer Matplotlib en plus de Pandas.\n\nimport matplotlib.pyplot as plt\n\nIllustrons quelques possibilités de personnalisation en reprenant un des graphiques précédents.\n\ndf_caisse.plot(x='Quantité', y='Prix', kind='scatter', color=\"green\", alpha=0.6)\nplt.title('Relation entre le prix et la quantité des produits')\nplt.xlabel('Quantité vendue')\nplt.xlabel('Prix (en €)')\n\nText(0.5, 0, 'Prix (en €)')\n\n\n\n\n\n\n\n\n\n\n\n\nLà encore, de nombreuses autres possibilités sont décrites dans la documentation. Néanmoins, les fonctionnalités graphiques intégrées à Pandas restent avant tout faites pour de la visualisation rapide des données analysées. Pour des visualisations plus attrayantes sans avoir besoin de produire beaucoup plus de code, on préférera la librairie Seaborn.",
    "crumbs": [
      "Manipulation de données",
      "Introduction à la visualisation de données"
    ]
  },
  {
    "objectID": "source/manipulation/dataviz/tutorial.html#seaborn",
    "href": "source/manipulation/dataviz/tutorial.html#seaborn",
    "title": "Introduction à la visualisation de données",
    "section": "",
    "text": "Seaborn est une bibliothèque de visualisation de données qui offre une interface de haut niveau pour créer des graphiques statistiques esthétiques. Elle est également construite sur Matplotlib et s’intègre bien avec les structures de données Pandas, permettant des visualisations plus élaborées que celles proposées nativement par Pandas sans pour autant exiger une quantité de code significative. Cela en fait un excellent choix pour aller au-delà des capacités graphiques de Pandas tout en évitant la complexité de Matplotlib.\nImportons le package Seaborn. L’usage courant est de lui donner l’alias sns pour éviter les redondances de code.\n\nimport seaborn as sns\n\n\n\nPour les mêmes graphiques que ceux réalisés précédemment avec Pandas, Seaborn offre des représentations beaucoup plus agréables à l’oeil. On en présente quelques unes dans la suite de ce tutoriel.\n\n\nOn peut facilement ajouter de l’information à un nuage de point, par exemple via la couleur des points ou leur style (taille, marqueur..). Analysons le nuage de points des prix en fonction de la quantité selon l’enseigne dans laquelle a eu lieu la transaction.\n\nsns.scatterplot(data=df_caisse, x='Prix', y='Quantité', hue='Enseigne', alpha=0.6)\n\n\n\n\n\n\n\n\n\n\n\nAvec Seaborn, on peut facilement ajouter une courbe d’estimation de densité à un histogramme. Cela permet de vérifier visuellement la normalité des données.\n\nsns.histplot(df_caisse['Prix'], kde=True, color='skyblue')\n\n\n\n\n\n\n\n\n\n\n\nLe pair plot permet d’analyser les relations entre deux variables continues en couplant un nuage de points et des courbes de densité.\n\nsubset = df_caisse[['Prix', 'Quantité', 'Enseigne']]\nsns.pairplot(subset, hue='Enseigne')\n\n\n\n\n\n\n\n\n\n\n\nSimilaire à la boîte à moustache, le violin plot ajoute une courbe d’estimation de densité afin de mieux visualiser les masses de la distribution.\n\nsns.violinplot(data=df_caisse, x='Enseigne', y='Prix', hue=\"Enseigne\")\n\n\n\n\n\n\n\n\n\n\n\n\nComme Pandas, les fonctionnalités graphiques de Seaborn sont basées sur celles de Matplotlib. Là encore, on peut donc personnaliser les graphiques en faisant appel aux fonctions plt.xxx de Matplotlib.\n\nsns.scatterplot(data=df_caisse, x='Prix', y='Quantité', hue='Enseigne', alpha=0.6)\nplt.title('Relation entre prix et quantité selon les enseignes')\n\nText(0.5, 1.0, 'Relation entre prix et quantité selon les enseignes')\n\n\n\n\n\n\n\n\n\n\n\n\nLes possibilités de Seaborn sont vraiment larges, et la gallerie d’exemples de Seaborn illustre de nombreuses possibilités visuellement agréables et faciles à reproduire. Pour des besoins plus avancés, on pourra s’orienter selon les cas vers d’autres librairies graphiques :\n\npour des possibilités de personnalisation maximales (au prix d’un certain coût d’apprentissage) : Matplotlib, la librairie fondamentale de visualisation en Python ;\npour les utilisateurs de R : plotnine, une librairie qui implémente la “grammaire graphique” propre à ggplot2 ;\npour de la visualisation interactive : plotly et bokeh sont les plus utilisées.",
    "crumbs": [
      "Manipulation de données",
      "Introduction à la visualisation de données"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html",
    "href": "source/fundamentals/loops/tutorial.html",
    "title": "Boucles",
    "section": "",
    "text": "Dans le tutoriel précédent, nous avons étudié les tests, qui permettent à un ordinateur de prendre des décisions selon des conditions spécifiées dans un programme. Nous allons à présent aller encore plus loin dans l’automatisation des opérations, grâce à la notion de boucle. Les boucles vont permettre de répéter plusieurs fois une instruction semblable sans avoir à réécrire le même code à chaque fois.\nPour illustrer cette idée, imaginons que l’on souhaite afficher chaque élément d’une liste. Pour l’instant, on ferait :\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nprint(gamme[0])\nprint(gamme[1])\nprint(gamme[2])\n\ndo\nre\nmi\n\n\nEt ainsi de suite. On voit tout de suite qu’une telle opération serait impraticable pour une liste contenant des centaines d’éléments. Les boucles vont résoudre ce problème de manière élégante et efficiente.\n\n\n\n\nLe premier type de boucles auquel nous allons nous intéresser est la boucle for. Une boucle for permet de parcourir les différents éléments contenus dans un objet dit itérable, et de réaliser des opérations avec ces éléments. Les objets itérables incluent notamment tous les objets séquentiels que nous avons vus jusqu’à présent : chaînes de caractères, listes, tuples, etc.\nIllustrons le fonctionnement d’une boucle for en résolvant le problème exposé précédemment.\n\nfor note in gamme:\n    print(note)\n\ndo\nre\nmi\nfa\nsol\nla\nsi\n\n\n\n\n\nAnalysons la structure d’une boucle for :\n\nLa première ligne spécifie une instruction for, et comme toute instruction en Python se termine par :.\nVient ensuite un bloc d’instructions, i.e. une suite d’opérations (une seule dans notre exemple) qui sera exécutée à chaque itération de la boucle. Ce bloc est visible par son niveau d’indentation, incrémenté de 1 par rapport à l’instruction. Le bloc s’arrête dès lors que l’indentation revient à son niveau initial.\n\nComme pour les instructions conditionnelles de type if/else, l’indentation est donc capitale. Si on l’oublie, Python renvoie une erreur.\n\nfor note in gamme:\n    print(note)\n\ndo\nre\nmi\nfa\nsol\nla\nsi\n\n\n\n\n\nRegardons maintenant plus en détail ce que fait l’instruction for. Elle définit une variable d’itération (appelée note dans notre exemple), qui va parcourir les éléments de l’itérateur spécifié après le in (la liste gamme dans notre exemple). La syntaxe d’une boucle en Python se prête bien à une description littérale ; dans notre cas : “pour chaque note contenue dans la liste gamme, imprime la note”.\nInsistons sur le fait qu’une boucle définit une variable, sans que l’on ait besoin de passer par la syntaxe traditionnelle d’assignation variable = valeur. De plus, cette variable n’est pas supprimée une fois la boucle terminée, elle prend alors la valeur du dernier élément de l’itérateur.\n\nnote\n\n'si'\n\n\nL’itérateur n’est pas nécessairement une liste, il peut être tout objet itérable. Cela inclut notamment tous les objets séquentiels que nous avons vu.\n\nfor char in \"YMCA\":\n    print(char)\n    \nprint()  # Saut de ligne\n    \nt = (1, 2, 3, 4, 5)\nfor i in t:\n    print(i*9)\n\nY\nM\nC\nA\n\n9\n18\n27\n36\n45\n\n\nLa classe des objets itérables est cependant bien plus grande que les seuls objets séquentiels. Par exemple, on peut itérer sur les clés d’un dictionnaire, alors que l’on a vu dans un tutoriel précédent que ce n’était pas un objet séquentiel, puisqu’il n’y a pas de notion d’ordre dans un dictionnaire.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L', 'cereales': '1kg'}\nfor key in inventaire:\n    print(key)\n    print(inventaire[key])\n    print()  # Saut de ligne\n\ncafe\n500g\n\nlait\n1,5L\n\ncereales\n1kg\n\n\n\n\n\n\nEn programmation, il est courant de vouloir itérer sur une suite d’entiers. Plutôt que de spécifier cette suite dans une liste, ce qui n’est pas très pratique si la suite est longue, on utilise pour ce faire la fonction range(n). Celle-ci crée un objet itérable qui contient tous les entiers compris entre \\(0\\) et \\(n-1\\), et qui peut être utilisé dans le cadre d’une boucle.\nRegardons par exemple comment on peut très simplement afficher une table de multiplication à l’aide de cette fonction.\n\ntable = 9\n\nfor i in range(11):\n    print(i, i*9)\n\n0 0\n1 9\n2 18\n3 27\n4 36\n5 45\n6 54\n7 63\n8 72\n9 81\n10 90\n\n\n\n\n\nOn a vu qu’une boucle for avait pour principe d’itérer sur les éléments d’un itérable. Cependant, dans le cas d’un objet séquentiel comme une liste, on peut parfois vouloir itérer sur les indices de l’objet, afin de pouvoir manipuler à la fois les indices et les éléments contenus dans l’objet. Dans ce cas, la fonction range peut être utilisée en combinaison avec la fonction len pour créer un objet itérable qui contient exactement les indices de la liste initiale.\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nfor i in range(len(gamme)):\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + gamme[i])\n\nLa note numéro 0 de la gamme de do majeur est do\nLa note numéro 1 de la gamme de do majeur est re\nLa note numéro 2 de la gamme de do majeur est mi\nLa note numéro 3 de la gamme de do majeur est fa\nLa note numéro 4 de la gamme de do majeur est sol\nLa note numéro 5 de la gamme de do majeur est la\nLa note numéro 6 de la gamme de do majeur est si\n\n\nComme ce besoin est fréquent mais que le code ci-dessus n’est pas très lisible, il existe une fonction built-in de Python appelée enumerate qui permet d’itérer à la fois sur les objets et les indices. Il est donc préférable d’utiliser cette syntaxe, plus claire, et qui permet d’éviter certaines erreurs.\nLa fonction enumerate appliquée à un objet itérable renvoie un nouvel objet itérable qui contient l’ensemble des couples (indice, élément) contenus dans l’objet, sous forme de tuples. Comme c’est un objet de type particulier – un générateur, que nous verrons dans un tutoriel plus avancé – il faut lui appliquer la fonction list pour afficher son contenu.\n\nlist(enumerate(gamme))\n\n[(0, 'do'), (1, 're'), (2, 'mi'), (3, 'fa'), (4, 'sol'), (5, 'la'), (6, 'si')]\n\n\nRegardons comment réécrire la boucle précédente avec cette nouvelle syntaxe.\n\nfor i, note in enumerate(gamme):\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + note)\n\nLa note numéro 0 de la gamme de do majeur est do\nLa note numéro 1 de la gamme de do majeur est re\nLa note numéro 2 de la gamme de do majeur est mi\nLa note numéro 3 de la gamme de do majeur est fa\nLa note numéro 4 de la gamme de do majeur est sol\nLa note numéro 5 de la gamme de do majeur est la\nLa note numéro 6 de la gamme de do majeur est si\n\n\nNB : pour faire l’assignation de variables dans l’instruction if, on a utilisé une technique bien pratique que l’on avait déjà évoquée dans un exercice du tutoriel sur les listes et les tuples : le tuple unpacking. Illustrons le par un exemple :\n\nt = (1, 2, 3)\na, b, c = t\nprint(a)\nprint(b)\nprint(c)\n\n1\n2\n3\n\n\n\n\n\n\n\n\nLes boucles while fournissent une manière alternative de spécifier des procédures répétitives. L’idée n’est plus d’itérer sur un nombre d’objets fixé à l’avance, mais d’itérer tant qu’une condition (test logique) est remplie.\n\ni = 1\nwhile i &lt;= 5:\n    print(i)\n    i = i + 1\n\n1\n2\n3\n4\n5\n\n\n\n\n\nLa différence essentielle avec la boucle for est l’instruction : c’est désormais une instruction while, suivie d’une condition (test), et comme toute instruction de :.\nPour le reste, le principe est le même : l’instruction while est suivi d’un bloc d’instructions, indenté d’un niveau, et qui s’exécute séquentiellement à chaque itération de la boucle.\n\n\n\nUne différence essentielle des boucles while par rapport aux boucles for tient au critère d’arrêt. Dans une boucle for, ce critère est clair : la boucle itère sur les éléments d’un objet itérable, nécessairement de taille finie. La boucle s’arrête donc lorsque chaque élément de l’itérable a été parcouru.\nDans une boucle while au contraire, le critère d’arrêt est donné par une condition logique, c’est donc l’utilisateur qui doit fixer le critère d’arrêt. Dans l’exemple, pour que la boucle s’arrête, il faut que la condition i &lt;= 5 devienne False, c’est à dire que i devienne strictement supérieur à \\(5\\). On s’est assuré de cela en initialisant i à \\(1\\) avant le début de la boucle, puis en incrémentant i d’une unité à chaque itération.\nQue se passe-t-il si l’on oublie d’incrémenter i ? Le critère d’arrêt n’est jamais atteint, la boucle est donc infinie, et il faut utiliser le bouton “Stop” (carré noir) de Jupyter pour arrêter le programme en cours. Vérifions cela en incrémentant la mauvaise variable.\n\ni = 1\nj = 1\nwhile i &lt;= 5:\n    j = j + 1\n\nAinsi, lorsqu’on pressent qu’une boucle while met trop longtemps à tourner, il faut considérer l’hypothèse que l’on soit tombé dans une boucle infinie, et bien vérifier que le critère d’arrêt est atteignable.\n\n\n\nUne manière alternative de spécifier un critère d’arrêt est d’utiliser l’instruction break. Lorsque cette instruction est atteinte et exécutée, la boucle est immédiatement interrompue.\nIllustrons son fonctionnement à l’aide d’un exemple. La première ligne crée une boucle infinie, dans la mesure où, par définition, True est toujours évalué à True. Le programme demande ensuite à l’utilisateur de taper un prénom, et ce infiniment jusqu’à que l’utilisateur tape le prénom attendu. Dans ce cas seulement, l’instruction break est atteinte et la boucle s’arrête. Le message “Bienvenue ” s’affiche enfin, dans la mesure où le deuxième print n’est pas inclus dans la boucle.\n\nvotre_prenom = \"Romain\"\n\nwhile True:\n    print(\"Veuillez entrer votre prénom.\")\n    prenom = input()\n    if prenom == votre_prenom:\n        break\nprint(\"Bienvenue \" + votre_prenom)\n\nIl est important de noter qu’une instruction break ne met fin qu’à la boucle de niveau directement supérieur à elle. Dans le cas d’une boucle à plusieurs niveaux, il est tout à fait possible que les opérations continuent même lorsqu’une instruction break a été atteinte.\nIllustrons ce principe avec un exemple.\n\ni = 0\nwhile i &lt;= 5:\n    for j in range(5):\n        if j == 2:\n            print(\"Break.\")\n            break\n    i += 1\n\nBreak.\nBreak.\nBreak.\nBreak.\nBreak.\nBreak.\n\n\nA chaque itération de la boucle while, une boucle for est lancée, qui atteint une instruction break à la troisième itération (lorsque j vaut 2). Cela a pour effet de mettre fin à la boucle for, mais pas à la boucle while, qui exécute la suite de ses instructions (l’incrémentation de i d’une unité) avant de passer à l’itération suivante.\n\n\n\nL’instruction continue permet de passer à l’itération suivante de la boucle.\nAgrémentons l’exemple précédent pour illustrer son fonctionnement. Tant qu’un prénom différent de celui attendu est rentré, l’instruction continue est évaluée, et le programme continue à demander un prénom à l’utilisateur. Lorsque le bon prénom est rentré, le programme demande à l’utilisateur de rentrer un mot de passe. Si le mot de passe est celui attendu, l’instruction break est atteinte et exécutée, la boucle s’arrête. En cas de mauvais mot de passe en revanche, la boucle redémarre au début du bloc d’exécution, il faut donc de nouveau rentrer un prénom avant le mot de passe.\n\nvotre_prenom = \"\"\n\nwhile True:\n    print(\"Veuillez entrer votre prénom.\")\n    prenom = input()\n    if prenom != votre_prenom:\n        continue\n    print(\"Veuillez entrer votre mot de passe.\")\n    mdp = input()\n    if mdp == \"insee2021\":\n        break\nprint(\"Bienvenue \" + votre_prenom)\n\nNB : le code ci-dessus à seulement valeur d’exemple. Comme on le verra dans un prochain tutoriel sur les bonnes pratiques de code, il ne faut jamais écrire de secrets (mots de passe, tokens..) en clair dans son code.\n\n\n\n\n\n\n\n1/ Comment fonctionne une boucle for ?\n2/ La variable d’itération définie lors d’une boucle for persiste-t-elle en mémoire une fois la boucle terminée ?\n3/ Que fait la fonction range ? Pourquoi est-elle particulièrement utile dans le cadre des boucles for ?\n4/ Que fait la fonction enumerate ? Pourquoi est-elle particulièrement utile dans le cadre des boucles for ?\n5/ Comment fonctionne une boucle while ?\n6/ Quand s’arrête une boucle while ? En quoi cela diffère-t-il des boucles for ?\n7/ Que fait l’instruction break ?\n8/ Que fait l’instruction continue ?\n\n\n\n\nAfficher la solution\n\n1/ Une boucle for définit une variable d’itération qui va parcourir chaque élément d’un objet itérable. A chaque itération, une série d’instructions est effectuée.\n2/ Oui, et sa valeur finale est égale à la dernière valeur de l’objet itérable.\n3/ La fonction range(n) crée un objet itérable qui contient tous les entiers compris entre 0 et n-1. Elle est très utilisée comme itérable dans les boucles for car elle permet d’itérer sur une séquence d’entiers sans avoir à mettre celle-ci dans une liste à la main.\n4/ La fonction enumerate appliquée à un objet itérable renvoie un nouvel objet itérable qui contient l’ensemble des couples (indice, élément) associés à l’objet initial, sous forme de tuples. Dans le cadre d’une boucle for, elle permet d’itérer à la fois sur les éléments d’un itérable et sur les positions de ces éléments.\n5/ Une boucle while exécute une série d’instructions de manière répétée tant que la condition logique spécifiée évalue à True.\n6/ Une boucle while s’arrête dès lors que la condition logique spécifiée évalue à False. Si ce cas ne se produit jamais, une boucle while peut donc être infinie. A l’inverse, une boucle for peut être très longue mais jamais infinie, dans la mesure où elle s’arrête dès lors qu’elle a terminé de parcourir l’objet.\n7/ L’instruction break force la boucle de niveau directement supérieur à se terminer.\n8/ L’instruction continue force la boucle de niveau directement supérieur à passer à l’itération suivante.\n\n\n\n\n\nEssayer de prédire ce que vont produire les boucles while suivantes, et vérifiez vos résultats.\n\n# 1.\ni = 0\nwhile i &lt;= 10:\n    print(i)\n    \n# 2.\na = 1\nwhile (a &lt; 10):\n    a += 1\n    if a == 5:\n        break\n    print(\"Condition d'arrêt atteinte.\")\n    \n# 3.\nwhile False:\n    print(\"hello world\")\n\n# 4.\nwhile True:\n    print(\"hello world\")\n    break\n\n# 5.\nwhile 5 &gt;= 3:\n    continue\n    print(\"hello world\")\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n\nBoucle infinie car le i n’est jamais incrémenté, la condition est donc toujours vérifiée. 0 va s’imprimer à l’infini.\n\n\nLa boucle va s’arrêter à la 4ème itération, lorsque a vaut 5. Cependant, le print est mal indenté =&gt; il va s’imprimer 3 fois au lieu d’1.\n\n\nFalse évalue à False =&gt; la boucle ne s’exécute pas du tout. Aucun output.\n\n\nTrue évalue à True =&gt; la boucle est théoriquement infinie, mais il y a un break. Il va donc y avoir une seule itération, soit un seul print de “hello world”\n\n\n5 &gt;= 3 évalue à True =&gt; la boucle est infinie. Le continue est exécuté à chaque itération avant que le print ne puisse s’exécuter. La boucle tourne à l’infini, mais sans output.\n\n\n\n\n\n\n\nSource : python.sdv.univ-paris-diderot.fr\nAfin de visualiser l’importance de l’indentation dans les blocs d’instruction, essayez de prédire ce que vont respectivement retourner les deux programmes suivants. Lequel a l’effet attendu ?\n\nnombres = [4, 5, 6]\nfor nb in nombres:\n    if nb == 5:\n        print(\"Le test est vrai\")\n        print(f\"car la variable nb vaut {nb}\")\n\nLe test est vrai\ncar la variable nb vaut 5\n\n\n\nnombres = [4, 5, 6]\nfor nb in nombres:\n    if nb == 5:\n        print(\"Le test est vrai\")\n    print(f\"car la variable nb vaut {nb}\")\n\ncar la variable nb vaut 4\nLe test est vrai\ncar la variable nb vaut 5\ncar la variable nb vaut 6\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nLe premier programme est correct. Dans le second, le second print n’est pas correctement indenté. En conséquence, il s’exécute à chaque itération et non pas juste lorsque nb == 5.\n\n\n\n\n\nRéécrivez la boucle for suivante à l’aide d’une boucle while.\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nfor i, note in enumerate(gamme):\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + note)\n\nLa note numéro 0 de la gamme de do majeur est do\nLa note numéro 1 de la gamme de do majeur est re\nLa note numéro 2 de la gamme de do majeur est mi\nLa note numéro 3 de la gamme de do majeur est fa\nLa note numéro 4 de la gamme de do majeur est sol\nLa note numéro 5 de la gamme de do majeur est la\nLa note numéro 6 de la gamme de do majeur est si\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\ni = 0\nwhile i &lt;= (len(gamme) - 1):\n    # On soustrait 1 à la longueur de `gamme` car l'index maximal est 6\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + gamme[i])\n    i += 1\n\n\n\n\n\nSoit un entier cible n_cible et une liste d’entiers l tels que définis dans la cellule suivante. A l’aide d’une boucle for et de la fonction enumerate :\n\nvérifier si l’entier cible est présent dans la liste l.\nsi oui, afficher le message ‘Le nombre n_cible est à la position i de la liste’, et mettre fin à la boucle.\n\n\nn_cible = 78\n\nl = [12, 98, 65, 39, 78, 55, 119, 27, 33]\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nn_cible = 78\n\nl = [12, 98, 65, 39, 78, 55, 119, 27, 33]\n\nfor i, n in enumerate(l):\n    if n == n_cible:\n        print(\"Le nombre \" + str(n) + \" est à la position \" + str(i) + \" de la liste.\")\n        break\n\n# NB : version plus efficiente sans boucle\nif n_cible in l:\n    pos = l.index(n_cible)\n    print(\"Le nombre \" + str(n_cible) + \" est à la position \" + str(pos) + \" de la liste.\")\n\n\n\n\n\nLa suite de Fibonacci se définit de la manière suivante :\n\nles deux premiers nombres sont 0 et 1\nchaque autre nombre de la suite s’obtient en additionnant les deux nombres qui le précèdent\n\nEcrire un programme permettant de calculer les \\(n\\) premiers termes de la suite à l’aide d’une boucle for.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nn_termes = 20\nnum1 = 0\nnum2 = 1\n\nfor i in range(n_termes):\n    print(num1)\n    num3 = num1 + num2\n    num1 = num2\n    num2 = num3\n\n\n\n\n\nA l’aide de deux boucles for imbriquées, construire un dictionnaire tables permettant de réaliser les tables de multiplication jusqu’à la table de 12. Requêtez votre dictionnaire pour vérifier sa pertinence.\nVoici quelques exemples de requête que doit renvoyer votre dictionnaire :\n\ntables[2][3] -&gt; 6\ntables[9][5] -&gt; 45\ntables[12][7] -&gt; 84\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ntables = {}\n\nfor i in range(13):\n    tables[i] = {}\n    for j in range(13):\n        tables[i][j] = i*j\n\nprint(tables[2][3])\nprint(tables[9][5])\nprint(tables[12][7])\n\n\n\n\n\nCalculer le minimum et le maximum de la série de valeurs suivantes, sans utiliser les fonctions min et max de Python.\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\n\ncurrent_min = x[0]\ncurrent_max = x[0]\nfor n in x[1:]:\n    if n &lt;= current_min:\n        current_min = n\n    if n &gt;= current_max:\n        current_max = n\n\nprint(current_min == min(x))\nprint(current_max == max(x))\n\n\n\n\n\nCalculer la moyenne et la variance de la série de valeurs suivantes, sans utiliser des fonctions déjà codées :\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nPour rappel, les formules sont :\n\nmoyenne : \\[\\bar{x} = {\\frac {1}{n}}\\sum_{i=1}^{n}x_{i}\\]\nvariance : \\[\\sigma^2 = {\\frac {1}{n}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\]\n\nNB :\n\nn à la puissance k s’écrit en Python n**k\nen pratique, il ne faut surtout pas essayer de recoder soi-même ce genre de fonctions, mais utiliser des fonctions issues de packages adaptés, comme numpy.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nn = len(x)\n\nsomme_moy = 0\nfor x_i in x:\n    somme_moy += x_i\nmoyenne = somme_moy / n\n\nsomme_var = 0\nfor x_i in x:\n    somme_var += (x_i - moyenne)**2\nvariance = somme_var / n\n\nprint(moyenne)\nprint(variance)\n\n# Vérification avec les fonctions du package numpy\nimport numpy as np\nprint(np.mean(x))\nprint(np.var(x))\n\n\n\n\n\nNous avons vu plus haut l’usage basique de la fonction range : range(n) crée un objet itérable qui contient l’ensemble des entiers de \\(0\\) à \\(n-1\\). Les usages possibles de cette fonction sont cependant plus complets, et parfois utiles dans le cadre de problèmes précis.\nLa syntaxe complète de la fonction est range(start, stop, step) où :\n\nstart est l’entier à partir duquel commence la séquence d’entiers\nstop est l’entier avant lequel se termine la séquence d’entiers\nstep est le pas, i.e. la valeur de l’incrément entre chaque entier de la séquence.\n\nSeul le paramètre stop est obligatoire, c’est celui qui est utilisé lorsqu’on appelle range(n).\nEn utilisant la fonction range, afficher :\n\nl’ensemble des entiers de 0 à 10 (10 exclu)\nl’ensemble des entiers de 10 à 20 (20 inclus)\nl’ensemble des nombres pairs compris entre 30 et 40 (40 inclus)\nl’ensemble des multiples de 10 entre 1 et 100 (100 exclu)\nl’ensemble des entiers de 10 à 20 (20 inclus), dans l’ordre inverse (de 20 à 10)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(list(range(10)))\n\nprint(list(range(10, 21)))\n\nprint(list(range(30, 41, 2)))\n\nprint(list(range(10, 100, 10)))\n\nprint(list(range(20, 9, -1)))\n\n\n\n\n\nDans le précédent tutoriel, nous avons codé un jeu du juste prix. Mais il était un peu limité, puisqu’il fallait réexécuter le code à chaque étape du jeu. A l’aide de boucles, réécrivez le jeu de manière complètement automatique.\nRappel des règles :\nEn utilisant input et les instructions if, elif et else, coder le programme suivant :\n\ndemander une valeur à l’utilisateur, qui sera stockée dans une variable p\nsi p est strictement inférieur à \\(15\\), imprimer (avec la fonction print) le message “trop bas !”.\nsi p est strictement supérieur à \\(15\\), imprimer le message “trop haut !”.\nsi p est égal à \\(15\\), imprimer le message “dans le mille !”\n\nAttention, input renvoie par défaut une chaîne de caractère. Il faut donc convertir la valeur de p au format entier (via la fonction int) pour que le jeu fonctionne.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\njuste_prix = 15\n\nwhile True:\n    print(\"Proposer un nombre entre 1 et 50.\")\n    p = input()\n    p = int(p)\n    if p &lt; juste_prix:\n        print(\"trop bas !\")\n    elif p &gt; juste_prix:\n        print(\"trop haut !\")\n    else:\n        break\n\nprint(\"dans le mille !\")",
    "crumbs": [
      "Fondamentaux du langage",
      "Boucles"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html#boucles-for",
    "href": "source/fundamentals/loops/tutorial.html#boucles-for",
    "title": "Boucles",
    "section": "",
    "text": "Le premier type de boucles auquel nous allons nous intéresser est la boucle for. Une boucle for permet de parcourir les différents éléments contenus dans un objet dit itérable, et de réaliser des opérations avec ces éléments. Les objets itérables incluent notamment tous les objets séquentiels que nous avons vus jusqu’à présent : chaînes de caractères, listes, tuples, etc.\nIllustrons le fonctionnement d’une boucle for en résolvant le problème exposé précédemment.\n\nfor note in gamme:\n    print(note)\n\ndo\nre\nmi\nfa\nsol\nla\nsi\n\n\n\n\n\nAnalysons la structure d’une boucle for :\n\nLa première ligne spécifie une instruction for, et comme toute instruction en Python se termine par :.\nVient ensuite un bloc d’instructions, i.e. une suite d’opérations (une seule dans notre exemple) qui sera exécutée à chaque itération de la boucle. Ce bloc est visible par son niveau d’indentation, incrémenté de 1 par rapport à l’instruction. Le bloc s’arrête dès lors que l’indentation revient à son niveau initial.\n\nComme pour les instructions conditionnelles de type if/else, l’indentation est donc capitale. Si on l’oublie, Python renvoie une erreur.\n\nfor note in gamme:\n    print(note)\n\ndo\nre\nmi\nfa\nsol\nla\nsi\n\n\n\n\n\nRegardons maintenant plus en détail ce que fait l’instruction for. Elle définit une variable d’itération (appelée note dans notre exemple), qui va parcourir les éléments de l’itérateur spécifié après le in (la liste gamme dans notre exemple). La syntaxe d’une boucle en Python se prête bien à une description littérale ; dans notre cas : “pour chaque note contenue dans la liste gamme, imprime la note”.\nInsistons sur le fait qu’une boucle définit une variable, sans que l’on ait besoin de passer par la syntaxe traditionnelle d’assignation variable = valeur. De plus, cette variable n’est pas supprimée une fois la boucle terminée, elle prend alors la valeur du dernier élément de l’itérateur.\n\nnote\n\n'si'\n\n\nL’itérateur n’est pas nécessairement une liste, il peut être tout objet itérable. Cela inclut notamment tous les objets séquentiels que nous avons vu.\n\nfor char in \"YMCA\":\n    print(char)\n    \nprint()  # Saut de ligne\n    \nt = (1, 2, 3, 4, 5)\nfor i in t:\n    print(i*9)\n\nY\nM\nC\nA\n\n9\n18\n27\n36\n45\n\n\nLa classe des objets itérables est cependant bien plus grande que les seuls objets séquentiels. Par exemple, on peut itérer sur les clés d’un dictionnaire, alors que l’on a vu dans un tutoriel précédent que ce n’était pas un objet séquentiel, puisqu’il n’y a pas de notion d’ordre dans un dictionnaire.\n\ninventaire = {'cafe': '500g', 'lait': '1,5L', 'cereales': '1kg'}\nfor key in inventaire:\n    print(key)\n    print(inventaire[key])\n    print()  # Saut de ligne\n\ncafe\n500g\n\nlait\n1,5L\n\ncereales\n1kg\n\n\n\n\n\n\nEn programmation, il est courant de vouloir itérer sur une suite d’entiers. Plutôt que de spécifier cette suite dans une liste, ce qui n’est pas très pratique si la suite est longue, on utilise pour ce faire la fonction range(n). Celle-ci crée un objet itérable qui contient tous les entiers compris entre \\(0\\) et \\(n-1\\), et qui peut être utilisé dans le cadre d’une boucle.\nRegardons par exemple comment on peut très simplement afficher une table de multiplication à l’aide de cette fonction.\n\ntable = 9\n\nfor i in range(11):\n    print(i, i*9)\n\n0 0\n1 9\n2 18\n3 27\n4 36\n5 45\n6 54\n7 63\n8 72\n9 81\n10 90\n\n\n\n\n\nOn a vu qu’une boucle for avait pour principe d’itérer sur les éléments d’un itérable. Cependant, dans le cas d’un objet séquentiel comme une liste, on peut parfois vouloir itérer sur les indices de l’objet, afin de pouvoir manipuler à la fois les indices et les éléments contenus dans l’objet. Dans ce cas, la fonction range peut être utilisée en combinaison avec la fonction len pour créer un objet itérable qui contient exactement les indices de la liste initiale.\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nfor i in range(len(gamme)):\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + gamme[i])\n\nLa note numéro 0 de la gamme de do majeur est do\nLa note numéro 1 de la gamme de do majeur est re\nLa note numéro 2 de la gamme de do majeur est mi\nLa note numéro 3 de la gamme de do majeur est fa\nLa note numéro 4 de la gamme de do majeur est sol\nLa note numéro 5 de la gamme de do majeur est la\nLa note numéro 6 de la gamme de do majeur est si\n\n\nComme ce besoin est fréquent mais que le code ci-dessus n’est pas très lisible, il existe une fonction built-in de Python appelée enumerate qui permet d’itérer à la fois sur les objets et les indices. Il est donc préférable d’utiliser cette syntaxe, plus claire, et qui permet d’éviter certaines erreurs.\nLa fonction enumerate appliquée à un objet itérable renvoie un nouvel objet itérable qui contient l’ensemble des couples (indice, élément) contenus dans l’objet, sous forme de tuples. Comme c’est un objet de type particulier – un générateur, que nous verrons dans un tutoriel plus avancé – il faut lui appliquer la fonction list pour afficher son contenu.\n\nlist(enumerate(gamme))\n\n[(0, 'do'), (1, 're'), (2, 'mi'), (3, 'fa'), (4, 'sol'), (5, 'la'), (6, 'si')]\n\n\nRegardons comment réécrire la boucle précédente avec cette nouvelle syntaxe.\n\nfor i, note in enumerate(gamme):\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + note)\n\nLa note numéro 0 de la gamme de do majeur est do\nLa note numéro 1 de la gamme de do majeur est re\nLa note numéro 2 de la gamme de do majeur est mi\nLa note numéro 3 de la gamme de do majeur est fa\nLa note numéro 4 de la gamme de do majeur est sol\nLa note numéro 5 de la gamme de do majeur est la\nLa note numéro 6 de la gamme de do majeur est si\n\n\nNB : pour faire l’assignation de variables dans l’instruction if, on a utilisé une technique bien pratique que l’on avait déjà évoquée dans un exercice du tutoriel sur les listes et les tuples : le tuple unpacking. Illustrons le par un exemple :\n\nt = (1, 2, 3)\na, b, c = t\nprint(a)\nprint(b)\nprint(c)\n\n1\n2\n3",
    "crumbs": [
      "Fondamentaux du langage",
      "Boucles"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html#boucles-while",
    "href": "source/fundamentals/loops/tutorial.html#boucles-while",
    "title": "Boucles",
    "section": "",
    "text": "Les boucles while fournissent une manière alternative de spécifier des procédures répétitives. L’idée n’est plus d’itérer sur un nombre d’objets fixé à l’avance, mais d’itérer tant qu’une condition (test logique) est remplie.\n\ni = 1\nwhile i &lt;= 5:\n    print(i)\n    i = i + 1\n\n1\n2\n3\n4\n5\n\n\n\n\n\nLa différence essentielle avec la boucle for est l’instruction : c’est désormais une instruction while, suivie d’une condition (test), et comme toute instruction de :.\nPour le reste, le principe est le même : l’instruction while est suivi d’un bloc d’instructions, indenté d’un niveau, et qui s’exécute séquentiellement à chaque itération de la boucle.\n\n\n\nUne différence essentielle des boucles while par rapport aux boucles for tient au critère d’arrêt. Dans une boucle for, ce critère est clair : la boucle itère sur les éléments d’un objet itérable, nécessairement de taille finie. La boucle s’arrête donc lorsque chaque élément de l’itérable a été parcouru.\nDans une boucle while au contraire, le critère d’arrêt est donné par une condition logique, c’est donc l’utilisateur qui doit fixer le critère d’arrêt. Dans l’exemple, pour que la boucle s’arrête, il faut que la condition i &lt;= 5 devienne False, c’est à dire que i devienne strictement supérieur à \\(5\\). On s’est assuré de cela en initialisant i à \\(1\\) avant le début de la boucle, puis en incrémentant i d’une unité à chaque itération.\nQue se passe-t-il si l’on oublie d’incrémenter i ? Le critère d’arrêt n’est jamais atteint, la boucle est donc infinie, et il faut utiliser le bouton “Stop” (carré noir) de Jupyter pour arrêter le programme en cours. Vérifions cela en incrémentant la mauvaise variable.\n\ni = 1\nj = 1\nwhile i &lt;= 5:\n    j = j + 1\n\nAinsi, lorsqu’on pressent qu’une boucle while met trop longtemps à tourner, il faut considérer l’hypothèse que l’on soit tombé dans une boucle infinie, et bien vérifier que le critère d’arrêt est atteignable.\n\n\n\nUne manière alternative de spécifier un critère d’arrêt est d’utiliser l’instruction break. Lorsque cette instruction est atteinte et exécutée, la boucle est immédiatement interrompue.\nIllustrons son fonctionnement à l’aide d’un exemple. La première ligne crée une boucle infinie, dans la mesure où, par définition, True est toujours évalué à True. Le programme demande ensuite à l’utilisateur de taper un prénom, et ce infiniment jusqu’à que l’utilisateur tape le prénom attendu. Dans ce cas seulement, l’instruction break est atteinte et la boucle s’arrête. Le message “Bienvenue ” s’affiche enfin, dans la mesure où le deuxième print n’est pas inclus dans la boucle.\n\nvotre_prenom = \"Romain\"\n\nwhile True:\n    print(\"Veuillez entrer votre prénom.\")\n    prenom = input()\n    if prenom == votre_prenom:\n        break\nprint(\"Bienvenue \" + votre_prenom)\n\nIl est important de noter qu’une instruction break ne met fin qu’à la boucle de niveau directement supérieur à elle. Dans le cas d’une boucle à plusieurs niveaux, il est tout à fait possible que les opérations continuent même lorsqu’une instruction break a été atteinte.\nIllustrons ce principe avec un exemple.\n\ni = 0\nwhile i &lt;= 5:\n    for j in range(5):\n        if j == 2:\n            print(\"Break.\")\n            break\n    i += 1\n\nBreak.\nBreak.\nBreak.\nBreak.\nBreak.\nBreak.\n\n\nA chaque itération de la boucle while, une boucle for est lancée, qui atteint une instruction break à la troisième itération (lorsque j vaut 2). Cela a pour effet de mettre fin à la boucle for, mais pas à la boucle while, qui exécute la suite de ses instructions (l’incrémentation de i d’une unité) avant de passer à l’itération suivante.\n\n\n\nL’instruction continue permet de passer à l’itération suivante de la boucle.\nAgrémentons l’exemple précédent pour illustrer son fonctionnement. Tant qu’un prénom différent de celui attendu est rentré, l’instruction continue est évaluée, et le programme continue à demander un prénom à l’utilisateur. Lorsque le bon prénom est rentré, le programme demande à l’utilisateur de rentrer un mot de passe. Si le mot de passe est celui attendu, l’instruction break est atteinte et exécutée, la boucle s’arrête. En cas de mauvais mot de passe en revanche, la boucle redémarre au début du bloc d’exécution, il faut donc de nouveau rentrer un prénom avant le mot de passe.\n\nvotre_prenom = \"\"\n\nwhile True:\n    print(\"Veuillez entrer votre prénom.\")\n    prenom = input()\n    if prenom != votre_prenom:\n        continue\n    print(\"Veuillez entrer votre mot de passe.\")\n    mdp = input()\n    if mdp == \"insee2021\":\n        break\nprint(\"Bienvenue \" + votre_prenom)\n\nNB : le code ci-dessus à seulement valeur d’exemple. Comme on le verra dans un prochain tutoriel sur les bonnes pratiques de code, il ne faut jamais écrire de secrets (mots de passe, tokens..) en clair dans son code.",
    "crumbs": [
      "Fondamentaux du langage",
      "Boucles"
    ]
  },
  {
    "objectID": "source/fundamentals/loops/tutorial.html#exercices",
    "href": "source/fundamentals/loops/tutorial.html#exercices",
    "title": "Boucles",
    "section": "",
    "text": "1/ Comment fonctionne une boucle for ?\n2/ La variable d’itération définie lors d’une boucle for persiste-t-elle en mémoire une fois la boucle terminée ?\n3/ Que fait la fonction range ? Pourquoi est-elle particulièrement utile dans le cadre des boucles for ?\n4/ Que fait la fonction enumerate ? Pourquoi est-elle particulièrement utile dans le cadre des boucles for ?\n5/ Comment fonctionne une boucle while ?\n6/ Quand s’arrête une boucle while ? En quoi cela diffère-t-il des boucles for ?\n7/ Que fait l’instruction break ?\n8/ Que fait l’instruction continue ?\n\n\n\n\nAfficher la solution\n\n1/ Une boucle for définit une variable d’itération qui va parcourir chaque élément d’un objet itérable. A chaque itération, une série d’instructions est effectuée.\n2/ Oui, et sa valeur finale est égale à la dernière valeur de l’objet itérable.\n3/ La fonction range(n) crée un objet itérable qui contient tous les entiers compris entre 0 et n-1. Elle est très utilisée comme itérable dans les boucles for car elle permet d’itérer sur une séquence d’entiers sans avoir à mettre celle-ci dans une liste à la main.\n4/ La fonction enumerate appliquée à un objet itérable renvoie un nouvel objet itérable qui contient l’ensemble des couples (indice, élément) associés à l’objet initial, sous forme de tuples. Dans le cadre d’une boucle for, elle permet d’itérer à la fois sur les éléments d’un itérable et sur les positions de ces éléments.\n5/ Une boucle while exécute une série d’instructions de manière répétée tant que la condition logique spécifiée évalue à True.\n6/ Une boucle while s’arrête dès lors que la condition logique spécifiée évalue à False. Si ce cas ne se produit jamais, une boucle while peut donc être infinie. A l’inverse, une boucle for peut être très longue mais jamais infinie, dans la mesure où elle s’arrête dès lors qu’elle a terminé de parcourir l’objet.\n7/ L’instruction break force la boucle de niveau directement supérieur à se terminer.\n8/ L’instruction continue force la boucle de niveau directement supérieur à passer à l’itération suivante.\n\n\n\n\n\nEssayer de prédire ce que vont produire les boucles while suivantes, et vérifiez vos résultats.\n\n# 1.\ni = 0\nwhile i &lt;= 10:\n    print(i)\n    \n# 2.\na = 1\nwhile (a &lt; 10):\n    a += 1\n    if a == 5:\n        break\n    print(\"Condition d'arrêt atteinte.\")\n    \n# 3.\nwhile False:\n    print(\"hello world\")\n\n# 4.\nwhile True:\n    print(\"hello world\")\n    break\n\n# 5.\nwhile 5 &gt;= 3:\n    continue\n    print(\"hello world\")\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\n\nBoucle infinie car le i n’est jamais incrémenté, la condition est donc toujours vérifiée. 0 va s’imprimer à l’infini.\n\n\nLa boucle va s’arrêter à la 4ème itération, lorsque a vaut 5. Cependant, le print est mal indenté =&gt; il va s’imprimer 3 fois au lieu d’1.\n\n\nFalse évalue à False =&gt; la boucle ne s’exécute pas du tout. Aucun output.\n\n\nTrue évalue à True =&gt; la boucle est théoriquement infinie, mais il y a un break. Il va donc y avoir une seule itération, soit un seul print de “hello world”\n\n\n5 &gt;= 3 évalue à True =&gt; la boucle est infinie. Le continue est exécuté à chaque itération avant que le print ne puisse s’exécuter. La boucle tourne à l’infini, mais sans output.\n\n\n\n\n\n\n\nSource : python.sdv.univ-paris-diderot.fr\nAfin de visualiser l’importance de l’indentation dans les blocs d’instruction, essayez de prédire ce que vont respectivement retourner les deux programmes suivants. Lequel a l’effet attendu ?\n\nnombres = [4, 5, 6]\nfor nb in nombres:\n    if nb == 5:\n        print(\"Le test est vrai\")\n        print(f\"car la variable nb vaut {nb}\")\n\nLe test est vrai\ncar la variable nb vaut 5\n\n\n\nnombres = [4, 5, 6]\nfor nb in nombres:\n    if nb == 5:\n        print(\"Le test est vrai\")\n    print(f\"car la variable nb vaut {nb}\")\n\ncar la variable nb vaut 4\nLe test est vrai\ncar la variable nb vaut 5\ncar la variable nb vaut 6\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nLe premier programme est correct. Dans le second, le second print n’est pas correctement indenté. En conséquence, il s’exécute à chaque itération et non pas juste lorsque nb == 5.\n\n\n\n\n\nRéécrivez la boucle for suivante à l’aide d’une boucle while.\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\nfor i, note in enumerate(gamme):\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + note)\n\nLa note numéro 0 de la gamme de do majeur est do\nLa note numéro 1 de la gamme de do majeur est re\nLa note numéro 2 de la gamme de do majeur est mi\nLa note numéro 3 de la gamme de do majeur est fa\nLa note numéro 4 de la gamme de do majeur est sol\nLa note numéro 5 de la gamme de do majeur est la\nLa note numéro 6 de la gamme de do majeur est si\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ngamme = ['do', 're', 'mi', 'fa', 'sol', 'la', 'si']\n\ni = 0\nwhile i &lt;= (len(gamme) - 1):\n    # On soustrait 1 à la longueur de `gamme` car l'index maximal est 6\n    print(\"La note numéro \" + str(i) + \" de la gamme de do majeur est \" + gamme[i])\n    i += 1\n\n\n\n\n\nSoit un entier cible n_cible et une liste d’entiers l tels que définis dans la cellule suivante. A l’aide d’une boucle for et de la fonction enumerate :\n\nvérifier si l’entier cible est présent dans la liste l.\nsi oui, afficher le message ‘Le nombre n_cible est à la position i de la liste’, et mettre fin à la boucle.\n\n\nn_cible = 78\n\nl = [12, 98, 65, 39, 78, 55, 119, 27, 33]\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nn_cible = 78\n\nl = [12, 98, 65, 39, 78, 55, 119, 27, 33]\n\nfor i, n in enumerate(l):\n    if n == n_cible:\n        print(\"Le nombre \" + str(n) + \" est à la position \" + str(i) + \" de la liste.\")\n        break\n\n# NB : version plus efficiente sans boucle\nif n_cible in l:\n    pos = l.index(n_cible)\n    print(\"Le nombre \" + str(n_cible) + \" est à la position \" + str(pos) + \" de la liste.\")\n\n\n\n\n\nLa suite de Fibonacci se définit de la manière suivante :\n\nles deux premiers nombres sont 0 et 1\nchaque autre nombre de la suite s’obtient en additionnant les deux nombres qui le précèdent\n\nEcrire un programme permettant de calculer les \\(n\\) premiers termes de la suite à l’aide d’une boucle for.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nn_termes = 20\nnum1 = 0\nnum2 = 1\n\nfor i in range(n_termes):\n    print(num1)\n    num3 = num1 + num2\n    num1 = num2\n    num2 = num3\n\n\n\n\n\nA l’aide de deux boucles for imbriquées, construire un dictionnaire tables permettant de réaliser les tables de multiplication jusqu’à la table de 12. Requêtez votre dictionnaire pour vérifier sa pertinence.\nVoici quelques exemples de requête que doit renvoyer votre dictionnaire :\n\ntables[2][3] -&gt; 6\ntables[9][5] -&gt; 45\ntables[12][7] -&gt; 84\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ntables = {}\n\nfor i in range(13):\n    tables[i] = {}\n    for j in range(13):\n        tables[i][j] = i*j\n\nprint(tables[2][3])\nprint(tables[9][5])\nprint(tables[12][7])\n\n\n\n\n\nCalculer le minimum et le maximum de la série de valeurs suivantes, sans utiliser les fonctions min et max de Python.\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\n\ncurrent_min = x[0]\ncurrent_max = x[0]\nfor n in x[1:]:\n    if n &lt;= current_min:\n        current_min = n\n    if n &gt;= current_max:\n        current_max = n\n\nprint(current_min == min(x))\nprint(current_max == max(x))\n\n\n\n\n\nCalculer la moyenne et la variance de la série de valeurs suivantes, sans utiliser des fonctions déjà codées :\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nPour rappel, les formules sont :\n\nmoyenne : \\[\\bar{x} = {\\frac {1}{n}}\\sum_{i=1}^{n}x_{i}\\]\nvariance : \\[\\sigma^2 = {\\frac {1}{n}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\]\n\nNB :\n\nn à la puissance k s’écrit en Python n**k\nen pratique, il ne faut surtout pas essayer de recoder soi-même ce genre de fonctions, mais utiliser des fonctions issues de packages adaptés, comme numpy.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nn = len(x)\n\nsomme_moy = 0\nfor x_i in x:\n    somme_moy += x_i\nmoyenne = somme_moy / n\n\nsomme_var = 0\nfor x_i in x:\n    somme_var += (x_i - moyenne)**2\nvariance = somme_var / n\n\nprint(moyenne)\nprint(variance)\n\n# Vérification avec les fonctions du package numpy\nimport numpy as np\nprint(np.mean(x))\nprint(np.var(x))\n\n\n\n\n\nNous avons vu plus haut l’usage basique de la fonction range : range(n) crée un objet itérable qui contient l’ensemble des entiers de \\(0\\) à \\(n-1\\). Les usages possibles de cette fonction sont cependant plus complets, et parfois utiles dans le cadre de problèmes précis.\nLa syntaxe complète de la fonction est range(start, stop, step) où :\n\nstart est l’entier à partir duquel commence la séquence d’entiers\nstop est l’entier avant lequel se termine la séquence d’entiers\nstep est le pas, i.e. la valeur de l’incrément entre chaque entier de la séquence.\n\nSeul le paramètre stop est obligatoire, c’est celui qui est utilisé lorsqu’on appelle range(n).\nEn utilisant la fonction range, afficher :\n\nl’ensemble des entiers de 0 à 10 (10 exclu)\nl’ensemble des entiers de 10 à 20 (20 inclus)\nl’ensemble des nombres pairs compris entre 30 et 40 (40 inclus)\nl’ensemble des multiples de 10 entre 1 et 100 (100 exclu)\nl’ensemble des entiers de 10 à 20 (20 inclus), dans l’ordre inverse (de 20 à 10)\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprint(list(range(10)))\n\nprint(list(range(10, 21)))\n\nprint(list(range(30, 41, 2)))\n\nprint(list(range(10, 100, 10)))\n\nprint(list(range(20, 9, -1)))\n\n\n\n\n\nDans le précédent tutoriel, nous avons codé un jeu du juste prix. Mais il était un peu limité, puisqu’il fallait réexécuter le code à chaque étape du jeu. A l’aide de boucles, réécrivez le jeu de manière complètement automatique.\nRappel des règles :\nEn utilisant input et les instructions if, elif et else, coder le programme suivant :\n\ndemander une valeur à l’utilisateur, qui sera stockée dans une variable p\nsi p est strictement inférieur à \\(15\\), imprimer (avec la fonction print) le message “trop bas !”.\nsi p est strictement supérieur à \\(15\\), imprimer le message “trop haut !”.\nsi p est égal à \\(15\\), imprimer le message “dans le mille !”\n\nAttention, input renvoie par défaut une chaîne de caractère. Il faut donc convertir la valeur de p au format entier (via la fonction int) pour que le jeu fonctionne.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\njuste_prix = 15\n\nwhile True:\n    print(\"Proposer un nombre entre 1 et 50.\")\n    p = input()\n    p = int(p)\n    if p &lt; juste_prix:\n        print(\"trop bas !\")\n    elif p &gt; juste_prix:\n        print(\"trop haut !\")\n    else:\n        break\n\nprint(\"dans le mille !\")",
    "crumbs": [
      "Fondamentaux du langage",
      "Boucles"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html",
    "href": "source/fundamentals/functions/tutorial.html",
    "title": "Fonctions",
    "section": "",
    "text": "Dans les précédents tutoriels, nous avons étudié le fonctionnement des tests et des boucles, qui permettent de rédiger des programmes Python qui prennent des décisions automatisées. En pratique, un programme va généralement être constitué de différents blocs, qui exécutent chacun une action ou un groupe d’actions (ex : import des données, nettoyage des données, modélisation statistique, etc.). Par ailleurs, certaines de ces actions sont amenées à être répétées avec une légère différence au fil d’un programme (ex : importer plusieurs jeux de données différents). Il va être utile de modéliser chacune de ces actions par une fonction, sorte de mini-programme au sein du programme global. Utiliser des fonctions est une bonne pratique de programmation, dans la mesure où elles rendent plus explicite la structure logique du code et permettent de réduire la duplication de code.\n\n\nUne fonction peut être définie comme un bloc de code structuré qui :\n\nprend un ensemble d’arguments (des objets Python) en entrée\neffectue une action spécifique via un ensemble d’instructions\nrenvoie un résultat (un objet Python) en sortie\n\nNous avons déjà vu et utilisé un certains nombres de fonctions dans les tutoriels précédents (range, len, etc.). Nous avons également utilisé des méthodes, qui sont simplement des fonctions attachées à un type d’objet particulier. Utilisons une fonction bien connue pour illustrer leur fonctionnement général.\n\nlen('do re mi fa sol')\n\n15\n\n\nDans cet exemple, la fonction len :\n\nprend un argument en entrée (une chaîne de caractères)\ncalcule le nombre de caractères présent dans cette chaîne\nrenvoie ce nombre en sortie\n\nL’“ensemble d’instructions” qui permettent de calculer la longueur de la chaîne n’est pas connu. En tant qu’utilisateur, on a seulement besoin de savoir ce que prend la fonction en entrée et ce qu’elle renvoie en sortie. Cela vaut pour les cas dans lesquels on utilise des fonctions natives de Python ou bien des fonctions issus de librairies Python auxquelles on fait confiance. On parle de “boîtes noires” pour caractériser de telles fonctions.\nEn pratique, on va vouloir définir ses propres fonctions pour structurer son code et le réutiliser dans les analyses.\n\n\n\nL’instruction def permet de définir une fonction.\n\ndef accueil(prenom):\n    msg = \"Salutations \" + prenom + \" !\"\n    return msg\n\nAnalysons la syntaxe de la definition d’une fonction :\n\nune instruction def qui :\n\nspécifie le nom de la fonction (ici, accueil)\nspécifie les arguments attendus entre parenthèse (ici, un seul argument : prenom)\nse termine par : comme les différentes instructions que nous avons vues\n\nun ensemble d’opérations qui seront effectuées par la fonction, qui doivent être indentées d’un niveau par rapport à l’instruction def\nune instruction return, qui spécifie ce que la fonction va renvoyer lorsqu’elle sera appelée (ici, le contenu de la variable msg).\n\nLe fait de définir une fonction comme ci-dessus revient à rendre disponible dans l’environnement Python le code de la fonction. Ce n’est que lorsque celle-ci est appelée dans le code, avec des arguments, que le code contenu est exécuté et produit un résultat.\n\naccueil(\"Miranda\")\n\n'Salutations Miranda !'\n\n\nComme expliqué en introduction, tout l’intérêt d’une fonction est de pouvoir réutiliser du code sans avoir à le dupliquer dans le programme.\n\naccueil(\"Romuald\")\n\n'Salutations Romuald !'\n\n\n\n\n\n\n\nLorsqu’on appelle une fonction en lui spécifiant des arguments, on dit qu’on lui “passe” des arguments. Ces arguments deviennent alors des variables qui peuvent être utilisées dans le contexte de la fonction. A l’inverse d’une boucle for par exemple, les variables créées ne persistent pas après l’appel de la fonction\n\ndef addition(x, y):\n    return x + y\n\n\naddition(5, 3)\n\n8\n\n\n\nx  # La variable ne persiste pas en mémoire après l'appel de la fonction\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 x  # La variable ne persiste pas en mémoire après l'appel de la fonction\n\nNameError: name 'x' is not defined\n\n\n\nNB : on verra plus en détails ce comportement plus loin dans le tutoriel, à travers les concepts de variables globales et de variables locales.\n\n\n\nLe nombre d’arguments que l’on peut passer à une fonction est variable. En toute rigueur, il est possible de définir une fonction qui n’a besoin d’aucun argument, même si c’est rarement utile en pratique.\n\ndef neuf():\n    return 9\n\n\na = neuf()\na\n\n9\n\n\n\n\n\nEn Python, les fonctions admettent deux modes de passage des arguments :\n\nle passage par position, qui correspond à celui que nous avons vu dans tous les exemples précédents : les arguments sont passés à la fonction dans l’ordre dans lequel ils ont été définis, sans avoir à préciser le nom du paramètre.\nle passage par mot-clé : on précise le nom du paramètre lors du passage de l’argument, ce qui permet de ne pas avoir à suivre l’ordre indiqué lors de la définition.\n\nIllustrons cette différence à partir d’une fonction qui réalise simplement une division.\n\ndef division(x, y):\n    return x / y\n\n\ndivision(4, 2)  # Passage par position\n\n2.0\n\n\n\ndivision(x=4, y=2)  # Passage par mot-clé\n\n2.0\n\n\nDans le cas du passage par position, le respect de l’ordre est impératif.\n\nprint(division(0, 5))\nprint(division(5, 0))\n\n0.0\n\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[13], line 2\n      1 print(division(0, 5))\n----&gt; 2 print(division(5, 0))\n\nCell In[10], line 2, in division(x, y)\n      1 def division(x, y):\n----&gt; 2     return x / y\n\nZeroDivisionError: division by zero\n\n\n\nDans le cas du passage par mot-clé, l’ordre n’a plus d’importance.\n\nprint(division(x=0, y=5))\nprint(division(y=5, x=0))\n\n0.0\n0.0\n\n\n\n\n\nLorsqu’on définit une fonction, il est fréquent de vouloir faire cohabiter des arguments que doit absolument spécifier l’utilisateur, et des arguments optionnels qui spécifient un comportement par défaut de la fonction, mais peuvent également être modifiés si nécessaire.\nRegardons par exemple comment on peut modifier le comportement de la fonction print à l’aide d’un argument optionnel.\n\nprint(\"bonjour\")\nprint(\"bonjour\")\n\nbonjour\nbonjour\n\n\n\nprint(\"bonjour\", end=' ')\nprint(\"bonjour\")\n\nbonjour bonjour\n\n\nOn a modifié le comportement du premier appel à print via le paramètre optionnel end. Par défaut, cette valeur est fixée à '\\n', soit un retour à la ligne. On l’a modifié dans la deuxième cellule à un espace, d’où la différence de résultat.\nCet exemple illustre également le lien entre le caractère obligatoire ou non d’un argument et sa modalité de passage :\n\nen général, les arguments obligatoires sont passés par position. Ils peuvent également être passés par mot-clé, mais dans la mesure où ils sont “attendus”, on les passe généralement par position pour être plus concis\nles arguments optionnels doivent être passés par mot-clé, afin de bien marquer qu’on modifie le comportement par défaut de la fonction\n\nComment spécifier qu’un argument est optionnel lorsqu’on définit une fonction soi-même ? Simplement en spécifiant une valeur par défaut de l’argument. Par exemple, construisons une fonction qui concatène deux chaînes de caractères, et laisse à l’utilisateur l’option de spécifier un séparateur.\n\ndef concat_string(str1, str2, sep=''):\n    return str1 + sep + str2\n\n\nconcat_string('bonjour', 'bonjour')  # Comportement par défaut\n\n'bonjourbonjour'\n\n\n\nconcat_string('bonjour', 'bonjour', sep=', ')  # Comportement modifié\n\n'bonjour, bonjour'\n\n\nCet exemple illustre également la règle lorsqu’on a un mélange d’arguments positionnels et par mot-clé : les arguments positionnels doivent toujours être placés avant les arguments par mot-clé.\n\n\n\n\n\n\nOn a vu :\n\nque toute fonction renvoie un résultat en sortie\nque l’instruction return permet de spécifier ce résultat\n\nLorsque la fonction est appelée, elle est évaluée à la valeur spécifiée par return, et cette valeur peut alors être récupérée dans une variable et utilisée dans des calculs ultérieurs, et ainsi de suite.\n\ndef division(x, y):\n    return x / y\n\n\na = division(4, 2)\nb = division(9, 3)\ndivision(a, b)  # 2 / 3\n\n0.6666666666666666\n\n\nRemarque importante : lorsqu’une instruction return est atteinte dans une fonction, le reste de la fonction n’est pas exécuté.\n\ndef test(x):\n    return x\n    print(\"vais-je être affiché ?\")\n    \ntest(3)\n\n3\n\n\n\n\n\nUne fonction renvoie nécessairement un résultat lorsqu’elle est appelée… mais que se passe-t-il si l’on ne spécifie pas d’instruction return ?\n\ndef accueil(prenom):\n    print(\"Salutations \" + prenom + \" !\")\n    \nx = accueil(\"Léontine\")\nprint(x)\nprint(type(x))\n\nSalutations Léontine !\nNone\n&lt;class 'NoneType'&gt;\n\n\nComme attendu, la fonction a imprimé un message de bienvenue dans la console. Mais on n’a pas spécifié de valeur à retourner. Comme un objet doit malgré tout être retourné par définition, Python renvoie la valeur None, qui est un objet particulier, de type NoneType, et qui représente l’absence de valeur. Son seul intérêt est de bien marquer la différence entre une valeur réelle et l’absence de valeur.\nPour tester si un objet a pour valeur None, on utilise une syntaxe particulière :\n\nx is None  # et non pas x == None\n\nTrue\n\n\n\n\n\nUne fonction renvoie par définition un résultat, qui peut être tout objet Python. Comment faire si l’on souhaite renvoyer plusieurs résultats ? On peut simplement enregistrer les différents résultats dans un conteneur (liste, tuple, dictionnaire, etc.), qui peut lui contenir un grand nombre d’objets.\nEn pratique, il est très fréquent de renvoyer un tuple lorsque l’on souhaite renvoyer plusieurs objets. En effet, les tuples ont la propriété de tuple unpacking, que nous avons vues à plusieurs reprises dans les précédents tutoriels. Cette propriété rend possible une syntaxe très pratique et élégante pour l’assignation des résultats d’une fonction à des variables.\n\ndef puissances(x):\n    return x**2, x**3, x**4\n\na, b, c = puissances(2)\n\nprint(a)\nprint(b)\nprint(c)\n\n4\n8\n16\n\n\n\n\n\n\nNous avons vu en introduction que les fonctions pouvaient être vues comme des mini-programmes dans un programme global. Cette interprétation nous donne l’occasion d’aborder rapidement la notion de scope (contexte) en Python. Un scope est une sorte de conteneur à objets Python, auxquels il est possible d’accéder seulement dans le cadre de ce scope.\nTous les objets (variables, fonctions, etc.) que l’on définit lors d’une session Python sont enregistrés dans le scope global de Python. Ces objets peuvent alors être accédés à n’importe quel endroit du programme, y compris au sein d’une fonction. Lorsque c’est le cas, on parle de variables globales.\n\nx = 5  # variable globale\n\ndef ajoute(y):\n    return x + y\n\najoute(6)\n\n11\n\n\nLa variable x n’a pas été passée en argument à la fonction ajoute ni été définie dans le cadre de cette fonction. Pourtant, on peut l’appeler au sein de la fonction. Cela permet de partager des éléments entre plusieurs fonctions.\nEn revanche, les arguments passés à une fonction ou bien les variables définies dans le cadre d’une fonction sont des variables locales : elles n’existent que dans le contexte spécifique de la fonction, et ne peuvent pas être réutilisées une fois que celle-ci s’est exécutée.\n\ndef ajoute(y):\n    z = 5  # variable locale\n    return z + y\n\najoute(6)\nprint(z)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[27], line 6\n      3     return z + y\n      5 ajoute(6)\n----&gt; 6 print(z)\n\nNameError: name 'z' is not defined\n\n\n\nAu sein d’un contexte donné, chaque variable est unique. En revanche, il est possible d’avoir des variables qui portent le même nom dans des contextes différents. Regardons par exemple ce qui se passe lorsque l’on crée une variable dans le contexte d’une fonction, alors qu’elle existe déjà dans le contexte global.\n\nx = 5  # variable globale\n\ndef ajoute(y):\n    x = 10\n    return x + y\n\najoute(6)\n\n16\n\n\nC’est un bon exemple d’un principe plus général : c’est toujours le contexte le plus local qui prime. Lorsque Python effectue l’opération x + y, il va chercher les valeurs de x et de y d’abord dans le contexte local, puis, seulement s’il ne les trouve pas, dans le contexte supérieur – en l’occurence, le contexte global.\nNB : on verra dans un prochain tutoriel sur les bonnes pratiques qu’il est préférable de limiter au strict minimum l’utilisation de variables globales, car elles réduisent la reproductibilité des analyses.\n\n\n\n\n\n\n1/ Pourquoi dit-on que l’utilisation de fonctions dans un programme est une bonne pratique de développement ?\n2/ Quelles sont les trois caractéristiques d’une fonction ?\n3/ Qu’est-ce qu’une fonction “boîte noire” ? A quelles autres fonctions s’oppose-t-elle ?\n4/ Que se passe-t-il quand on définit une fonction ? Et quand on l’appelle ?\n5/ Combien d’arguments peut-on passer à une fonction ?\n6/ Quelles sont les deux modalités de passage d’arguments à une fonction ?\n7/ Quelle est l’utilité de passer des arguments optionnels à une fonction ?\n8/ Dans quel ordre doivent être passés les arguments d’une fonction si celle-ci a à la fois des arguments obligatoires et optionnels ?\n9/ Existe-il des fonctions qui ne renvoient rien ?\n10/ Une fonction peut-elle renvoyer plusieurs objets ?\n11/ Que deviennent les variables du scope local d’une fonction une fois que la fonction a été appelée ?\n\n\n\n\nAfficher la solution\n\n\n1/ L’utilisation de fonction permet de réduire la duplication du code et de mieux isoler les différents blocs logiques d’un programme.\n2/ Une fonction prend en entrée des arguments, réalise une action donnée via un ensemble d’instructions, et renvoie un résultat en sortie.\n3/ Les fonctions “boîtes noires” sont les fonctions dont on ne connaît pas le code lorsqu’on les exécute, comme les fonctions built-in de Python (len, range..). Elles s’opposent aux fonctions créées par l’utilisateur.\n4/ Quand on définit une fonction via l’instruction def, on met en mémoire le code de la fonction. Ce n’est que quand on appelle la fonction que ce code s’exécute, et renvoie un résultat.\n5/ Autant que l’on souhaite.\n6/ Par position : on passe les arguments dans l’ordre où ils ont été spécifiés lors de la définition de la fonction. Par mot-clé : on passe les arguments en les nommant.\n7/ Modifier le comportement par défaut d’une fonction, tel qu’il a été voulu par son concepteur.\n8/ D’abord les arguments obligatoires, puis les arguments optionnels.\n9/ Non, une fonction renvoie toujours un objet. Si l’on ne spécifie pas d’instruction return, la fonction renvoie la valeur None, qui est un objet de type NoneType.\n10/ Non, une fonction renvoie un seul objet. En revanche, si l’on veut qu’une fonction renvoie plusieurs résultats, il suffit de les mettre dans un conteneur (liste, tuple, dictionnaire..).\n11/ Elles disparaissent et ne peuvent donc pas être réutilisées dans le scope global.\n\n\n\n\n\n\nCréer une fonction puissance qui prend en entrée deux nombres x et y et renvoie la fonction puissance \\(x^y\\).\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef puissance(x, y):\n    return x**y\n\npuissance(2, 3)\n\n\n\n\n\nSoit x = 5 et y = 3 des arguments que l’on passe à chacune des fonctions définies dans la cellule suivante. Prédire ce que vont retourner les fonctions (valeur et type de l’objet), et vérifier vos réponses.\n\ndef f1(x):\n    return x\n\ndef f2(x):\n    return ''\n\ndef f3(x):\n    print(\"Hello World\")\n    \ndef f4(x, y):\n    print(x + y)\n    \ndef f5(x, y):\n    x + y\n    \ndef f6(x, y):\n    if x &gt;= 3 and y &lt; 9:\n        return 'test ok'\n    else:\n        return 'test not ok'\n    \ndef f7(x, y):\n    return f6(2, 8)\n\ndef f8(x, y, z):\n    return x + y + z\n\ndef f9(x, y, z=5):\n    return x + y + z\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n- f1. Valeur : 5 ; Type : int\n\n- f2. Valeur : '' ; Type : str\n\n- f3. Valeur : None ; Type : NoneType\n\n- f4. Valeur : None ; Type : NoneType\n\n- f5. Valeur : None ; Type : NoneType\n\n- f6. Valeur : 'test ok' ; Type : str\n\n- f7. Valeur : 'test not ok' ; Type : str\n\n- f8. Erreur : z n'est pas défini\n\n- f9. Valeur : 13 ; Type : int\n\n\n\n\n\nQue vaut la variable total dans le programme suivant ?\n\nz = 3\n\ndef f1(x, y):\n    z = 5\n    return x + y + z\n\ndef f2(x, y, z=1):\n    return x + y + z\n\ndef f3(x, y):\n    return x + y + z\n\ntotal = f1(2, 3) + f2(3, 1) + f3(1, 0)\nprint(total)\n\n19\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nz = 3\n\ndef f1(x, y):\n    z = 5\n    return x + y + z\n\ndef f2(x, y, z=1):\n    return x + y + z\n\ndef f3(x, y):\n    return x + y + z\n\ntotal = f1(2, 3) + f2(3, 1) + f3(1, 0)\n\nprint(f1(2, 3))  \n# c'est la variable z locale à f1 qui est utilisée -&gt; f1 renvoie 10\n\nprint(f2(3, 1))  \n# c'est la variable z locale à f1 qui est utilisée\n# sa valeur par défaut est 1 -&gt; f2 renvoie 5\n\nprint(f3(1, 0)) \n# c'est la variable z globale qui est utilisée -&gt; f3 renvoie 4\n\nprint(total)\n\n\n\n\n\nEcrire une fonction calculatrice qui :\n\nprend deux nombres en entrée\nrenvoie l’addition, la soustraction, la multiplication et la division de ces deux nombres en sortie\n\nUtiliser la propriété de tuple unpacking pour assigner les résultats à des variables en une seule ligne.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef calculatrice(a, b):\n    return a+b, a-b, a*b, a/b\n\nadd, sub, mult, div = calculatrice(5, 3)\nprint(add, sub, mult, div)\n\n\n\n\n\nEcrire une fonction qui :\n\nprend en entrée une liste d’éléments quelconques\nrenvoie une nouvelle liste constituée des éléments uniques de la liste initiale\npermet via un paramètre optionnel de trier ou non la liste finale par ordre alphanumérique. Le comportement par défaut doit être de ne pas trier.\n\nIndice : la procédure a été abordée dans le tutoriel sur les dictionnaires et les sets.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef dedup(l, sort=False):\n    l_dedup = list(set(l))\n    if sort:\n        l_dedup.sort()\n    return l_dedup\n\nl = [\"a\", \"a\", \"b\", \"c\"]\nprint(dedup(l))  # Comportement par défaut : pas de tri\nprint(dedup(l, sort=True))  # Comportement modifié : tri\n\n\n\n\n\nEcrire une fonction qui :\n\nprend en entrée une liste de nombres\nimprime : “Il y a \\(n\\) nombres dans la liste.” avec \\(n\\) le nombre effectif\nmultiplie tous les éléments de la liste (sans utiliser de fonction pré-codée)\nretourne le résultat\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef multiplier(l):\n    print(\"Il y a \" + str(len(l)) + \" nombres dans la liste.\")\n    c = 1\n    for x in l:\n        c *= x  # Equivalent à : c = c * x\n    return c\n\nl = [2, 8, 3]\nmultiplier(l)\n\n\n\n\n\nDans un exercice du précédent tutoriel, nous avons codé “à la main” le calcul de la variance d’une liste de nombres, à partir de la formule : \\[\\sigma^2 = {\\frac {1}{n}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\]\nEn toute rigueur, cette formule est valide lorsqu’on calcule la variance en population complète. Si l’on n’observe qu’un échantillon de la population, on ne calcule pas la variance mais on l’estime, et il faut alors utiliser la formule suivante pour obtenir un estimateur sans biais de la vraie variance : \\[s^2 = {\\frac {1}{n-1}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\].\nPour tenir compte de cette distinction :\n\ncoder une fonction mean qui calcule la moyenne comme dans l’exercice du tutoriel précédent\ncoder une fonction var qui calcule la variance comme dans l’exercice du tutoriel précédent (en appelant la fonction mean pour calculer la moyenne)\nmodifier la fonction var afin de permettre à l’utilisateur de choisir la méthode de calcul via un paramètre optionnel mode (valeur par défaut : ‘population’ pour le calcul via la formule en population ; valeur alternative : ‘sample’ pour le calcul via la formule en échantillon)\n\nComparer les valeurs obtenues dans les deux cas avec ce que renvoie la fonction black box var de la librarie numpy (cf. corrigé de l’exercice du tutoriel précédent pour la syntaxe, et voir la doc de la fonction et en particulier le paramètre ddof pour faire varier la méthode de calcul).\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef mean(x):\n    n = len(x)\n    somme_moy = 0\n    for x_i in x:\n        somme_moy += x_i\n    moyenne = somme_moy / n\n    return moyenne\n\ndef var(x, mode=\"population\"):\n    n = len(x)\n    moyenne = mean(x)\n    somme_var = 0\n    for x_i in x:\n        somme_var += (x_i - moyenne)**2\n    if mode == \"population\":\n        variance = somme_var / n\n    elif mode == \"sample\":\n        variance = somme_var / (n-1)\n    return variance\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nprint(mean(x))\nprint(var(x))  # population\nprint(var(x, mode=\"sample\"))  # échantillon\n\n# Vérification avec les fonctions de la librairie numpy\nimport numpy as np\nprint(np.mean(x))\nprint(np.var(x))  # population\nprint(np.var(x, ddof=1))  # sample\n\n\n\n\n\nLes fonctions récursives sont des fonctions qui s’appellent elles-mêmes dans le corps de la fonction, ce qui entraîne des appels infinis jusqu’à atteindre un critère d’arrêt.\nUn bon exemple de fonction récursive est la fonction qui calcule la factorielle d’un entier. La factorielle d’un entier naturel \\(n\\) est le produit des nombres entiers strictement positifs inférieurs ou égaux à n. Par exemple : \\(5! = 5*4*3*2*1 = 120\\).\nCoder cette fonction et vérifier qu’elle fonctionne correctement.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef factorielle(n):\n    if n == 0:\n        # Critère d'arrêt\n        return 1\n    else:\n        return n * factorielle(n-1)\n\nfactorielle(5)",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#définition",
    "href": "source/fundamentals/functions/tutorial.html#définition",
    "title": "Fonctions",
    "section": "",
    "text": "Une fonction peut être définie comme un bloc de code structuré qui :\n\nprend un ensemble d’arguments (des objets Python) en entrée\neffectue une action spécifique via un ensemble d’instructions\nrenvoie un résultat (un objet Python) en sortie\n\nNous avons déjà vu et utilisé un certains nombres de fonctions dans les tutoriels précédents (range, len, etc.). Nous avons également utilisé des méthodes, qui sont simplement des fonctions attachées à un type d’objet particulier. Utilisons une fonction bien connue pour illustrer leur fonctionnement général.\n\nlen('do re mi fa sol')\n\n15\n\n\nDans cet exemple, la fonction len :\n\nprend un argument en entrée (une chaîne de caractères)\ncalcule le nombre de caractères présent dans cette chaîne\nrenvoie ce nombre en sortie\n\nL’“ensemble d’instructions” qui permettent de calculer la longueur de la chaîne n’est pas connu. En tant qu’utilisateur, on a seulement besoin de savoir ce que prend la fonction en entrée et ce qu’elle renvoie en sortie. Cela vaut pour les cas dans lesquels on utilise des fonctions natives de Python ou bien des fonctions issus de librairies Python auxquelles on fait confiance. On parle de “boîtes noires” pour caractériser de telles fonctions.\nEn pratique, on va vouloir définir ses propres fonctions pour structurer son code et le réutiliser dans les analyses.",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#syntaxe",
    "href": "source/fundamentals/functions/tutorial.html#syntaxe",
    "title": "Fonctions",
    "section": "",
    "text": "L’instruction def permet de définir une fonction.\n\ndef accueil(prenom):\n    msg = \"Salutations \" + prenom + \" !\"\n    return msg\n\nAnalysons la syntaxe de la definition d’une fonction :\n\nune instruction def qui :\n\nspécifie le nom de la fonction (ici, accueil)\nspécifie les arguments attendus entre parenthèse (ici, un seul argument : prenom)\nse termine par : comme les différentes instructions que nous avons vues\n\nun ensemble d’opérations qui seront effectuées par la fonction, qui doivent être indentées d’un niveau par rapport à l’instruction def\nune instruction return, qui spécifie ce que la fonction va renvoyer lorsqu’elle sera appelée (ici, le contenu de la variable msg).\n\nLe fait de définir une fonction comme ci-dessus revient à rendre disponible dans l’environnement Python le code de la fonction. Ce n’est que lorsque celle-ci est appelée dans le code, avec des arguments, que le code contenu est exécuté et produit un résultat.\n\naccueil(\"Miranda\")\n\n'Salutations Miranda !'\n\n\nComme expliqué en introduction, tout l’intérêt d’une fonction est de pouvoir réutiliser du code sans avoir à le dupliquer dans le programme.\n\naccueil(\"Romuald\")\n\n'Salutations Romuald !'",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#passage-darguments",
    "href": "source/fundamentals/functions/tutorial.html#passage-darguments",
    "title": "Fonctions",
    "section": "",
    "text": "Lorsqu’on appelle une fonction en lui spécifiant des arguments, on dit qu’on lui “passe” des arguments. Ces arguments deviennent alors des variables qui peuvent être utilisées dans le contexte de la fonction. A l’inverse d’une boucle for par exemple, les variables créées ne persistent pas après l’appel de la fonction\n\ndef addition(x, y):\n    return x + y\n\n\naddition(5, 3)\n\n8\n\n\n\nx  # La variable ne persiste pas en mémoire après l'appel de la fonction\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 x  # La variable ne persiste pas en mémoire après l'appel de la fonction\n\nNameError: name 'x' is not defined\n\n\n\nNB : on verra plus en détails ce comportement plus loin dans le tutoriel, à travers les concepts de variables globales et de variables locales.\n\n\n\nLe nombre d’arguments que l’on peut passer à une fonction est variable. En toute rigueur, il est possible de définir une fonction qui n’a besoin d’aucun argument, même si c’est rarement utile en pratique.\n\ndef neuf():\n    return 9\n\n\na = neuf()\na\n\n9\n\n\n\n\n\nEn Python, les fonctions admettent deux modes de passage des arguments :\n\nle passage par position, qui correspond à celui que nous avons vu dans tous les exemples précédents : les arguments sont passés à la fonction dans l’ordre dans lequel ils ont été définis, sans avoir à préciser le nom du paramètre.\nle passage par mot-clé : on précise le nom du paramètre lors du passage de l’argument, ce qui permet de ne pas avoir à suivre l’ordre indiqué lors de la définition.\n\nIllustrons cette différence à partir d’une fonction qui réalise simplement une division.\n\ndef division(x, y):\n    return x / y\n\n\ndivision(4, 2)  # Passage par position\n\n2.0\n\n\n\ndivision(x=4, y=2)  # Passage par mot-clé\n\n2.0\n\n\nDans le cas du passage par position, le respect de l’ordre est impératif.\n\nprint(division(0, 5))\nprint(division(5, 0))\n\n0.0\n\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[13], line 2\n      1 print(division(0, 5))\n----&gt; 2 print(division(5, 0))\n\nCell In[10], line 2, in division(x, y)\n      1 def division(x, y):\n----&gt; 2     return x / y\n\nZeroDivisionError: division by zero\n\n\n\nDans le cas du passage par mot-clé, l’ordre n’a plus d’importance.\n\nprint(division(x=0, y=5))\nprint(division(y=5, x=0))\n\n0.0\n0.0\n\n\n\n\n\nLorsqu’on définit une fonction, il est fréquent de vouloir faire cohabiter des arguments que doit absolument spécifier l’utilisateur, et des arguments optionnels qui spécifient un comportement par défaut de la fonction, mais peuvent également être modifiés si nécessaire.\nRegardons par exemple comment on peut modifier le comportement de la fonction print à l’aide d’un argument optionnel.\n\nprint(\"bonjour\")\nprint(\"bonjour\")\n\nbonjour\nbonjour\n\n\n\nprint(\"bonjour\", end=' ')\nprint(\"bonjour\")\n\nbonjour bonjour\n\n\nOn a modifié le comportement du premier appel à print via le paramètre optionnel end. Par défaut, cette valeur est fixée à '\\n', soit un retour à la ligne. On l’a modifié dans la deuxième cellule à un espace, d’où la différence de résultat.\nCet exemple illustre également le lien entre le caractère obligatoire ou non d’un argument et sa modalité de passage :\n\nen général, les arguments obligatoires sont passés par position. Ils peuvent également être passés par mot-clé, mais dans la mesure où ils sont “attendus”, on les passe généralement par position pour être plus concis\nles arguments optionnels doivent être passés par mot-clé, afin de bien marquer qu’on modifie le comportement par défaut de la fonction\n\nComment spécifier qu’un argument est optionnel lorsqu’on définit une fonction soi-même ? Simplement en spécifiant une valeur par défaut de l’argument. Par exemple, construisons une fonction qui concatène deux chaînes de caractères, et laisse à l’utilisateur l’option de spécifier un séparateur.\n\ndef concat_string(str1, str2, sep=''):\n    return str1 + sep + str2\n\n\nconcat_string('bonjour', 'bonjour')  # Comportement par défaut\n\n'bonjourbonjour'\n\n\n\nconcat_string('bonjour', 'bonjour', sep=', ')  # Comportement modifié\n\n'bonjour, bonjour'\n\n\nCet exemple illustre également la règle lorsqu’on a un mélange d’arguments positionnels et par mot-clé : les arguments positionnels doivent toujours être placés avant les arguments par mot-clé.",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#renvoi-de-résultats",
    "href": "source/fundamentals/functions/tutorial.html#renvoi-de-résultats",
    "title": "Fonctions",
    "section": "",
    "text": "On a vu :\n\nque toute fonction renvoie un résultat en sortie\nque l’instruction return permet de spécifier ce résultat\n\nLorsque la fonction est appelée, elle est évaluée à la valeur spécifiée par return, et cette valeur peut alors être récupérée dans une variable et utilisée dans des calculs ultérieurs, et ainsi de suite.\n\ndef division(x, y):\n    return x / y\n\n\na = division(4, 2)\nb = division(9, 3)\ndivision(a, b)  # 2 / 3\n\n0.6666666666666666\n\n\nRemarque importante : lorsqu’une instruction return est atteinte dans une fonction, le reste de la fonction n’est pas exécuté.\n\ndef test(x):\n    return x\n    print(\"vais-je être affiché ?\")\n    \ntest(3)\n\n3\n\n\n\n\n\nUne fonction renvoie nécessairement un résultat lorsqu’elle est appelée… mais que se passe-t-il si l’on ne spécifie pas d’instruction return ?\n\ndef accueil(prenom):\n    print(\"Salutations \" + prenom + \" !\")\n    \nx = accueil(\"Léontine\")\nprint(x)\nprint(type(x))\n\nSalutations Léontine !\nNone\n&lt;class 'NoneType'&gt;\n\n\nComme attendu, la fonction a imprimé un message de bienvenue dans la console. Mais on n’a pas spécifié de valeur à retourner. Comme un objet doit malgré tout être retourné par définition, Python renvoie la valeur None, qui est un objet particulier, de type NoneType, et qui représente l’absence de valeur. Son seul intérêt est de bien marquer la différence entre une valeur réelle et l’absence de valeur.\nPour tester si un objet a pour valeur None, on utilise une syntaxe particulière :\n\nx is None  # et non pas x == None\n\nTrue\n\n\n\n\n\nUne fonction renvoie par définition un résultat, qui peut être tout objet Python. Comment faire si l’on souhaite renvoyer plusieurs résultats ? On peut simplement enregistrer les différents résultats dans un conteneur (liste, tuple, dictionnaire, etc.), qui peut lui contenir un grand nombre d’objets.\nEn pratique, il est très fréquent de renvoyer un tuple lorsque l’on souhaite renvoyer plusieurs objets. En effet, les tuples ont la propriété de tuple unpacking, que nous avons vues à plusieurs reprises dans les précédents tutoriels. Cette propriété rend possible une syntaxe très pratique et élégante pour l’assignation des résultats d’une fonction à des variables.\n\ndef puissances(x):\n    return x**2, x**3, x**4\n\na, b, c = puissances(2)\n\nprint(a)\nprint(b)\nprint(c)\n\n4\n8\n16",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#variables-locales-et-variables-globales",
    "href": "source/fundamentals/functions/tutorial.html#variables-locales-et-variables-globales",
    "title": "Fonctions",
    "section": "",
    "text": "Nous avons vu en introduction que les fonctions pouvaient être vues comme des mini-programmes dans un programme global. Cette interprétation nous donne l’occasion d’aborder rapidement la notion de scope (contexte) en Python. Un scope est une sorte de conteneur à objets Python, auxquels il est possible d’accéder seulement dans le cadre de ce scope.\nTous les objets (variables, fonctions, etc.) que l’on définit lors d’une session Python sont enregistrés dans le scope global de Python. Ces objets peuvent alors être accédés à n’importe quel endroit du programme, y compris au sein d’une fonction. Lorsque c’est le cas, on parle de variables globales.\n\nx = 5  # variable globale\n\ndef ajoute(y):\n    return x + y\n\najoute(6)\n\n11\n\n\nLa variable x n’a pas été passée en argument à la fonction ajoute ni été définie dans le cadre de cette fonction. Pourtant, on peut l’appeler au sein de la fonction. Cela permet de partager des éléments entre plusieurs fonctions.\nEn revanche, les arguments passés à une fonction ou bien les variables définies dans le cadre d’une fonction sont des variables locales : elles n’existent que dans le contexte spécifique de la fonction, et ne peuvent pas être réutilisées une fois que celle-ci s’est exécutée.\n\ndef ajoute(y):\n    z = 5  # variable locale\n    return z + y\n\najoute(6)\nprint(z)\n\n\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[27], line 6\n      3     return z + y\n      5 ajoute(6)\n----&gt; 6 print(z)\n\nNameError: name 'z' is not defined\n\n\n\nAu sein d’un contexte donné, chaque variable est unique. En revanche, il est possible d’avoir des variables qui portent le même nom dans des contextes différents. Regardons par exemple ce qui se passe lorsque l’on crée une variable dans le contexte d’une fonction, alors qu’elle existe déjà dans le contexte global.\n\nx = 5  # variable globale\n\ndef ajoute(y):\n    x = 10\n    return x + y\n\najoute(6)\n\n16\n\n\nC’est un bon exemple d’un principe plus général : c’est toujours le contexte le plus local qui prime. Lorsque Python effectue l’opération x + y, il va chercher les valeurs de x et de y d’abord dans le contexte local, puis, seulement s’il ne les trouve pas, dans le contexte supérieur – en l’occurence, le contexte global.\nNB : on verra dans un prochain tutoriel sur les bonnes pratiques qu’il est préférable de limiter au strict minimum l’utilisation de variables globales, car elles réduisent la reproductibilité des analyses.",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/functions/tutorial.html#exercices",
    "href": "source/fundamentals/functions/tutorial.html#exercices",
    "title": "Fonctions",
    "section": "",
    "text": "1/ Pourquoi dit-on que l’utilisation de fonctions dans un programme est une bonne pratique de développement ?\n2/ Quelles sont les trois caractéristiques d’une fonction ?\n3/ Qu’est-ce qu’une fonction “boîte noire” ? A quelles autres fonctions s’oppose-t-elle ?\n4/ Que se passe-t-il quand on définit une fonction ? Et quand on l’appelle ?\n5/ Combien d’arguments peut-on passer à une fonction ?\n6/ Quelles sont les deux modalités de passage d’arguments à une fonction ?\n7/ Quelle est l’utilité de passer des arguments optionnels à une fonction ?\n8/ Dans quel ordre doivent être passés les arguments d’une fonction si celle-ci a à la fois des arguments obligatoires et optionnels ?\n9/ Existe-il des fonctions qui ne renvoient rien ?\n10/ Une fonction peut-elle renvoyer plusieurs objets ?\n11/ Que deviennent les variables du scope local d’une fonction une fois que la fonction a été appelée ?\n\n\n\n\nAfficher la solution\n\n\n1/ L’utilisation de fonction permet de réduire la duplication du code et de mieux isoler les différents blocs logiques d’un programme.\n2/ Une fonction prend en entrée des arguments, réalise une action donnée via un ensemble d’instructions, et renvoie un résultat en sortie.\n3/ Les fonctions “boîtes noires” sont les fonctions dont on ne connaît pas le code lorsqu’on les exécute, comme les fonctions built-in de Python (len, range..). Elles s’opposent aux fonctions créées par l’utilisateur.\n4/ Quand on définit une fonction via l’instruction def, on met en mémoire le code de la fonction. Ce n’est que quand on appelle la fonction que ce code s’exécute, et renvoie un résultat.\n5/ Autant que l’on souhaite.\n6/ Par position : on passe les arguments dans l’ordre où ils ont été spécifiés lors de la définition de la fonction. Par mot-clé : on passe les arguments en les nommant.\n7/ Modifier le comportement par défaut d’une fonction, tel qu’il a été voulu par son concepteur.\n8/ D’abord les arguments obligatoires, puis les arguments optionnels.\n9/ Non, une fonction renvoie toujours un objet. Si l’on ne spécifie pas d’instruction return, la fonction renvoie la valeur None, qui est un objet de type NoneType.\n10/ Non, une fonction renvoie un seul objet. En revanche, si l’on veut qu’une fonction renvoie plusieurs résultats, il suffit de les mettre dans un conteneur (liste, tuple, dictionnaire..).\n11/ Elles disparaissent et ne peuvent donc pas être réutilisées dans le scope global.\n\n\n\n\n\n\nCréer une fonction puissance qui prend en entrée deux nombres x et y et renvoie la fonction puissance \\(x^y\\).\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef puissance(x, y):\n    return x**y\n\npuissance(2, 3)\n\n\n\n\n\nSoit x = 5 et y = 3 des arguments que l’on passe à chacune des fonctions définies dans la cellule suivante. Prédire ce que vont retourner les fonctions (valeur et type de l’objet), et vérifier vos réponses.\n\ndef f1(x):\n    return x\n\ndef f2(x):\n    return ''\n\ndef f3(x):\n    print(\"Hello World\")\n    \ndef f4(x, y):\n    print(x + y)\n    \ndef f5(x, y):\n    x + y\n    \ndef f6(x, y):\n    if x &gt;= 3 and y &lt; 9:\n        return 'test ok'\n    else:\n        return 'test not ok'\n    \ndef f7(x, y):\n    return f6(2, 8)\n\ndef f8(x, y, z):\n    return x + y + z\n\ndef f9(x, y, z=5):\n    return x + y + z\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n- f1. Valeur : 5 ; Type : int\n\n- f2. Valeur : '' ; Type : str\n\n- f3. Valeur : None ; Type : NoneType\n\n- f4. Valeur : None ; Type : NoneType\n\n- f5. Valeur : None ; Type : NoneType\n\n- f6. Valeur : 'test ok' ; Type : str\n\n- f7. Valeur : 'test not ok' ; Type : str\n\n- f8. Erreur : z n'est pas défini\n\n- f9. Valeur : 13 ; Type : int\n\n\n\n\n\nQue vaut la variable total dans le programme suivant ?\n\nz = 3\n\ndef f1(x, y):\n    z = 5\n    return x + y + z\n\ndef f2(x, y, z=1):\n    return x + y + z\n\ndef f3(x, y):\n    return x + y + z\n\ntotal = f1(2, 3) + f2(3, 1) + f3(1, 0)\nprint(total)\n\n19\n\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nz = 3\n\ndef f1(x, y):\n    z = 5\n    return x + y + z\n\ndef f2(x, y, z=1):\n    return x + y + z\n\ndef f3(x, y):\n    return x + y + z\n\ntotal = f1(2, 3) + f2(3, 1) + f3(1, 0)\n\nprint(f1(2, 3))  \n# c'est la variable z locale à f1 qui est utilisée -&gt; f1 renvoie 10\n\nprint(f2(3, 1))  \n# c'est la variable z locale à f1 qui est utilisée\n# sa valeur par défaut est 1 -&gt; f2 renvoie 5\n\nprint(f3(1, 0)) \n# c'est la variable z globale qui est utilisée -&gt; f3 renvoie 4\n\nprint(total)\n\n\n\n\n\nEcrire une fonction calculatrice qui :\n\nprend deux nombres en entrée\nrenvoie l’addition, la soustraction, la multiplication et la division de ces deux nombres en sortie\n\nUtiliser la propriété de tuple unpacking pour assigner les résultats à des variables en une seule ligne.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef calculatrice(a, b):\n    return a+b, a-b, a*b, a/b\n\nadd, sub, mult, div = calculatrice(5, 3)\nprint(add, sub, mult, div)\n\n\n\n\n\nEcrire une fonction qui :\n\nprend en entrée une liste d’éléments quelconques\nrenvoie une nouvelle liste constituée des éléments uniques de la liste initiale\npermet via un paramètre optionnel de trier ou non la liste finale par ordre alphanumérique. Le comportement par défaut doit être de ne pas trier.\n\nIndice : la procédure a été abordée dans le tutoriel sur les dictionnaires et les sets.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef dedup(l, sort=False):\n    l_dedup = list(set(l))\n    if sort:\n        l_dedup.sort()\n    return l_dedup\n\nl = [\"a\", \"a\", \"b\", \"c\"]\nprint(dedup(l))  # Comportement par défaut : pas de tri\nprint(dedup(l, sort=True))  # Comportement modifié : tri\n\n\n\n\n\nEcrire une fonction qui :\n\nprend en entrée une liste de nombres\nimprime : “Il y a \\(n\\) nombres dans la liste.” avec \\(n\\) le nombre effectif\nmultiplie tous les éléments de la liste (sans utiliser de fonction pré-codée)\nretourne le résultat\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef multiplier(l):\n    print(\"Il y a \" + str(len(l)) + \" nombres dans la liste.\")\n    c = 1\n    for x in l:\n        c *= x  # Equivalent à : c = c * x\n    return c\n\nl = [2, 8, 3]\nmultiplier(l)\n\n\n\n\n\nDans un exercice du précédent tutoriel, nous avons codé “à la main” le calcul de la variance d’une liste de nombres, à partir de la formule : \\[\\sigma^2 = {\\frac {1}{n}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\]\nEn toute rigueur, cette formule est valide lorsqu’on calcule la variance en population complète. Si l’on n’observe qu’un échantillon de la population, on ne calcule pas la variance mais on l’estime, et il faut alors utiliser la formule suivante pour obtenir un estimateur sans biais de la vraie variance : \\[s^2 = {\\frac {1}{n-1}}\\sum_{i=1}^{n} (x_{i}-\\bar{x})^2\\].\nPour tenir compte de cette distinction :\n\ncoder une fonction mean qui calcule la moyenne comme dans l’exercice du tutoriel précédent\ncoder une fonction var qui calcule la variance comme dans l’exercice du tutoriel précédent (en appelant la fonction mean pour calculer la moyenne)\nmodifier la fonction var afin de permettre à l’utilisateur de choisir la méthode de calcul via un paramètre optionnel mode (valeur par défaut : ‘population’ pour le calcul via la formule en population ; valeur alternative : ‘sample’ pour le calcul via la formule en échantillon)\n\nComparer les valeurs obtenues dans les deux cas avec ce que renvoie la fonction black box var de la librarie numpy (cf. corrigé de l’exercice du tutoriel précédent pour la syntaxe, et voir la doc de la fonction et en particulier le paramètre ddof pour faire varier la méthode de calcul).\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef mean(x):\n    n = len(x)\n    somme_moy = 0\n    for x_i in x:\n        somme_moy += x_i\n    moyenne = somme_moy / n\n    return moyenne\n\ndef var(x, mode=\"population\"):\n    n = len(x)\n    moyenne = mean(x)\n    somme_var = 0\n    for x_i in x:\n        somme_var += (x_i - moyenne)**2\n    if mode == \"population\":\n        variance = somme_var / n\n    elif mode == \"sample\":\n        variance = somme_var / (n-1)\n    return variance\n\nx = [8, 18, 6, 0, 15, 17.5, 9, 1]\nprint(mean(x))\nprint(var(x))  # population\nprint(var(x, mode=\"sample\"))  # échantillon\n\n# Vérification avec les fonctions de la librairie numpy\nimport numpy as np\nprint(np.mean(x))\nprint(np.var(x))  # population\nprint(np.var(x, ddof=1))  # sample\n\n\n\n\n\nLes fonctions récursives sont des fonctions qui s’appellent elles-mêmes dans le corps de la fonction, ce qui entraîne des appels infinis jusqu’à atteindre un critère d’arrêt.\nUn bon exemple de fonction récursive est la fonction qui calcule la factorielle d’un entier. La factorielle d’un entier naturel \\(n\\) est le produit des nombres entiers strictement positifs inférieurs ou égaux à n. Par exemple : \\(5! = 5*4*3*2*1 = 120\\).\nCoder cette fonction et vérifier qu’elle fonctionne correctement.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ndef factorielle(n):\n    if n == 0:\n        # Critère d'arrêt\n        return 1\n    else:\n        return n * factorielle(n-1)\n\nfactorielle(5)",
    "crumbs": [
      "Fondamentaux du langage",
      "Fonctions"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html",
    "href": "source/fundamentals/data-structures1/tutorial.html",
    "title": "Structures de données 1 : listes et tuples",
    "section": "",
    "text": "Dans ce tutoriel, nous allons nous intéresser à des structures de données de base en Python : les listes et les tuples. Les structures de données peuvent être vues comme des conteneurs car ils permettent de stocker, d’organiser et d’accéder à des données. Les listes et les tuples sont des conteneurs séquentiels : les éléments qu’ils contiennent sont ordonnés, et leur position est enregistrée dans un index.\n\n\n\n\nDans le tutoriel précédent, nous avons vu que les chaînes de caractères étaient des séquences de caractères. Les listes sont également des séquences, c’est à dire des suites ordonnées d’éléments, mais plus générales : les éléments peuvent être de différente nature.\nLes listes sont construites avec des crochets [], et les éléments de la liste sont séparés par des virgules.\nAssignons une première liste à une variable a :\n\na = [1, 2, 3]\nprint(a)\n\n[1, 2, 3]\n\n\nLa liste a est constituée d’entiers, mais une liste peut en pratique contenir des objets de tout type.\n\nb = [\"une séquence\", 56, \"d\"]\nprint(b)\n\n['une séquence', 56, 'd']\n\n\nIl est notamment possible de créer des listes de listes (et ainsi de suite), ce qui permet de créer des structures hiérarchiques de données.\n\nc = [\"une séquence\", 56, [\"cette liste est imbriquée\", 75, \"o\"]]\nprint(c)\n\n['une séquence', 56, ['cette liste est imbriquée', 75, 'o']]\n\n\nUne liste imbriquée peut aussi être construite à partir de listes déjà définies.\n\nitem1 = [\"cafe\", \"500g\"]\nitem2 = [\"biscuits\", \"20\"]\nitem3 = [\"lait\", \"1L\"]\ninventaire = [item1, item2, item3]\nprint(inventaire)\n\n[['cafe', '500g'], ['biscuits', '20'], ['lait', '1L']]\n\n\nOn verra cependant dans le prochain tutoriel que les dictionnaires sont généralement des structures de données souvent plus adaptées que les listes pour représenter des données sous forme hiérarchique.\n\n\n\nComme les chaînes de caractères, il est possible d’utiliser la fonction len pour compter le nombre d’éléments présents dans une liste.\n\nd = [\"ceci\", \"est\", \"une\", \"liste\"]\nlen(d)\n\n4\n\n\n\n\n\nLes listes étant des séquences, elles s’indexent de la même manière que les chaînes de caractères. Il est notamment important de se rappeler que la numérotation des positions commence à 0 en Python.\n\n# Troisième élément de la liste a\nprint(a[2])\n\n3\n\n\nBien entendu, il n’est pas possible de demander un élément qui n’existe pas. Python renvoie une erreur nous indiquant que l’index demandé est hors limites.\n\nprint(a[5])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 print(a[5])\n\nIndexError: list index out of range\n\n\n\nPour indexer une liste contenue dans une autre liste, on utilise une double indexation.\n\n# Premier élément de la sous-liste qui est à la deuxième position de la liste c\nprint(c[2][0])\n\ncette liste est imbriquée\n\n\nEn termes d’indexation, tout ce qui était possible sur les chaînes caractères l’est également avec les listes.\n\n# Tous les éléments à partir de la 1ère position\nprint(b[1:])\n\n[56, 'd']\n\n\n\n# Inverser une liste\nprint(a[::-1])\n\n[3, 2, 1]\n\n\n\n\n\nIl est possible de modifier les éléments d’une liste manuellement, avec une syntaxe similaire à l’assignation de variable.\n\n# Réassignation d'un élément\nd = [1, 2, \"toto\", 4]\nd[2] = 3\nprint(d)\n\n[1, 2, 3, 4]\n\n\n\n# Substitution d'un élément\na = [1, 2, 3]\nb = [\"do\", \"re\", \"mi\"]\nb[0] = a[2]\nprint(b)\n\n[3, 're', 'mi']\n\n\n\n\n\nL’instruction del permet de supprimer un élément par position. Les éléments qui se trouvaient après l’élément supprimé voient donc leur index réduit de 1.\n\ne = [1, \"do\", 6]\nprint(e)\nprint(e[2])\n\ndel e[1]\nprint(e)\nprint(e[1])\n\n[1, 'do', 6]\n6\n[1, 6]\n6\n\n\n\n\n\nLà encore, on retrouve des propriétés inhérentes aux séquences.\n\n# Concaténation\n[1, 2, 3] + [\"a\", 12]\n\n[1, 2, 3, 'a', 12]\n\n\n\n# Réplication\n[\"a\", \"b\", \"c\"] * 3\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c']\n\n\n\n\n\nA l’instar des chaînes de caractères, les listes ont de nombreuses méthodes built-in, qui s’utilisent selon le format objet.methode(parametres). Les plus utiles sont présentées ci-dessous ; d’autres méthodes seront utilisées dans le cadre des exercices de fin de section.\n\n# Ajouter un élément\na = [1, 2, 3]\na.append(4)\nprint(a)\n\n[1, 2, 3, 4]\n\n\n\n# Supprimer un élément par position\nb = [\"do\", \"re\", \"mi\"]\nb.pop(0)\nprint(b)\n\n['re', 'mi']\n\n\n\n# Supprimer un élément par valeur\nb = [\"do\", \"re\", \"mi\"]\nb.remove(\"mi\")\nprint(b)\n\n['do', 're']\n\n\n\n# Inverser une liste\nl = [1, 2, 3, 4, 5]\nl.reverse()\nprint(l)\n\n[5, 4, 3, 2, 1]\n\n\n\n# Trouver la position d'un élément\nb = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nb.index(\"d\")\n\n3\n\n\n\n\n\n\n\n\nLes tuples sont une autre structure de données basique en Python, semblable à celle des listes dans leur fonctionnement. Il y a cependant une différence fondamentale : là où les éléments d’une liste peuvent être modifiés par position comme on l’a vu précédemment, les tuples sont non-modifiables (immutable). Ainsi, les éléments d’un tuple ne peuvent pas être modifiés sans redéfinir complètement le tuple.\nQuand est-il pertinent d’utiliser un tuple plutôt qu’une liste ? En pratique, les tuples sont beaucoup moins fréquemment utilisés que les listes. On utilise généralement les tuples pour stocker des données qui n’ont pas vocation à être modifiées lors de l’exécution de notre programme Python. Cela permet de se prémunir contre des problèmes d’intégrité de données, c’est à dire de modification non-voulue des données d’entrée. On s’évite ainsi parfois de longues et pénibles séances de debugging.\nUne autre différence, mineure celle-ci, est que les tuples s’écrivent avec des parenthèses au lieu des crochets. Les différents éléments sont toujours séparés par des virgules.\n\nx = (1, 2, \"mi\", \"fa\", 5)\nx\n\n(1, 2, 'mi', 'fa', 5)\n\n\nAfin de bien faire la différence avec l’usage normal des parenthèses (dans les calculs ou pour délimiter les expressions), un tuple à un seul élément se définit avec une virgule après le premier élément.\n\nx1 = (\"a\", )\nx1\n\n('a',)\n\n\nVérifions qu’il est impossible de modifier ou d’ajouter un élément à un tuple.\n\nt = (\"do\", \"rez\", \"mi\")\nt[1] = \"re\"\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[23], line 2\n      1 t = (\"do\", \"rez\", \"mi\")\n----&gt; 2 t[1] = \"re\"\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\n\nt = (\"do\", \"re\", \"mi\")\nt.append(\"fa\")\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[24], line 2\n      1 t = (\"do\", \"re\", \"mi\")\n----&gt; 2 t.append(\"fa\")\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\n\n\n\nLes tuples s’indexent comme les listes.\n\nprint(x[0])\nprint(x[3:5])\n\n1\n('fa', 5)\n\n\nEt peuvent également s’utiliser de manière hiérarchique.\n\nt1 = (\"a\", \"b\", \"c\")\nt2 = (1, 2, 3)\nt3 = (t1, \"et\", t2)\n\nprint(t3)\nprint(t3[2][1])\n\n(('a', 'b', 'c'), 'et', (1, 2, 3))\n2\n\n\nLes tuples partagent certaines méthodes built-in avec les listes : celles qui ne provoquent pas de modification de l’objet.\n\nt = (\"do\", \"re\", \"mi\")\nt.index(\"do\")\n\n0\n\n\n\nt = (\"do\", \"re\", \"mi\", \"re\", \"do\")\nt.count(\"re\")\n\n2\n\n\n\n\n\nLes fonctions list et tuple permettent de convertir une liste en tuple et inversement.\n\ntuple([\"do\", \"re\", \"mi\"])\n\n('do', 're', 'mi')\n\n\n\nlist((1, 2, 3, 4, 5))\n\n[1, 2, 3, 4, 5]\n\n\nCes fonctions ont d’autres usages en pratique, que nous verrons en exercice.\n\n\n\n\n\n\n\nPourquoi dit-on des listes et des tuples que ce sont des conteneurs ?\nQuel est le point commun entre les listes et les chaînes de caractères ?\nComment est enregistré l’ordre des éléments dans une séquence en Python ?\nQuelle est la différence fondamentale entre une liste et un tuple ?\nDans quel cas aura-t-on plutôt intérêt à utiliser un tuple qu’une liste ?\nPeut-on avoir des éléments de types différents (ex : int et string) dans une même liste ? Dans un même tuple ?\n\n\n\n\nAfficher la solution\n\n\n1/ On dit que les listes et les tuples sont des conteneurs parce qu’ils permettent de stocker et d’organiser une collection d’éléments de différente nature dans une unique structure de données.\n2/ Les listes et les chaînes de caractères sont toutes deux des séquences ordonnées d’éléments, qui peuvent être requêtées par position. Dans le cas d’une chaîne de caractères, chaque élément est lui même une chaîne de caractères. Dans le cas d’une liste, les éléments peuvent être de différente nature (chaîne de caractère, liste, tuple, etc.)\n3/ Chaque élément d’une séquence a une position unique, appelée indice, qui commence à 0 pour le premier élément, 1 pour le second, et ainsi de suite. Les éléments sont stockés dans l’ordre où ils sont ajoutés.\n4/ Une liste est un objet mutable : il est possible d’ajouter, supprimer ou modifier des éléments d’une liste après sa création. A l’inverse, les tuples sont immutables : une fois qu’un tuple est défini, on ne peut ni changer ses éléments, ni ajouter ou supprimer des éléments.\n5/ En vertu de leur immutabilité, les tuples sont particulièrement adaptés pour stocker des données dont on voudrait s’assurer qu’elle ne seront pas modifiés par erreur. Par exemples, pour stocker des constantes d’un algorithme (paramètres, coordonnées géographiques, chemin de fichier, etc).\n6/ Oui, il est tout à fait possible d’avoir des éléments de types différents dans une même liste ou dans un même tuple. Ces éléments peuvent être de types de base (ex : int et string), mais également des conteneurs (ex : liste, tuple, dictionnaire, etc.).\n\n\n\n\n\n\nCréez 4 listes portant les noms des 4 saisons, contenant chacune les noms des mois associés (les mois de changement de saison seront attribués à la saison précédente). Puis créez une liste saisons contenant les 4 listes. Essayez de prévoir ce que vont renvoyer (type de l’objet, nombre d’éléments et contenu) les instructions suivantes, puis vérifiez le.\n\nsaisons\nsaisons[0]\nsaisons[0][0]\nsaisons[1][-1]\nsaisons[2][:3]\nsaisons[1][1:2] + saisons[-1][3:]\nsaisons[2:]\nsaisons + saisons[0]\nsaisons[3][::]\nsaisons[3][::-1]\nsaisons * 3\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprintemps = [\"avril\", \"mai\", \"juin\"]\nete = [\"juillet\", \"aout\", \"septembre\"]\nautomne = [\"octobre\", \"novembre\", \"decembre\"]\nhiver = [\"janvier\", \"fevrier\", \"mars\"]\n\nsaisons = [printemps, ete, automne, hiver]\n\nl = saisons\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[0][0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[1][-1]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[2][:3]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[1][1:2] + saisons[-1][3:]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[2:]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons + saisons[0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[3][::]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[3][::-1]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons * 3\nprint(type(l), len(l), l, \"\\n\")\n\n\n\n\n\nEn ajoutant, supprimant et modifiant des éléments, nettoyez la liste suivante pour qu’elle contienne les notes de musique “do re mi fa sol la si” dans le bon ordre.\nl = [\"do\", \"re\", \"re\", \"re\", \"fa\", \"sol\", \"solsi\", \"la\"]\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl = [\"do\", \"re\", \"re\", \"re\", \"fa\", \"sol\", \"solsi\", \"la\"]\n\ndel l[1]  # On aurait aussi pu utiliser : l.pop(1)\nl[2] = \"mi\"\ndel l[5]\nl.append(\"si\")\n\nprint(l)\nCet exemple visait simplement à pratiquer la modification et la suppression d’éléments. En pratique, il aurait été bien plus simple de directement créer la liste correcte.\n\n\n\n\n\nProposez deux méthodes pour inverser la liste [\"une\", \"liste\", \"quelconque\"]. Quelle est la différence majeure entre les deux méthodes ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl1 = [\"une\", \"liste\", \"quelconque\"]\nl1.reverse()\nprint(l1)\n\nl2 = [\"une\", \"liste\", \"quelconque\"]\nprint(l2[::-1])\nprint(l2)\nLa méthode reverse modifie la liste “en place” : la liste est durablement inversée après l’avoir exécutée. En revanche, la méthode qui inverse la liste via l’indexation renvoie une nouvelle liste et ne modifie pas l’existante. Pour que ce changement soit durable, il faudrait donc écraser la liste existante, ou bien en créer une nouvelle.\nl2 = l2[::-1]\nprint(l2)\n\n\n\n\n\nNous avons vu que l’instruction ma_liste.pop(i) supprimait le i-ème élément de la liste ma_liste. A l’aide de la documentation Python ou d’une recherche sur Google, déterminez le comportement par défaut de cette méthode, c’est à dire ce qu’il se passe lorsqu’on ne donne aucun paramètre à la fonction pop. Vérifiez que vous observez bien ce comportement à l’aide d’un exemple de votre choix.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl = [\"do\", \"re\", \"mi\"]\nl.pop()\nprint(l)\n\n\n\n\n\nIl existe beaucoup d’autres méthodes built-in pour les listes que celles que nous avons déjà vues. Par exemple : min et max. Vérifiez leur comportement :\n\nsur une liste composée uniquement d’objets numériques (int et float) ;\nsur une liste composée uniquement de chaînes de caractères ;\nsur une liste composée d’un mélange d’objets numériques et textuels.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = [5, 800, 9.92, 0]\nb = [\"do\", \"re\", \"mi\", \"fa\", \"sol\"]\nc = [1, \"melange\", \"des\", 2]\n\nprint(min(a), max(a))\nprint(min(b), max(b))\nprint(min(c), max(c))\nLa troisième expression renvoie une erreur : il n’existe pas de relation d’ordre pertinente.\n\n\n\n\n\nEssayer de créer une liste vide. Vérifiez son type. Quel intérêt pourrait avoir un tel objet ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl = []\nprint(l)\nprint(type(l))\nOn peut donc effectivement créer une liste vide. Mais quel intérêt ? Un usage très fréquent est d’initialiser une liste, que l’on va ensuite remplir au fur et à mesure des itérations d’une boucle. Les boucles feront l’objet d’un prochain tutoriel ; mais voici un exemple simple d’un tel usage.\nfor i in range(10):\n    l.append(i)\n    \nprint(l)\n\n\n\n\n\nDans le tutoriel, nous avons vu les fonctions list et tuple qui permettent de passer d’un type à l’autre. En réalité, le fonctionnement de ces fonctions est plus subtil : le code list(mon_objet) renvoie la “version liste” de cet objet, de la même manière par exemple que str(3) renvoie '3', c’est à dire la version string de l’entier 3.\nA l’aide de la fonction list, trouver les “versions liste” des objets suivants :\n\nle tuple a = (1, 2, 3) ;\nla chaîne de caractères b = \"bonjour\" ;\nl’entier c = 5\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = (1, 2, 3)\nprint(list(a))\n\nb = \"bonjour\"\nprint(list(b))\n\nc = 5\nprint(list(c))\nLa dernière expression renvoie une erreur : un entier n’est pas une séquence, une “version liste” n’a donc pas sens. On peut par contre bien entendu créer une liste avec pour seul élément 5.\nd = [5]\nprint(d)\n\n\n\n\n\nNous avons vu que les tuples avaient la particularité d’être non-modifiables. Mais est-ce que cette propriété se transfère de manière récursive ? Par exemple, est-ce qu’une liste contenue dans un tuple est-elle même non-modifiable ? Vérifiez à l’aide d’un exemple de votre choix.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nt = (1, 2, [\"une\", \"liste\"])\nt[2][0] = 26\nprint(t)\nVerdict : la non-modifiabilité ne s’applique qu’au premier niveau. Elle ne se transfère pas aux sous-éléments.\n\n\n\n\n\nLisez la partie concernant l’agrégation et la dissociation de séquences dans la documentation Python. La dissociation est une propriété souvent utilisée en pratique. Vérifiez qu’elle fonctionne sur les différents objets séquentiels que nous avons vus jusqu’à maintenant (chaînes de caractères, listes et tuples).\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx, y, z = \"abc\"\nprint(y)\n\na, b, c, d = [\"do\", \"re\", \"mi\", \"fa\"]\nprint(c)\n\nr, s, t, u = (\"un\", \"tuple\", \"de\", \"test\")\nprint(r)",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 1 : listes et tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html#listes",
    "href": "source/fundamentals/data-structures1/tutorial.html#listes",
    "title": "Structures de données 1 : listes et tuples",
    "section": "",
    "text": "Dans le tutoriel précédent, nous avons vu que les chaînes de caractères étaient des séquences de caractères. Les listes sont également des séquences, c’est à dire des suites ordonnées d’éléments, mais plus générales : les éléments peuvent être de différente nature.\nLes listes sont construites avec des crochets [], et les éléments de la liste sont séparés par des virgules.\nAssignons une première liste à une variable a :\n\na = [1, 2, 3]\nprint(a)\n\n[1, 2, 3]\n\n\nLa liste a est constituée d’entiers, mais une liste peut en pratique contenir des objets de tout type.\n\nb = [\"une séquence\", 56, \"d\"]\nprint(b)\n\n['une séquence', 56, 'd']\n\n\nIl est notamment possible de créer des listes de listes (et ainsi de suite), ce qui permet de créer des structures hiérarchiques de données.\n\nc = [\"une séquence\", 56, [\"cette liste est imbriquée\", 75, \"o\"]]\nprint(c)\n\n['une séquence', 56, ['cette liste est imbriquée', 75, 'o']]\n\n\nUne liste imbriquée peut aussi être construite à partir de listes déjà définies.\n\nitem1 = [\"cafe\", \"500g\"]\nitem2 = [\"biscuits\", \"20\"]\nitem3 = [\"lait\", \"1L\"]\ninventaire = [item1, item2, item3]\nprint(inventaire)\n\n[['cafe', '500g'], ['biscuits', '20'], ['lait', '1L']]\n\n\nOn verra cependant dans le prochain tutoriel que les dictionnaires sont généralement des structures de données souvent plus adaptées que les listes pour représenter des données sous forme hiérarchique.\n\n\n\nComme les chaînes de caractères, il est possible d’utiliser la fonction len pour compter le nombre d’éléments présents dans une liste.\n\nd = [\"ceci\", \"est\", \"une\", \"liste\"]\nlen(d)\n\n4\n\n\n\n\n\nLes listes étant des séquences, elles s’indexent de la même manière que les chaînes de caractères. Il est notamment important de se rappeler que la numérotation des positions commence à 0 en Python.\n\n# Troisième élément de la liste a\nprint(a[2])\n\n3\n\n\nBien entendu, il n’est pas possible de demander un élément qui n’existe pas. Python renvoie une erreur nous indiquant que l’index demandé est hors limites.\n\nprint(a[5])\n\n\n---------------------------------------------------------------------------\nIndexError                                Traceback (most recent call last)\nCell In[7], line 1\n----&gt; 1 print(a[5])\n\nIndexError: list index out of range\n\n\n\nPour indexer une liste contenue dans une autre liste, on utilise une double indexation.\n\n# Premier élément de la sous-liste qui est à la deuxième position de la liste c\nprint(c[2][0])\n\ncette liste est imbriquée\n\n\nEn termes d’indexation, tout ce qui était possible sur les chaînes caractères l’est également avec les listes.\n\n# Tous les éléments à partir de la 1ère position\nprint(b[1:])\n\n[56, 'd']\n\n\n\n# Inverser une liste\nprint(a[::-1])\n\n[3, 2, 1]\n\n\n\n\n\nIl est possible de modifier les éléments d’une liste manuellement, avec une syntaxe similaire à l’assignation de variable.\n\n# Réassignation d'un élément\nd = [1, 2, \"toto\", 4]\nd[2] = 3\nprint(d)\n\n[1, 2, 3, 4]\n\n\n\n# Substitution d'un élément\na = [1, 2, 3]\nb = [\"do\", \"re\", \"mi\"]\nb[0] = a[2]\nprint(b)\n\n[3, 're', 'mi']\n\n\n\n\n\nL’instruction del permet de supprimer un élément par position. Les éléments qui se trouvaient après l’élément supprimé voient donc leur index réduit de 1.\n\ne = [1, \"do\", 6]\nprint(e)\nprint(e[2])\n\ndel e[1]\nprint(e)\nprint(e[1])\n\n[1, 'do', 6]\n6\n[1, 6]\n6\n\n\n\n\n\nLà encore, on retrouve des propriétés inhérentes aux séquences.\n\n# Concaténation\n[1, 2, 3] + [\"a\", 12]\n\n[1, 2, 3, 'a', 12]\n\n\n\n# Réplication\n[\"a\", \"b\", \"c\"] * 3\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c']\n\n\n\n\n\nA l’instar des chaînes de caractères, les listes ont de nombreuses méthodes built-in, qui s’utilisent selon le format objet.methode(parametres). Les plus utiles sont présentées ci-dessous ; d’autres méthodes seront utilisées dans le cadre des exercices de fin de section.\n\n# Ajouter un élément\na = [1, 2, 3]\na.append(4)\nprint(a)\n\n[1, 2, 3, 4]\n\n\n\n# Supprimer un élément par position\nb = [\"do\", \"re\", \"mi\"]\nb.pop(0)\nprint(b)\n\n['re', 'mi']\n\n\n\n# Supprimer un élément par valeur\nb = [\"do\", \"re\", \"mi\"]\nb.remove(\"mi\")\nprint(b)\n\n['do', 're']\n\n\n\n# Inverser une liste\nl = [1, 2, 3, 4, 5]\nl.reverse()\nprint(l)\n\n[5, 4, 3, 2, 1]\n\n\n\n# Trouver la position d'un élément\nb = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nb.index(\"d\")\n\n3",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 1 : listes et tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html#tuples",
    "href": "source/fundamentals/data-structures1/tutorial.html#tuples",
    "title": "Structures de données 1 : listes et tuples",
    "section": "",
    "text": "Les tuples sont une autre structure de données basique en Python, semblable à celle des listes dans leur fonctionnement. Il y a cependant une différence fondamentale : là où les éléments d’une liste peuvent être modifiés par position comme on l’a vu précédemment, les tuples sont non-modifiables (immutable). Ainsi, les éléments d’un tuple ne peuvent pas être modifiés sans redéfinir complètement le tuple.\nQuand est-il pertinent d’utiliser un tuple plutôt qu’une liste ? En pratique, les tuples sont beaucoup moins fréquemment utilisés que les listes. On utilise généralement les tuples pour stocker des données qui n’ont pas vocation à être modifiées lors de l’exécution de notre programme Python. Cela permet de se prémunir contre des problèmes d’intégrité de données, c’est à dire de modification non-voulue des données d’entrée. On s’évite ainsi parfois de longues et pénibles séances de debugging.\nUne autre différence, mineure celle-ci, est que les tuples s’écrivent avec des parenthèses au lieu des crochets. Les différents éléments sont toujours séparés par des virgules.\n\nx = (1, 2, \"mi\", \"fa\", 5)\nx\n\n(1, 2, 'mi', 'fa', 5)\n\n\nAfin de bien faire la différence avec l’usage normal des parenthèses (dans les calculs ou pour délimiter les expressions), un tuple à un seul élément se définit avec une virgule après le premier élément.\n\nx1 = (\"a\", )\nx1\n\n('a',)\n\n\nVérifions qu’il est impossible de modifier ou d’ajouter un élément à un tuple.\n\nt = (\"do\", \"rez\", \"mi\")\nt[1] = \"re\"\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[23], line 2\n      1 t = (\"do\", \"rez\", \"mi\")\n----&gt; 2 t[1] = \"re\"\n\nTypeError: 'tuple' object does not support item assignment\n\n\n\n\nt = (\"do\", \"re\", \"mi\")\nt.append(\"fa\")\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[24], line 2\n      1 t = (\"do\", \"re\", \"mi\")\n----&gt; 2 t.append(\"fa\")\n\nAttributeError: 'tuple' object has no attribute 'append'\n\n\n\n\n\n\nLes tuples s’indexent comme les listes.\n\nprint(x[0])\nprint(x[3:5])\n\n1\n('fa', 5)\n\n\nEt peuvent également s’utiliser de manière hiérarchique.\n\nt1 = (\"a\", \"b\", \"c\")\nt2 = (1, 2, 3)\nt3 = (t1, \"et\", t2)\n\nprint(t3)\nprint(t3[2][1])\n\n(('a', 'b', 'c'), 'et', (1, 2, 3))\n2\n\n\nLes tuples partagent certaines méthodes built-in avec les listes : celles qui ne provoquent pas de modification de l’objet.\n\nt = (\"do\", \"re\", \"mi\")\nt.index(\"do\")\n\n0\n\n\n\nt = (\"do\", \"re\", \"mi\", \"re\", \"do\")\nt.count(\"re\")\n\n2\n\n\n\n\n\nLes fonctions list et tuple permettent de convertir une liste en tuple et inversement.\n\ntuple([\"do\", \"re\", \"mi\"])\n\n('do', 're', 'mi')\n\n\n\nlist((1, 2, 3, 4, 5))\n\n[1, 2, 3, 4, 5]\n\n\nCes fonctions ont d’autres usages en pratique, que nous verrons en exercice.",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 1 : listes et tuples"
    ]
  },
  {
    "objectID": "source/fundamentals/data-structures1/tutorial.html#exercices",
    "href": "source/fundamentals/data-structures1/tutorial.html#exercices",
    "title": "Structures de données 1 : listes et tuples",
    "section": "",
    "text": "Pourquoi dit-on des listes et des tuples que ce sont des conteneurs ?\nQuel est le point commun entre les listes et les chaînes de caractères ?\nComment est enregistré l’ordre des éléments dans une séquence en Python ?\nQuelle est la différence fondamentale entre une liste et un tuple ?\nDans quel cas aura-t-on plutôt intérêt à utiliser un tuple qu’une liste ?\nPeut-on avoir des éléments de types différents (ex : int et string) dans une même liste ? Dans un même tuple ?\n\n\n\n\nAfficher la solution\n\n\n1/ On dit que les listes et les tuples sont des conteneurs parce qu’ils permettent de stocker et d’organiser une collection d’éléments de différente nature dans une unique structure de données.\n2/ Les listes et les chaînes de caractères sont toutes deux des séquences ordonnées d’éléments, qui peuvent être requêtées par position. Dans le cas d’une chaîne de caractères, chaque élément est lui même une chaîne de caractères. Dans le cas d’une liste, les éléments peuvent être de différente nature (chaîne de caractère, liste, tuple, etc.)\n3/ Chaque élément d’une séquence a une position unique, appelée indice, qui commence à 0 pour le premier élément, 1 pour le second, et ainsi de suite. Les éléments sont stockés dans l’ordre où ils sont ajoutés.\n4/ Une liste est un objet mutable : il est possible d’ajouter, supprimer ou modifier des éléments d’une liste après sa création. A l’inverse, les tuples sont immutables : une fois qu’un tuple est défini, on ne peut ni changer ses éléments, ni ajouter ou supprimer des éléments.\n5/ En vertu de leur immutabilité, les tuples sont particulièrement adaptés pour stocker des données dont on voudrait s’assurer qu’elle ne seront pas modifiés par erreur. Par exemples, pour stocker des constantes d’un algorithme (paramètres, coordonnées géographiques, chemin de fichier, etc).\n6/ Oui, il est tout à fait possible d’avoir des éléments de types différents dans une même liste ou dans un même tuple. Ces éléments peuvent être de types de base (ex : int et string), mais également des conteneurs (ex : liste, tuple, dictionnaire, etc.).\n\n\n\n\n\n\nCréez 4 listes portant les noms des 4 saisons, contenant chacune les noms des mois associés (les mois de changement de saison seront attribués à la saison précédente). Puis créez une liste saisons contenant les 4 listes. Essayez de prévoir ce que vont renvoyer (type de l’objet, nombre d’éléments et contenu) les instructions suivantes, puis vérifiez le.\n\nsaisons\nsaisons[0]\nsaisons[0][0]\nsaisons[1][-1]\nsaisons[2][:3]\nsaisons[1][1:2] + saisons[-1][3:]\nsaisons[2:]\nsaisons + saisons[0]\nsaisons[3][::]\nsaisons[3][::-1]\nsaisons * 3\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nprintemps = [\"avril\", \"mai\", \"juin\"]\nete = [\"juillet\", \"aout\", \"septembre\"]\nautomne = [\"octobre\", \"novembre\", \"decembre\"]\nhiver = [\"janvier\", \"fevrier\", \"mars\"]\n\nsaisons = [printemps, ete, automne, hiver]\n\nl = saisons\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[0][0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[1][-1]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[2][:3]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[1][1:2] + saisons[-1][3:]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[2:]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons + saisons[0]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[3][::]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons[3][::-1]\nprint(type(l), len(l), l, \"\\n\")\n\nl = saisons * 3\nprint(type(l), len(l), l, \"\\n\")\n\n\n\n\n\nEn ajoutant, supprimant et modifiant des éléments, nettoyez la liste suivante pour qu’elle contienne les notes de musique “do re mi fa sol la si” dans le bon ordre.\nl = [\"do\", \"re\", \"re\", \"re\", \"fa\", \"sol\", \"solsi\", \"la\"]\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl = [\"do\", \"re\", \"re\", \"re\", \"fa\", \"sol\", \"solsi\", \"la\"]\n\ndel l[1]  # On aurait aussi pu utiliser : l.pop(1)\nl[2] = \"mi\"\ndel l[5]\nl.append(\"si\")\n\nprint(l)\nCet exemple visait simplement à pratiquer la modification et la suppression d’éléments. En pratique, il aurait été bien plus simple de directement créer la liste correcte.\n\n\n\n\n\nProposez deux méthodes pour inverser la liste [\"une\", \"liste\", \"quelconque\"]. Quelle est la différence majeure entre les deux méthodes ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl1 = [\"une\", \"liste\", \"quelconque\"]\nl1.reverse()\nprint(l1)\n\nl2 = [\"une\", \"liste\", \"quelconque\"]\nprint(l2[::-1])\nprint(l2)\nLa méthode reverse modifie la liste “en place” : la liste est durablement inversée après l’avoir exécutée. En revanche, la méthode qui inverse la liste via l’indexation renvoie une nouvelle liste et ne modifie pas l’existante. Pour que ce changement soit durable, il faudrait donc écraser la liste existante, ou bien en créer une nouvelle.\nl2 = l2[::-1]\nprint(l2)\n\n\n\n\n\nNous avons vu que l’instruction ma_liste.pop(i) supprimait le i-ème élément de la liste ma_liste. A l’aide de la documentation Python ou d’une recherche sur Google, déterminez le comportement par défaut de cette méthode, c’est à dire ce qu’il se passe lorsqu’on ne donne aucun paramètre à la fonction pop. Vérifiez que vous observez bien ce comportement à l’aide d’un exemple de votre choix.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl = [\"do\", \"re\", \"mi\"]\nl.pop()\nprint(l)\n\n\n\n\n\nIl existe beaucoup d’autres méthodes built-in pour les listes que celles que nous avons déjà vues. Par exemple : min et max. Vérifiez leur comportement :\n\nsur une liste composée uniquement d’objets numériques (int et float) ;\nsur une liste composée uniquement de chaînes de caractères ;\nsur une liste composée d’un mélange d’objets numériques et textuels.\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = [5, 800, 9.92, 0]\nb = [\"do\", \"re\", \"mi\", \"fa\", \"sol\"]\nc = [1, \"melange\", \"des\", 2]\n\nprint(min(a), max(a))\nprint(min(b), max(b))\nprint(min(c), max(c))\nLa troisième expression renvoie une erreur : il n’existe pas de relation d’ordre pertinente.\n\n\n\n\n\nEssayer de créer une liste vide. Vérifiez son type. Quel intérêt pourrait avoir un tel objet ?\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nl = []\nprint(l)\nprint(type(l))\nOn peut donc effectivement créer une liste vide. Mais quel intérêt ? Un usage très fréquent est d’initialiser une liste, que l’on va ensuite remplir au fur et à mesure des itérations d’une boucle. Les boucles feront l’objet d’un prochain tutoriel ; mais voici un exemple simple d’un tel usage.\nfor i in range(10):\n    l.append(i)\n    \nprint(l)\n\n\n\n\n\nDans le tutoriel, nous avons vu les fonctions list et tuple qui permettent de passer d’un type à l’autre. En réalité, le fonctionnement de ces fonctions est plus subtil : le code list(mon_objet) renvoie la “version liste” de cet objet, de la même manière par exemple que str(3) renvoie '3', c’est à dire la version string de l’entier 3.\nA l’aide de la fonction list, trouver les “versions liste” des objets suivants :\n\nle tuple a = (1, 2, 3) ;\nla chaîne de caractères b = \"bonjour\" ;\nl’entier c = 5\n\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = (1, 2, 3)\nprint(list(a))\n\nb = \"bonjour\"\nprint(list(b))\n\nc = 5\nprint(list(c))\nLa dernière expression renvoie une erreur : un entier n’est pas une séquence, une “version liste” n’a donc pas sens. On peut par contre bien entendu créer une liste avec pour seul élément 5.\nd = [5]\nprint(d)\n\n\n\n\n\nNous avons vu que les tuples avaient la particularité d’être non-modifiables. Mais est-ce que cette propriété se transfère de manière récursive ? Par exemple, est-ce qu’une liste contenue dans un tuple est-elle même non-modifiable ? Vérifiez à l’aide d’un exemple de votre choix.\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nt = (1, 2, [\"une\", \"liste\"])\nt[2][0] = 26\nprint(t)\nVerdict : la non-modifiabilité ne s’applique qu’au premier niveau. Elle ne se transfère pas aux sous-éléments.\n\n\n\n\n\nLisez la partie concernant l’agrégation et la dissociation de séquences dans la documentation Python. La dissociation est une propriété souvent utilisée en pratique. Vérifiez qu’elle fonctionne sur les différents objets séquentiels que nous avons vus jusqu’à maintenant (chaînes de caractères, listes et tuples).\n\n# Testez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx, y, z = \"abc\"\nprint(y)\n\na, b, c, d = [\"do\", \"re\", \"mi\", \"fa\"]\nprint(c)\n\nr, s, t, u = (\"un\", \"tuple\", \"de\", \"test\")\nprint(r)",
    "crumbs": [
      "Fondamentaux du langage",
      "Structures de données 1 : listes et tuples"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html",
    "href": "source/projects/puissance4/tutorial.html",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Dans ce projet nous allons implémenter un puissance 4 avec une interface graphique assez sommaire. Pour y arriver, nous allons utiliser les objets fondamentaux de Python.\n\nimport copy\n\nimport solutions\n\n\n\nLe but du jeu de Puissance 4 est d’aligner une suite de 4 pions de même couleur sur une grille comptant 6 rangées et 7 colonnes. Chaque joueur dispose de 21 pions d’une couleur (par convention, en général jaune ou rouge). Tour à tour, les deux joueurs placent un pion dans la colonne de leur choix, le pion coulisse alors jusqu’à la position la plus basse possible dans la dite colonne à la suite de quoi c’est à l’adversaire de jouer. Le vainqueur est le joueur qui réalise le premier un alignement (horizontal, vertical ou diagonal) consécutif d’au moins quatre pions de sa couleur. Si, alors que toutes les cases de la grille de jeu sont remplies, aucun des deux joueurs n’a réalisé un tel alignement, la partie est déclarée nulle.\nAfin de simplifier le code de ce projet, on partira du principe que les alignements victorieux ne peuvent être qu’horizontaux ou verticaux. Les diagonales ne seront donc pas considérées (mais constituent un exercice intéressant pour aller plus loin !).\n\n\n\nNous allons décomposer la construction du jeu en différentes parties :\n\ninitialisation de la grille\nreprésentation de la grille\nfonction de jeu\ndétection d’une victoire (horizontale)\ndétection d’une victoire (verticale)\nfin de partie\n\n\n\n\nL’objectif de cette partie est d’initialiser un objet Python qui représente une grille de puissance 4. Le choix que nous allons faire est de représenter la grille comme une liste de listes. Il s’agira d’une matrice 6x7 : on aura par conséquent une liste de 6 élements (qui représenteront les lignes de la grille), dont chacun des éléments sera une liste contenant 7 éléments (qui représenterons les pions).\nChaque élément de la grille sera représenté par un string, qui pourra prendre trois valeurs :\n\n’ ’ : s’il s’agit d’une case vide\n‘R’ : s’il s’agit d’un pion rouge.\n‘Y’ : s’il s’agit d’un pion jaune (yellow).\n\nDans la fonction d’initialisation de la grille, chaque élément sera donc initialisé comme un string contenant un espace.\nAttention : Bien faire attention à ce que les lignes soient des objets indépendants, autrement dit que modifier l’une des listes n’affecte pas les autres.\n\n\n\ngrid_solution = solutions.initialize_grid()\ngrid_solution\n\n\nprint(f'Nombre de lignes : {len(grid_solution)}')\nprint(f'Nombre de colonnes : {len(grid_solution[0])}')\n\n\n\n\n\ndef initialize_grid():\n    # Votre code ici\n    return grid\n\n\n# Vérification du résultat\ngrid = initialize_grid()\ngrid\n\n\n# Vérification du résultat\nprint(f'Nombre de lignes : {len(grid)}')\nprint(f'Nombre de colonnes : {len(grid[0])}')\n\n\n\n\n\nNotre grille est initialisée, mais son affichage est assez sommaire. L’idée de cette partie est d’offrir une représentation plus visuelle du jeu pendant une partie.\nPour cela, nous allons créer une fonction qui prend en entrée la grille précédemment initialisée et renvoie sa représentation (via la fonction print). Les colonnes seront séparées par le caractère | (barre verticale).\nIndice : une solution possible fait intervenir deux notions que nous avons vues dans les TP précédents : la concaténation de strings et la fonction join qui “joint” les éléments d’une liste en les séparant par un certain caractère. Pour rappel, voici un exemple qui utilise ces deux concepts :\n\nl = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nl_join = \"DEBUT \" + \", \".join(l) + \" FIN\"\nprint(l_join)\n\n\n\n\nsolutions.display_grid(grid_solution)\n\n\n\n\n\ndef display_grid():\n    # Votre code ici\n\n\n# Vérification du résultat\ndisplay_grid(grid)\n\n\n\n\n\nMaintenant que nous pouvons représenter notre grille, intéressons-nous au coeur du puissance 4 : le jeu. L’objectif de cette partie est de coder une fonction make_move qui va modifier la grille lorsqu’un joueur joue son tour.\nCette fonction prend en entrée :\n\nla grille\nla colonne choisie par le joueur\nla couleur du pion (‘R’ pour le pion rouge, et ‘Y’ pour le pion jaune)\n\net renvoie en sortie la grille actualisée suite au tour du joueur.\nSi la colonne choisie est déjà complète, renvoyer un message d’erreur.\nAttention : en Python, la numérotation commence à 0. La première colonne correspond donc à la colonne 0 du point de vue de l’indexation.\nOptionnel : Renvoyer un message d’erreur si un joueur essaie de jouer dans une colonne inexistante ou bien avec une couleur non autorisée.\n\n\n\ngrid_solution = solutions.initialize_grid()  # Initialisation\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"R\")  # 1er tour de jeu\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=5, disc_color=\"J\")  # 2ème tour de jeu\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"R\")  # 3ème tour de jeu\nsolutions.display_grid(grid_solution)\n\n\n\n\n\ndef make_move(grid, column_to_play, disc_color):\n    new_grid = copy.deepcopy(grid)  # Evite la modification de la grille initiale\n    # Votre code ici\n    return new_grid\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 1er tour de jeu\ngrid = make_move(grid=grid, column_to_play=5, disc_color=\"J\")  # 2ème tour de jeu\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 3ème tour de jeu\ndisplay_grid(grid)\n\n\n\n\n\nMaintenant qu’il est possible de jouer effectivement à notre puissance 4, il faut pouvoir détecter une victoire pour mettre fin à la partie en cours. Pour se faire, on va simplifier le problème en le décomposant au maximum.\nDans un premier temps, on s’intéresse à la détection d’une victoire horizontale. Pour cela, on va s’aider de deux fonctions :\n\nune fonction check_row_victory qui prend en entrée une ligne du puissance 4 (i.e. une liste de taille 7) et retourne True si jamais 4 pions consécutifs de même couleur se trouvent sur la ligne, et False sinon\nune fonction check_horizontal_victory qui prend en entrée une grille complète et retourne True si jamais une ligne de la grille remplit la condition précédente, et False sinon\n\n\n\n\n# Détection d'une victoire (horizontale) sur une ligne\nligne1 = [\" \", \"R\", \"R\", \"R\", \"J\", \"J\", \" \"]\nligne2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"J\", \" \"]\n\nprint(solutions.check_row_victory(ligne1))  # Renvoie False\nprint()  # Retour à la ligne\nprint(solutions.check_row_victory(ligne2))  # Renvoie True\n\n\n# Détection d'une victoire (horizontale) sur une grille\ngrid_solution = solutions.initialize_grid()  # Initialisation\nprint(solutions.check_horizontal_victory(grid_solution))  # Renvoie False\nprint()  # Retour à la ligne\n\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"R\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=3, disc_color=\"R\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=4, disc_color=\"R\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=5, disc_color=\"R\")\nsolutions.display_grid(grid_solution)\nprint()  # Retour à la ligne\n\nprint(solutions.check_horizontal_victory(grid_solution))  # Renvoie True\n\n\n\n\n\ndef check_row_victory(ligne):\n    # Votre code ici\n\n\n# Vérification du résultat\nrow1 = [\" \", \"R\", \"R\", \"R\", \"J\", \"R\", \" \"]\nrow2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"J\", \" \"]\n\nprint(check_row_victory(row1))  # Renvoie False\nprint(check_row_victory(row2))  # Renvoie True\n\n\ndef check_horizontal_victory(grid):\n    # Votre code ici\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\nprint(check_horizontal_victory(grid))  # Renvoie False\n\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=3, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=4, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=5, disc_color=\"R\")\ndisplay_grid(grid)\nprint(check_horizontal_victory(grid))  # Renvoie True\n\n\n\n\n\nA présent, on s’intéresse à la détection d’une victoire verticale. Par rapport à la situation précédente, la difficulté est que l’on ne peut pas directement boucler sur les colonnes. On va donc construire une fonction check_vertical_victory qui, pour chaque colonne :\n\nrécupère les éléments de la colonne dans une liste\napplique à cette liste la fonction check_row_victory pour vérifier la présence de 4 pions consécutifs de même couleur dans la colonne considérée\n\n\n\n\n# Détection d'une victoire (verticale) sur une grille\ngrid_solution = solutions.initialize_grid()  # Initialisation\nprint(solutions.check_vertical_victory(grid_solution))  # Renvoie False\nprint()  # Retour à la ligne\n\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nsolutions.display_grid(grid_solution)\nprint()  # Retour à la ligne\n\nprint(solutions.check_vertical_victory(grid_solution))  # Renvoie True\n\n\n\n\n\ndef check_vertical_victory(grid):\n    # Votre code ici\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\nprint(check_vertical_victory(grid))  # Renvoie False\nprint()  # Retour à la ligne\n\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ndisplay_grid(grid)\nprint()  # Retour à la ligne\n\nprint(check_vertical_victory(grid))  # Renvoie True\n\n\n\n\n\nDans notre version simplifiée du puissance 4, on peut à présent déclarer la fin de partie : dès lors qu’une victoire horizontale ou verticale est détectée.\nOn va donc pour commencer créer une fonction victoire qui prend la grille en entrée et renvoie True si une victoire horizontale ou verticale est détectée, et False sinon.\nDans l’idéal, on voudrait ne pas avoir à tester manuellement après chaque coup si la partie est terminée afin de limiter la duplication de code. On va donc ensuite créer une fonction make_move_and_check_victory qui :\n\nprend en entrée les mêmes inputs que la fonction tour\nva appeler la fonction tour pour réaliser le tour de jeu\nva tester après le tour de jeu si une victoire est détectée via la fonction victoire. Si une victoire est détectée, la fonction imprime “FIN DE PARTIE”.\n\n\n\n\ngrid_solution = solutions.initialize_grid()  # Initialisation\nprint(\"Tour 1\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 2\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 3\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 4\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\n\n\n\n\n\ndef check_victory(grid):\n    # Votre code ici\n\n\ndef make_move_and_check_victory(grille, column_to_play, disc_color):\n    grid = copy.deepcopy(grid)\n    # Votre code ici\n    return grid\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\nprint(\"Tour 1\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 2\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 3\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 4\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#règles-du-jeu",
    "href": "source/projects/puissance4/tutorial.html#règles-du-jeu",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Le but du jeu de Puissance 4 est d’aligner une suite de 4 pions de même couleur sur une grille comptant 6 rangées et 7 colonnes. Chaque joueur dispose de 21 pions d’une couleur (par convention, en général jaune ou rouge). Tour à tour, les deux joueurs placent un pion dans la colonne de leur choix, le pion coulisse alors jusqu’à la position la plus basse possible dans la dite colonne à la suite de quoi c’est à l’adversaire de jouer. Le vainqueur est le joueur qui réalise le premier un alignement (horizontal, vertical ou diagonal) consécutif d’au moins quatre pions de sa couleur. Si, alors que toutes les cases de la grille de jeu sont remplies, aucun des deux joueurs n’a réalisé un tel alignement, la partie est déclarée nulle.\nAfin de simplifier le code de ce projet, on partira du principe que les alignements victorieux ne peuvent être qu’horizontaux ou verticaux. Les diagonales ne seront donc pas considérées (mais constituent un exercice intéressant pour aller plus loin !).",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#plan-du-projet",
    "href": "source/projects/puissance4/tutorial.html#plan-du-projet",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Nous allons décomposer la construction du jeu en différentes parties :\n\ninitialisation de la grille\nreprésentation de la grille\nfonction de jeu\ndétection d’une victoire (horizontale)\ndétection d’une victoire (verticale)\nfin de partie",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#initialisation-de-la-grille",
    "href": "source/projects/puissance4/tutorial.html#initialisation-de-la-grille",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "L’objectif de cette partie est d’initialiser un objet Python qui représente une grille de puissance 4. Le choix que nous allons faire est de représenter la grille comme une liste de listes. Il s’agira d’une matrice 6x7 : on aura par conséquent une liste de 6 élements (qui représenteront les lignes de la grille), dont chacun des éléments sera une liste contenant 7 éléments (qui représenterons les pions).\nChaque élément de la grille sera représenté par un string, qui pourra prendre trois valeurs :\n\n’ ’ : s’il s’agit d’une case vide\n‘R’ : s’il s’agit d’un pion rouge.\n‘Y’ : s’il s’agit d’un pion jaune (yellow).\n\nDans la fonction d’initialisation de la grille, chaque élément sera donc initialisé comme un string contenant un espace.\nAttention : Bien faire attention à ce que les lignes soient des objets indépendants, autrement dit que modifier l’une des listes n’affecte pas les autres.\n\n\n\ngrid_solution = solutions.initialize_grid()\ngrid_solution\n\n\nprint(f'Nombre de lignes : {len(grid_solution)}')\nprint(f'Nombre de colonnes : {len(grid_solution[0])}')\n\n\n\n\n\ndef initialize_grid():\n    # Votre code ici\n    return grid\n\n\n# Vérification du résultat\ngrid = initialize_grid()\ngrid\n\n\n# Vérification du résultat\nprint(f'Nombre de lignes : {len(grid)}')\nprint(f'Nombre de colonnes : {len(grid[0])}')",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#représentation-de-la-grille",
    "href": "source/projects/puissance4/tutorial.html#représentation-de-la-grille",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Notre grille est initialisée, mais son affichage est assez sommaire. L’idée de cette partie est d’offrir une représentation plus visuelle du jeu pendant une partie.\nPour cela, nous allons créer une fonction qui prend en entrée la grille précédemment initialisée et renvoie sa représentation (via la fonction print). Les colonnes seront séparées par le caractère | (barre verticale).\nIndice : une solution possible fait intervenir deux notions que nous avons vues dans les TP précédents : la concaténation de strings et la fonction join qui “joint” les éléments d’une liste en les séparant par un certain caractère. Pour rappel, voici un exemple qui utilise ces deux concepts :\n\nl = [\"a\", \"b\", \"c\", \"d\", \"e\"]\nl_join = \"DEBUT \" + \", \".join(l) + \" FIN\"\nprint(l_join)\n\n\n\n\nsolutions.display_grid(grid_solution)\n\n\n\n\n\ndef display_grid():\n    # Votre code ici\n\n\n# Vérification du résultat\ndisplay_grid(grid)",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#fonction-de-jeu",
    "href": "source/projects/puissance4/tutorial.html#fonction-de-jeu",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Maintenant que nous pouvons représenter notre grille, intéressons-nous au coeur du puissance 4 : le jeu. L’objectif de cette partie est de coder une fonction make_move qui va modifier la grille lorsqu’un joueur joue son tour.\nCette fonction prend en entrée :\n\nla grille\nla colonne choisie par le joueur\nla couleur du pion (‘R’ pour le pion rouge, et ‘Y’ pour le pion jaune)\n\net renvoie en sortie la grille actualisée suite au tour du joueur.\nSi la colonne choisie est déjà complète, renvoyer un message d’erreur.\nAttention : en Python, la numérotation commence à 0. La première colonne correspond donc à la colonne 0 du point de vue de l’indexation.\nOptionnel : Renvoyer un message d’erreur si un joueur essaie de jouer dans une colonne inexistante ou bien avec une couleur non autorisée.\n\n\n\ngrid_solution = solutions.initialize_grid()  # Initialisation\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"R\")  # 1er tour de jeu\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=5, disc_color=\"J\")  # 2ème tour de jeu\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"R\")  # 3ème tour de jeu\nsolutions.display_grid(grid_solution)\n\n\n\n\n\ndef make_move(grid, column_to_play, disc_color):\n    new_grid = copy.deepcopy(grid)  # Evite la modification de la grille initiale\n    # Votre code ici\n    return new_grid\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 1er tour de jeu\ngrid = make_move(grid=grid, column_to_play=5, disc_color=\"J\")  # 2ème tour de jeu\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")  # 3ème tour de jeu\ndisplay_grid(grid)",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#détection-dune-victoire-horizontale",
    "href": "source/projects/puissance4/tutorial.html#détection-dune-victoire-horizontale",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Maintenant qu’il est possible de jouer effectivement à notre puissance 4, il faut pouvoir détecter une victoire pour mettre fin à la partie en cours. Pour se faire, on va simplifier le problème en le décomposant au maximum.\nDans un premier temps, on s’intéresse à la détection d’une victoire horizontale. Pour cela, on va s’aider de deux fonctions :\n\nune fonction check_row_victory qui prend en entrée une ligne du puissance 4 (i.e. une liste de taille 7) et retourne True si jamais 4 pions consécutifs de même couleur se trouvent sur la ligne, et False sinon\nune fonction check_horizontal_victory qui prend en entrée une grille complète et retourne True si jamais une ligne de la grille remplit la condition précédente, et False sinon\n\n\n\n\n# Détection d'une victoire (horizontale) sur une ligne\nligne1 = [\" \", \"R\", \"R\", \"R\", \"J\", \"J\", \" \"]\nligne2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"J\", \" \"]\n\nprint(solutions.check_row_victory(ligne1))  # Renvoie False\nprint()  # Retour à la ligne\nprint(solutions.check_row_victory(ligne2))  # Renvoie True\n\n\n# Détection d'une victoire (horizontale) sur une grille\ngrid_solution = solutions.initialize_grid()  # Initialisation\nprint(solutions.check_horizontal_victory(grid_solution))  # Renvoie False\nprint()  # Retour à la ligne\n\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"R\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=3, disc_color=\"R\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=4, disc_color=\"R\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=5, disc_color=\"R\")\nsolutions.display_grid(grid_solution)\nprint()  # Retour à la ligne\n\nprint(solutions.check_horizontal_victory(grid_solution))  # Renvoie True\n\n\n\n\n\ndef check_row_victory(ligne):\n    # Votre code ici\n\n\n# Vérification du résultat\nrow1 = [\" \", \"R\", \"R\", \"R\", \"J\", \"R\", \" \"]\nrow2 = [\" \", \"R\", \"R\", \"R\", \"R\", \"J\", \" \"]\n\nprint(check_row_victory(row1))  # Renvoie False\nprint(check_row_victory(row2))  # Renvoie True\n\n\ndef check_horizontal_victory(grid):\n    # Votre code ici\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\nprint(check_horizontal_victory(grid))  # Renvoie False\n\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=3, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=4, disc_color=\"R\")\ngrid = make_move(grid=grid, column_to_play=5, disc_color=\"R\")\ndisplay_grid(grid)\nprint(check_horizontal_victory(grid))  # Renvoie True",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#détection-dune-victoire-verticale",
    "href": "source/projects/puissance4/tutorial.html#détection-dune-victoire-verticale",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "A présent, on s’intéresse à la détection d’une victoire verticale. Par rapport à la situation précédente, la difficulté est que l’on ne peut pas directement boucler sur les colonnes. On va donc construire une fonction check_vertical_victory qui, pour chaque colonne :\n\nrécupère les éléments de la colonne dans une liste\napplique à cette liste la fonction check_row_victory pour vérifier la présence de 4 pions consécutifs de même couleur dans la colonne considérée\n\n\n\n\n# Détection d'une victoire (verticale) sur une grille\ngrid_solution = solutions.initialize_grid()  # Initialisation\nprint(solutions.check_vertical_victory(grid_solution))  # Renvoie False\nprint()  # Retour à la ligne\n\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\ngrid_solution = solutions.make_move(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nsolutions.display_grid(grid_solution)\nprint()  # Retour à la ligne\n\nprint(solutions.check_vertical_victory(grid_solution))  # Renvoie True\n\n\n\n\n\ndef check_vertical_victory(grid):\n    # Votre code ici\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\nprint(check_vertical_victory(grid))  # Renvoie False\nprint()  # Retour à la ligne\n\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ngrid = make_move(grid=grid, column_to_play=2, disc_color=\"J\")\ndisplay_grid(grid)\nprint()  # Retour à la ligne\n\nprint(check_vertical_victory(grid))  # Renvoie True",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/puissance4/tutorial.html#fin-de-partie",
    "href": "source/projects/puissance4/tutorial.html#fin-de-partie",
    "title": "Projet 1 - Puissance 4",
    "section": "",
    "text": "Dans notre version simplifiée du puissance 4, on peut à présent déclarer la fin de partie : dès lors qu’une victoire horizontale ou verticale est détectée.\nOn va donc pour commencer créer une fonction victoire qui prend la grille en entrée et renvoie True si une victoire horizontale ou verticale est détectée, et False sinon.\nDans l’idéal, on voudrait ne pas avoir à tester manuellement après chaque coup si la partie est terminée afin de limiter la duplication de code. On va donc ensuite créer une fonction make_move_and_check_victory qui :\n\nprend en entrée les mêmes inputs que la fonction tour\nva appeler la fonction tour pour réaliser le tour de jeu\nva tester après le tour de jeu si une victoire est détectée via la fonction victoire. Si une victoire est détectée, la fonction imprime “FIN DE PARTIE”.\n\n\n\n\ngrid_solution = solutions.initialize_grid()  # Initialisation\nprint(\"Tour 1\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 2\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 3\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 4\")\ngrid_solution = solutions.make_move_and_check_victory(grid=grid_solution, column_to_play=2, disc_color=\"J\")\n\n\n\n\n\ndef check_victory(grid):\n    # Votre code ici\n\n\ndef make_move_and_check_victory(grille, column_to_play, disc_color):\n    grid = copy.deepcopy(grid)\n    # Votre code ici\n    return grid\n\n\n# Vérification du résultat\ngrid = initialize_grid()  # Initialisation\nprint(\"Tour 1\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 2\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 3\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")\nprint(\"Tour 4\")\ngrid = make_move_and_check_victory(grid=grid, column_to_play=2, disc_color=\"J\")",
    "crumbs": [
      "Projets",
      "Projet 1 - Puissance 4"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html",
    "href": "source/projects/RP/tutorial.html",
    "title": "Partie 1 : Téléchargement et mise en forme des données",
    "section": "",
    "text": "Le but de ce projet est de réaliser une analyse statistique rapide d’un jeu de données dont le format n’est pas directement optimisé pour une analyse en python. Nous allons utiliser exclusivement la librairie pandas pour l’analyse de données. Pour reproduire au mieux une situation à laquelle vous pouvez être confrontés, nous vous invitons vivement à consulter la documentation de la librairie (docs).\nNous allons nous intéresser à l’estimation de la population au 1er janvier de chaque année, cette estimation étant effectuée à partir des recensements et des modèles d’évolution de la population. Les données sont accessibles sur le site de l’Insee à l’adresse suivante : https://www.insee.fr/fr/statistiques/1893198. Le fichier que nous allons utilisé peut être téléchargé directement via cet url : https://www.insee.fr/fr/statistiques/fichier/1893198/estim-pop-dep-sexe-aq-1975-2023.xls.\n\nimport copy\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport seaborn as sns\n\nimport solutions\n\nAvant d’effectuer le téléchargement des données avec python il est nécessaire de connaître le format de nos données. Dans notre cas, il s’agit du format Excel (.xlsx). De plus, il peut être utile de regarder à quoi ressemble les données que l’on souhaite importer, notamment lorsque leur format n’est pas standard. Ainsi, avant de commencer, prenez le temps de jeter un œil aux données.\n\n\nTéléchargez les données en cliquant sur ce lien et ouvrez-le avec votre logiciel tableur préféré. Analysez la structure des données.\n\n\n\nDéfinir la fonction load_data() qui n’a pas de paramètre et renvoie un Dict où les clés correspondent aux noms des onglets de notre fichier et les valeurs correspondent aux données des différentes feuilles de calcul. Pour cela, utilisez une fonction de la librairie pandas en spécifiant les bons paramètres.\n\n\n\ndata = solutions.load_data()\ndata[\"2022\"]\n\n\n\n\n\ndef load_data():\n    # Votre code ici\n    return data\n\n\n\n\n\nMaintenant que les données sont importées nous allons les mettre sous la forme d’un seul DataFrame dont les colonnes sont :\n\ngenre ;\nage ;\npopulation ;\ndep_code ;\ndep ;\nannee.\n\n2.1 - Pour ce faire créez une fonction reshape_data_by_year(df, year) qui prend en argument un DataFrame issu de votre Dict data et une année donnée.\n\n\n\nannee = 2022\ndf = solutions.reshape_table_by_year(data[f\"{annee}\"], annee)\ndf\n\n\n\n\n\ndef reshape_table_by_year(df, year):\n    # Votre code ici\n    return df\n\n2.2 - Créer une fonction reshape_data(data) qui produit un DataFrame avec les données pour toutes les années entre 1975 et 2022.\n\n\n\n\ndf = solutions.reshape_data(data)\ndf\n\n\n\n\n\ndef reshape_data(data):\n    # Votre code ici\n    return df\n\n\n\n\n\nNous avons maintenant un jeu de données prêt à être analysé ! Commençons tout d’abord par visualiser l’évolution de la population pour différents départements.\n\n\nEcrire une fonction plot_population_by_gender_per_department(df, department_code) qui renvoie un graphique représentant l’évolution de la population dans un département donné. Utilisez la librairie matplotlib. Vous pouvez regarder les données de la Haute Garonne (31), du Loir-et-Cher (41) et de la Réunion (974) pour constater des disparités d’évolutions.\n\n\n\nsolutions.plot_population_by_gender_per_department(df, \"31\")\n\n\n\n\n\ndef plot_population_by_gender_per_department(data, department_code):\n    # Votre code ici\n\n\n\n\n\nAfin de comparer 2 graphiques il est parfois utile de les afficher côte à côte. Grâce à la méthode subplots() de matplotlib cela est très facile à réaliser en python. Pour le constater, nous allons représenter la pyramide des âges de la France en 1975 et en 2022.\n4.1- Définissez la fonction get_age_pyramid_data(df, year) qui, à partir du DataFrame généré par la fonction reshape_data(), renvoie un DataFrame avec les colonnes age, Femmes, Hommes. La colonne age doit contenir toutes les tranches d’âges présentes dans le jeu de données, les colonnes Femmes/Hommes correspond à la population féminine/masculine pour une tranche d’âge donnée. Dans un souci d’esthétique, la colonne Hommes sera au préalable multipliée par -1.\n\n\n\npyramide_data = solutions.get_age_pyramid_data(df, 2022)\npyramide_data\n\n\n\n\n\ndef get_age_pyramid_data(df, year):\n    # Votre code ici\n    return pyramide_data\n\n4.2- Définissez la fonction plot_age_pyramid(df, year, ax=None) qui représente la pyramide des âges de la France pour une année donnée. Vous pouvez vous inspirer de ce qui a été fait dans ce blog.\n\n\n\n\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))\n\nsolutions.plot_age_pyramid(df, 1975, ax=ax1)\nsolutions.plot_age_pyramid(df, 2022, ax=ax2)\n\n\n\n\n\ndef plot_age_pyramid(df, year, ax=None):\n    if ax is None:\n        ax = plt.gca()\n    # Votre code ici\n    return df\n\n\n\n\n\n\nLes données géographiques sont très utiles car elles permettent de visualiser et d’analyser des informations liées à des emplacements spécifiques sur la terre. Les données géographiques peuvent être utilisées pour créer des cartes, des visualisations en 3D et des analyses spatiales pour comprendre les tendances, les modèles et les relations dans les données. En utilisant des bibliothèques Python telles que Geopandas ou Folium, vous pouvez facilement manipuler et visualiser des données géographiques pour répondre à vos besoins analytiques.\nAfin de représenter graphiquement des données géographiques il est nécessaire d’obtenir les données des contours (shapefile) des zones que l’on souhaite représenter. L’objectif de cette partie est de créer une carte choropleth des régions en fonction de leur population respective.\nLes données que nous avons actuellement contiennent les informations par département et non par région. Avant toute chose il est nécessaire d’affecter à chaque département sa région correspondante. Pour cela, vous pourrez utiliser le fichier .json disponible à l’adresse suivante : https://static.data.gouv.fr/resources/departements-et-leurs-regions/20190815-175403/departements-region.json.\n\n\nCréez un DataFrame à partir du fichier .json des départements et régions de France précédemment mentionné. Assurez-vous que les colonnes soient au bon format.\n\n\n\ndf_matching = solutions.load_departements_regions(\"https://static.data.gouv.fr/resources/departements-et-leurs-regions/20190815-175403/departements-region.json\")\ndf_matching\n\n\n\n\n\ndef load_departements_regions(url):\n    # Votre code ici\n    return df_matching\n\n\n\n\n\nApparier le DataFrame contenant les données de population par département avec le DataFrame des régions de France.\n\n\n\ndf_regions = solutions.match_department_regions(df, df_matching)\ndf_regions\n\n\n\n\n\ndef match_department_regions(df, df_matching):\n    # Votre code ici\n    return df_regions\n\n\n\n\n\nTéléchargez les données des contours géographiques des régions en utilisant le package cartiflette et la librairie geopandas. Les données sont accessibles à cette adresse.\n\n\n\ngeo = solutions.load_geo_data(\"https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year=2022/administrative_level=REGION/crs=4326/FRANCE_ENTIERE=metropole/vectorfile_format='geojson'/provider='IGN'/source='EXPRESS-COG-CARTO-TERRITOIRE'/raw.geojson\")\ngeo\n\n\n\n\n\ndef load_geo_data(url):\n    # Votre code ici\n    return geo\n\n\n\n\n\nProduire une carte choropleth de la population en 2022 des régions de France. Vous pouvez consulter la documentation de geopandas ici.\n\n\n\nsolutions.plot_population_by_regions(df_regions, geo, 2022)\n\n\n\n\n\ndef plot_population_by_regions(df, geo, year):\n    # Votre code ici\n\n\n\n\n\nLa population totale d’une région n’est pas suffisante pour analyser la démographie d’une région. Il peut être intéressant de s’intéresser à la croissance démographique.\n9.1- Ecrire une fonction compute_population_growth_per_region(df) qui calcule la croissance de la population en pourcentage par an pour chaque région.\n\n\n\ndf_croissance = solutions.compute_population_growth_per_region(df_regions)\ndf_croissance\n\n\n\n\n\ndef compute_population_growth_per_region(df_regions):\n    # Votre code ici\n    return df_croissance\n\n9.2- Ecrire une fonction compute_mean_population_growth_per_region(df, min_year, max_year) qui calcule la croissance moyenne de la population entre deux années données.\n\n\n\n\ndf_croissance = solutions.compute_mean_population_growth_per_region(df_regions, 2015, 2022)\ndf_croissance\n\n\n\n\n\ndef compute_mean_population_growth_per_region(df, geo, year):\n    # Votre code ici\n    return df_croissance\n\n9.3- Ecrire une fonction plot_growth_population_by_regions(df, geo, min_year, max_year) qui représente la croissance moyenne de la population entre deux années données pour toutes les régions de France sur une carte choropleth.\n\n\n\n\nsolutions.plot_growth_population_by_regions(df_regions, geo, 2015, 2022)\n\n\n\n\n\ndef plot_growth_population_by_regions(df, geo, min_year, max_year):\n    # Votre code ici",
    "crumbs": [
      "Projets",
      "Projet 3 - Estimations de population à partir du recensement"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html#partie-2-visualisation-des-données",
    "href": "source/projects/RP/tutorial.html#partie-2-visualisation-des-données",
    "title": "Partie 1 : Téléchargement et mise en forme des données",
    "section": "",
    "text": "Nous avons maintenant un jeu de données prêt à être analysé ! Commençons tout d’abord par visualiser l’évolution de la population pour différents départements.\n\n\nEcrire une fonction plot_population_by_gender_per_department(df, department_code) qui renvoie un graphique représentant l’évolution de la population dans un département donné. Utilisez la librairie matplotlib. Vous pouvez regarder les données de la Haute Garonne (31), du Loir-et-Cher (41) et de la Réunion (974) pour constater des disparités d’évolutions.\n\n\n\nsolutions.plot_population_by_gender_per_department(df, \"31\")\n\n\n\n\n\ndef plot_population_by_gender_per_department(data, department_code):\n    # Votre code ici\n\n\n\n\n\nAfin de comparer 2 graphiques il est parfois utile de les afficher côte à côte. Grâce à la méthode subplots() de matplotlib cela est très facile à réaliser en python. Pour le constater, nous allons représenter la pyramide des âges de la France en 1975 et en 2022.\n4.1- Définissez la fonction get_age_pyramid_data(df, year) qui, à partir du DataFrame généré par la fonction reshape_data(), renvoie un DataFrame avec les colonnes age, Femmes, Hommes. La colonne age doit contenir toutes les tranches d’âges présentes dans le jeu de données, les colonnes Femmes/Hommes correspond à la population féminine/masculine pour une tranche d’âge donnée. Dans un souci d’esthétique, la colonne Hommes sera au préalable multipliée par -1.\n\n\n\npyramide_data = solutions.get_age_pyramid_data(df, 2022)\npyramide_data\n\n\n\n\n\ndef get_age_pyramid_data(df, year):\n    # Votre code ici\n    return pyramide_data\n\n4.2- Définissez la fonction plot_age_pyramid(df, year, ax=None) qui représente la pyramide des âges de la France pour une année donnée. Vous pouvez vous inspirer de ce qui a été fait dans ce blog.\n\n\n\n\nfig,(ax1,ax2) = plt.subplots(1,2,figsize=(15,6))\n\nsolutions.plot_age_pyramid(df, 1975, ax=ax1)\nsolutions.plot_age_pyramid(df, 2022, ax=ax2)\n\n\n\n\n\ndef plot_age_pyramid(df, year, ax=None):\n    if ax is None:\n        ax = plt.gca()\n    # Votre code ici\n    return df",
    "crumbs": [
      "Projets",
      "Projet 3 - Estimations de population à partir du recensement"
    ]
  },
  {
    "objectID": "source/projects/RP/tutorial.html#partie-3-une-introduction-aux-données-géographiques",
    "href": "source/projects/RP/tutorial.html#partie-3-une-introduction-aux-données-géographiques",
    "title": "Partie 1 : Téléchargement et mise en forme des données",
    "section": "",
    "text": "Les données géographiques sont très utiles car elles permettent de visualiser et d’analyser des informations liées à des emplacements spécifiques sur la terre. Les données géographiques peuvent être utilisées pour créer des cartes, des visualisations en 3D et des analyses spatiales pour comprendre les tendances, les modèles et les relations dans les données. En utilisant des bibliothèques Python telles que Geopandas ou Folium, vous pouvez facilement manipuler et visualiser des données géographiques pour répondre à vos besoins analytiques.\nAfin de représenter graphiquement des données géographiques il est nécessaire d’obtenir les données des contours (shapefile) des zones que l’on souhaite représenter. L’objectif de cette partie est de créer une carte choropleth des régions en fonction de leur population respective.\nLes données que nous avons actuellement contiennent les informations par département et non par région. Avant toute chose il est nécessaire d’affecter à chaque département sa région correspondante. Pour cela, vous pourrez utiliser le fichier .json disponible à l’adresse suivante : https://static.data.gouv.fr/resources/departements-et-leurs-regions/20190815-175403/departements-region.json.\n\n\nCréez un DataFrame à partir du fichier .json des départements et régions de France précédemment mentionné. Assurez-vous que les colonnes soient au bon format.\n\n\n\ndf_matching = solutions.load_departements_regions(\"https://static.data.gouv.fr/resources/departements-et-leurs-regions/20190815-175403/departements-region.json\")\ndf_matching\n\n\n\n\n\ndef load_departements_regions(url):\n    # Votre code ici\n    return df_matching\n\n\n\n\n\nApparier le DataFrame contenant les données de population par département avec le DataFrame des régions de France.\n\n\n\ndf_regions = solutions.match_department_regions(df, df_matching)\ndf_regions\n\n\n\n\n\ndef match_department_regions(df, df_matching):\n    # Votre code ici\n    return df_regions\n\n\n\n\n\nTéléchargez les données des contours géographiques des régions en utilisant le package cartiflette et la librairie geopandas. Les données sont accessibles à cette adresse.\n\n\n\ngeo = solutions.load_geo_data(\"https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year=2022/administrative_level=REGION/crs=4326/FRANCE_ENTIERE=metropole/vectorfile_format='geojson'/provider='IGN'/source='EXPRESS-COG-CARTO-TERRITOIRE'/raw.geojson\")\ngeo\n\n\n\n\n\ndef load_geo_data(url):\n    # Votre code ici\n    return geo\n\n\n\n\n\nProduire une carte choropleth de la population en 2022 des régions de France. Vous pouvez consulter la documentation de geopandas ici.\n\n\n\nsolutions.plot_population_by_regions(df_regions, geo, 2022)\n\n\n\n\n\ndef plot_population_by_regions(df, geo, year):\n    # Votre code ici\n\n\n\n\n\nLa population totale d’une région n’est pas suffisante pour analyser la démographie d’une région. Il peut être intéressant de s’intéresser à la croissance démographique.\n9.1- Ecrire une fonction compute_population_growth_per_region(df) qui calcule la croissance de la population en pourcentage par an pour chaque région.\n\n\n\ndf_croissance = solutions.compute_population_growth_per_region(df_regions)\ndf_croissance\n\n\n\n\n\ndef compute_population_growth_per_region(df_regions):\n    # Votre code ici\n    return df_croissance\n\n9.2- Ecrire une fonction compute_mean_population_growth_per_region(df, min_year, max_year) qui calcule la croissance moyenne de la population entre deux années données.\n\n\n\n\ndf_croissance = solutions.compute_mean_population_growth_per_region(df_regions, 2015, 2022)\ndf_croissance\n\n\n\n\n\ndef compute_mean_population_growth_per_region(df, geo, year):\n    # Votre code ici\n    return df_croissance\n\n9.3- Ecrire une fonction plot_growth_population_by_regions(df, geo, min_year, max_year) qui représente la croissance moyenne de la population entre deux années données pour toutes les régions de France sur une carte choropleth.\n\n\n\n\nsolutions.plot_growth_population_by_regions(df_regions, geo, 2015, 2022)\n\n\n\n\n\ndef plot_growth_population_by_regions(df, geo, min_year, max_year):\n    # Votre code ici",
    "crumbs": [
      "Projets",
      "Projet 3 - Estimations de population à partir du recensement"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html",
    "href": "source/fundamentals/types-variables/tutorial.html",
    "title": "Types de base et variables",
    "section": "",
    "text": "Dans ce premier TP, nous allons découvrir les objets les plus fondamentaux de Python : les nombres et les chaînes de caractère. Nous allons également voir comment l’on peut assigner des objets à des variables, afin de réaliser des opérations avec ces objets.\n\n\n\n\nPython propose différents objets de type numérique. Dans ce tutoriel, on va s’intéresser aux deux types principalement utilisés :\n\nles entiers (type int pour integer)\nles réels (type float pour nombres à virgule flottante)\n\nDe manière générale, on utilise la fonction type pour imprimer le type d’un objet Python.\n\ntype(3)\n\nint\n\n\n\ntype(3.14)\n\nfloat\n\n\nLes fonctions float et int peuvent être utilisées pour passer d’un type à l’autre.\n\n# Conversion en float\nfloat(3)\n\n3.0\n\n\n\n# Conversion en float\ntype(float(3))\n\nfloat\n\n\n\n# Conversion en int\nint(3.79)\n\n3\n\n\nAttention à la conversion float -&gt; int, qui tronque la partie décimale.\nLes floats peuvent par ailleurs être écrits en notation scientifique :\n\n2e3\n\n2000.0\n\n\n\ntype(2e3)\n\nfloat\n\n\n\n\n\n\n# Addition\n8 + 9\n\n17\n\n\n\n# Soustraction\n5 - 2\n\n3\n\n\n\n# Multiplication\n2 * 6\n\n12\n\n\n\n# Division\n9 / 4\n\n2.25\n\n\n\n# Division par 0\n3 / 0\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[12], line 2\n      1 # Division par 0\n----&gt; 2 3 / 0\n\nZeroDivisionError: division by zero\n\n\n\nLa division par 0 produit une erreur. C’était bien sûr prévisible. Mais il n’est pas rare d’avoir de telles erreurs dans le cadre de calculs statistiques, notamment avec NumPy ou Pandas, produisant une erreur similaire qu’il faut alors débugger.\n\n\n\n\n\n\nDebugger une erreur\n\n\n\nLes erreurs de code sont un passage obligatoire et en réalité nécessaire de l’apprentissage d’un langage: c’est en debuggant les erreurs que notre code produit que l’on apprend à les éviter à l’avenir ! Pour ce faire, il est nécessaire de bien les comprendre en premier lieu.\nL’erreur ci-dessus, liée à la division par 0, a produit un Traceback, i.e. un log détaillé précisant à quelle étape des différentes opérations effectuées par Python s’est produite l’erreur, ainsi que le nom de l’erreur (ZeroDivisionError) et un descriptif (“division by zero”). En l’occurence, l’erreur est simple, le message permet donc de comprendre directement le problème. Pour des opérations plus compliquées, les noms et messages peuvent être moins évidents… mais néanmoins utiles pour comprendre la source de l’erreur - en les indiquant dans un moteur de recherche par exemple.\n\n\n\n# Division euclidienne : quotient\n9 // 4\n\n2\n\n\n\n# Division euclidienne : reste\n9 % 4\n\n1\n\n\n\n# Puissance\n2 ** 5\n\n32\n\n\n\n# Racine carrée\n5 ** 0.5\n\n2.23606797749979\n\n\n\n# Ordre des opérations : convention usuelle\n2 + 5 * (10 - 4)\n\n32\n\n\n\n\n\n\nLes chaînes de caractères (ou strings) sont utilisées pour stocker de l’information textuelle. Plus précisément, elles peuvent stocker tout caractère de type Unicode, ce qui inclut les lettres des différentes langues, mais également la ponctuation, les chiffres, les smileys, etc.\nUn string se définit en mettant l’information entre apostrophes ou entre guillemets (anglais).\n\n\n\n# Première manière \n'mot'\n\n'mot'\n\n\n\n# Deuxième manière\n\"ça fonctionne aussi\"\n\n'ça fonctionne aussi'\n\n\n\n# Mais attention au mélange des deux !\n'l'apostrophe, quelle catastrophe'\n\n\n  Cell In[20], line 2\n    'l'apostrophe, quelle catastrophe'\n                                     ^\nSyntaxError: unterminated string literal (detected at line 2)\n\n\n\n\nErreur de syntaxe : la seconde apostrophe est comprise comme la fin du string, et Python ne sait pas interpréter le reste de la séquence.\n\n\n\n\n\n\nErreurs de syntaxe et exception\n\n\n\nDepuis le début du TP, on a vu plusieurs erreurs produites par le code. En pratique, il est important de distinguer deux types d’erreurs :\n\nles erreurs de syntaxe: le code ne respecte pas les règles de syntaxe de Python, comme l’erreur ci-dessus. Le Traceback (message d’erreur) indique avec des flèches pointant vers le haut la ligne et le moment où à commencé le problème\nles exceptions: le code est syntaxiquement correct mais produit une erreur lors de son exécution, comme la division par zéro effectuée plus haut.\n\nPourquoi alors est-il important de distinguer ces deux types d’erreur ? Car là où une syntaxe incorrecte génère nécessairement une SyntaxError et arrête l’exécution du code, une exception peut être gérée dans le code. Par exemple, dans le cadre d’un code où l’on réaliserait de multiples divisions avec des paramètres multiples, on pourrait vouloir faire en sorte qu’une division par zéro ne renvoie pas une erreur qui interrompe l’exécution du code, mais une valeur arbitraire (infini, valeur manquante…).\n\n\nPour éviter l’erreur de syntaxe, il faut varier les caractères en cas de besoin :\n\n\"l'apostrophe, aucun problème\"\n\n\"l'apostrophe, aucun problème\"\n\n\nMême chose en sens inverse :\n\n'les guillemets, \"aucun problème\"'\n\n'les guillemets, \"aucun problème\"'\n\n\n\n\n\nLe travail avec les strings est l’occasion de découvrir la très pratique et très utilisée fonction print. Elle affiche simplement l’argument qu’on lui passe entre parenthèses et un retour à la ligne par défaut.\n\n# Affichage de la chaîne \"moi\"\n\"moi\"\n\n'moi'\n\n\n\n# Affichage de la chaîne \"moi\" avec print\nprint(\"moi\")\n\nmoi\n\n\nOn a vu jusqu’à maintenant que l’on pouvait simplement exécuter une cellule pour afficher le contenu d’un string. Mais est-ce cela marche avec plusieurs strings ?\n\n# Qui va être affiché ?\n\"moi\"\n\"non moi\"\n\n'non moi'\n\n\nOn voit là un comportement caractéristique des notebooks Jupyter : seule la dernière valeur renvoyée dans une cellule est affichée. La fonction print permet de s’affranchir de cette limite.\n\n# Et cette fois ?\nprint(\"moi\")\nprint(\"moi aussi\")\n\nmoi\nmoi aussi\n\n\n\n\n\nLa fonction len permet de compter le nombre de caractères d’un string, tous caractères inclus (lettres, chiffres, espaces, ponctuation…).\n\nlen(\"J'ai 19 charactères\")\n\n19\n\n\nLe type “caractère” n’existe pas en Python : un caractère seul est défini comme un string de taille 1.\n\nprint(type(\"a\"))\nprint(len(\"a\"))\n\n&lt;class 'str'&gt;\n1\n\n\n\n\n\nEn Python, un string est une séquence, c’est à dire une suite de caractères dans un ordre spécifique. Par conséquent, chaque caractère d’un string est indexé (Python connaît sa position), et l’on peut utiliser cet index pour extraire des caractères particuliers, des sous-chaînes de caractères, etc.\nEn Python, on utilise les crochets [] pour appeler l’index d’une séquence. Plus précisément, l’index fonctionne sur le modèle suivant : x[a:b:c] renvoie un sub-string du string x où a est la position du caractère de départ, b la position du caractère d’arrivée plus 1, et c le pas de l’indexation. Tout cela sera plus clair avec les exemples suivants.\nNote importante : l’indexation commence à 0 en Python.\n\n\"une séquence que l'on va indexer\"\n\n\"une séquence que l'on va indexer\"\n\n\n\n# Premier élémént\n\"une séquence que l'on va indexer\"[0]\n\n'u'\n\n\n\n# Deuxième élémént\n\"une séquence que l'on va indexer\"[1]\n\n'n'\n\n\n\n# Dernier élémént\n\"une séquence que l'on va indexer\"[-1]\n\n'r'\n\n\n\n# Extraire tout à partir d'un certain caractère\n\"une séquence que l'on va indexer\"[4:]\n\n\"séquence que l'on va indexer\"\n\n\n\n# Extraire tout jusqu'à un certain caractère\n\"une séquence que l'on va indexer\"[:12]\n\n'une séquence'\n\n\n\n# Extraire un sub-string\n\"une séquence que l'on va indexer\"[4:12]\n\n'séquence'\n\n\n\n# Extraire tous les 2 caractères, à partir de la 4 ème position\n\"une séquence que l'on va indexer\"[4::2]\n\n\"sqec u 'nv nee\"\n\n\n\n# Inverser une séquence\n\"une séquence que l'on va indexer\"[::-1]\n\n\"rexedni av no'l euq ecneuqés enu\"\n\n\nA retenir : c’est bien parce qu’un string est considéré comme une séquence par Python que l’on peut l’indexer. Par exemple, indexer un nombre n’a pas de sens, et renvoie donc une erreur.\n\n2[3]\n\n&lt;&gt;:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n&lt;&gt;:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n/tmp/ipykernel_2576/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n/tmp/ipykernel_2576/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n/tmp/ipykernel_2576/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[38], line 1\n----&gt; 1 2[3]\n\nTypeError: 'int' object is not subscriptable\n\n\n\n\n\n\n\n# Concaténation de strings\n\"mon adresse est : \" + \"10 rue des Peupliers\"\n\n'mon adresse est : 10 rue des Peupliers'\n\n\n\n# Répétition\n\"echo - \" * 5\n\n'echo - echo - echo - echo - echo - '\n\n\n\n\n\nLes différents objets Python ont généralement des méthodes dites built-in (standard), qui permettent d’effectuer des opérations de base à partir de l’objet.\nNous verrons dans un prochain chapitre en quoi consistent précisément les méthodes en Python. Pour le moment, on peut retenir que les méthodes s’utilisent selon le format objet.methode(parametres) où les paramètres sont optionnels.\n\n# Mettre en majuscules\n\"sequence 850\".upper()\n\n'SEQUENCE 850'\n\n\n\n# Mettre en minuscules\n\"sequence 850\".lower()\n\n'sequence 850'\n\n\n\n# Séparer les mots selon les espaces\n\"une séquence    à séparer\".split()\n\n['une', 'séquence', 'à', 'séparer']\n\n\n\n# Séparer les mots selon un caractère arbitraire\n\"pratique pour faire des sous-séquences\".split(\"-\")\n\n['pratique pour faire des sous', 'séquences']\n\n\n\n# Utiliser les strings comme templates\n\"mon adresse est : {}\".format(\"10 rue des Peupliers\")\n\n'mon adresse est : 10 rue des Peupliers'\n\n\n\n\n\nTout ceci n’est qu’un aperçu des innombrables opérations possibles sur les strings. La documentation officielle liste l’ensemble des méthodes built-in disponibles. Les exercices du chapitre et les mini-projets de fin de partie seront l’occasion de découvrir d’autres utilisations.\n\n\n\n\nJusqu’ici, nous avons dû définir à chaque fois notre objet avant de pouvoir lui appliquer une transformation. Comment faire si l’on veut réutiliser un objet et lui appliquer plusieurs transformations ? Ou faire des opérations à partir de différents objets ?\nPour cela, on va assigner les objets à des variables.\n\n\nL’assignation se fait suivant le format : nom_de_la_variable = objet. Cela permet ensuite de réaliser des opérations à partir de ces variables.\n\nx = 5\nx\n\n5\n\n\n\ntype(x)\n\nint\n\n\n\nx + 5\n\n10\n\n\n\ny = x + 2*x\ny\n\n15\n\n\nContrairement à d’autres langages de programmation, Python est dit dynamiquement typé : il est possible de réassigner une variable à un objet de type différent. Cela facilite la lecture et le développement, mais peut parfois générer des problèmes difficiles à débugger… Il faut donc toujours bien faire attention que le type de la variable est bien celui que l’on s’imagine manipuler.\n\nx = 3\nx = \"blabla\"\ntype(x)\n\nstr\n\n\nIl y a naturellement certaines contraintes sur les opérations selon les types des objets.\n\nx = \"test\"\ny = 3\nx + y\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[51], line 3\n      1 x = \"test\"\n      2 y = 3\n----&gt; 3 x + y\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\nIl est par contre possible d’harmoniser les types en amont :\n\nx = \"test\"\ny = 3\nz = str(y)\nx + z\n\n'test3'\n\n\n\n\n\nIl est fréquent d’utiliser une variable comme un compteur, en l’incrémentant à chaque fois qu’un évènement donné apparaît par exemple.\n\na = 0\nprint(a)\na = a +1\nprint(a)\n\n0\n1\n\n\nCette pratique est tellement fréquente qu’il existe des opérateurs spéciaux pour les opérations arithmétiques courantes.\n\na = 0\na += 1\na\n\n1\n\n\n\nb = 5\nb *= 3\nb\n\n15\n\n\n\n\n\n\n\n\n\nQuels sont les différents types de base de Python vus dans ce tutoriel ?\nComment convertir un entier en réel et inversement ?\nComment définit-on une chaîne de caractères en Python ?\nQu’est ce qu’un Traceback ?\nQuelle est la différence entre une erreur de syntaxe et une exception ?\nA quoi sert la fonction print ?\nComment afficher plusieurs valeurs dans une cellule de notebook Jupyter ?\nA quoi sert la fonction len ?\nQu’est-ce qu’une méthode built-in et comment la reconnaître ?\nA quoi servent les variables ?\nPourquoi dit-on que Python est “dynamiquement typé” ?\n\n\n\n\nAfficher la solution\n\n\n1/ Les types de base en Python vus dans ce tutoriel sont les types numériques, notamment les entiers (int) et les réels (nombres à virgule flottante, float), et les chaînes de caractères (str), qui stockent de l’information textuelle.\n2/ Pour convertir un entier en réel, on utilise la fonction float(). Pour convertir un réel en entier, on utilise la fonction int().\n3/ Une chaîne de caractères est définie en mettant l’information entre apostrophes (’) ou entre guillemets (“).\n4/ Un Traceback est un rapport d’erreur qui montre la séquence d’opérations qui ont conduit à une exception. Il aide à identifier l’origine de l’erreur dans le code.\n5/ Une erreur de syntaxe survient lorsque le code Python ne respecte pas les règles de syntaxe du langage, rendant le script non exécutable. Une exception est une erreur détectée pendant l’exécution, même si le code a une syntaxe correcte. Les exceptions peuvent être gérées dans le code, alors que les erreurs de syntaxe produisent conduisent nécessairement à l’arrêt de l’exécution du code.\n6/ La fonction print affiche le contenu de l’argument qu’on lui passe entre parenthèses sur la console Python ou dans une cellule de notebook Jupyter.\n7/ Par défaut, l’exécution d’une cellule Jupyter affiche la dernière valeur renvoyée par le code exécuté dans cette cellule. Si deux lignes de code renvoient quelque chose, seul le dernier sera donc affiché. Pour pouvoir afficher plusieurs éléments dans une même cellule, on utilise la fonction print pour chaque opération dont on souhaite afficher le résultat.\n8/ La fonction len renvoie le nombre d’éléments d’un objet. Par exemple, le nombre de caractères dans une chaîne de caractères. Cette fonction n’a de sens que pour les objets de type séquence.\n9/ Une méthode built-in est une fonction intégrée à un type d’objet en Python qui permet d’effectuer des opérations spécifiques sur cet objet. On la reconnaît car elle est appelée directement sur l’objet avec la syntaxe objet.methode().\n10/ Les variables servent à stocker des valeurs ou des objets pour pouvoir les réutiliser et les manipuler plus facilement dans le code. Elles permettent égalemetn de donner un nom aux données pour les rendre plus lisibles et faciliter leur manipulation.\n11/ Python est dit dynamiquement typé parce que le type des variables est déterminé au moment de l’exécution et peut changer au cours de l’exécution. Ainsi, une variable initialement définie comme chaîne de caractère peut tout à fait devenir une variable numérique au cours de l’exécution du code, ce qui est impossible dans les langages de programmation basés sur un typage statique.\n\n\n\n\n\n\nAfficher le type de x lorsque :\n\nx = 3\nx = “test”\nx = 3.5\n\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = 3\nprint(type(x))\n\nx = \"test\"\nprint(type(x))\n\nx = 3.5\nprint(type(x))\n\n\n\n\n\nCalculer la somme des longueurs des trois chaînes de caractères suivantes :\n\n“une première chaîne”\n“et une deuxième”\n“jamais deux sans trois”\n\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = \"une première chaîne\"\nb = \"et une deuxième\"\nc = \"jamais deux sans trois\"\n\nlen(a) + len(b) + len(c)\n\n\n\n\n\nQuel est le type adapté pour définir un code postal ?\nEssayer de définir les codes postaux suivants au format int et au format string :\n\n92120\n02350\n\nQue concluez-vous ?\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ncp1_int = 92120\ncp1_str = \"92120\"\n\nprint(cp1_int, cp1_str) # Pas de problème\n\ncp2_int = 02350 \nErreur : Python n’accepte pas de définir un entier qui commence par un 0. Il faut donc définir les codes postaux comme des strings.\n\n\n\n\n\nCompter le nombre de fois où la lettre e est présente dans la chaîne suivante : “Je fais un comptage des e.”\nIndice : on peut utiliser la méthode built-in count.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = \"Je fais un comptage des e.\"\na.count('e')\n\n\n\n\n\nRepérer la première position où la lettre e est présente dans la chaîne suivante : “Je fais un comptage des e.”\nIndice : on peut utiliser la méthode built-in find.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = \"Je fais un comptage des e.\"\na.find('e')\n\n\n\n\n\nSupprimer les espaces superflus au début et à la fin de la chaîne suivante :\nIndice : on peut utiliser la méthode built-in strip.\n\n# Tapez votre réponse dans cette cellule\na = \"    Un string très mal formatté.         \"\n\n\n\n\nAfficher la solution\n\na = \"    Un string très mal formatté.         \"\na.strip()\n\n\n\n\n\nLe caractère \\ permet d’échapper (neutraliser) un caractère spécial au sein d’une chaîne de caractères. Trouvez comment ce caractère permet de résoudre le problème lié à l’utilisation de guillemets (ou d’apostrophes) dans une chaîne définie par des guillemets (apostrophe).\nIndice : des exemples d’utilisation sont disponibles dans la documentation officielle.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\"juste un \\\"petit\\\" test\"\n\n\n\n\n\nRéaliser la suite d’opérations suivantes à l’aide des opérateurs d’incrémentation, et imprimer la valeur finale :\n\ninitialiser une variable à 1\nlui soustraire 5\nla multiplier par 4\nlui ajouter 22\n\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = 1\na -= 5\na *= 4\na += 22\nprint(a)\n\n\n\n\n\nConsidérons les deux séquences suivantes :\n\n“nous sommes en”\n“2024”\n\nTrouvez à partir du tutoriel deux manières différentes de les utiliser pour composer la séquence “nous sommes en 2024”.\nIndice : l’une des deux méthodes implique de modifier (légèrement) une des deux séquences.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na1 = \"nous sommes en\"\na2 = \"nous sommes en {}\"\nb = \"2024\"\n\nprint(a1 + \" \" + b)\nprint(a2.format(b))\n\n\n\n\n\nLes f-strings sont une forme de strings un peu particulière mais très pratique, qui ont été ajoutés dans la version 3.6 de Python. Pour comprendre leur intérêt, repartons de la solution de l’exercice précédent, qui illustrait deux manières de composer la chaîne “nous sommes en 2024”.\n\na1 = \"nous sommes en\"\na2 = \"nous sommes en {}\"\nb = \"2024\"\n\nprint(a1 + \" \" + b)\nprint(a2.format(b))\n\nnous sommes en 2024\nnous sommes en 2024\n\n\nCes deux méthodes fonctionnent mais présentent des limites. Réfléchissez à ce qui se passerait dans les cas suivants, et n’hésitez pas à faire des tests pour vous en convaincre :\n\nsi l’on souhaite injecter via la méthode format() une variable qui n’est pas un string (ex : si “2024” était un entier et non un string) ?\nsi l’on souhaite concaténer plusieurs strings ensemble ?\nsi l’on souhaite concaténer plusieurs strings ensemble et qu’en plus on souhaite injecter les valeurs d’autres variables dans chaque partie ?\n\nEn vous inspirant de la documentation officielle, utilisez les f-strings pour résoudre ces différents problèmes.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nPremier problème : composition de strings avec des valeurs numériques.\na1 = \"nous sommes en\"\nb = 2024\n\n# print(a1 + \" \" + b)  # Erreur\nprint(a1 + \" \" + str(b))\nLa concaténation directe renvoie une erreur -&gt; il faut au préalable convertir la valeur numérique en string.\nDeuxième problème : juxtaposition de multiples chaînes de caractères.\na = \"nous sommes en\"\nb = \"2024\"\nc = \"et je m'appelle\"\nd = \"Miranda\"\n\nprint(a + \" \" + b + \" \" + c + \" \" + d)\nLa syntaxe devient vite illisible, car il faut ajouter les séparateurs (espace) manuellement entre chaque partie.\nTroisième problème : composition de chaînes de caractères avec injection de variables.\na = \"nous sommes en {}\"\nb = \"2024\"\nc = \"et je m'appelle {}\"\nd = \"Miranda\"\n\nprint(a.format(b) + \" \" + c.format(d))\nLa syntaxe reste peu lisibile, car il faut injecter les valeurs dans chaque chaîne.\nSolution : avec les f-strings.\nannee = 2024\nprenom = \"Miranda\"\n\nprint(f\"nous sommes en {annee} et je m'appelle {prenom}\")\nBeaucoup plus lisible !",
    "crumbs": [
      "Fondamentaux du langage",
      "Types de base et variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#nombres",
    "href": "source/fundamentals/types-variables/tutorial.html#nombres",
    "title": "Types de base et variables",
    "section": "",
    "text": "Python propose différents objets de type numérique. Dans ce tutoriel, on va s’intéresser aux deux types principalement utilisés :\n\nles entiers (type int pour integer)\nles réels (type float pour nombres à virgule flottante)\n\nDe manière générale, on utilise la fonction type pour imprimer le type d’un objet Python.\n\ntype(3)\n\nint\n\n\n\ntype(3.14)\n\nfloat\n\n\nLes fonctions float et int peuvent être utilisées pour passer d’un type à l’autre.\n\n# Conversion en float\nfloat(3)\n\n3.0\n\n\n\n# Conversion en float\ntype(float(3))\n\nfloat\n\n\n\n# Conversion en int\nint(3.79)\n\n3\n\n\nAttention à la conversion float -&gt; int, qui tronque la partie décimale.\nLes floats peuvent par ailleurs être écrits en notation scientifique :\n\n2e3\n\n2000.0\n\n\n\ntype(2e3)\n\nfloat\n\n\n\n\n\n\n# Addition\n8 + 9\n\n17\n\n\n\n# Soustraction\n5 - 2\n\n3\n\n\n\n# Multiplication\n2 * 6\n\n12\n\n\n\n# Division\n9 / 4\n\n2.25\n\n\n\n# Division par 0\n3 / 0\n\n\n---------------------------------------------------------------------------\nZeroDivisionError                         Traceback (most recent call last)\nCell In[12], line 2\n      1 # Division par 0\n----&gt; 2 3 / 0\n\nZeroDivisionError: division by zero\n\n\n\nLa division par 0 produit une erreur. C’était bien sûr prévisible. Mais il n’est pas rare d’avoir de telles erreurs dans le cadre de calculs statistiques, notamment avec NumPy ou Pandas, produisant une erreur similaire qu’il faut alors débugger.\n\n\n\n\n\n\nDebugger une erreur\n\n\n\nLes erreurs de code sont un passage obligatoire et en réalité nécessaire de l’apprentissage d’un langage: c’est en debuggant les erreurs que notre code produit que l’on apprend à les éviter à l’avenir ! Pour ce faire, il est nécessaire de bien les comprendre en premier lieu.\nL’erreur ci-dessus, liée à la division par 0, a produit un Traceback, i.e. un log détaillé précisant à quelle étape des différentes opérations effectuées par Python s’est produite l’erreur, ainsi que le nom de l’erreur (ZeroDivisionError) et un descriptif (“division by zero”). En l’occurence, l’erreur est simple, le message permet donc de comprendre directement le problème. Pour des opérations plus compliquées, les noms et messages peuvent être moins évidents… mais néanmoins utiles pour comprendre la source de l’erreur - en les indiquant dans un moteur de recherche par exemple.\n\n\n\n# Division euclidienne : quotient\n9 // 4\n\n2\n\n\n\n# Division euclidienne : reste\n9 % 4\n\n1\n\n\n\n# Puissance\n2 ** 5\n\n32\n\n\n\n# Racine carrée\n5 ** 0.5\n\n2.23606797749979\n\n\n\n# Ordre des opérations : convention usuelle\n2 + 5 * (10 - 4)\n\n32",
    "crumbs": [
      "Fondamentaux du langage",
      "Types de base et variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#chaînes-de-charactères",
    "href": "source/fundamentals/types-variables/tutorial.html#chaînes-de-charactères",
    "title": "Types de base et variables",
    "section": "",
    "text": "Les chaînes de caractères (ou strings) sont utilisées pour stocker de l’information textuelle. Plus précisément, elles peuvent stocker tout caractère de type Unicode, ce qui inclut les lettres des différentes langues, mais également la ponctuation, les chiffres, les smileys, etc.\nUn string se définit en mettant l’information entre apostrophes ou entre guillemets (anglais).\n\n\n\n# Première manière \n'mot'\n\n'mot'\n\n\n\n# Deuxième manière\n\"ça fonctionne aussi\"\n\n'ça fonctionne aussi'\n\n\n\n# Mais attention au mélange des deux !\n'l'apostrophe, quelle catastrophe'\n\n\n  Cell In[20], line 2\n    'l'apostrophe, quelle catastrophe'\n                                     ^\nSyntaxError: unterminated string literal (detected at line 2)\n\n\n\n\nErreur de syntaxe : la seconde apostrophe est comprise comme la fin du string, et Python ne sait pas interpréter le reste de la séquence.\n\n\n\n\n\n\nErreurs de syntaxe et exception\n\n\n\nDepuis le début du TP, on a vu plusieurs erreurs produites par le code. En pratique, il est important de distinguer deux types d’erreurs :\n\nles erreurs de syntaxe: le code ne respecte pas les règles de syntaxe de Python, comme l’erreur ci-dessus. Le Traceback (message d’erreur) indique avec des flèches pointant vers le haut la ligne et le moment où à commencé le problème\nles exceptions: le code est syntaxiquement correct mais produit une erreur lors de son exécution, comme la division par zéro effectuée plus haut.\n\nPourquoi alors est-il important de distinguer ces deux types d’erreur ? Car là où une syntaxe incorrecte génère nécessairement une SyntaxError et arrête l’exécution du code, une exception peut être gérée dans le code. Par exemple, dans le cadre d’un code où l’on réaliserait de multiples divisions avec des paramètres multiples, on pourrait vouloir faire en sorte qu’une division par zéro ne renvoie pas une erreur qui interrompe l’exécution du code, mais une valeur arbitraire (infini, valeur manquante…).\n\n\nPour éviter l’erreur de syntaxe, il faut varier les caractères en cas de besoin :\n\n\"l'apostrophe, aucun problème\"\n\n\"l'apostrophe, aucun problème\"\n\n\nMême chose en sens inverse :\n\n'les guillemets, \"aucun problème\"'\n\n'les guillemets, \"aucun problème\"'\n\n\n\n\n\nLe travail avec les strings est l’occasion de découvrir la très pratique et très utilisée fonction print. Elle affiche simplement l’argument qu’on lui passe entre parenthèses et un retour à la ligne par défaut.\n\n# Affichage de la chaîne \"moi\"\n\"moi\"\n\n'moi'\n\n\n\n# Affichage de la chaîne \"moi\" avec print\nprint(\"moi\")\n\nmoi\n\n\nOn a vu jusqu’à maintenant que l’on pouvait simplement exécuter une cellule pour afficher le contenu d’un string. Mais est-ce cela marche avec plusieurs strings ?\n\n# Qui va être affiché ?\n\"moi\"\n\"non moi\"\n\n'non moi'\n\n\nOn voit là un comportement caractéristique des notebooks Jupyter : seule la dernière valeur renvoyée dans une cellule est affichée. La fonction print permet de s’affranchir de cette limite.\n\n# Et cette fois ?\nprint(\"moi\")\nprint(\"moi aussi\")\n\nmoi\nmoi aussi\n\n\n\n\n\nLa fonction len permet de compter le nombre de caractères d’un string, tous caractères inclus (lettres, chiffres, espaces, ponctuation…).\n\nlen(\"J'ai 19 charactères\")\n\n19\n\n\nLe type “caractère” n’existe pas en Python : un caractère seul est défini comme un string de taille 1.\n\nprint(type(\"a\"))\nprint(len(\"a\"))\n\n&lt;class 'str'&gt;\n1\n\n\n\n\n\nEn Python, un string est une séquence, c’est à dire une suite de caractères dans un ordre spécifique. Par conséquent, chaque caractère d’un string est indexé (Python connaît sa position), et l’on peut utiliser cet index pour extraire des caractères particuliers, des sous-chaînes de caractères, etc.\nEn Python, on utilise les crochets [] pour appeler l’index d’une séquence. Plus précisément, l’index fonctionne sur le modèle suivant : x[a:b:c] renvoie un sub-string du string x où a est la position du caractère de départ, b la position du caractère d’arrivée plus 1, et c le pas de l’indexation. Tout cela sera plus clair avec les exemples suivants.\nNote importante : l’indexation commence à 0 en Python.\n\n\"une séquence que l'on va indexer\"\n\n\"une séquence que l'on va indexer\"\n\n\n\n# Premier élémént\n\"une séquence que l'on va indexer\"[0]\n\n'u'\n\n\n\n# Deuxième élémént\n\"une séquence que l'on va indexer\"[1]\n\n'n'\n\n\n\n# Dernier élémént\n\"une séquence que l'on va indexer\"[-1]\n\n'r'\n\n\n\n# Extraire tout à partir d'un certain caractère\n\"une séquence que l'on va indexer\"[4:]\n\n\"séquence que l'on va indexer\"\n\n\n\n# Extraire tout jusqu'à un certain caractère\n\"une séquence que l'on va indexer\"[:12]\n\n'une séquence'\n\n\n\n# Extraire un sub-string\n\"une séquence que l'on va indexer\"[4:12]\n\n'séquence'\n\n\n\n# Extraire tous les 2 caractères, à partir de la 4 ème position\n\"une séquence que l'on va indexer\"[4::2]\n\n\"sqec u 'nv nee\"\n\n\n\n# Inverser une séquence\n\"une séquence que l'on va indexer\"[::-1]\n\n\"rexedni av no'l euq ecneuqés enu\"\n\n\nA retenir : c’est bien parce qu’un string est considéré comme une séquence par Python que l’on peut l’indexer. Par exemple, indexer un nombre n’a pas de sens, et renvoie donc une erreur.\n\n2[3]\n\n&lt;&gt;:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n&lt;&gt;:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n/tmp/ipykernel_2576/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n/tmp/ipykernel_2576/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n/tmp/ipykernel_2576/769348720.py:1: SyntaxWarning: 'int' object is not subscriptable; perhaps you missed a comma?\n  2[3]\n\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[38], line 1\n----&gt; 1 2[3]\n\nTypeError: 'int' object is not subscriptable\n\n\n\n\n\n\n\n# Concaténation de strings\n\"mon adresse est : \" + \"10 rue des Peupliers\"\n\n'mon adresse est : 10 rue des Peupliers'\n\n\n\n# Répétition\n\"echo - \" * 5\n\n'echo - echo - echo - echo - echo - '\n\n\n\n\n\nLes différents objets Python ont généralement des méthodes dites built-in (standard), qui permettent d’effectuer des opérations de base à partir de l’objet.\nNous verrons dans un prochain chapitre en quoi consistent précisément les méthodes en Python. Pour le moment, on peut retenir que les méthodes s’utilisent selon le format objet.methode(parametres) où les paramètres sont optionnels.\n\n# Mettre en majuscules\n\"sequence 850\".upper()\n\n'SEQUENCE 850'\n\n\n\n# Mettre en minuscules\n\"sequence 850\".lower()\n\n'sequence 850'\n\n\n\n# Séparer les mots selon les espaces\n\"une séquence    à séparer\".split()\n\n['une', 'séquence', 'à', 'séparer']\n\n\n\n# Séparer les mots selon un caractère arbitraire\n\"pratique pour faire des sous-séquences\".split(\"-\")\n\n['pratique pour faire des sous', 'séquences']\n\n\n\n# Utiliser les strings comme templates\n\"mon adresse est : {}\".format(\"10 rue des Peupliers\")\n\n'mon adresse est : 10 rue des Peupliers'\n\n\n\n\n\nTout ceci n’est qu’un aperçu des innombrables opérations possibles sur les strings. La documentation officielle liste l’ensemble des méthodes built-in disponibles. Les exercices du chapitre et les mini-projets de fin de partie seront l’occasion de découvrir d’autres utilisations.",
    "crumbs": [
      "Fondamentaux du langage",
      "Types de base et variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#variables",
    "href": "source/fundamentals/types-variables/tutorial.html#variables",
    "title": "Types de base et variables",
    "section": "",
    "text": "Jusqu’ici, nous avons dû définir à chaque fois notre objet avant de pouvoir lui appliquer une transformation. Comment faire si l’on veut réutiliser un objet et lui appliquer plusieurs transformations ? Ou faire des opérations à partir de différents objets ?\nPour cela, on va assigner les objets à des variables.\n\n\nL’assignation se fait suivant le format : nom_de_la_variable = objet. Cela permet ensuite de réaliser des opérations à partir de ces variables.\n\nx = 5\nx\n\n5\n\n\n\ntype(x)\n\nint\n\n\n\nx + 5\n\n10\n\n\n\ny = x + 2*x\ny\n\n15\n\n\nContrairement à d’autres langages de programmation, Python est dit dynamiquement typé : il est possible de réassigner une variable à un objet de type différent. Cela facilite la lecture et le développement, mais peut parfois générer des problèmes difficiles à débugger… Il faut donc toujours bien faire attention que le type de la variable est bien celui que l’on s’imagine manipuler.\n\nx = 3\nx = \"blabla\"\ntype(x)\n\nstr\n\n\nIl y a naturellement certaines contraintes sur les opérations selon les types des objets.\n\nx = \"test\"\ny = 3\nx + y\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[51], line 3\n      1 x = \"test\"\n      2 y = 3\n----&gt; 3 x + y\n\nTypeError: can only concatenate str (not \"int\") to str\n\n\n\nIl est par contre possible d’harmoniser les types en amont :\n\nx = \"test\"\ny = 3\nz = str(y)\nx + z\n\n'test3'\n\n\n\n\n\nIl est fréquent d’utiliser une variable comme un compteur, en l’incrémentant à chaque fois qu’un évènement donné apparaît par exemple.\n\na = 0\nprint(a)\na = a +1\nprint(a)\n\n0\n1\n\n\nCette pratique est tellement fréquente qu’il existe des opérateurs spéciaux pour les opérations arithmétiques courantes.\n\na = 0\na += 1\na\n\n1\n\n\n\nb = 5\nb *= 3\nb\n\n15",
    "crumbs": [
      "Fondamentaux du langage",
      "Types de base et variables"
    ]
  },
  {
    "objectID": "source/fundamentals/types-variables/tutorial.html#exercices",
    "href": "source/fundamentals/types-variables/tutorial.html#exercices",
    "title": "Types de base et variables",
    "section": "",
    "text": "Quels sont les différents types de base de Python vus dans ce tutoriel ?\nComment convertir un entier en réel et inversement ?\nComment définit-on une chaîne de caractères en Python ?\nQu’est ce qu’un Traceback ?\nQuelle est la différence entre une erreur de syntaxe et une exception ?\nA quoi sert la fonction print ?\nComment afficher plusieurs valeurs dans une cellule de notebook Jupyter ?\nA quoi sert la fonction len ?\nQu’est-ce qu’une méthode built-in et comment la reconnaître ?\nA quoi servent les variables ?\nPourquoi dit-on que Python est “dynamiquement typé” ?\n\n\n\n\nAfficher la solution\n\n\n1/ Les types de base en Python vus dans ce tutoriel sont les types numériques, notamment les entiers (int) et les réels (nombres à virgule flottante, float), et les chaînes de caractères (str), qui stockent de l’information textuelle.\n2/ Pour convertir un entier en réel, on utilise la fonction float(). Pour convertir un réel en entier, on utilise la fonction int().\n3/ Une chaîne de caractères est définie en mettant l’information entre apostrophes (’) ou entre guillemets (“).\n4/ Un Traceback est un rapport d’erreur qui montre la séquence d’opérations qui ont conduit à une exception. Il aide à identifier l’origine de l’erreur dans le code.\n5/ Une erreur de syntaxe survient lorsque le code Python ne respecte pas les règles de syntaxe du langage, rendant le script non exécutable. Une exception est une erreur détectée pendant l’exécution, même si le code a une syntaxe correcte. Les exceptions peuvent être gérées dans le code, alors que les erreurs de syntaxe produisent conduisent nécessairement à l’arrêt de l’exécution du code.\n6/ La fonction print affiche le contenu de l’argument qu’on lui passe entre parenthèses sur la console Python ou dans une cellule de notebook Jupyter.\n7/ Par défaut, l’exécution d’une cellule Jupyter affiche la dernière valeur renvoyée par le code exécuté dans cette cellule. Si deux lignes de code renvoient quelque chose, seul le dernier sera donc affiché. Pour pouvoir afficher plusieurs éléments dans une même cellule, on utilise la fonction print pour chaque opération dont on souhaite afficher le résultat.\n8/ La fonction len renvoie le nombre d’éléments d’un objet. Par exemple, le nombre de caractères dans une chaîne de caractères. Cette fonction n’a de sens que pour les objets de type séquence.\n9/ Une méthode built-in est une fonction intégrée à un type d’objet en Python qui permet d’effectuer des opérations spécifiques sur cet objet. On la reconnaît car elle est appelée directement sur l’objet avec la syntaxe objet.methode().\n10/ Les variables servent à stocker des valeurs ou des objets pour pouvoir les réutiliser et les manipuler plus facilement dans le code. Elles permettent égalemetn de donner un nom aux données pour les rendre plus lisibles et faciliter leur manipulation.\n11/ Python est dit dynamiquement typé parce que le type des variables est déterminé au moment de l’exécution et peut changer au cours de l’exécution. Ainsi, une variable initialement définie comme chaîne de caractère peut tout à fait devenir une variable numérique au cours de l’exécution du code, ce qui est impossible dans les langages de programmation basés sur un typage statique.\n\n\n\n\n\n\nAfficher le type de x lorsque :\n\nx = 3\nx = “test”\nx = 3.5\n\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nx = 3\nprint(type(x))\n\nx = \"test\"\nprint(type(x))\n\nx = 3.5\nprint(type(x))\n\n\n\n\n\nCalculer la somme des longueurs des trois chaînes de caractères suivantes :\n\n“une première chaîne”\n“et une deuxième”\n“jamais deux sans trois”\n\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = \"une première chaîne\"\nb = \"et une deuxième\"\nc = \"jamais deux sans trois\"\n\nlen(a) + len(b) + len(c)\n\n\n\n\n\nQuel est le type adapté pour définir un code postal ?\nEssayer de définir les codes postaux suivants au format int et au format string :\n\n92120\n02350\n\nQue concluez-vous ?\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\ncp1_int = 92120\ncp1_str = \"92120\"\n\nprint(cp1_int, cp1_str) # Pas de problème\n\ncp2_int = 02350 \nErreur : Python n’accepte pas de définir un entier qui commence par un 0. Il faut donc définir les codes postaux comme des strings.\n\n\n\n\n\nCompter le nombre de fois où la lettre e est présente dans la chaîne suivante : “Je fais un comptage des e.”\nIndice : on peut utiliser la méthode built-in count.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = \"Je fais un comptage des e.\"\na.count('e')\n\n\n\n\n\nRepérer la première position où la lettre e est présente dans la chaîne suivante : “Je fais un comptage des e.”\nIndice : on peut utiliser la méthode built-in find.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = \"Je fais un comptage des e.\"\na.find('e')\n\n\n\n\n\nSupprimer les espaces superflus au début et à la fin de la chaîne suivante :\nIndice : on peut utiliser la méthode built-in strip.\n\n# Tapez votre réponse dans cette cellule\na = \"    Un string très mal formatté.         \"\n\n\n\n\nAfficher la solution\n\na = \"    Un string très mal formatté.         \"\na.strip()\n\n\n\n\n\nLe caractère \\ permet d’échapper (neutraliser) un caractère spécial au sein d’une chaîne de caractères. Trouvez comment ce caractère permet de résoudre le problème lié à l’utilisation de guillemets (ou d’apostrophes) dans une chaîne définie par des guillemets (apostrophe).\nIndice : des exemples d’utilisation sont disponibles dans la documentation officielle.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\n\"juste un \\\"petit\\\" test\"\n\n\n\n\n\nRéaliser la suite d’opérations suivantes à l’aide des opérateurs d’incrémentation, et imprimer la valeur finale :\n\ninitialiser une variable à 1\nlui soustraire 5\nla multiplier par 4\nlui ajouter 22\n\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na = 1\na -= 5\na *= 4\na += 22\nprint(a)\n\n\n\n\n\nConsidérons les deux séquences suivantes :\n\n“nous sommes en”\n“2024”\n\nTrouvez à partir du tutoriel deux manières différentes de les utiliser pour composer la séquence “nous sommes en 2024”.\nIndice : l’une des deux méthodes implique de modifier (légèrement) une des deux séquences.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\na1 = \"nous sommes en\"\na2 = \"nous sommes en {}\"\nb = \"2024\"\n\nprint(a1 + \" \" + b)\nprint(a2.format(b))\n\n\n\n\n\nLes f-strings sont une forme de strings un peu particulière mais très pratique, qui ont été ajoutés dans la version 3.6 de Python. Pour comprendre leur intérêt, repartons de la solution de l’exercice précédent, qui illustrait deux manières de composer la chaîne “nous sommes en 2024”.\n\na1 = \"nous sommes en\"\na2 = \"nous sommes en {}\"\nb = \"2024\"\n\nprint(a1 + \" \" + b)\nprint(a2.format(b))\n\nnous sommes en 2024\nnous sommes en 2024\n\n\nCes deux méthodes fonctionnent mais présentent des limites. Réfléchissez à ce qui se passerait dans les cas suivants, et n’hésitez pas à faire des tests pour vous en convaincre :\n\nsi l’on souhaite injecter via la méthode format() une variable qui n’est pas un string (ex : si “2024” était un entier et non un string) ?\nsi l’on souhaite concaténer plusieurs strings ensemble ?\nsi l’on souhaite concaténer plusieurs strings ensemble et qu’en plus on souhaite injecter les valeurs d’autres variables dans chaque partie ?\n\nEn vous inspirant de la documentation officielle, utilisez les f-strings pour résoudre ces différents problèmes.\n\n# Tapez votre réponse dans cette cellule\n\n\n\n\nAfficher la solution\n\nPremier problème : composition de strings avec des valeurs numériques.\na1 = \"nous sommes en\"\nb = 2024\n\n# print(a1 + \" \" + b)  # Erreur\nprint(a1 + \" \" + str(b))\nLa concaténation directe renvoie une erreur -&gt; il faut au préalable convertir la valeur numérique en string.\nDeuxième problème : juxtaposition de multiples chaînes de caractères.\na = \"nous sommes en\"\nb = \"2024\"\nc = \"et je m'appelle\"\nd = \"Miranda\"\n\nprint(a + \" \" + b + \" \" + c + \" \" + d)\nLa syntaxe devient vite illisible, car il faut ajouter les séparateurs (espace) manuellement entre chaque partie.\nTroisième problème : composition de chaînes de caractères avec injection de variables.\na = \"nous sommes en {}\"\nb = \"2024\"\nc = \"et je m'appelle {}\"\nd = \"Miranda\"\n\nprint(a.format(b) + \" \" + c.format(d))\nLa syntaxe reste peu lisibile, car il faut injecter les valeurs dans chaque chaîne.\nSolution : avec les f-strings.\nannee = 2024\nprenom = \"Miranda\"\n\nprint(f\"nous sommes en {annee} et je m'appelle {prenom}\")\nBeaucoup plus lisible !",
    "crumbs": [
      "Fondamentaux du langage",
      "Types de base et variables"
    ]
  }
]