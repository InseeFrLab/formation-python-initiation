::: {.content-visible when-profile="fr"}
---
title: "Travailler avec des fichiers CSV et JSON"
---



Dans le précédent tutoriel, nous avons vu comment utiliser des fonctions provenant de modules, ainsi que comment lire et écrire des fichiers texte. Dans ce tutoriel, nous allons mettre à profit ces nouvelles compétences en nous intéressant à **deux types de fichiers texte très fréquemment utilisés pour stocker et diffuser des données : les fichiers CSV et les fichiers JSON**. Nous allons apprendre à manipuler ces deux types de fichiers grâce aux modules Python dédiés à leur traitement respectif : **le module `csv` et le module `json`**.


## Manipuler des fichiers CSV


### Les fichiers CSV


CSV signifie ***comma-separated values***, soit en bon français "valeurs séparées par des virgules". Les fichiers CSV visent à reproduire la **structure des données issues de tableurs** type Excel de Microsoft ou Calc de LibreOffice, réduite à la stricte donnée textuelle (plus de formatage, plus de types de colonne, etc.).

Nous allons prendre pour exemple le fichier CSV qui contient la liste des départements en 2021, issue du Code Officiel Géographique (COG). Regardons les premières lignes de ce fichier à l'aide d'une commande `shell` pour avoir bien en tête la structure d'un tel fichier.

```{python}
!head -n 5 departement2021.csv
```

Pour reprendre l'analogie avec un fichier issu d'un tableur, chaque ligne du fichier représente une ligne du tableur, et les cellules d'une ligne sont séparées par des virgules. La première ligne peut contenir un `header` (en-tête), c'est à dire le nom des colonnes, mais ce n'est pas toujours le cas.


Les principaux avantages des fichiers CSV sont :

- leur **simplicité** : ils contiennent des données textuelles brutes, donc très légères et qui peuvent être éditées facilement via n'importe quel éditeur de texte ou langage de programmation

- leur **universalité** : ils sont très largement utilisés comme un format standard d'échanges de données


### Le module `csv`


Les données contenues dans un CSV étant des données textuelles, on peut se demander pourquoi l'on a besoin d'un module particulier pour les manipuler, et pourquoi les outils que l'on a vus dans le tutoriel précédent ne seraient pas suffisants. La raison principale est que les fichiers CSV ont tout de même quelques subtilités et normes, souvent invisibles à l'utilisateur, mais très importantes en pratique. Par exemple : si l'on veut séparer les différentes données selon les virgules, que se passe-t-il si les données textuelles elles-même contiennent des virgules ?

C'est pour cette raison qu'on utilise le **module `csv`** pour interagir avec ce type de fichiers, afin de capitaliser sur le fait que d'autres se sont posés toutes ces questions, et donc de ne pas avoir à réinventer la roue à chaque import de fichier CSV.

Notons qu'en pratique, on a plutôt tendance à manipuler ce type de données sous la forme de DataFrames (comme en `R`), afin de tirer parti de leur **structure tabulaire**. On étudiera dans un prochain tutoriel le ***package* `Pandas`** qui permet précisément de faire cela en Python. Néanmoins, il est toujours utile de savoir bien manipuler les données d'un CSV comme des données textuelles, et donc de connaître le module `csv`.


### Lecture

```{python}
import csv
```

La syntaxe permettant de lire et manipuler des fichiers CSV en Python est très proche de celle pour les fichiers texte simples. La seule différence est que l'on doit créer un objet `reader` à partir de l'objet fichier pour pouvoir itérer sur les lignes.

```{python}
rows = []

with open("departement2021.csv") as file_in:
    csv_reader = csv.reader(file_in)
    for row in csv_reader:
        rows.append(row)

rows[:4]
```

On retrouve bien la même syntaxe que pour les fichiers texte simples : une fois le `reader` créé, on peut itérer sur les lignes et réaliser des opérations avec celles-ci ; par exemple, les stocker dans une liste comme ci-dessus.


Lorsqu'on a un fichier CSV avec des noms de colonne comme dans notre cas, il est intéressant de les utiliser pour manipuler la donnée nommée, plutôt que par position en utilisant une liste simple. On utilise pour cela un `DictReader` au lieu du `reader`. A présent, lorsqu'on itère sur l'objet `DictReader` créé, chaque ligne est un dictionnaire, donc la clé est le nom de la colonne et la valeur la donnée de la cellule. 

Pour illustrer son intérêt, affichons les noms des départements donc le numéro de département est compris entre 20 et 29.

```{python}
with open("departement2021.csv") as file_in:
    dict_reader = csv.DictReader(file_in)
    for row in dict_reader:
        if row["DEP"].startswith("2"):
            print(row["LIBELLE"])
```

Le code est beaucoup plus lisible : on comprend facilement quelles données sont manipulées et de quelle manière.


### Écriture


La syntaxe pour l'écriture est là encore assez proche de celle pour les fichiers texte. La différence est que l'on traite des données en 2D (ligne x colonne), on ne peut donc plus passer seulement une chaîne de caractère à l'écriture, il faut **passer une liste d'éléments**.

```{python}
header = ["nom", "classe", "age"]
row1 = ["Maurice", "5èmeB", 12]
row2 = ["Manuela", "6èmeA", 11]

with open("test.csv", "w") as file_out:
    csv_writer = csv.writer(file_out)
    csv_writer.writerow(header)
    csv_writer.writerow(row1)
    csv_writer.writerow(row2)
```

Vérifions que notre fichier CSV brut ressemble bien à ce que nous attendions.

```{python}
# Commande shell pour afficher le contenu d'un fichier
!cat test.csv
```

### Le *header*


Comme dans un document de type tableur, la première ligne d'un fichier CSV contient généralement les **noms des variables** (colonnes). On appelle cette ligne le ***header***. Cette ligne n'est pas obligatoire en théorie, mais elle est quand même bien pratique pour comprendre rapidement la nature des données qui se trouvent dans un fichier CSV. C'est donc une bonne pratique d'inclure un *header* lorsqu'on génère un fichier CSV.

Nous avons vu dans l'exemple précédent que l'écriture du *header* se faisait comme celle de n'importe quelle autre ligne de donnée. C'est lors de la lecture que les choses se compliquent, puisqu'il faut récupérer le *header* séparément des autres données si le fichier CSV en contient un. Utilisons le CSV généré à l'étape précédente pour illustrer cela.

```{python}
data = []
with open("test.csv", "r") as file_in:
    csv_reader = csv.reader(file_in)
    header = next(csv_reader)
    for row in csv_reader:
        data.append(row)
```

```{python}
print(header)
```

```{python}
print(data)
```

Pour récupérer le *header*, on utilise la fonction `next`. C'est une fonction *built-in* qui va appeler la méthode `__next__` de l'objet `reader`, qui permet d'itérer d'un pas sur le `reader`. Le premier appel à la fonction `next` renvoie donc la première ligne du document. Si un *header* est présent dans le fichier (ce dont il faut s'assurer), l'élément renvoyé est le *header*. On récupère ensuite classiquement le reste des données via une boucle sur l'objet `reader`, que l'on stocke dans une liste de listes (une liste par ligne).


### Importance du délimiteur


Le **délimiteur** correspond au caractère qui est utilisé pour délimiter les valeurs successives d'une ligne dans un fichier CSV.

Le standard CSV utilise &mdash; comme son nom l'indique &mdash; la virgule comme délimiteur, mais cela est modifiable, et **il n'est pas rare de tomber sur des fichiers CSV qui ont un autre délimiteur**. Il faut dans ce cas aller regarder directement dans le texte brut quel est le délimiteur utilisé. On trouve par exemple souvent une délimitation par des `tabs` (le caractère est `\t`), i.e. un nombre d'espaces donné, auquel cas le fichier peut avoir pour extension `.tsv` pour *tab-separated value*. Il faut alors spécifier le délimiteur avec le paramètre `delimiter` lorsqu'on crée le `reader`.

En pratique, comme pour l'encodage d'un fichier texte, **il y a peu de raison valable pour changer de délimiteur**. Même si des virgules apparaissent dans des valeurs du fichier — par exemple, dans une adresse — ces valeurs sont alors entourées par des guillemets, ce qui permet à la séparation des valeurs de se faire correctement dans la grande majorité des cas.


## Manipuler des fichiers JSON


### Les fichiers JSON


Le JSON (*JavaScript Object Notation*) est un format de fichier très populaire pour écrire et échanger de la donnée sous la forme d'une chaîne de caractères unique et lisible par l'humain (*human-readable*) — du moins en théorie. 

Comme son nom le suggère, le JSON est lié au langage *JavaScript* dans la mesure où il constitue un dérivé de la notation des objets dans ce langage. Le format est cependant désormais indépendant de tout langage de programmation, mais est très fréquemment utilisé dans différents langages. 

Le format JSON est particulièrement important pour les statisticiens et data scientists car il constitue le **format quasi-standard de réponse des [API](https://fr.wikipedia.org/wiki/Interface_de_programmation)**. Le dialogue avec les API va au delà du programme de ce cours d'introduction. Cependant, les API tendant à se généraliser comme mode de communication standard pour l'échange de données, il est important de maîtriser les bases du format JSON afin de manipuler les réponses des API lorsqu'on doit interagir avec celles-ci.

Le JSON stockant les objets sous forme de **paires clé-valeur** et où les valeurs peuvent être des ***arrays*** — un concept assez large en informatique qui inclut notamment les listes que nous connaissons — il ressemble fortement aux dictionnaires Python. Il constitue ainsi un format de fichier assez naturel pour ***sérialiser*** ces derniers, c'est à dire passer d'une structure de données en mémoire (ici, un dictionnaire) à une séquence d'octets qui peut être universellement lue par tout ordinateur. Regardons à titre d'exemple la représentation JSON d'un dictionnaire Python.

```{python}
cv = {
    "marc": {"poste": "manager", "experience": 7, "hobbies": ["couture", "frisbee"]},
    "miranda": {"poste": "ingénieure", "experience": 5, "hobbies": ["trekking"]}
}

print(cv)
```

```{python}
import json

print(json.dumps(cv))
```

On le voit : la représentation JSON est assez proche de celle du dictionnaire Python, avec **quelques particularités**. Dans ce cas par exemple, les caractères spéciaux comme les accents sont automatiquement encodés en *Unicode*.


### Le module `json`


Le module `json` gère l'import de fichiers JSON et l'export d'objets Python au format JSON. Il s'occupe notamment de gérer les contraintes de conversion en JSON évoquées précédemment, comme celle des accents. 

En particulier, **le JSON peut stocker la majorité des types d'objets *built-in* de Python** que nous avons vus jusqu'à présent (*strings*, valeurs numériques, Booléens, listes, dictionnaires, `NoneType`) et bien d'autres, mais il ne peut pas représenter des objets Python créés manuellement via des classes par exemple.


### Écriture


Commençons cette fois par l'écriture. Comme nous l'avons vu dans l'exemple précédent, la fonction `dumps` (pour *dump string*) convertit une valeur Python **sérialisable** en sa représentation JSON sous forme de chaîne de caractères.

```{python}
x = "test"
json.dumps(x)
```

```{python}
x = [1, 2, 3]
json.dumps(x)
```

Ecrire un fichier JSON à partir de Python revient simplement à écrire cette représentation dans un fichier texte, auquel on donnera l'extension `.json` pour bien marquer qu'il s'agit d'un fichier texte particulier. Comme cette opération est très fréquente, il existe une fonction très proche, `dump`, qui effectue à la fois la conversion et l'écriture.

```{python}
with open("cv.json", "w") as file_out:
    json.dump(cv, file_out)
```

```{python}
!cat cv.json
```

En une seule opération, on a sérialisé un dictionnaire Python (l'objet `cv`) dans un fichier JSON.


### Lecture


Le module `json` propose les fonctions `load` et `loads`, qui réalisent respectivement les opérations opposées des fonctions `dump` et `dumps` :

- la fonction `load` permet d'importer du contenu JSON présent dans un fichier texte et de le convertir en un dictionnaire

- la fonction `loads` permet de convertir du contenu JSON présent dans une chaîne de caractères en un dictionnaire


Reprenons le CV que nous avons sérialisé précédemment au format JSON pour illustrer la lecture à partir d'un fichier.

```{python}
with open("cv.json", "r") as file_in:
    data = json.load(file_in)
    
data
```

Nous allons illustrer la lecture de contenu JSON à partir d'une chaîne de caractères à partir d'un exemple réaliste : celui du requêtage d'une API. Pour l'exemple, nous allons requêter la Base Adresse Nationale (BAN), qui permet de géolocaliser n'importe quelle adresse nationale.

Le requêtage d'API en Python se fait très simplement grâce à la librairie `requests`. Regardons par exemple comment l'on peut récupérer en seulement deux lignes de code les informations géographiques sur toutes les voies qui contiennent le nom "comédie" en France.

```{python}
import requests
```

```{python}
response = requests.get("https://api-adresse.data.gouv.fr/search/?q=comedie&type=street")
r_text = response.text
print(r_text[:150])
```

L'API nous renvoie une réponse, dont on extrait le contenu textuel. Comme pour la très grande majorité des API, ce contenu est du JSON. On peut alors l'importer dans un dictionnaire Python via la fonction `loads` (pour *load string*) pour pouvoir manipuler la donnée qu'il contient.

```{python}
r_dict = json.loads(r_text)
```

```{python}
r_dict.keys()
```

```{python}
type(r_dict["features"])
```

Les résultats qui nous intéressent sont contenues dans la valeur du dictionnaire associée à la clé `features`, qui est une liste de dictionnaires, un par résultat.

```{python}
r_dict["features"][0]
```

```{python}
r_dict["features"][1]
```

## Exercices

### Questions de compréhension



- 1/ Qu'est ce qu'un fichier CSV ?

- 2/ Quel sont les avantages du format CSV ?

- 3/ Pourquoi utilise-t-on le module `csv` pour lire et écrire des fichiers CSV ?

- 4/ Les données d'un fichier CSV sont-elles forcément séparées par des virgules ?

- 5/ Qu'est-ce que le *header* d'un fichier CSV ? Existe-t-il nécessairement ?

- 6/ Pourquoi le format JSON est très utilisé dans la manipulation de données ?

- 7/ A quel objet Python ressemble du contenu au format JSON ?

- 8/ Quels types d'objets Python peuvent être convertis en JSON ?

- 9/ Qu'est ce que la sérialisation d'un objet Python ?

- 10/ Quel est le principal point commun entre les fichiers CSV et les fichiers JSON ?

- 11/ Un fichier dont l'extension est .json contient-il nécessairement du JSON ?

<details>
<summary>Afficher la solution</summary>

- 1/ Un CSV est un fichier texte qui représente l'information brute d'un document type tableur. Chaque ligne du fichier représente une ligne du tableur, et les cellules d'une ligne sont séparées par des virgules. La première ligne peut contenir un `header` (en-tête), c'est à dire le nom des colonnes, mais ce n'est pas toujours le cas.

- 2/ Simplicité de lecture et d'édition, universalité.

- 3/ Même si le format CSV est très simple, il présente certaines caractéristiques (délimiteur, caractère de fin de ligne, etc.) dont il faut tenir compte lorsqu'on lit ou édite du CSV. Le module csv fournit des fonctions qui tiennent compte de ces particularités.

- 4/ Non, on peut en théorie séparer les données par n'importe quel caractère ou suite de caractères. En pratique, il faut suivre la convention dans la majorité des cas, qui est d'utiliser une virgule.

- 5/ C'est la première ligne du fichier CSV, qui contient normalement les noms de variables, mais ce n'est pas toujours le cas.

- 6/ C'est le format majoritaire de réponse des API, qui sont très utilisées pour la diffusion et l'échange de données.

- 7/ Aux dictionnaires.

- 8/ Tous les objets dits sérialisables, ce qui inclut la plupart des objets de base que l'on a vus, mais pas les objets créés manuellement via des classes.

- 9/ La sérialisation d'un objet Python (sérialisable) consiste à convertir la donnée contenue dans cet objet en une séquence d'octets, c'est à dire en un message qui peut être compris par n'importe quel ordinateur.

- 10/ Ce sont des fichiers texte. 

- 11/ Non, les fichiers JSON comme les fichiers CSV sont des fichiers texte. L'extension est une convention qui permet dans la grande majorité des cas de savoir ce que contient le fichier, mais elle ne peut pas le garantir.

</details>

### Trier les clés lors de l'écriture d'un JSON


La cellule suivante contient un dictionnaire. Le but de l'exercice est d'écrire ces données dans un fichier JSON, en triant les clés du dictionnaire par ordre alphabétique.

Indice : la fonction `dump` du module `json` contient un paramètre permettant de trier les clés. Lisez la [documentation de la fonction](https://docs.python.org/fr/3/library/json.html#json.dump) pour le déterminer.

```{python}
data = {"id": 1, "nom": "Isidore", "age": 29}
```

```{python}
# Testez votre réponse dans cette cellule

```

<details>
<summary>Afficher la solution</summary>

```python
import json

data = {"id": 1, "nom": "Isidore", "age": 29}

with open("data_sorted.json", "w") as file_out:
    json.dump(data, file_out, sort_keys=True)
```

</details>

### Convertir un objet non-sérialisable en JSON


Nous avons vu que les objets que l'on crée manuellement via des classes ne sont généralement pas sérialisables. La cellule suivante en montre un exemple avec notre objet `Citron` utilisé dans le tutoriel sur la POO. Essayer de convertir directement l'objet en JSON renvoie une erreur.

Vous devez modifier le code suivant afin de pouvoir sérialiser l'objet. Pour cela, vous devez : 

- convertir l'instance `mon_citron` en utilisant la méthode *built-in* `__dict__` que possèdent tous les objets Python

- convertir le dictionnaire obtenu en JSON sous forme de chaîne de caractères

```{python}
import json

class Citron:

    def __init__(self, couleur, qte_jus):
        self.saveur = "acide"
        self.couleur = couleur
        self.jus = qte_jus
        
mon_citron = Citron(couleur="jaune", qte_jus=45)
json.dumps(mon_citron)
```

```{python}
# Testez votre réponse dans cette cellule

```

<details>
<summary>Afficher la solution</summary>

```python
import json

class Citron:

    def __init__(self, couleur, qte_jus):
        self.saveur = "acide"
        self.couleur = couleur
        self.jus = qte_jus
        
mon_citron = Citron(couleur="jaune", qte_jus=45)
mon_citron_dict = mon_citron.__dict__

json.dumps(mon_citron_dict)
```

</details>

### Changer le délimiteur d'un fichier CSV


Votre répertoire courant contient le fichier `nat2020.csv`. Il s'agit du fichier des prénoms diffusé par l'Insee : il contient des données sur les prénoms attribués aux enfants nés en France entre 1900 et 2020. 

Problème : contrairement au standard CSV, le délimiteur utilisé n'est pas la virgule. Vous devez donc :

- trouver le séparateur utilisé (via l'éditeur de texte Jupyter, via une commande shell, en testant avec le module `csv` en Python..) pour lire correctement le fichier

- générer un nouveau fichier CSV `nat2020_corr.csv` contenant les mêmes données, mais cette fois avec la virgule comme séparateur.

```{python}
# Testez votre réponse dans cette cellule

```

<details>
<summary>Afficher la solution</summary>

```python
# Trouvons à l'aide d'une commande shell le séparateur utilisé
!head -n 3 nat2020.csv

with open('nat2020.csv', 'r') as file_in:
    # Lecture du fichier CSV existant
    reader = csv.reader(file_in, delimiter=';')
    with open('nat2020_corr.csv', 'w') as file_out:
        # Ecriture dans le nouveau fichier CSV
        writer = csv.writer(file_out)  # Par défaut, le délimiteur est la virgule
        for row in reader:
            writer.writerow(row)
            
# Vérification à l'aide d'une commande shell
!head -n 3 nat2020_corr.csv
```

</details>

### Extraire et sauvegarder des données issues d'une API


L'exercice consiste à effectuer une requête à l'API de la Base Adresse Nationale, et sauvegarder les résultats dans un fichier CSV. Voici les étapes à implémenter :

- effectuer une requête de nom de rue avec un mot clé comme dans le tutoriel (si vous souhaitez faire une requête plus complexe, vous pouvez regarder la [documentation de l'API](https://adresse.data.gouv.fr/api-doc/adresse)) et stocker les résultats dans un dictionnaire

- créer un fichier CSV `resultats_ban.csv` dans lequel on va stocker les informations suivantes : 'nom', 'ville', 'code_commune', 'longitude', 'latitude'

- à l'aide d'un objet `writer` et d'une boucle sur les résultats renvoyés par l'API, écrivez chaque ligne dans le CSV

Par exemple, pour la requête de voie contenant le mot "comedie", voici le CSV à obtenir :

```
nom,ville,code_commune,longitude,latitude
Rue de la Vieille Comedie,Lille,59350,3.063832,50.635192
Place de la Comédie,Montpellier,34172,3.879638,43.608525
Rue de la Comédie,Cherbourg-en-Cotentin,50129,-1.629732,49.641574
Allee de la Comedie,Villeneuve-d'Ascq,59009,3.162808,50.64628
Rue de l’Ancienne Comedie,Poitiers,86194,0.342649,46.580457
```

```{python}
# Testez votre réponse dans cette cellule

```

<details>
<summary>Afficher la solution</summary>

```python
response = requests.get("https://api-adresse.data.gouv.fr/search/?q=comedie&type=street")
r_text = response.text
r_dict = json.loads(r_text)

with open('resultats_ban.csv', 'w') as file_out:
    header = ['nom', 'ville', 'code_commune', 'longitude', 'latitude']
    csv_writer = csv.writer(file_out)
    csv_writer.writerow(header)
    for result in r_dict['features']:
        nom = result['properties']['name']
        commune = result['properties']['city']
        code_commune = result['properties']['citycode']
        long, lat = result['geometry']['coordinates']
        row = [nom, commune, code_commune, long, lat]
        csv_writer.writerow(row)
```

</details>

### Découper la base des départements par régions


L'objectif de cet exercice est de découper le fichier CSV des départements que nous avons utilisé dans le tutoriel en plusieurs petits CSV, un par région. Ce type d'opération peut être utile par exemple lorsqu'on travaille avec un fichier de très grande taille, qui ne passe pas en mémoire ; le découper en plusieurs fichiers que l'on traite indépendamment, lorsque cela est possible, permet de réduire la volumétrie.

Voici la liste des opérations à effectuer : 

- créer un dossier `dep` dans le répertoire courant à l'aide du module `pathlib` (cf. tutoriel précédent)

- avec un objet `reader` du module `csv`, faire une boucle sur les lignes du fichier CSV des départements. Attention à ne pas inclure le *header*, en utilisant la fonction `next` pour passer la première ligne. Pour chaque ligne suivante : 

    - récupérer le code région (variable `REG`)

    - générer le chemin du fichier CSV `dep/{REG}.csv` où {REG} est à remplacer par le code région de la ligne

    - ouvrir ce fichier CSV en mode `append` pour écrire la ligne à la fin du fichier

```{python}
# Testez votre réponse dans cette cellule

```

<details>
<summary>Afficher la solution</summary>

```python
from pathlib import Path

path_dep = Path("dep/")
path_dep.mkdir(exist_ok=True)

with open('departement2021.csv', 'r') as file_in:
    csv_reader = csv.reader(file_in)
    next(csv_reader)  # Passe le header
    for row in csv_reader:
        reg = row[1]
        filename = reg + '.csv'
        path_reg_file = path_dep / filename  # Chemin du fichier csv region
        with open(path_reg_file, 'a') as file_reg_in:
                writer = csv.writer(file_reg_in)
                writer.writerow(row)
```

</details>

### Rajouter des *headers* manquants


Dans l'exercice précédent, nous avons découpé le fichier CSV des départements français en plusieurs fichiers CSV, un par région. Mais nous n'avons pas inclus dans les différents fichiers le *header*, i.e. la première ligne qui contient les noms de colonnes. On va donc l'ajouter manuellement à chacun des fichiers CSV créés lors de l'exercice précédent.

Voici la liste des opérations à effectuer :

- lire le fichier des départements complet et récupérer le `header` dans une liste avec la fonction `next`

- enregistrer dans une liste les chemins des différents fichiers CSV contenus dans le dossier `dep` avec la méthode `glob` de `pathlib` (cf. tutoriel précédent)

- pour chaque chemin :

    - ouvrir le fichier CSV déjà existant, et récupérer les données sous forme d'une liste de listes (une liste par ligne)

    - ouvrir le fichier CSV en écriture pour le réinitialiser, écrire le header en premier lieu, puis écrire les données que l'on a au préalable sauvegardées dans une liste de liste

```{python}
# Testez votre réponse dans cette cellule

```

<details>
<summary>Afficher la solution</summary>

```python
from pathlib import Path

with open('departement2021.csv', 'r') as file_in:
    csv_reader = csv.reader(file_in)
    header = next(csv_reader)

dep_files_paths = list(Path("dep/").glob('*.csv'))

for path in dep_files_paths:
    # Lecture du fichier existant, dont on stocke les lignes dans une liste
    with open(path, 'r') as file_dep_in:
        reader = csv.reader(file_dep_in)
        dep_rows = []
        for row in reader:
            dep_rows.append(row)
    # On réécrit le fichier de sortie, en rajoutant au préalable le header
    with open(path, 'w') as file_dep_out:
        writer = csv.writer(file_dep_out)
        writer.writerow(header)
        for row in dep_rows:
            writer.writerow(row)
```

</details>

:::










::: {.content-visible when-profile="en"}

# Working with CSV and JSON files

In the previous tutorial, we learned how to use functions from modules and how to read and write text files. In this tutorial, we will leverage these new skills by focusing on **two types of text files commonly used for storing and sharing data: CSV and JSON files**. We will learn to handle these two types of files using Python modules dedicated to their respective processing: **the `csv` module and the `json` module**.

## Handling CSV files

### CSV files

CSV stands for ***comma-separated values***. CSV files aim to reproduce the **structure of data from spreadsheet software** like Microsoft Excel or LibreOffice Calc, reduced to strictly textual data (no formatting, no column types, etc.).

We will use the CSV file containing the list of departments in 2021 from the Official Geographic Code (COG) as an example. Let's look at the first few lines of this file using a `shell` command to keep in mind the structure of such a file.

```{python}
!head -n 5 departement2021.csv
```

In analogy with a spreadsheet file, each line of the file represents a row in the spreadsheet, and the cells in a row are separated by commas. The first line may contain a `header`, i.e., the column names, but this is not always the case.

The main advantages of CSV files are:

- their **simplicity**: they contain raw textual data, so they are very lightweight and can be easily edited using any text editor or programming language
- their **universality**: they are widely used as a standard format for data exchange

### The `csv` module

Since the data in a CSV file is textual, one might wonder why a particular module is needed to manipulate them and why the tools we saw in the previous tutorial would not suffice. The main reason is that CSV files have some subtleties and standards, often invisible to the user, but very important in practice. For example: if we want to separate different data with commas, what happens if the text data itself contains commas?

This is why we use the **`csv` module** to interact with such files, leveraging the fact that others have already considered these questions, thus avoiding reinventing the wheel every time we import a CSV file.

In practice, we tend to handle this type of data in the form of DataFrames (like in `R`) to take advantage of their **tabular structure**. We will study the ***`Pandas` package***, which allows us to do this in Python in a future tutorial. However, it is always useful to know how to handle CSV data as textual data and, thus, know the `csv` module.

### Reading

```{python}
import csv
```

The syntax for reading and manipulating CSV files in Python is very similar to that for simple text files. The only difference is that you must create a `reader` object from the file object to iterate over the lines.

```{python}
rows = []

with open("departement2021.csv") as file_in:
    csv_reader = csv.reader(file_in)
    for row in csv_reader:
        rows.append(row)

rows[:4]
```

The syntax is the same as for simple text files: once the `reader` is created, you can iterate over the lines and perform operations with them, such as storing them in a list as shown above.

When you have a CSV file with column names like in our case, it is useful to use them to manipulate named data rather than by position using a simple list. To do this, use a `DictReader` instead of a `reader`. Now, when iterating over the `DictReader` object, each line is a dictionary, with the key being the column name and the value being the cell data.

To illustrate its usefulness, display the names of departments whose department number is between 20 and 29.

```{python}
with open("departement2021.csv") as file_in:
    dict_reader = csv.DictReader(file_in)
    for row in dict_reader:
        if row["DEP"].startswith("2"):
            print(row["LIBELLE"])
```

The code is much more readable: you can easily understand which data is being manipulated and how.

### Writing

The syntax for writing is again quite similar to that for text files. The difference is that you are dealing with 2D data (row x column), so you cannot just pass a string to write, but **pass a list of elements**.

```{python}
header = ["name", "class", "age"]
row1 = ["Maurice", "5thB", 12]
row2 = ["Manuela", "6thA", 11]

with open("test.csv", "w") as file_out:
    csv_writer = csv.writer(file_out)
    csv_writer.writerow(header)
    csv_writer.writerow(row1)
    csv_writer.writerow(row2)
```

Let's check that our raw CSV file looks as expected.

```{python}
# Shell command to display the content of a file
!cat test.csv
```

### The header

Like in a spreadsheet document, the first line of a CSV file usually contains the **variable names** (columns). This line is called the ***header***. This line is not mandatory in theory, but it is quite handy for quickly understanding the nature of the data in a CSV file. Therefore, it is good practice to include a header when generating a CSV file.

We saw in the previous example that writing the header is done like writing any other data row. It's during reading that things get complicated because you need to retrieve the header separately from the other data if the CSV file contains one. Let's use the CSV generated in the previous step to illustrate this.

```{python}
data = []
with open("test.csv", "r") as file_in:
    csv_reader = csv.reader(file_in)
    header = next(csv_reader)
    for row in csv_reader:
        data.append(row)
```

```{python}
print(header)
```

```{python}
print(data)
```

To retrieve the header, use the `next` function. It is a *built-in* function that calls the `__next__` method of the `reader` object, allowing it to iterate one step forward on the `reader`. The first call to the `next` function returns the first line of the document. If a header is present in the file (which must be ensured), the returned element is the header. Then, you typically retrieve the rest of the data via a loop on the `reader` object, storing it in a list of lists (one list per line).

### Importance of the delimiter

The **delimiter** is the character used to separate successive values in a line in a CSV file.

The CSV standard uses — as its name suggests — the comma as the delimiter, but this can be modified, and **it is not uncommon to encounter CSV files that have a different delimiter**. In such a case, look directly at the raw text to see the delimiter used. For example, you often find tab-separated values (the character is `\t`), i.e., a given number of spaces, and the file may have the extension `.tsv` for *tab-separated value*. In this case, specify the delimiter with the `delimiter` parameter when creating the `reader`.

In practice, like text file encoding, **there is little valid reason to change the delimiter**. Even if commas appear in file values — for example, in an address — these values are then enclosed in quotes, allowing the separation of values to be done correctly in most cases.

## Handling JSON files

### JSON files

JSON (*JavaScript Object Notation*) is a very popular file format for writing and exchanging data in the form of a single, human-readable string — at least in theory.

As its name suggests, JSON is linked to the *JavaScript* language, as it is derived from the notation of objects in that language. However, the format is now independent of any programming language but is widely used in various languages.

The JSON format is particularly important for statisticians and data scientists because it is the **quasi-standard response format for [APIs](https://en.wikipedia.org/wiki/Application_programming_interface)**. Interacting with APIs goes beyond this introductory course's scope. However, as APIs are becoming the standard mode of communication for data exchange, it is essential to master the basics of the JSON format to handle API responses when interacting with them.

Since JSON stores objects as **key-value pairs** and the values can be ***arrays*** — a broad concept in computing that includes lists we know — it closely resembles Python dictionaries. Thus, it is a natural file format for ***serializing*** them, i.e., converting a data structure in memory (here, a dictionary) to a byte sequence that any computer can read. Let's look at the JSON representation of a Python dictionary as an example.

```{python}
cv = {
    "marc": {"position": "manager", "experience": 7, "hobbies": ["sewing", "frisbee"]},
    "miranda": {"position": "engineer", "experience": 5, "hobbies": ["trekking"]}
}

print(cv)
```

```{python}
import json

print(json.dumps(cv))
```

You can see that the JSON representation is quite similar to the Python dictionary, with **a few peculiarities**. In this case, for example, special characters like accents are automatically encoded in *Unicode*.

### The `json` module

The `json` module handles importing JSON files and exporting Python objects to JSON format. It takes care of handling the conversion constraints to JSON mentioned earlier, such as accents.

In particular, **JSON can store most of the *built-in* Python object types** we have seen so far (*strings*, numeric values, Booleans, lists, dictionaries, `NoneType`) and many others, but it cannot represent manually created Python objects via classes.

### Writing

Let's start with writing. As we saw in the previous example, the `dumps` function (for *dump string*) converts a **serializable** Python value to its JSON representation as a string.

```{python}
x = "test"
json.dumps(x)
```

```{python}
x = [1, 2, 3]
json.dumps(x)
```

Writing a JSON file from Python simply means writing this representation into a text file, which we will give the `.json` extension to clearly indicate that it is a particular text file. As this operation is very common, there is a similar function, `dump`, which performs both conversion and writing.

```{python}
with open("cv.json", "w") as file_out:
    json.dump(cv, file_out)
```

```{python}
!cat cv.json
```

In a single operation, we serialized a Python dictionary (the `cv` object) into a JSON file.

### Reading

The `json` module provides the `load` and `loads` functions, which respectively perform the opposite operations of the `dump` and `dumps` functions:

- The `load` function imports JSON content from a text file and converts it into a dictionary.
- The `loads` function converts JSON content from a string into a dictionary.

Let's reuse the CV we serialized earlier into JSON format to illustrate reading from a file.

```{python}
with open("cv.json", "r") as file_in:
    data = json.load(file_in)
    
data
```

We will illustrate reading JSON content from a string with a realistic example: querying an API. For example, we will query the National Address Base (BAN), which allows geolocating any national address.

Querying an API in Python is straightforward with the `requests` library. Let's see how we can retrieve geographical information about all streets that contain the name "comedie" in France in just two lines of code.

```{python}
import requests
```

```{python}
response = requests.get("https://api-adresse.data.gouv.fr/search/?q=comedie&type=street")
r_text = response.text
print(r_text[:150])
```

The API sends us a response, from which we extract the textual content. As with most APIs, this content is JSON. We can then import it into a Python dictionary using the `loads` function (for *load string*) to manipulate the data it contains.

```{python}
r_dict = json.loads(r_text)
```

```{python}
r_dict.keys()
```

```{python}
type(r_dict["features"])
```

The results we are interested in are contained in the dictionary value associated with the `features` key, which is a list of dictionaries, one per result.

```{python}
r_dict["features"][0]
```

```{python}
r_dict["features"][1]
```

## Exercises

### Questions of understanding

- 1/ What is a CSV file?
- 2/ What are the advantages of the CSV format?
- 3/ Why do we use the `csv` module to read and write CSV files?
- 4/ Are the data in a CSV file always separated by commas?
- 5/ What is the header of a CSV file? Does it necessarily exist?
- 6/ Why is the JSON format widely used in data manipulation?
- 7/ What Python object does JSON content resemble?
- 8/ What types of Python objects can be converted to JSON?
- 9/ What is the serialization of a Python object?
- 10/ What is the main similarity between CSV and JSON files?
- 11/ Does a file with a .json extension necessarily contain JSON?

<details>
<summary>Show solution</summary>

- 1/ A CSV is a text file that represents the raw data of a spreadsheet-like document. Each line of the file represents a row in the spreadsheet, and the cells in a row are separated by commas. The first line may contain a `header` (column names), but this is not always the case.
- 2/ Simplicity of reading and editing, universality.
- 3/ Even though the CSV format is very simple, it has some characteristics (delimiter, end-of-line character, etc.) that need to be considered when reading or editing CSV. The csv module provides functions that account for these peculiarities.
- 4/ No, data can theoretically be separated by any character or sequence of characters. In practice, follow the convention in most cases, which is to use a comma.
- 5/ It is the first line of the CSV file, which usually contains the variable names, but this is not always the case.
- 6/ It is the primary response format for APIs, which are widely used for data dissemination and exchange.
- 7/ Dictionaries.
- 8/ All serializable objects, which include most of the basic objects we have seen, but not manually created objects via classes.
- 9/ The serialization of a (serializable) Python object is converting the data contained in that object into a byte sequence, i.e., a message that any computer can understand.
- 10/ They are text files.
- 11/ No, JSON files like CSV files are text files. The extension is a convention that allows, in most cases, knowing what the file contains, but it cannot guarantee it.

</details>

### Sort the keys when writing a JSON

The following cell contains a dictionary. The goal of the exercise is to write this data to a JSON file, sorting the dictionary keys alphabetically.

Hint: The `dump` function of the `json` module contains a parameter that allows sorting the keys. Read the [function documentation](https://docs.python.org/3/library/json.html#json.dump) to determine it.

```{python}
data = {"id": 1, "name": "Isidore", "age": 29}
```

```{python}
# Test your answer in this cell
```

<details>
<summary>Show solution</summary>

```{python}
import json

data = {"id": 1, "name": "Isidore", "age": 29}

with open("data_sorted.json", "w") as file_out:
    json.dump(data, file_out, sort_keys=True)
```

</details>

### Convert a non-serializable object to JSON

We have seen that manually created objects via classes are generally not serializable. The following cell shows an example with our `Citron` object used in the OOP tutorial. Trying to convert the object directly to JSON returns an error.

You must modify the following code to serialize the object. To do this, you must:

- Convert the `mon_citron` instance using the *built-in* `__dict__` method that all Python objects have.
- Convert the obtained dictionary to JSON as a string.

```{python}
import json

class Citron:

    def __init__(self, color, juice_qty):
        self.flavor = "acidic"
        self.color = color
        self.juice = juice_qty
        
mon_citron = Citron(color="yellow", juice_qty=45)
json.dumps(mon_citron)
```

```{python}
# Test your answer in this cell
```

<details>
<summary>Show solution</summary>

```{python}
import json

class Citron:

    def __init__(self, color, juice_qty):
        self.flavor = "acidic"
        self.color = color
        self.juice = juice_qty
        
mon_citron = Citron(color="yellow", juice_qty=45)
mon_citron_dict = mon_citron.__dict__

json.dumps(mon_citron_dict)
```

</details>

### Change the delimiter of a CSV file

Your current directory contains the file `nat2020.csv`. It is the file of first names published by Insee, containing data on the first names given to children born in France between 1900 and 2020.

Problem: Contrary to the CSV standard, the delimiter used is not a comma. You must:

- Find the delimiter used (via the Jupyter text editor, a shell command, or by testing with the `csv` module in Python) to read the file correctly.
- Generate a new CSV file `nat2020_corr.csv` containing the same data, but this time with a comma as the separator.

```{python}
# Test your answer in this cell
```

<details>
<summary>Show solution</summary>

```{python}
# Let's find the delimiter used with a shell command
!head -n 3 nat2020.csv

with open('nat2020.csv', 'r') as file_in:
    # Read the existing CSV file
    reader = csv.reader(file_in, delimiter=';')
    with open('nat2020_corr.csv', 'w') as file_out:
        # Write to the new CSV file
        writer = csv.writer(file_out)  # By default, the delimiter is a comma
        for row in reader:
            writer.writerow(row)
            
# Verify with a shell command
!head -n 3 nat2020_corr.csv
```

</details>

### Extract and save data from an API

The exercise is to make a request to the National Address Base API and save the results in a CSV file. Here are the steps to implement:

- Make a street name request with a keyword like in the tutorial (if you want to make a more complex request, you can check the [API documentation](https://adresse.data.gouv.fr/api-doc/adresse)) and store the results in a dictionary.
- Create a CSV file `resultats_ban.csv` in which we will store the following information: 'name', 'city', 'city_code', 'longitude', 'latitude'.
- Using a `writer` object and a loop on the results returned by the API, write each line to the CSV.

For example, for the query of streets containing the word "comédie", here is the CSV to obtain:

```
name,city,city_code,longitude,latitude
Rue de la Vieille Comedie,Lille,59350,3.063832,50.635192
Place de la Comédie,Montpellier,34172,3.879638,43.608525
Rue de la Comédie,Cherbourg-en-Cotentin,50129,-1.629732,49.641574
Allee de la Comedie,Villeneuve-d'Ascq,59009,3.162808,50.64628
Rue de l’Ancienne Comedie,Poitiers,86194,0.342649,46.580457
```


```{python}
# Test your answer in this cell
```

<details>
<summary>Show solution</summary>

```{python}
response = requests.get("https://api-adresse.data.gouv.fr/search/?q=comedie&type=street")
r_text = response.text
r_dict = json.loads(r_text)

with open('resultats_ban.csv', 'w') as file_out:
    header = ['name', 'city', 'city_code', 'longitude', 'latitude']
    csv_writer = csv.writer(file_out)
    csv_writer.writerow(header)
    for result in r_dict['features']:
        name = result['properties']['name']
        city = result['properties']['city']
        city_code = result['properties']['citycode']
        long, lat = result['geometry']['coordinates']
        row = [name, city, city_code, long, lat]
        csv_writer.writerow(row)
```

</details>

### Split the department base by regions

The goal of this exercise is to split the CSV file of French departments used in the tutorial into several small CSV files, one per region. This type of operation can be useful, for example, when working with a very large file that does not fit in memory; splitting it into several files to process independently, when possible, reduces the volume.

Here are the operations to perform:

- Create a `dep` folder in the current directory using the `pathlib` module (cf. previous tutorial).
- With a `csv` module reader object, loop through the lines of the department CSV file. Be careful not to include the header, using the `next` function to skip the first line. For each following line:
    - Retrieve the region code (variable `REG`).
    - Generate the path of the CSV file `dep/{REG}.csv` where {REG} is to be replaced by the region code of the line.
    - Open this CSV file in `append` mode to write the line at the end of the file.

```{python}
# Test your answer in this cell
```

<details>
<summary>Show solution</summary>

```{python}
from pathlib import Path

path_dep = Path("dep/")
path_dep.mkdir(exist_ok=True)

with open('departement2021.csv', 'r') as file_in:
    csv_reader = csv.reader(file_in)
    next(csv_reader)  # Skip the header
    for row in csv_reader:
        reg = row[1]
        filename = reg + '.csv'
        path_reg_file = path_dep / filename  # Path of the region csv file
        with open(path_reg_file, 'a') as file_reg_in:
                writer = csv.writer(file_reg_in)
                writer.writerow(row)
```

</details>

### Add missing headers

In the previous exercise, we split the CSV file of French departments into several CSV files, one per region. However, we did not include the header in the different files, i.e., the first line containing the column names. We will add it manually to each of the CSV files created in the previous exercise.

Here are the operations to perform:

- Read the complete department file and retrieve the `header` in a list with the `next` function.
- Record in a list the paths of the different CSV files contained in the `dep` folder using the `glob` method of `pathlib` (cf. previous tutorial).
- For each path:
    - Open the existing CSV file and retrieve the data as a list of lists (one list per line).
    - Open the CSV file in write mode to reset it, write the header first, and then write the data previously saved in a list of lists.

```{python}
# Test your answer in this cell
```

<details>
<summary>Show solution</summary>

```{python}
from pathlib import Path

with open('departement2021.csv', 'r') as file_in:
    csv_reader = csv.reader(file_in)
    header = next(csv_reader)

dep_files_paths = list(Path("dep/").glob('*.csv'))

for path in dep_files_paths:
    # Read the existing file, storing the lines in a list
    with open(path, 'r') as file_dep_in:
        reader = csv.reader(file_dep_in)
        dep_rows = []
        for row in reader:
            dep_rows.append(row)
    # Rewrite the output file, adding the header first
    with open(path, 'w') as file_dep_out:
        writer = csv.writer(file_dep_out)
        writer.writerow(header)
        for row in dep_rows:
            writer.writerow(row)
```

</details>


:::